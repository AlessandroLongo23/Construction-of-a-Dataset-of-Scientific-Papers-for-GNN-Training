{
    "key": "doc",
    "block_type": "document",
    "children": [
        {
            "leaf id": 0,
            "key": "doc/tit",
            "block type": "title",
            "content": "The Power of the Noisy Channel: Unsupervised EndtoEnd TaskOriented Dialogue with LLMs",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "0.0",
                    "matching_string": "The Power of the Noisy Channel: Unsupervised EndtoEnd TaskOriented "
                },
                {
                    "pdf_id": "0.1",
                    "matching_string": "Dialogue with LLMs"
                }
            ]
        },
        {
            "leaf id": 1,
            "key": "doc/aut0",
            "block type": "author",
            "content": "{Brendan King, Jeffrey Flanigan University of California, Santa Cruz {bking2,jmflanig}@ucsc.edu}",
            "leftover": "{du}",
            "matches": [
                {
                    "pdf_id": "0.3",
                    "matching_string": "University of California, Santa Cruz "
                },
                {
                    "pdf_id": "0.4",
                    "matching_string": "{bking2,jmflanig}@ucsc.e"
                },
                {
                    "pdf_id": "0.2",
                    "matching_string": "Brendan King, Jeffrey Flanigan "
                }
            ]
        },
        {
            "leaf id": 2,
            "key": "doc/abs",
            "block type": "abstract",
            "content": "Training taskoriented dialogue systems typically requires turnlevel annotations for interacting with their APIs: e.g. a dialogue state and the system actions taken at each step. These annotations can be costly to produce, errorprone, and require both domain and annotation expertise. With advances in LLMs, we hypothesize unlabelled data and a schema definition are sufficient for building a working taskoriented dialogue system, completely unsupervised. Using only (1) a welldefined API schema (2) a set of unlabelled dialogues between a user and agent, we develop a novel approach for inferring turnlevel annotations as latent variables using a noisy channel model. We iteratively improve these pseudolabels with expectationmaximization (EM), and use the inferred labels to train an endtoend dialogue agent. Evaluating our approach on the MultiWOZ benchmark, our method more than doubles the dialogue success rate of a strong GPT3.5 baseline.Our code will be available at https://github.com/jlabnlp/nclatenttod",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "0.39",
                    "matching_string": "requires turnlevel annotations for interacting "
                },
                {
                    "pdf_id": "0.43",
                    "matching_string": "and require both domain and annotation expertise. "
                },
                {
                    "pdf_id": "0.45",
                    "matching_string": "unlabelled data and a schema definition are "
                },
                {
                    "pdf_id": "0.48",
                    "matching_string": "only (1) a welldefined API schema (2) a "
                },
                {
                    "pdf_id": "0.49",
                    "matching_string": "set of unlabelled dialogues between a user and "
                },
                {
                    "pdf_id": "0.50",
                    "matching_string": "agent, we develop a novel approach for inferring "
                },
                {
                    "pdf_id": "0.52",
                    "matching_string": "using a noisy channel model. We iteratively "
                },
                {
                    "pdf_id": "0.53",
                    "matching_string": "improve these pseudolabels with expectationmaximization "
                },
                {
                    "pdf_id": "0.55",
                    "matching_string": "to train an endtoend dialogue agent. Evaluating "
                },
                {
                    "pdf_id": "0.57",
                    "matching_string": "our method more than doubles the dialogue success "
                },
                {
                    "pdf_id": "0.38",
                    "matching_string": "Training taskoriented dialogue systems typically "
                },
                {
                    "pdf_id": "0.42",
                    "matching_string": "can be costly to produce, errorprone, "
                },
                {
                    "pdf_id": "0.46",
                    "matching_string": "sufficient for building a working taskoriented "
                },
                {
                    "pdf_id": "0.47",
                    "matching_string": "dialogue system, completely unsupervised. Using "
                },
                {
                    "pdf_id": "0.44",
                    "matching_string": "With advances in LLMs, we hypothesize "
                },
                {
                    "pdf_id": "0.54",
                    "matching_string": "(EM), and use the inferred labels "
                },
                {
                    "pdf_id": "0.56",
                    "matching_string": "our approach on the MultiWOZ benchmark, "
                },
                {
                    "pdf_id": "0.58",
                    "matching_string": "rate of a strong GPT3.5 baseline.O"
                },
                {
                    "pdf_id": "0.76",
                    "matching_string": "code will be available at https://github.com/j"
                },
                {
                    "pdf_id": "0.40",
                    "matching_string": "with their APIs: e.g. a dialogue state and "
                },
                {
                    "pdf_id": "0.51",
                    "matching_string": "turnlevel annotations as latent variables "
                },
                {
                    "pdf_id": "0.41",
                    "matching_string": "the system actions taken at each step. These annotations "
                },
                {
                    "pdf_id": "0.77",
                    "matching_string": "ur labnlp/nclatenttod"
                },
                {
                    "pdf_id": "0.37",
                    "matching_string": ""
                }
            ]
        },
        {
            "key": "doc/body",
            "block_type": "body",
            "children": [
                {
                    "key": "doc/body/sec0",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 3,
                            "key": "doc/body/sec0/tit",
                            "block type": "title",
                            "content": "Introduction",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "0.59",
                                    "matching_string": "Introduction"
                                }
                            ]
                        },
                        {
                            "leaf id": 4,
                            "key": "doc/body/sec0/txl0",
                            "block type": "txl",
                            "content": "Taskoriented dialogue systems, which use APIs to complete tasks on behalf of users, have been a longstanding challenge within conversational AI. Recent advances in large language models (LLMs) have further stimulated interest in taskoriented systems and LLMs which can use APIs as tools. To facilitate API use, successful taskoriented dialogue systems usually employ a modular approach: predicting a dialogue state which includes arguments to API calls, and dialogue acts for planning an appropriate response, before finally producing a natural language reply. Training such systems typically requires expert annotation of these structured intermediates for every dialogue turn. Even in settings where humanhuman dialogues are abundantly available, the high cost and expertise required to annotate the dialogues poses a significant hurdle to system development.",
                            "leftover": "required ",
                            "matches": [
                                {
                                    "pdf_id": "0.61",
                                    "matching_string": "to complete tasks on behalf of users, have been a "
                                },
                                {
                                    "pdf_id": "0.62",
                                    "matching_string": "longstanding challenge within conversational AI. "
                                },
                                {
                                    "pdf_id": "0.63",
                                    "matching_string": "Recent advances in large language models (LLMs) "
                                },
                                {
                                    "pdf_id": "0.65",
                                    "matching_string": "systems and LLMs which can use APIs as tools. "
                                },
                                {
                                    "pdf_id": "0.67",
                                    "matching_string": "systems usually employ a modular approach: "
                                },
                                {
                                    "pdf_id": "0.68",
                                    "matching_string": "predicting a dialogue state which includes arguments "
                                },
                                {
                                    "pdf_id": "0.71",
                                    "matching_string": "a natural language reply. Training such systems "
                                },
                                {
                                    "pdf_id": "0.72",
                                    "matching_string": "typically requires expert annotation of these structured "
                                },
                                {
                                    "pdf_id": "0.74",
                                    "matching_string": "settings where humanhuman dialogues are abundantly "
                                },
                                {
                                    "pdf_id": "0.85",
                                    "matching_string": "hurdle to system development."
                                },
                                {
                                    "pdf_id": "0.60",
                                    "matching_string": "Taskoriented dialogue systems, which use APIs "
                                },
                                {
                                    "pdf_id": "0.64",
                                    "matching_string": "have further stimulated interest in taskoriented "
                                },
                                {
                                    "pdf_id": "0.69",
                                    "matching_string": "to API calls, and dialogue acts for planning "
                                },
                                {
                                    "pdf_id": "0.70",
                                    "matching_string": "an appropriate response, before finally producing "
                                },
                                {
                                    "pdf_id": "0.73",
                                    "matching_string": "intermediates for every dialogue turn. Even in "
                                },
                                {
                                    "pdf_id": "0.75",
                                    "matching_string": "available, the high cost and expertise "
                                },
                                {
                                    "pdf_id": "0.84",
                                    "matching_string": "to annotate the dialogues poses a significant "
                                },
                                {
                                    "pdf_id": "0.66",
                                    "matching_string": "To facilitate API use, successful taskoriented dialogue "
                                }
                            ]
                        },
                        {
                            "leaf id": 5,
                            "key": "doc/body/sec0/figure1",
                            "block type": "figure",
                            "content": "t] \\centering \\includegraphics[width=\\columnwidth]{imgs/fig1problemv3.pdf} An overview of our unsupervised dialogue problem. We assume 1) unlabelled goaloriented dialogues between a user and agent and 2) a welldefined schema with APIs suitable for fulfilling goals. We infer the unseen interactions between the agent and API, and use this to produce an endtoend dialogue agent.",
                            "leftover": "t] \\centering \\includegraphics[width=\\columnwidth]{imgs/fig1problemv3.pdf} ",
                            "matches": [
                                {
                                    "pdf_id": "0.79",
                                    "matching_string": "problem. We assume 1) unlabelled goaloriented dialogues "
                                },
                                {
                                    "pdf_id": "0.82",
                                    "matching_string": "infer the unseen interactions between the agent and API, "
                                },
                                {
                                    "pdf_id": "0.83",
                                    "matching_string": "and use this to produce an endtoend dialogue agent."
                                },
                                {
                                    "pdf_id": "0.80",
                                    "matching_string": "between a user and agent and 2) a welldefined "
                                },
                                {
                                    "pdf_id": "0.81",
                                    "matching_string": "schema with APIs suitable for fulfilling goals. We "
                                },
                                {
                                    "pdf_id": "0.78",
                                    "matching_string": "An overview of our unsupervised dialogue "
                                }
                            ]
                        },
                        {
                            "leaf id": 6,
                            "key": "doc/body/sec0/txl2",
                            "block type": "txl",
                            "content": "Recent work has shown that LLMs can accomplish a broad set of useful tasks without any structured labels for a task . These include 'zeroshot' approaches to taskoriented dialogue subtasks such as Dialogue State Tracking (DST), intent detection, grounded response generation, and even zeroshot endtoend dialogue systems . Still, existing approaches generally do not perform well enough for realworld use, and none are able to make effective use of indomain unlabelled dialogues.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "0.86",
                                    "matching_string": "Recent work has shown that LLMs can accomplish "
                                },
                                {
                                    "pdf_id": "0.87",
                                    "matching_string": "a broad set of useful tasks without any structured "
                                },
                                {
                                    "pdf_id": "0.96",
                                    "matching_string": "approaches generally do not perform well enough "
                                },
                                {
                                    "pdf_id": "0.97",
                                    "matching_string": "for realworld use, and none are able to make effective "
                                },
                                {
                                    "pdf_id": "0.90",
                                    "matching_string": "subtasks such as Dialogue State Tracking "
                                },
                                {
                                    "pdf_id": "0.94",
                                    "matching_string": "and even zeroshot endtoend dialogue "
                                },
                                {
                                    "pdf_id": "0.98",
                                    "matching_string": "use of indomain unlabelled dialogues."
                                },
                                {
                                    "pdf_id": "0.89",
                                    "matching_string": "include 'zeroshot' approaches to taskoriented dialogue "
                                },
                                {
                                    "pdf_id": "0.88",
                                    "matching_string": "labels for a task . These (DST), intent detection, grounded response generation, systems . Still, existing "
                                },
                                {
                                    "pdf_id": "0.91",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "0.92",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "0.93",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "0.95",
                                    "matching_string": ""
                                }
                            ]
                        },
                        {
                            "leaf id": 7,
                            "key": "doc/body/sec0/txl3",
                            "block type": "txl",
                            "content": "We ask: can we use existing unlabelled dialogues (without any labels or API calls annotated) along with an API specification, to build a working dialogue agent, without needing an expert to annotate data? This addresses a common realworld scenario. Many high value dialogue tasks are currently carried out by human agents, who interface a user with some software system. These conversations can be recorded and transcribed, and the API(s) supporting the agent typically have wellformed specifications. However, annotating the API calls and system acts needed for aligning the two is time consuming and requires annotation expertise. In lieu of this, 'zeroshot' systems have been proposed, but these still require an expert to annotate a 'formatting example', or a more detailed 'policy skeleton' .",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "0.99",
                                    "matching_string": "We ask: can we use existing unlabelled dialogues "
                                },
                                {
                                    "pdf_id": "0.100",
                                    "matching_string": "(without any labels or API calls annotated) "
                                },
                                {
                                    "pdf_id": "0.101",
                                    "matching_string": "along with an API specification, to build a working "
                                },
                                {
                                    "pdf_id": "0.103",
                                    "matching_string": "data? This addresses a common realworld "
                                },
                                {
                                    "pdf_id": "0.104",
                                    "matching_string": "scenario. Many high value dialogue tasks are currently "
                                },
                                {
                                    "pdf_id": "0.106",
                                    "matching_string": "a user with some software system. These conversations "
                                },
                                {
                                    "pdf_id": "1.0",
                                    "matching_string": "API(s) supporting the agent typically have wellformed "
                                },
                                {
                                    "pdf_id": "1.4",
                                    "matching_string": "API calls and system acts needed for aligning the "
                                },
                                {
                                    "pdf_id": "1.6",
                                    "matching_string": "two is time consuming and requires annotation expertise. "
                                },
                                {
                                    "pdf_id": "1.10",
                                    "matching_string": "been proposed, but these still require an expert to "
                                },
                                {
                                    "pdf_id": "0.105",
                                    "matching_string": "carried out by human agents, who interface "
                                },
                                {
                                    "pdf_id": "1.8",
                                    "matching_string": "In lieu of this, 'zeroshot' systems have "
                                },
                                {
                                    "pdf_id": "1.2",
                                    "matching_string": "specifications. However, annotating the "
                                },
                                {
                                    "pdf_id": "0.107",
                                    "matching_string": "can be recorded and transcribed, and the "
                                },
                                {
                                    "pdf_id": "0.102",
                                    "matching_string": "dialogue agent, without needing an expert to annotate annotate "
                                },
                                {
                                    "pdf_id": "1.12",
                                    "matching_string": "a 'formatting example', or a more detailed 'policy skeleton' ."
                                },
                                {
                                    "pdf_id": "1.14",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "1.16",
                                    "matching_string": ""
                                }
                            ]
                        },
                        {
                            "leaf id": 8,
                            "key": "doc/body/sec0/txl4",
                            "block type": "txl",
                            "content": "We instead propose the following setting: we assume an API schema definition, and plenty of available humanhuman dialogues in natural language, but no annotations on these dialogues (). To the best of our knowledge, we are the first to consider this setting. We demonstrate that one can develop a conversational agent for the API schema in this setting without any assistance from an expert annotator. Our contributions are as follows:",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.18",
                                    "matching_string": "We instead propose the following setting: we "
                                },
                                {
                                    "pdf_id": "1.22",
                                    "matching_string": "of available humanhuman dialogues in natural "
                                },
                                {
                                    "pdf_id": "1.27",
                                    "matching_string": "the first to consider this setting. We demonstrate "
                                },
                                {
                                    "pdf_id": "1.28",
                                    "matching_string": "that one can develop a conversational agent for the "
                                },
                                {
                                    "pdf_id": "1.29",
                                    "matching_string": "API schema in this setting without any assistance "
                                },
                                {
                                    "pdf_id": "1.30",
                                    "matching_string": "from an expert annotator. Our contributions are as "
                                },
                                {
                                    "pdf_id": "1.31",
                                    "matching_string": "follows:"
                                },
                                {
                                    "pdf_id": "1.24",
                                    "matching_string": "language, but no annotations on these dialogues "
                                },
                                {
                                    "pdf_id": "1.20",
                                    "matching_string": "assume an API schema definition, and plenty "
                                },
                                {
                                    "pdf_id": "1.26",
                                    "matching_string": "(). To the best of our knowledge, we are "
                                }
                            ]
                        },
                        {
                            "leaf id": 9,
                            "key": "doc/body/sec0/itemize5",
                            "block type": "itemize",
                            "content": "We construct an endtoend taskoriented dialogue agent with an LLM solely from unlabelled dialogues and an API definition, without any turnlevel labels or supervision from delexicalized utterances. We accomplish this by inferring all the pseudolabels necessary (API calls, system actions) to train a traditional endtoend dialogue system from unlabelled dialogues, using prompts which are automatically generated from the API schema. We propose a noisychannel 'codetotext' reranking method, which is instrumental to our pseudolabel quality and final system. We devise a novel HardEM approach which uses predictions as incontext examples for the LLM, and additionally as data for iteratively finetuning a final model.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.41",
                                    "matching_string": "dialogues and an API definition, without "
                                },
                                {
                                    "pdf_id": "1.46",
                                    "matching_string": "delexicalized utterances. "
                                },
                                {
                                    "pdf_id": "1.49",
                                    "matching_string": "to train a traditional endtoend dialogue system "
                                },
                                {
                                    "pdf_id": "1.51",
                                    "matching_string": "which are automatically generated from the "
                                },
                                {
                                    "pdf_id": "1.52",
                                    "matching_string": "API schema. "
                                },
                                {
                                    "pdf_id": "1.54",
                                    "matching_string": "method, which is instrumental to our "
                                },
                                {
                                    "pdf_id": "1.65",
                                    "matching_string": "pseudolabel quality and final system. "
                                },
                                {
                                    "pdf_id": "1.69",
                                    "matching_string": "examples for the LLM, and additionally "
                                },
                                {
                                    "pdf_id": "1.71",
                                    "matching_string": "model."
                                },
                                {
                                    "pdf_id": "1.38",
                                    "matching_string": "We construct an endtoend taskoriented dialogue "
                                },
                                {
                                    "pdf_id": "1.47",
                                    "matching_string": "We accomplish this by inferring all the pseudolabels "
                                },
                                {
                                    "pdf_id": "1.50",
                                    "matching_string": "from unlabelled dialogues, using prompts "
                                },
                                {
                                    "pdf_id": "1.53",
                                    "matching_string": "We propose a noisychannel 'codetotext' reranking "
                                },
                                {
                                    "pdf_id": "1.40",
                                    "matching_string": "agent with an LLM solely from unlabelled "
                                },
                                {
                                    "pdf_id": "1.44",
                                    "matching_string": "any turnlevel labels or supervision from "
                                },
                                {
                                    "pdf_id": "1.48",
                                    "matching_string": "necessary (API calls, system actions) "
                                },
                                {
                                    "pdf_id": "1.68",
                                    "matching_string": "approach which uses predictions as incontext "
                                },
                                {
                                    "pdf_id": "1.70",
                                    "matching_string": "as data for iteratively finetuning a final "
                                },
                                {
                                    "pdf_id": "1.67",
                                    "matching_string": "We devise a novel HardEM "
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec1",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 10,
                            "key": "doc/body/sec1/tit",
                            "block type": "title",
                            "content": "Preliminaries",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.72",
                                    "matching_string": "Preliminaries"
                                }
                            ]
                        },
                        {
                            "leaf id": 11,
                            "key": "doc/body/sec1/txl0",
                            "block type": "txl",
                            "content": "A taskoriented dialogue consists of turns of utterances between a user and an agent which interfaces the user with a programmable system or API to accomplish a task. Typically the system response utterance follows the user's utterance. We denote ut as the user's utterance at turn t, and rt as the system's response. We assume the APIs supported by the system are defined in a schema, which gives names and descriptions for all arguments supported in each API, as well as the possible values any categorical arguments may take . This is analogous to standardized formats for API documentation, many of which could be easily converted to a schema definition.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.1",
                                    "matching_string": "gives names and descriptions for all arguments supported "
                                },
                                {
                                    "pdf_id": "1.3",
                                    "matching_string": "in each API, as well as the possible values "
                                },
                                {
                                    "pdf_id": "1.9",
                                    "matching_string": "for API documentation, many of which could be "
                                },
                                {
                                    "pdf_id": "1.11",
                                    "matching_string": "easily converted to a schema definition."
                                },
                                {
                                    "pdf_id": "1.81",
                                    "matching_string": "A taskoriented dialogue consists of turns of utterances "
                                },
                                {
                                    "pdf_id": "1.85",
                                    "matching_string": "the user with a programmable system or API to "
                                },
                                {
                                    "pdf_id": "1.87",
                                    "matching_string": "accomplish a task. Typically the system response "
                                },
                                {
                                    "pdf_id": "1.89",
                                    "matching_string": "utterance follows the user's utterance. We denote "
                                },
                                {
                                    "pdf_id": "1.91",
                                    "matching_string": "ut as the user's utterance at turn t, and rt as the "
                                },
                                {
                                    "pdf_id": "1.93",
                                    "matching_string": "system's response. We assume the APIs supported "
                                },
                                {
                                    "pdf_id": "1.83",
                                    "matching_string": "between a user and an agent which interfaces "
                                },
                                {
                                    "pdf_id": "1.7",
                                    "matching_string": "This is analogous to standardized formats "
                                },
                                {
                                    "pdf_id": "1.95",
                                    "matching_string": "by the system are defined in a schema, which "
                                },
                                {
                                    "pdf_id": "1.5",
                                    "matching_string": "any categorical arguments may take . "
                                }
                            ]
                        },
                        {
                            "leaf id": 12,
                            "key": "doc/body/sec1/txl1",
                            "block type": "txl",
                            "content": "Taskoriented systems require some method for interacting with the APIs in . Modular approaches use a Dialogue State Tracking (DST) module, which predicts a belief state bt : a collection of arguments to API call(s) needed to satisfy the user's goal. A belief state is commonly represented with a set of slotvalue pairs:",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.13",
                                    "matching_string": "Taskoriented systems require some method for "
                                },
                                {
                                    "pdf_id": "1.17",
                                    "matching_string": "use a Dialogue State Tracking (DST) module, "
                                },
                                {
                                    "pdf_id": "1.21",
                                    "matching_string": "to API call(s) needed to satisfy the user's "
                                },
                                {
                                    "pdf_id": "1.23",
                                    "matching_string": "goal. A belief state is commonly represented with "
                                },
                                {
                                    "pdf_id": "1.25",
                                    "matching_string": "a set of slotvalue pairs:"
                                },
                                {
                                    "pdf_id": "1.19",
                                    "matching_string": "which predicts a belief state bt : a collection of arguments "
                                },
                                {
                                    "pdf_id": "1.15",
                                    "matching_string": "interacting with the APIs in . Modular approaches "
                                }
                            ]
                        },
                        {
                            "leaf id": 13,
                            "key": "doc/body/sec1/frm2",
                            "block type": "frm",
                            "content": "bt = (s1, v1), (s2, v2), ... (sn, vn)",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.32",
                                    "matching_string": "bt = (s1, v1), (s2, v2), ... (sn, vn)"
                                },
                                {
                                    "pdf_id": "15.0",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.1",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.2",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.3",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.4",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.5",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.6",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.7",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.8",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.9",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.10",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.11",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.12",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.13",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.14",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.16",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.17",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.18",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.19",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.20",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.21",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.22",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.23",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.24",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.25",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.26",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "15.27",
                                    "matching_string": ""
                                }
                            ]
                        },
                        {
                            "leaf id": 14,
                            "key": "doc/body/sec1/txl3",
                            "block type": "txl",
                            "content": "For example, if a user says 'I'm looking for a restaurant south of town', a DST system might produce the belief state {(restaurantarea, south)}, which can be used to query a restaurant API. We assume zero labeled belief states and infer them from unlabelled dialogues using the space of possible states supported by the schema definition .",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.34",
                                    "matching_string": "south of town', a DST system might produce "
                                },
                                {
                                    "pdf_id": "1.35",
                                    "matching_string": "the belief state {(restaurantarea, south)}, which "
                                },
                                {
                                    "pdf_id": "1.36",
                                    "matching_string": "can be used to query a restaurant API. We assume "
                                },
                                {
                                    "pdf_id": "1.37",
                                    "matching_string": "zero labeled belief states and infer them from unlabelled "
                                },
                                {
                                    "pdf_id": "1.33",
                                    "matching_string": "For example, if a user says 'I'm looking for a restaurant "
                                },
                                {
                                    "pdf_id": "1.39",
                                    "matching_string": "dialogues using the space of possible states "
                                },
                                {
                                    "pdf_id": "1.42",
                                    "matching_string": "supported by the schema definition "
                                },
                                {
                                    "pdf_id": "15.15",
                                    "matching_string": "."
                                }
                            ]
                        },
                        {
                            "leaf id": 15,
                            "key": "doc/body/sec1/txl4",
                            "block type": "txl",
                            "content": "We also make use of system dialogue acts to structure our agent's communicative intents with a policy module. Given a dialogue state and context for a turn t, the policy predicts set of dialogue acts to be communicated in the system response rt. For instance, the policy might determine that we should ask the user to narrow their search to a price range: At = Request(restaurantarea=?). An appropriate system response might be: ''Sure, are you looking for a particular price range?\" Like belief states, we assume zero supervised examples of At and infer them from unlabelled dialogues.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.43",
                                    "matching_string": "We also make use of system dialogue acts to "
                                },
                                {
                                    "pdf_id": "1.56",
                                    "matching_string": "for a turn t, the policy predicts set of dialogue "
                                },
                                {
                                    "pdf_id": "1.57",
                                    "matching_string": "acts to be communicated in the system response "
                                },
                                {
                                    "pdf_id": "1.59",
                                    "matching_string": "we should ask the user to narrow their search to "
                                },
                                {
                                    "pdf_id": "1.61",
                                    "matching_string": "An appropriate system response might be: ''Sure, "
                                },
                                {
                                    "pdf_id": "1.62",
                                    "matching_string": "are you looking for a particular price range?\" Like "
                                },
                                {
                                    "pdf_id": "1.63",
                                    "matching_string": "belief states, we assume zero supervised examples "
                                },
                                {
                                    "pdf_id": "1.64",
                                    "matching_string": "of At and infer them from unlabelled dialogues."
                                },
                                {
                                    "pdf_id": "1.55",
                                    "matching_string": "policy module. Given a dialogue state and context "
                                },
                                {
                                    "pdf_id": "1.58",
                                    "matching_string": "rt. For instance, the policy might determine that "
                                },
                                {
                                    "pdf_id": "1.45",
                                    "matching_string": "structure our agent's communicative intents with a "
                                },
                                {
                                    "pdf_id": "1.60",
                                    "matching_string": "a price range: At = Request(restaurantarea=?). "
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec2",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 16,
                            "key": "doc/body/sec2/tit",
                            "block type": "title",
                            "content": "Method Overview",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.66",
                                    "matching_string": "Method Overview"
                                }
                            ]
                        },
                        {
                            "leaf id": 17,
                            "key": "doc/body/sec2/figure*0",
                            "block type": "figure*",
                            "content": "\\centering \\includegraphics[width=\\textwidth]{imgs/figure2latentsv4.pdf} An overview of the latent variables annotated in our unsupervised labeling process which are used to train the dialogue model. Our \\textcolor{dstcolor}{{DST Module}} () infers the API call(s) with arguments at each turn, from which we can derive the dialogue state change. Our \\textcolor{datcolor}{{DAT or Act Tagging module}} () predicts the dialogue acts communicated in the observed system response, which can be used to infer delexicalized responses for training a response generator.",
                            "leftover": "\\centering \\includegraphics[width=\\textwidth]{imgs/figure2latentsv4.pdf} ",
                            "matches": [
                                {
                                    "pdf_id": "2.3",
                                    "matching_string": "the observed system response, which can be used to infer delexicalized responses for training a response generator."
                                },
                                {
                                    "pdf_id": "2.0",
                                    "matching_string": "An overview of the latent variables annotated in our unsupervised labeling process which are used to train "
                                },
                                {
                                    "pdf_id": "15.28",
                                    "matching_string": "DST "
                                },
                                {
                                    "pdf_id": "15.29",
                                    "matching_string": "Act Tagging "
                                },
                                {
                                    "pdf_id": "2.1",
                                    "matching_string": "the dialogue model. Our \\textcolor{dstcolor}{{Module}} () infers the API call(s) with arguments at each turn, from which we can "
                                },
                                {
                                    "pdf_id": "2.2",
                                    "matching_string": "derive the dialogue state change. Our \\textcolor{datcolor}{{DAT or module}} () predicts the dialogue acts communicated in "
                                }
                            ]
                        },
                        {
                            "leaf id": 18,
                            "key": "doc/body/sec2/txl1",
                            "block type": "txl",
                            "content": "We treat the turnlevel labels needed for training an endtoend dialogue system as a latent variables, and infer them from unlabelled dialogues. We assume only the fullylexicalized sequence of user and system utterances u1, r1, ... uT, rT, and the schema defining the system's capabilities, which defines the space of valid dialogue state and act labels. Importantly, our prompts are automatically generated from the API schema.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "1.73",
                                    "matching_string": "We treat the turnlevel labels needed for training "
                                },
                                {
                                    "pdf_id": "1.74",
                                    "matching_string": "an endtoend dialogue system as a latent variables, "
                                },
                                {
                                    "pdf_id": "1.76",
                                    "matching_string": "We assume only the fullylexicalized sequence of "
                                },
                                {
                                    "pdf_id": "1.79",
                                    "matching_string": "which defines the space of valid dialogue state and "
                                },
                                {
                                    "pdf_id": "1.80",
                                    "matching_string": "act labels. Importantly, our prompts are automatically "
                                },
                                {
                                    "pdf_id": "1.75",
                                    "matching_string": "and infer them from unlabelled dialogues. "
                                },
                                {
                                    "pdf_id": "1.77",
                                    "matching_string": "user and system utterances u1, r1, ... uT, rT, and "
                                },
                                {
                                    "pdf_id": "1.78",
                                    "matching_string": "the schema defining the system's capabilities, "
                                },
                                {
                                    "pdf_id": "1.82",
                                    "matching_string": "generated from the API schema."
                                }
                            ]
                        },
                        {
                            "leaf id": 19,
                            "key": "doc/body/sec2/txl2",
                            "block type": "txl",
                            "content": "In, we outline our noisychannel prompting method for inferring the turnlevel labels necessary for training our dialogue agent. We give an overview of the latent variables we infer in . We assume we cannot query the APIs or observe results while labeling dialogues offline, as the obtained API results may have changed. In, we train a complete dialogue agent by finetuning on prompts derived from our inferred pseudolabels.",
                            "leftover": "In, . ",
                            "matches": [
                                {
                                    "pdf_id": "1.86",
                                    "matching_string": "method for inferring the turnlevel labels necessary "
                                },
                                {
                                    "pdf_id": "1.92",
                                    "matching_string": "We assume we cannot query the APIs or observe "
                                },
                                {
                                    "pdf_id": "1.94",
                                    "matching_string": "results while labeling dialogues offline, as the obtained "
                                },
                                {
                                    "pdf_id": "2.4",
                                    "matching_string": "train a complete dialogue agent by finetuning on "
                                },
                                {
                                    "pdf_id": "2.5",
                                    "matching_string": "prompts derived from our inferred pseudolabels."
                                },
                                {
                                    "pdf_id": "1.88",
                                    "matching_string": "for training our dialogue agent. We give an "
                                },
                                {
                                    "pdf_id": "1.90",
                                    "matching_string": "overview of the latent variables we infer in "
                                },
                                {
                                    "pdf_id": "1.84",
                                    "matching_string": "we outline our noisychannel prompting "
                                },
                                {
                                    "pdf_id": "1.96",
                                    "matching_string": "API results may have changed. In, we "
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec3",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 20,
                            "key": "doc/body/sec3/tit",
                            "block type": "title",
                            "content": "Inferring Latents via Noisy Channel",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "2.6",
                                    "matching_string": "Inferring Latents via Noisy Channel"
                                }
                            ]
                        },
                        {
                            "leaf id": 21,
                            "key": "doc/body/sec3/txl0",
                            "block type": "txl",
                            "content": "In this section, we present our method for inferring latent annotations for the dialogue states b1...bT and dialogue acts A1...AT for each dialogue turn t given only the unlabelled user and system utterances (u1, r1, u2, r2, ... uT, rT). To do this, we devise a noisychannel prompting approach for DST and dialogue act tagging (DAT) using StarCoder, a codebased LLM. First, we use a texttocode prompt to infer the API call(s) made by the system in each dialogue, and build the dialogue state from inferred API call arguments (). We use a similar texttocode prompt to infer the latent act(s) communicated in each agent response, so that we can reverseengineer an agent's policy (). For both tasks, we find much better performance when reranking latent predictions according to a noisychannel model, in which we condition the observed utterance on a predicted latent in a codetotext prompt (). Finally, we leverage the incontext learning ability of LLMs by reusing our predictions as exemplars (). Given these initial pseudolabels, we iteratively improve their quality using HardEM ().",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "2.7",
                                    "matching_string": "In this section, we present our method for inferring "
                                },
                                {
                                    "pdf_id": "2.8",
                                    "matching_string": "latent annotations for the dialogue states b1...bT "
                                },
                                {
                                    "pdf_id": "2.9",
                                    "matching_string": "and dialogue acts A1...AT for each dialogue turn "
                                },
                                {
                                    "pdf_id": "2.10",
                                    "matching_string": "t given only the unlabelled user and system utterances "
                                },
                                {
                                    "pdf_id": "2.23",
                                    "matching_string": "a texttocode prompt to infer the API call(s) made "
                                },
                                {
                                    "pdf_id": "2.25",
                                    "matching_string": "by the system in each dialogue, and build the dialogue "
                                },
                                {
                                    "pdf_id": "2.31",
                                    "matching_string": "the latent act(s) communicated in each agent response, "
                                },
                                {
                                    "pdf_id": "2.37",
                                    "matching_string": "performance when reranking latent predictions "
                                },
                                {
                                    "pdf_id": "2.39",
                                    "matching_string": "according to a noisychannel model, in which we "
                                },
                                {
                                    "pdf_id": "2.41",
                                    "matching_string": "condition the observed utterance on a predicted latent "
                                },
                                {
                                    "pdf_id": "2.45",
                                    "matching_string": "leverage the incontext learning ability of LLMs "
                                },
                                {
                                    "pdf_id": "2.49",
                                    "matching_string": "Given these initial pseudolabels, we iteratively improve "
                                },
                                {
                                    "pdf_id": "2.12",
                                    "matching_string": "a noisychannel prompting approach for DST "
                                },
                                {
                                    "pdf_id": "2.13",
                                    "matching_string": "and dialogue act tagging (DAT) using "
                                },
                                {
                                    "pdf_id": "2.33",
                                    "matching_string": "so that we can reverseengineer an agent's "
                                },
                                {
                                    "pdf_id": "2.11",
                                    "matching_string": "(u1, r1, u2, r2, ... uT, rT). To do this, we devise "
                                },
                                {
                                    "pdf_id": "2.29",
                                    "matching_string": "We use a similar texttocode prompt to infer "
                                },
                                {
                                    "pdf_id": "2.35",
                                    "matching_string": "policy (). For both tasks, we find much better "
                                },
                                {
                                    "pdf_id": "2.47",
                                    "matching_string": "by reusing our predictions as exemplars ()"
                                },
                                {
                                    "pdf_id": "2.27",
                                    "matching_string": "state from inferred API call arguments ()"
                                },
                                {
                                    "pdf_id": "2.43",
                                    "matching_string": "in a codetotext prompt (). Finally, we "
                                },
                                {
                                    "pdf_id": "2.53",
                                    "matching_string": "()"
                                },
                                {
                                    "pdf_id": "2.14",
                                    "matching_string": "StarCoder, a codebased LLM. First, we use . . their quality using HardEM ."
                                },
                                {
                                    "pdf_id": "2.51",
                                    "matching_string": ""
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 22,
                                    "key": "doc/body/sec3/sub1/tit",
                                    "block type": "title",
                                    "content": "Inferring API Calls and Dialogue State",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "2.54",
                                            "matching_string": "Inferring API Calls and Dialogue State"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 23,
                                    "key": "doc/body/sec3/sub1/txl0",
                                    "block type": "txl",
                                    "content": "We prompt the LLM with a texttocode prompt for inferring the latent dialogue state as an API call. in gives an example of our prompt. We generate a prompt enumerating the intents available in the schema as APIs callable by our agent. Following, we predict the appropriate function call conditioned on the prior system response rt1, the current user utterance ut, and the previous belief state prediction bt1. We then extract a dialogue state change bt from the arguments to the call, and compute the next dialogue state as bt = bt + bt1. While used offline here, this DST method is causal with respect to dialogue inputs and is the same as our method in online inference.",
                                    "leftover": "utterance bt ",
                                    "matches": [
                                        {
                                            "pdf_id": "2.17",
                                            "matching_string": "from the arguments to the call, and compute the "
                                        },
                                        {
                                            "pdf_id": "2.19",
                                            "matching_string": "offline here, this DST method is causal with respect "
                                        },
                                        {
                                            "pdf_id": "2.20",
                                            "matching_string": "to dialogue inputs and is the same as our method "
                                        },
                                        {
                                            "pdf_id": "2.21",
                                            "matching_string": "in online inference."
                                        },
                                        {
                                            "pdf_id": "2.58",
                                            "matching_string": "We prompt the LLM with a texttocode prompt "
                                        },
                                        {
                                            "pdf_id": "2.60",
                                            "matching_string": "for inferring the latent dialogue state as an API "
                                        },
                                        {
                                            "pdf_id": "2.64",
                                            "matching_string": "prompt. We generate a prompt enumerating the "
                                        },
                                        {
                                            "pdf_id": "2.70",
                                            "matching_string": "the appropriate function call conditioned on "
                                        },
                                        {
                                            "pdf_id": "2.15",
                                            "matching_string": "the prior system response rt1, the current user "
                                        },
                                        {
                                            "pdf_id": "2.66",
                                            "matching_string": "intents available in the schema as APIs callable "
                                        },
                                        {
                                            "pdf_id": "2.16",
                                            "matching_string": "ut, and the previous belief state prediction bt1. We then extract a dialogue state change "
                                        },
                                        {
                                            "pdf_id": "2.18",
                                            "matching_string": "next dialogue state as bt = bt + bt1. While used "
                                        },
                                        {
                                            "pdf_id": "2.62",
                                            "matching_string": "call. in gives an example of our "
                                        },
                                        {
                                            "pdf_id": "2.68",
                                            "matching_string": "by our agent. Following, we predict "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub2",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 24,
                                    "key": "doc/body/sec3/sub2/tit",
                                    "block type": "title",
                                    "content": "Inferring System Acts",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "2.22",
                                            "matching_string": "Inferring System Acts"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 25,
                                    "key": "doc/body/sec3/sub2/txl0",
                                    "block type": "txl",
                                    "content": "For inferring system acts, we use a similar texttocode prompt for predicting the set of dialogue acts At communicated in a given system response rt. See in for an example of our prompt. We define each act our system could take in the prompt instructions. For input from each turn, we find best performance when conditioning only on the response to tag, rt. For our set of supported acts, we use a subset of the universal dialogue acts proposed in, where some acts such as ''Inform'' or ''Offer'' may use slots defined in . For example, an agent choosing to offer to book a user at a hotel named 'acorn guest house' might be represented as Offer(hotelname='acorn guest house'). See for our complete dialogue act set. Importantly, we use the schema definition and our act set to validate each act prediction, removing predicted keys which do not belong to, or acts which are not in the set. For example, the 'text' key is not valid for a 'ThankYou' act, so a prediction of ''ThankYou(text='thanks, have a good day')\" would be normalized to only ''ThankYou()''. Using the inferred system acts, we use a rulebased method to delexicalize the system responses for training the response generator (, right).",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "2.24",
                                            "matching_string": "For inferring system acts, we use a similar texttocode "
                                        },
                                        {
                                            "pdf_id": "2.32",
                                            "matching_string": "We define each act our system could take in the "
                                        },
                                        {
                                            "pdf_id": "2.34",
                                            "matching_string": "prompt instructions. For input from each turn, we "
                                        },
                                        {
                                            "pdf_id": "2.40",
                                            "matching_string": "we use a subset of the universal dialogue acts proposed "
                                        },
                                        {
                                            "pdf_id": "2.46",
                                            "matching_string": "For example, an agent choosing to offer to book "
                                        },
                                        {
                                            "pdf_id": "2.48",
                                            "matching_string": "a user at a hotel named 'acorn guest house' might "
                                        },
                                        {
                                            "pdf_id": "2.59",
                                            "matching_string": "or acts which are not in the set. For example, the "
                                        },
                                        {
                                            "pdf_id": "2.61",
                                            "matching_string": "'text' key is not valid for a 'ThankYou' act, so a prediction "
                                        },
                                        {
                                            "pdf_id": "2.65",
                                            "matching_string": "day')\" would be normalized to only ''ThankYou()''. "
                                        },
                                        {
                                            "pdf_id": "2.67",
                                            "matching_string": "Using the inferred system acts, we use a rulebased "
                                        },
                                        {
                                            "pdf_id": "2.69",
                                            "matching_string": "method to delexicalize the system responses for "
                                        },
                                        {
                                            "pdf_id": "2.26",
                                            "matching_string": "prompt for predicting the set of dialogue acts "
                                        },
                                        {
                                            "pdf_id": "2.36",
                                            "matching_string": "find best performance when conditioning only on "
                                        },
                                        {
                                            "pdf_id": "2.38",
                                            "matching_string": "the response to tag, rt. For our set of supported acts, "
                                        },
                                        {
                                            "pdf_id": "2.44",
                                            "matching_string": "as ''Inform'' or ''Offer'' may use slots defined in "
                                        },
                                        {
                                            "pdf_id": "2.50",
                                            "matching_string": "be represented as Offer(hotelname='acorn guest "
                                        },
                                        {
                                            "pdf_id": "2.55",
                                            "matching_string": "act set. Importantly, we use the schema definition "
                                        },
                                        {
                                            "pdf_id": "2.56",
                                            "matching_string": "and our act set to validate each act prediction, "
                                        },
                                        {
                                            "pdf_id": "2.28",
                                            "matching_string": "At communicated in a given system response rt. "
                                        },
                                        {
                                            "pdf_id": "2.57",
                                            "matching_string": "removing predicted keys which do not belong "
                                        },
                                        {
                                            "pdf_id": "2.63",
                                            "matching_string": "of ''ThankYou(text='thanks, have a good "
                                        },
                                        {
                                            "pdf_id": "2.71",
                                            "matching_string": "training the response generator (, right)."
                                        },
                                        {
                                            "pdf_id": "2.30",
                                            "matching_string": "See in for an example of our prompt. "
                                        },
                                        {
                                            "pdf_id": "2.52",
                                            "matching_string": "house'). See for our complete dialogue "
                                        },
                                        {
                                            "pdf_id": "2.42",
                                            "matching_string": "in, where some acts such . to, "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub3",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 26,
                                    "key": "doc/body/sec3/sub3/tit",
                                    "block type": "title",
                                    "content": "Noisy Channel LLM Prompting",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.0",
                                            "matching_string": "Noisy Channel LLM Prompting"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 27,
                                    "key": "doc/body/sec3/sub3/txl0",
                                    "block type": "txl",
                                    "content": "We find that a noisy channel prompting method significantly the quality of our inferred dialogue states and acts. Here we describe noisy channel prompting using a simple example, and then describe its application to dialogue state tracking and system act tagging.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.3",
                                            "matching_string": "inferred dialogue states and acts. Here we describe "
                                        },
                                        {
                                            "pdf_id": "3.5",
                                            "matching_string": "and then describe its application to dialogue state "
                                        },
                                        {
                                            "pdf_id": "3.6",
                                            "matching_string": "tracking and system act tagging."
                                        },
                                        {
                                            "pdf_id": "3.1",
                                            "matching_string": "We find that a noisy channel prompting method "
                                        },
                                        {
                                            "pdf_id": "3.4",
                                            "matching_string": "noisy channel prompting using a simple example, "
                                        },
                                        {
                                            "pdf_id": "3.2",
                                            "matching_string": "significantly the quality of our "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 28,
                                    "key": "doc/body/sec3/sub3/txl1",
                                    "block type": "txl",
                                    "content": "A typical prompt for machine reading comprehension might be:",
                                    "leftover": "comprehension ",
                                    "matches": [
                                        {
                                            "pdf_id": "3.7",
                                            "matching_string": "A typical prompt for machine reading "
                                        },
                                        {
                                            "pdf_id": "3.8",
                                            "matching_string": "might be:"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 29,
                                    "key": "doc/body/sec3/sub3/Verbatim2",
                                    "block type": "Verbatim",
                                    "content": "fontsize=\\small] <Optional incontext examples (c)> Passage: <Passage (z)> Question: <Question (x)> Answer:",
                                    "leftover": "fontsize=\\small] ",
                                    "matches": [
                                        {
                                            "pdf_id": "3.9",
                                            "matching_string": "<Optional incontext examples (c)> "
                                        },
                                        {
                                            "pdf_id": "3.10",
                                            "matching_string": "Passage: <Passage (z)> "
                                        },
                                        {
                                            "pdf_id": "3.11",
                                            "matching_string": "Question: <Question (x)> "
                                        },
                                        {
                                            "pdf_id": "3.12",
                                            "matching_string": "Answer:"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 30,
                                    "key": "doc/body/sec3/sub3/txl3",
                                    "block type": "txl",
                                    "content": "Given this prompt of the incontext examples c, passage z, question x, an answer y completion is found with the language model by maximizing or sampling from Pr(y|x,z,c). We call this the direct prompt.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.13",
                                            "matching_string": "Given this prompt of the incontext examples "
                                        },
                                        {
                                            "pdf_id": "3.14",
                                            "matching_string": "c, passage z, question x, an answer y completion "
                                        },
                                        {
                                            "pdf_id": "3.15",
                                            "matching_string": "is found with the language model by maximizing "
                                        },
                                        {
                                            "pdf_id": "3.17",
                                            "matching_string": "direct prompt."
                                        },
                                        {
                                            "pdf_id": "3.16",
                                            "matching_string": "or sampling from Pr(y|x,z,c). We call this the "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 31,
                                    "key": "doc/body/sec3/sub3/txl4",
                                    "block type": "txl",
                                    "content": "The ''noisy channel'' prompt is:",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.18",
                                            "matching_string": "The ''noisy channel'' prompt is:"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 32,
                                    "key": "doc/body/sec3/sub3/Verbatim5",
                                    "block type": "Verbatim",
                                    "content": "fontsize=\\small] <Optional incontext examples (c)> Passage: <Passage (z)> Answer: <Answer (y)> Question: <Question (x)>",
                                    "leftover": "fontsize=\\small] ",
                                    "matches": [
                                        {
                                            "pdf_id": "3.21",
                                            "matching_string": "Answer: <Answer (y)> "
                                        },
                                        {
                                            "pdf_id": "3.19",
                                            "matching_string": "<Optional incontext examples (c)> "
                                        },
                                        {
                                            "pdf_id": "3.20",
                                            "matching_string": "Passage: <Passage (z)> "
                                        },
                                        {
                                            "pdf_id": "3.22",
                                            "matching_string": "Question: <Question (x)>"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 33,
                                    "key": "doc/body/sec3/sub3/txl6",
                                    "block type": "txl",
                                    "content": "where the likelihood of the question now depends on the answer. To use the noisy channel LLM prompt, we first sample k samples from the direct prompt, and then pick the best output answer y according to the noisy channel prompt probability. One can choose to score the joint probability of the answer followed by the question, i.e. Pr(x|y,z,c)Pr(y|z,c), or only the conditional Pr(x|y,z,c), following .In the latter case, the prior Pr(y|z, c) is uniformly 1k for the k samples from the direct prompt.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.23",
                                            "matching_string": "where the likelihood of the question now depends "
                                        },
                                        {
                                            "pdf_id": "3.24",
                                            "matching_string": "on the answer. To use the noisy channel LLM "
                                        },
                                        {
                                            "pdf_id": "3.25",
                                            "matching_string": "prompt, we first sample k samples from the direct "
                                        },
                                        {
                                            "pdf_id": "3.26",
                                            "matching_string": "prompt, and then pick the best output answer y "
                                        },
                                        {
                                            "pdf_id": "3.27",
                                            "matching_string": "according to the noisy channel prompt probability. "
                                        },
                                        {
                                            "pdf_id": "3.29",
                                            "matching_string": "of the answer followed by the question, i.e. "
                                        },
                                        {
                                            "pdf_id": "3.50",
                                            "matching_string": "the k samples from the direct prompt."
                                        },
                                        {
                                            "pdf_id": "3.28",
                                            "matching_string": "One can choose to score the joint probability "
                                        },
                                        {
                                            "pdf_id": "3.30",
                                            "matching_string": "x|y,z,c)Pr(y|z,c), or only the conditional "
                                        },
                                        {
                                            "pdf_id": "3.48",
                                            "matching_string": "the latter case, the prior Pr(y|z, c) is uniformly "
                                        },
                                        {
                                            "pdf_id": "3.49",
                                            "matching_string": "for "
                                        },
                                        {
                                            "pdf_id": "3.31",
                                            "matching_string": "Pr(Pr(x|y,z,c), following .In 1k "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 34,
                                    "key": "doc/body/sec3/sub3/txl7",
                                    "block type": "txl",
                                    "content": "To apply this method to inferring dialogue states, we first sample a set of possible belief state changes using topp sampling from the direct DST prompt, and then pick the best dialogue state according to the noisy channel prompt (see ). We use an analogous procedure for inferring system acts. For DST, we find scoring with the joint Pr(x|y,z,c)Pr(y|z,c) to perform best, and scoring with the conditional Pr(x|y,z,c) best for act tagging.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.32",
                                            "matching_string": "To apply this method to inferring dialogue states, "
                                        },
                                        {
                                            "pdf_id": "3.33",
                                            "matching_string": "we first sample a set of possible belief state changes "
                                        },
                                        {
                                            "pdf_id": "3.35",
                                            "matching_string": "the direct DST prompt, and then pick the best dialogue "
                                        },
                                        {
                                            "pdf_id": "3.41",
                                            "matching_string": "best for act tagging."
                                        },
                                        {
                                            "pdf_id": "3.36",
                                            "matching_string": "state according to the noisy channel prompt "
                                        },
                                        {
                                            "pdf_id": "3.37",
                                            "matching_string": "(see ). We use an analogous procedure for "
                                        },
                                        {
                                            "pdf_id": "3.39",
                                            "matching_string": "with the joint Pr(x|y,z,c)Pr(y|z,c) to perform "
                                        },
                                        {
                                            "pdf_id": "3.40",
                                            "matching_string": "best, and scoring with the conditional Pr(x|y,z,c) "
                                        },
                                        {
                                            "pdf_id": "3.38",
                                            "matching_string": "inferring system acts. For DST, we find scoring "
                                        },
                                        {
                                            "pdf_id": "3.34",
                                            "matching_string": "using topp sampling from "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub4",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 35,
                                    "key": "doc/body/sec3/sub4/tit",
                                    "block type": "title",
                                    "content": "RetrievalAugmented Incontext Learning",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.42",
                                            "matching_string": "RetrievalAugmented Incontext Learning"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 36,
                                    "key": "doc/body/sec3/sub4/txl0",
                                    "block type": "txl",
                                    "content": "To leverage the incontext learning abilities of LLMs, we retrieve from a pool of examples from our predictions. Because we assume no labeled examples, this pool starts with zero examples and is filled incrementally. We retrieve up to k examples for incontext learning from this pool using an unsupervised dense retriever, with examples ranked by embedding cosine distance.We use MPNet, available on Huggingface as sentencetransformers/allmpnetbasev2 We use k=8 and k=6 for DST, DAT respectively. For retriever inputs, we use (bt1 rt1 ut) and (ut rt) for DST and DAT respectively, where  indicates concatenation. Applied naively, this incontext learning approach can suffer a majority label bias . We adjust for biases introduced in the initially small example pool by 1) not using any incontext examples until we have a minimum of n=32 examples in the pool and 2) using our API schema to require at least 4 distinct labels in each set of incontext examples.We consider two dialogue state change labels to be distinct if they update different slots, and two act labels to be distinct if they embody different acts or different slots Our algorithm for producing initial pseudolabels is in .",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.43",
                                            "matching_string": "To leverage the incontext learning abilities of "
                                        },
                                        {
                                            "pdf_id": "3.45",
                                            "matching_string": "our predictions. Because we assume no labeled examples, "
                                        },
                                        {
                                            "pdf_id": "3.56",
                                            "matching_string": "for incontext learning from this pool using an unsupervised "
                                        },
                                        {
                                            "pdf_id": "3.61",
                                            "matching_string": "and DAT respectively, where  indicates concatenation. "
                                        },
                                        {
                                            "pdf_id": "3.65",
                                            "matching_string": "the initially small example pool by 1) not using "
                                        },
                                        {
                                            "pdf_id": "3.89",
                                            "matching_string": "if they update different slots, and two act labels to be distinct "
                                        },
                                        {
                                            "pdf_id": "3.90",
                                            "matching_string": "if they embody different acts or different slots "
                                        },
                                        {
                                            "pdf_id": "3.44",
                                            "matching_string": "LLMs, we retrieve from a pool of examples from "
                                        },
                                        {
                                            "pdf_id": "3.46",
                                            "matching_string": "this pool starts with zero examples and is "
                                        },
                                        {
                                            "pdf_id": "3.66",
                                            "matching_string": "any incontext examples until we have a minimum "
                                        },
                                        {
                                            "pdf_id": "3.67",
                                            "matching_string": "of n=32 examples in the pool and 2) using our "
                                        },
                                        {
                                            "pdf_id": "3.70",
                                            "matching_string": "for producing initial pseudolabels is in "
                                        },
                                        {
                                            "pdf_id": "3.57",
                                            "matching_string": "dense retriever, with examples ranked "
                                        },
                                        {
                                            "pdf_id": "3.60",
                                            "matching_string": "we use (bt1 rt1 ut) and (ut rt) for DST "
                                        },
                                        {
                                            "pdf_id": "3.62",
                                            "matching_string": "Applied naively, this incontext learning "
                                        },
                                        {
                                            "pdf_id": "3.63",
                                            "matching_string": "approach can suffer a majority label bias "
                                        },
                                        {
                                            "pdf_id": "3.68",
                                            "matching_string": "API schema to require at least 4 distinct labels "
                                        },
                                        {
                                            "pdf_id": "3.88",
                                            "matching_string": "consider two dialogue state change labels to be distinct "
                                        },
                                        {
                                            "pdf_id": "3.47",
                                            "matching_string": "filled incrementally. We retrieve up to k examples "
                                        },
                                        {
                                            "pdf_id": "3.59",
                                            "matching_string": "6 for DST, DAT respectively. For retriever inputs, "
                                        },
                                        {
                                            "pdf_id": "3.64",
                                            "matching_string": "We adjust for biases introduced in "
                                        },
                                        {
                                            "pdf_id": "3.69",
                                            "matching_string": "in each set of incontext examples.We Our algorithm "
                                        },
                                        {
                                            "pdf_id": "3.87",
                                            "matching_string": "as sentencetransformers/allmpnetbasev2 "
                                        },
                                        {
                                            "pdf_id": "3.58",
                                            "matching_string": "by embedding cosine distance.We use MPNet, available on Huggingface We use k=8 and k=. ."
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 37,
                                    "key": "doc/body/sec3/sub4/figure1",
                                    "block type": "figure",
                                    "content": "\\centering \\includegraphics[width=\\columnwidth]{imgs/figdirectvschanneldstv2.pdf} Instances from our 'direct' and 'noisy channel' prompts for DST. Best viewed in color. After sampling a \\textcolor{dstcolor}{{DST Module}} from the 'direct' prompt, we score it by the likelihood of the input \\textcolor{usercolor}{{user utterance}} conditioned on it in the 'noisy channel' prompt.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.52",
                                            "matching_string": "prompts for DST. Best viewed in color. After sampling "
                                        },
                                        {
                                            "pdf_id": "3.55",
                                            "matching_string": "on it in the 'noisy channel' prompt."
                                        },
                                        {
                                            "pdf_id": "3.51",
                                            "matching_string": "Instances from our 'direct' and 'noisy channel' "
                                        },
                                        {
                                            "pdf_id": "3.53",
                                            "matching_string": "\\centering \\includegraphics[width=\\columnwidth]{imgs/figdirectvschanneldstv2.pdf} a \\textcolor{dstcolor}{{DST Module}} from the 'direct' prompt, we score it by the likelihood of the input \\textcolor{usercolor}{{user utterance}} conditioned "
                                        },
                                        {
                                            "pdf_id": "3.54",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub5",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 38,
                                    "key": "doc/body/sec3/sub5/tit",
                                    "block type": "title",
                                    "content": "Refining the Labels with HardEM",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.71",
                                            "matching_string": "Refining the Labels with HardEM"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 39,
                                    "key": "doc/body/sec3/sub5/txl0",
                                    "block type": "txl",
                                    "content": "While the labels we produce in  can be used directly for training an endtoend dialogue system, we find their quality can be improved through expectationmaximization . For every dialogue turn in our dataset, our initial pseudolabels provide the expected dialogue state and system dialogue acts according to our zeroshot system. We then jointly finetune an LLM as a noisychannel DST & DAT system to maximize the likelihood of these expected labels. We use smaller version of our prompted LLM, StarCoder 3B .",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "3.74",
                                            "matching_string": "system, we find their quality can be improved "
                                        },
                                        {
                                            "pdf_id": "3.77",
                                            "matching_string": "initial pseudolabels provide the expected dialogue "
                                        },
                                        {
                                            "pdf_id": "3.78",
                                            "matching_string": "state and system dialogue acts according to our "
                                        },
                                        {
                                            "pdf_id": "3.79",
                                            "matching_string": "zeroshot system. We then jointly finetune an "
                                        },
                                        {
                                            "pdf_id": "3.80",
                                            "matching_string": "LLM as a noisychannel DST & DAT system to "
                                        },
                                        {
                                            "pdf_id": "3.81",
                                            "matching_string": "maximize the likelihood of these expected labels. "
                                        },
                                        {
                                            "pdf_id": "3.82",
                                            "matching_string": "We use smaller version of our prompted LLM, StarCoder "
                                        },
                                        {
                                            "pdf_id": "3.76",
                                            "matching_string": "For every dialogue turn in our dataset, our "
                                        },
                                        {
                                            "pdf_id": "3.72",
                                            "matching_string": "While the labels we produce in  can "
                                        },
                                        {
                                            "pdf_id": "3.73",
                                            "matching_string": "be used directly for training an endtoend dialogue "
                                        },
                                        {
                                            "pdf_id": "3.75",
                                            "matching_string": "through expectationmaximization . 3B ."
                                        },
                                        {
                                            "pdf_id": "3.83",
                                            "matching_string": ""
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 40,
                                    "key": "doc/body/sec3/sub5/txl1",
                                    "block type": "txl",
                                    "content": "For each turn, we derive (prompt, completion) pairs for 'direct' texttocode and 'channel' codetotext DST and DAT modules, as defined in . We then combine and shuffle these pairs into a single training set for joint finetuning. For efficient training, we shorten our prompts by removing incontext examples as well as the function definitions used in the incontext learning setting. We find upsampling the 'channel' prompts so that there is a 2:1 ratio of 'channel' to 'direct' instances for training improves performance.",
                                    "leftover": "codetotext . ",
                                    "matches": [
                                        {
                                            "pdf_id": "3.84",
                                            "matching_string": "For each turn, we derive (prompt, completion) "
                                        },
                                        {
                                            "pdf_id": "3.85",
                                            "matching_string": "pairs for 'direct' texttocode and 'channel' "
                                        },
                                        {
                                            "pdf_id": "4.2",
                                            "matching_string": "We then combine and shuffle these pairs into a "
                                        },
                                        {
                                            "pdf_id": "4.4",
                                            "matching_string": "single training set for joint finetuning. For efficient "
                                        },
                                        {
                                            "pdf_id": "4.8",
                                            "matching_string": "examples as well as the function definitions "
                                        },
                                        {
                                            "pdf_id": "4.10",
                                            "matching_string": "used in the incontext learning setting. We find upsampling "
                                        },
                                        {
                                            "pdf_id": "4.12",
                                            "matching_string": "the 'channel' prompts so that there is a 2:1 "
                                        },
                                        {
                                            "pdf_id": "4.14",
                                            "matching_string": "ratio of 'channel' to 'direct' instances for training "
                                        },
                                        {
                                            "pdf_id": "4.16",
                                            "matching_string": "improves performance."
                                        },
                                        {
                                            "pdf_id": "4.0",
                                            "matching_string": "DST and DAT modules, as defined in "
                                        },
                                        {
                                            "pdf_id": "4.6",
                                            "matching_string": "training, we shorten our prompts by removing incontext "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 41,
                                    "key": "doc/body/sec3/sub5/txl2",
                                    "block type": "txl",
                                    "content": "After finetuning, the model can be used to produce improved pseudolabels by relabeling each dialogue, using the same noisychannel inference methods. Following this, we can repeat the finetuning process. This train and relabel process can be repeated for any number of iterations, though we find a single relabeling is sufficient.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.18",
                                            "matching_string": "After finetuning, the model can be used to produce "
                                        },
                                        {
                                            "pdf_id": "4.20",
                                            "matching_string": "dialogue, using the same noisychannel inference "
                                        },
                                        {
                                            "pdf_id": "4.21",
                                            "matching_string": "methods. Following this, we can repeat the finetuning "
                                        },
                                        {
                                            "pdf_id": "4.23",
                                            "matching_string": "be repeated for any number of iterations, though "
                                        },
                                        {
                                            "pdf_id": "4.24",
                                            "matching_string": "we find a single relabeling is sufficient."
                                        },
                                        {
                                            "pdf_id": "4.19",
                                            "matching_string": "improved pseudolabels by relabeling each "
                                        },
                                        {
                                            "pdf_id": "4.22",
                                            "matching_string": "process. This train and relabel process can "
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec4",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 42,
                            "key": "doc/body/sec4/tit",
                            "block type": "title",
                            "content": "EndtoEnd System",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "4.25",
                                    "matching_string": "EndtoEnd System"
                                }
                            ]
                        },
                        {
                            "leaf id": 43,
                            "key": "doc/body/sec4/txl0",
                            "block type": "txl",
                            "content": "Following, we utilize a multitask finetuning method for training a single LLM as a complete dialogue system, consisting of a dialogue state tracker, policy, and response generator.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "4.27",
                                    "matching_string": "finetuning method for training a single LLM as a "
                                },
                                {
                                    "pdf_id": "4.28",
                                    "matching_string": "complete dialogue system, consisting of a dialogue "
                                },
                                {
                                    "pdf_id": "4.29",
                                    "matching_string": "state tracker, policy, and response generator."
                                },
                                {
                                    "pdf_id": "4.26",
                                    "matching_string": "Following, we utilize a multitask "
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec4/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 44,
                                    "key": "doc/body/sec4/par1/txl0",
                                    "block type": "txl",
                                    "content": "DST For the DST subtask, we again use both 'direct' and 'channel' (prompt, completion) pairs. This allows us to use the same noisychannel inference method presented in .",
                                    "leftover": ".",
                                    "matches": [
                                        {
                                            "pdf_id": "4.43",
                                            "matching_string": "DST For the DST subtask, we again use both "
                                        },
                                        {
                                            "pdf_id": "4.44",
                                            "matching_string": "'direct' and 'channel' (prompt, completion) pairs. "
                                        },
                                        {
                                            "pdf_id": "4.46",
                                            "matching_string": "This allows us to use the same noisychannel inference "
                                        },
                                        {
                                            "pdf_id": "4.48",
                                            "matching_string": "method presented in "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec4/par2",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 45,
                                    "key": "doc/body/sec4/par2/txl0",
                                    "block type": "txl",
                                    "content": "Policy For the Policy subtask, we use a texttocode prompt where we simply condition on the k=5 most recent utterances in the dialogue history: Ht = (ut2, rt2, ut1, rt1, ut). The completion is the current turn's system acts At, which will be used to ground the next response rt. We do not use a noisychannel variant for Policy, and greedily decode an act prediction at inference time:",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.49",
                                            "matching_string": "Policy For the Policy subtask, we use a texttocode "
                                        },
                                        {
                                            "pdf_id": "4.50",
                                            "matching_string": "prompt where we simply condition on the "
                                        },
                                        {
                                            "pdf_id": "4.51",
                                            "matching_string": "k=5 most recent utterances in the dialogue history: "
                                        },
                                        {
                                            "pdf_id": "4.52",
                                            "matching_string": "Ht = (ut2, rt2, ut1, rt1, ut). The completion "
                                        },
                                        {
                                            "pdf_id": "4.53",
                                            "matching_string": "is the current turn's system acts At, which will be "
                                        },
                                        {
                                            "pdf_id": "4.54",
                                            "matching_string": "used to ground the next response rt. We do not "
                                        },
                                        {
                                            "pdf_id": "4.56",
                                            "matching_string": "decode an act prediction at inference time:"
                                        },
                                        {
                                            "pdf_id": "4.55",
                                            "matching_string": "use a noisychannel variant for Policy, and greedily "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 46,
                                    "key": "doc/body/sec4/par2/frm1",
                                    "block type": "frm",
                                    "content": "t = At ^*argmax At ^* P(fprompt (Ht)))",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.57",
                                            "matching_string": "t = At ^*argmax At ^* P(fprompt (Ht)))"
                                        },
                                        {
                                            "pdf_id": "3.86",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "4.58",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "4.68",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.52",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec4/par3",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 47,
                                    "key": "doc/body/sec4/par3/txl0",
                                    "block type": "txl",
                                    "content": "Response Generation For Response Generation, we condition on the turn's observed system and user utterances (rt1, ut) and our policy's act prediction t). The completion is the observed system response rt. We also do not use a noisychannel variant for response generation, and greedily decode the response:",
                                    "leftover": "t). ",
                                    "matches": [
                                        {
                                            "pdf_id": "4.60",
                                            "matching_string": "Response Generation For Response Generation, "
                                        },
                                        {
                                            "pdf_id": "4.61",
                                            "matching_string": "we condition on the turn's observed system and "
                                        },
                                        {
                                            "pdf_id": "4.62",
                                            "matching_string": "user utterances (rt1, ut) and our policy's act prediction "
                                        },
                                        {
                                            "pdf_id": "4.64",
                                            "matching_string": "response rt. We also do not use a noisychannel "
                                        },
                                        {
                                            "pdf_id": "4.65",
                                            "matching_string": "variant for response generation, and greedily decode "
                                        },
                                        {
                                            "pdf_id": "4.63",
                                            "matching_string": "The completion is the observed system "
                                        },
                                        {
                                            "pdf_id": "4.66",
                                            "matching_string": "the response:"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 48,
                                    "key": "doc/body/sec4/par3/frm1",
                                    "block type": "frm",
                                    "content": "rt = At ^*argmax At ^* P(fprompt (rt1, ut, At)))",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.67",
                                            "matching_string": "rt = At ^*argmax At ^* P(fprompt (rt1, ut, At)))"
                                        },
                                        {
                                            "pdf_id": "5.48",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.49",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.50",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.51",
                                            "matching_string": ""
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 49,
                                    "key": "doc/body/sec4/par3/txl2",
                                    "block type": "txl",
                                    "content": "Following prior works, we predict delexicalized responses, where values for slots in the system response are replaced with placeholders for the slot name. For example, instead of generating ''The phone number for acorn guest house is 5555309\" directly, we would predict ''The phone number for the [hotelname] is [hotelphone]'', where values could be filled in. Importantly, we never presume access to gold delexicalized responses. Instead, we use our predicted acts, e.g. ''Inform(name='acorn guest house', phone='5558309')'', to delexicalize the observed response for training.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.3",
                                            "matching_string": "phone number for acorn guest house is 5555309\" "
                                        },
                                        {
                                            "pdf_id": "4.5",
                                            "matching_string": "directly, we would predict ''The phone number for "
                                        },
                                        {
                                            "pdf_id": "4.9",
                                            "matching_string": "could be filled in. Importantly, we never presume "
                                        },
                                        {
                                            "pdf_id": "4.11",
                                            "matching_string": "access to gold delexicalized responses. Instead, we "
                                        },
                                        {
                                            "pdf_id": "4.13",
                                            "matching_string": "use our predicted acts, e.g. ''Inform(name='acorn "
                                        },
                                        {
                                            "pdf_id": "4.15",
                                            "matching_string": "guest house', phone='5558309')'', to delexicalize "
                                        },
                                        {
                                            "pdf_id": "4.17",
                                            "matching_string": "the observed response for training."
                                        },
                                        {
                                            "pdf_id": "4.92",
                                            "matching_string": "Following prior works, we predict delexicalized "
                                        },
                                        {
                                            "pdf_id": "4.94",
                                            "matching_string": "responses, where values for slots in the system "
                                        },
                                        {
                                            "pdf_id": "4.96",
                                            "matching_string": "response are replaced with placeholders for the slot "
                                        },
                                        {
                                            "pdf_id": "4.1",
                                            "matching_string": "name. For example, instead of generating ''The "
                                        },
                                        {
                                            "pdf_id": "4.7",
                                            "matching_string": "the [hotelname] is [hotelphone]'', where values "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec4/par4",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 50,
                                    "key": "doc/body/sec4/par4/txl0",
                                    "block type": "txl",
                                    "content": "Endtoend Training For each turn, we derive (prompt, completion) pairs for 'direct' and 'channel' DST, and direct Policy, and Response Generation prompts. We then combine and shuffle these pairs into a single training set for joint finetuning. For efficient training, we shorten our prompts by removing incontext examples as well as the function definitions used in the incontext learning setting. We find upsampling the 'channel' prompts so that there is a 2:1 ratio of 'channel' to 'direct' instances for training improves performance. Finally, we finetune StarCoder 3B using crossentropy loss and AdamW with default hyperparameters.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.30",
                                            "matching_string": "Endtoend Training For each turn, we derive "
                                        },
                                        {
                                            "pdf_id": "4.32",
                                            "matching_string": "DST, and direct Policy, and Response Generation "
                                        },
                                        {
                                            "pdf_id": "4.34",
                                            "matching_string": "pairs into a single training set for joint finetuning. "
                                        },
                                        {
                                            "pdf_id": "4.35",
                                            "matching_string": "For efficient training, we shorten our prompts by removing "
                                        },
                                        {
                                            "pdf_id": "4.38",
                                            "matching_string": "We find upsampling the 'channel' prompts so that "
                                        },
                                        {
                                            "pdf_id": "4.39",
                                            "matching_string": "there is a 2:1 ratio of 'channel' to 'direct' instances "
                                        },
                                        {
                                            "pdf_id": "4.40",
                                            "matching_string": "for training improves performance. Finally, we "
                                        },
                                        {
                                            "pdf_id": "4.41",
                                            "matching_string": "finetune StarCoder 3B using crossentropy loss "
                                        },
                                        {
                                            "pdf_id": "4.42",
                                            "matching_string": "and AdamW with default hyperparameters."
                                        },
                                        {
                                            "pdf_id": "4.31",
                                            "matching_string": "(prompt, completion) pairs for 'direct' and 'channel' "
                                        },
                                        {
                                            "pdf_id": "4.33",
                                            "matching_string": "prompts. We then combine and shuffle these "
                                        },
                                        {
                                            "pdf_id": "4.36",
                                            "matching_string": "incontext examples as well as the function "
                                        },
                                        {
                                            "pdf_id": "4.37",
                                            "matching_string": "definitions used in the incontext learning setting. "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 51,
                                    "key": "doc/body/sec4/par4/table*1",
                                    "block type": "table*",
                                    "content": "h!] \\centering \\begin{tabular}{lrrr|rrrr} Model & Schema? & Labels? & Dialogues? & Inform & Success & BLEU & Combined \\multicolumn{8}{c}{Supervised Results} PPTOD & \\cmark & \\cmark & \\cmark & 82.6 & 72.2 & 18.2 & 95.6 DiactTOD & \\cmark & \\cmark & \\cmark & 89.5 & 84.2 & 17.5 & 104.4 Our (supervised) & \\cmark & \\cmark & \\cmark & 67.9 & 61.7 & 14.6 & 79.4 \\multicolumn{8}{c}{ZeroShot with Formatting Example(s)} SGPTODGPT3.5 & \\cmark & Few (\\ddag) & \\xmark & 82.0 & 72.5 & 9.22 & 86.5 \\multicolumn{8}{c}{Fully Unsupervised Results} \\multicolumn{8}{l}{Sees gold delexicalized conversation history} LLaMa\\textsuperscript{\\textdagger} & \\cmark & \\xmark & \\xmark &  & 4 & 1.61 &  GPT 3.5 Turbo\\textsuperscript{\\dag} & \\cmark & \\xmark & \\xmark & 44.8 & 31.2 & 3.3 & 41.3 \\hdashline \\multicolumn{8}{l}{Sees only fullylexicalized dialogues} GPT 3.5 Turbo ( gold delex.) & \\cmark & \\xmark & \\xmark & 40.7 & 26.7 & 3.7 & 37.4 Ours (StarCoder 15B  no EM) & \\cmark & \\xmark & \\xmark & 50.0 & 19.6 & 3.2 & 38 Ours (StarCoder 3B  w/ EM) & \\cmark & \\xmark & \\cmark & 78.1 & 68.3 & 13.6 & 86.8 \\end{tabular} Unsupervised endtoend results in MultiWOZ 2.2. (\\dag) indicates models from . Results for LLaMa are from, which does not report the Inform rate. (\\ddag) SGPTOD uses a prompt with both a formatting example and a ''Policy Skeleton'', which contains an additional 1020 handcrafted instances of the correct system acts and response for an input user utterance or returned DB result. For fairer comparison in our fully unsupervised setting, we rerun the GPT 3.5 baseline without the supervision of delexicalized responses provided in the conversation history ( gold delex.). Despite far fewer parameters, we find substantial improvements in our methods which leverage unlabelled dialogues",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.71",
                                            "matching_string": "h!] \\centering \\begin{tabular}{lrrr|rrrr} Model & Schema? & Labels? & Dialogues? & Inform & Success & BLEU & Combined \\multicolumn{8}{c}{Supervised Results} PPTOD & \\cmark & \\cmark & \\cmark & 82.6 & 72.2 & 18.2 & 95.6 DiactTOD & \\cmark & \\cmark & \\cmark & 89.5 & 84.2 & 17.5 & 104.4 Our (supervised) & \\cmark & \\cmark & \\cmark & 67.9 & 61.7 & 14.6 & 79.4 \\multicolumn{8}{c}{ZeroShot with Formatting Example(s)} SGPTODGPT3.5 & \\cmark & Few (\\ddag) & \\xmark & 82.0 & 72.5 & 9.22 & 86.5 \\multicolumn{8}{c}{Fully Unsupervised Results} \\multicolumn{8}{l}{Sees gold delexicalized conversation history} LLaMa\\textsuperscript{\\textdagger} & \\cmark & \\xmark & \\xmark &  & 4 & 1.61 &  GPT 3.5 Turbo\\textsuperscript{\\dag} & \\cmark & \\xmark & \\xmark & 44.8 & 31.2 & 3.3 & 41.3 \\hdashline \\multicolumn{8}{l}{Sees only fullylexicalized dialogues} GPT 3.5 Turbo ( gold delex.) & \\cmark & \\xmark & \\xmark & 40.7 & 26.7 & 3.7 & 37.4 Ours (StarCoder 15B  no EM) & \\cmark & \\xmark & \\xmark & 50.0 & 19.6 & 3.2 & 38 Ours (StarCoder 3B  w/ EM) & \\cmark & \\xmark & \\cmark & 78.1 & 68.3 & 13.6 & 86.8 \\end{tabular} Unsupervised endtoend results in MultiWOZ 2.2. (\\dag) indicates models from . Results for LLaMa are from, which does not report the Inform rate. (\\ddag) SGPTOD uses a prompt with both a formatting example and a ''Policy Skeleton'', which contains an additional 1020 handcrafted instances of the correct system acts and response for an input user utterance or returned DB result. For fairer comparison in our fully unsupervised setting, we rerun the GPT 3.5 baseline without the supervision of delexicalized responses provided in the conversation history ( gold delex.). Despite far fewer parameters, we find substantial improvements in our methods which leverage unlabelled dialogues"
                                        },
                                        {
                                            "pdf_id": "4.72",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.44",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.45",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.46",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.47",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec5",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 52,
                            "key": "doc/body/sec5/tit",
                            "block type": "title",
                            "content": "Experiments",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "4.45",
                                    "matching_string": "Experiments"
                                }
                            ]
                        },
                        {
                            "leaf id": 53,
                            "key": "doc/body/sec5/txl0",
                            "block type": "txl",
                            "content": "We conduct unsupervised endtoend dialogue (E2E) and dialogue state tracking (DST) experiments on the MultiWOZ 2.2 dataset, containing over ten thousand multidomain taskoriented dialogues crowdsourced in a wizardofoz setup. We use the fully lexicalized, unlabelled dialogues from the training set to build our system, and evaluate on the test set. First, we demonstrate the value of our approach in an endtoend dialogue evaluation, following prior works on taskoriented dialogue (). Second, we conduct a dialogue state tracking evaluation to more carefully evaluate the quality of our pseudoannotations ().",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "4.47",
                                    "matching_string": "We conduct unsupervised endtoend dialogue "
                                },
                                {
                                    "pdf_id": "4.70",
                                    "matching_string": "(E2E) and dialogue state tracking (DST) experiments "
                                },
                                {
                                    "pdf_id": "4.73",
                                    "matching_string": "ten thousand multidomain taskoriented dialogues "
                                },
                                {
                                    "pdf_id": "4.75",
                                    "matching_string": "the fully lexicalized, unlabelled dialogues from the "
                                },
                                {
                                    "pdf_id": "4.77",
                                    "matching_string": "the test set. First, we demonstrate the value of our "
                                },
                                {
                                    "pdf_id": "4.78",
                                    "matching_string": "approach in an endtoend dialogue evaluation, following "
                                },
                                {
                                    "pdf_id": "4.81",
                                    "matching_string": "evaluation to more carefully evaluate the quality of "
                                },
                                {
                                    "pdf_id": "4.74",
                                    "matching_string": "crowdsourced in a wizardofoz setup. We use "
                                },
                                {
                                    "pdf_id": "4.76",
                                    "matching_string": "training set to build our system, and evaluate on "
                                },
                                {
                                    "pdf_id": "4.80",
                                    "matching_string": "Second, we conduct a dialogue state tracking "
                                },
                                {
                                    "pdf_id": "4.79",
                                    "matching_string": "prior works on taskoriented dialogue ()"
                                },
                                {
                                    "pdf_id": "4.82",
                                    "matching_string": "our pseudoannotations ()"
                                },
                                {
                                    "pdf_id": "5.43",
                                    "matching_string": "on the MultiWOZ 2.2 dataset, containing over . ."
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec5/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 54,
                                    "key": "doc/body/sec5/sub1/tit",
                                    "block type": "title",
                                    "content": "EndtoEnd (E2E) Experiments",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.83",
                                            "matching_string": "EndtoEnd (E2E) Experiments"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 55,
                                    "key": "doc/body/sec5/sub1/txl0",
                                    "block type": "txl",
                                    "content": "In E2E experiments, we use our complete system to both predict API call arguments and generate a next system response in natural language. We evaluate our generated responses with Inform rate, Success rate, and BLEU, as well as a Combined score of 0.5(Inform + Success) + BLEU, following prior works. We provide details on these metrics in .",
                                    "leftover": ".",
                                    "matches": [
                                        {
                                            "pdf_id": "4.84",
                                            "matching_string": "In E2E experiments, we use our complete system "
                                        },
                                        {
                                            "pdf_id": "4.85",
                                            "matching_string": "to both predict API call arguments and generate "
                                        },
                                        {
                                            "pdf_id": "4.86",
                                            "matching_string": "a next system response in natural language. We "
                                        },
                                        {
                                            "pdf_id": "4.87",
                                            "matching_string": "evaluate our generated responses with Inform rate, "
                                        },
                                        {
                                            "pdf_id": "4.88",
                                            "matching_string": "Success rate, and BLEU, as well as a Combined "
                                        },
                                        {
                                            "pdf_id": "4.89",
                                            "matching_string": "score of 0.5(Inform + Success) + BLEU, following "
                                        },
                                        {
                                            "pdf_id": "4.90",
                                            "matching_string": "prior works. We provide details on these metrics "
                                        },
                                        {
                                            "pdf_id": "4.91",
                                            "matching_string": "in "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 56,
                                    "key": "doc/body/sec5/sub1/txl1",
                                    "block type": "txl",
                                    "content": "We compare our approach to the previous stateoftheart unsupervised methods, a GPT3.5 zeroshot baseline, and SGPTOD . Where possible, we report results for both the original approach and modifications required to fit our fully unsupervised setting. For reference, we also run our own method in the fullysupervised setting. We train a model using the procedure in using the annotations sourced from crowdworkers in the MultiWOZ 2.2 corpus, rather than the pseudolabels predicted in . We also compare with existing supervised approaches as a reference point. We include DiactTOD, which to our knowledge is the supervised stateoftheart, and PPTOD, which uses a multitask finetuning approach similar to our own in, for T5 encoderdecoder models .",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "4.93",
                                            "matching_string": "We compare our approach to the previous stateoftheart "
                                        },
                                        {
                                            "pdf_id": "5.23",
                                            "matching_string": "we report results for both the original approach "
                                        },
                                        {
                                            "pdf_id": "5.24",
                                            "matching_string": "and modifications required to fit our fully unsupervised "
                                        },
                                        {
                                            "pdf_id": "5.26",
                                            "matching_string": "own method in the fullysupervised setting. We "
                                        },
                                        {
                                            "pdf_id": "5.28",
                                            "matching_string": "annotations sourced from crowdworkers in the "
                                        },
                                        {
                                            "pdf_id": "5.32",
                                            "matching_string": "supervised approaches as a reference point. We "
                                        },
                                        {
                                            "pdf_id": "4.95",
                                            "matching_string": "unsupervised methods, a GPT3.5 zeroshot "
                                        },
                                        {
                                            "pdf_id": "5.34",
                                            "matching_string": "knowledge is the supervised stateoftheart, and "
                                        },
                                        {
                                            "pdf_id": "5.27",
                                            "matching_string": "train a model using the procedure in using the "
                                        },
                                        {
                                            "pdf_id": "5.31",
                                            "matching_string": "predicted in . We also compare with existing "
                                        },
                                        {
                                            "pdf_id": "5.36",
                                            "matching_string": "finetuning approach similar to our own in, for "
                                        },
                                        {
                                            "pdf_id": "5.25",
                                            "matching_string": "setting. For reference, we also run our "
                                        },
                                        {
                                            "pdf_id": "5.53",
                                            "matching_string": "baseline, and SGPTOD . Where possible, MultiWOZ 2.2 corpus, rather than the pseudolabels include DiactTOD, which to our PPTOD, which uses a multitask T5 encoderdecoder models ."
                                        },
                                        {
                                            "pdf_id": "4.97",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.22",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.29",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.30",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.33",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.35",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.37",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec5/sub2",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 57,
                                    "key": "doc/body/sec5/sub2/tit",
                                    "block type": "title",
                                    "content": "DST Experiments",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "5.38",
                                            "matching_string": "DST Experiments"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 58,
                                    "key": "doc/body/sec5/sub2/txl0",
                                    "block type": "txl",
                                    "content": "We conduct multidomain DST experiments on the MultiWOZ Dataset in order to evaluate the quality of our pseudoannotations. We use our DST Module to predict and evaluate only latent dialogue states, which collect the arguments required for unseen API calls.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "5.39",
                                            "matching_string": "We conduct multidomain DST experiments on the "
                                        },
                                        {
                                            "pdf_id": "5.40",
                                            "matching_string": "MultiWOZ Dataset in order to evaluate the quality "
                                        },
                                        {
                                            "pdf_id": "5.42",
                                            "matching_string": "Module to predict and evaluate only latent dialogue "
                                        },
                                        {
                                            "pdf_id": "5.62",
                                            "matching_string": "states, which collect the arguments required for "
                                        },
                                        {
                                            "pdf_id": "5.64",
                                            "matching_string": "unseen API calls."
                                        },
                                        {
                                            "pdf_id": "5.41",
                                            "matching_string": "of our pseudoannotations. We use our DST "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 59,
                                    "key": "doc/body/sec5/sub2/txl1",
                                    "block type": "txl",
                                    "content": "Following prior works, we evaluate DST performance with jointgoal accuracy (JGA), or whether a given dialogue state is completely accurate. More details are available in .",
                                    "leftover": ".",
                                    "matches": [
                                        {
                                            "pdf_id": "5.66",
                                            "matching_string": "Following prior works, we evaluate DST performance "
                                        },
                                        {
                                            "pdf_id": "5.70",
                                            "matching_string": "a given dialogue state is completely accurate. More "
                                        },
                                        {
                                            "pdf_id": "5.68",
                                            "matching_string": "with jointgoal accuracy (JGA), or whether "
                                        },
                                        {
                                            "pdf_id": "5.72",
                                            "matching_string": "details are available in "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 60,
                                    "key": "doc/body/sec5/sub2/txl2",
                                    "block type": "txl",
                                    "content": "We compare to our ChatGPT 3.5 Turbo baseline, as well as prior zeroshot DST methods. These include ICDST, which reframes DST as texttoSQL, and RefPyDST which reframes DST as texttopython . By default, both of these works use OpenAI Codex, and we apply their prompting approaches to StarCoder 15B for clearer comparison.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "5.56",
                                            "matching_string": "and RefPyDST which reframes DST as texttopython "
                                        },
                                        {
                                            "pdf_id": "5.60",
                                            "matching_string": "StarCoder 15B for clearer comparison."
                                        },
                                        {
                                            "pdf_id": "5.59",
                                            "matching_string": "and we apply their prompting approaches to "
                                        },
                                        {
                                            "pdf_id": "5.74",
                                            "matching_string": "We compare to our ChatGPT 3.5 Turbo "
                                        },
                                        {
                                            "pdf_id": "5.78",
                                            "matching_string": "DST methods. These include "
                                        },
                                        {
                                            "pdf_id": "5.55",
                                            "matching_string": "which reframes DST as texttoSQL, "
                                        },
                                        {
                                            "pdf_id": "5.57",
                                            "matching_string": "baseline, as well as prior zeroshot ICDST, . By default, both of these works use OpenAI Codex, "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 61,
                                    "key": "doc/body/sec5/sub2/table3",
                                    "block type": "table",
                                    "content": "] \\centering \\resizebox{\\columnwidth}{!}{ \\begin{tabular}{l|r} \\multicolumn{2}{c}{With One Formatting Example} ICDST (StarCoder 15B) & 24.58 RefPyDST (StarCoder 15B) & 17.17 ICDST (Codex) & 35.02 RefPyDST (Codex) & 40.88 \\multicolumn{2}{c}{Fully Unsupervised} ICDST (StarCoder 15B) & 15.66 RefPyDST (StarCoder 15B) & 13.88 GPT 3.5 Turbo & 13.05 Ours (StarCoder 15B  3B) & 39.70 \\end{tabular} } Joint Goal Accuracy (JGA) of our method's dialogue state predictions and zeroshot baselines",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "5.15",
                                            "matching_string": "] \\centering \\resizebox{\\columnwidth}{!}{ \\begin{tabular}{l|r} \\multicolumn{2}{c}{With One Formatting Example} ICDST (StarCoder 15B) & 24.58 RefPyDST (StarCoder 15B) & 17.17 ICDST (Codex) & 35.02 RefPyDST (Codex) & 40.88 \\multicolumn{2}{c}{Fully Unsupervised} ICDST (StarCoder 15B) & 15.66 RefPyDST (StarCoder 15B) & 13.88 GPT 3.5 Turbo & 13.05 Ours (StarCoder 15B  3B) & 39.70 \\end{tabular} } Joint Goal Accuracy (JGA) of our method's dialogue state predictions and zeroshot baselines"
                                        },
                                        {
                                            "pdf_id": "5.16",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.18",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.19",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.20",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.21",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "5.76",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "6.24",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "6.25",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "6.26",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "15.30",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "15.31",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec6",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 62,
                            "key": "doc/body/sec6/tit",
                            "block type": "title",
                            "content": "Results",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "5.61",
                                    "matching_string": "Results"
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec6/par0",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 63,
                                    "key": "doc/body/sec6/par0/txl0",
                                    "block type": "txl",
                                    "content": "E2E Performance We present E2E results for our unsupervised dialogue agent in . We find that our method achieves stateoftheart performance in our fully unsupervised setting, more than doubling the Success Rate and Combined score of the GPT 3.5 Turbo baseline of . When we remove the supervision of delexicalization for fairer comparison ( gold delex.), we find even greater improvement across all endtoend metrics. As discussed in, SGPTOD uses both a supervised formatting example and a 'Policy Skeleton', containing additional supervision for Policy and Response Generation. With no implementation publicly available, we were unable to run a modified version of their experiments without this supervision for fair comparison. Despite a lesssupervised setting, our method is able to perform comparably, even slightly outperforming SGPTOD in Combined score. Remarkably, our unsupervised EM approach also outperforms the supervised variant of our model due to improvements in Inform and Success rate, suggesting the Dialogue acts we infer are of high quality.",
                                    "leftover": ". in, ",
                                    "matches": [
                                        {
                                            "pdf_id": "5.67",
                                            "matching_string": "find that our method achieves stateoftheart performance "
                                        },
                                        {
                                            "pdf_id": "5.71",
                                            "matching_string": "than doubling the Success Rate and Combined "
                                        },
                                        {
                                            "pdf_id": "5.77",
                                            "matching_string": "of delexicalization for fairer comparison ( "
                                        },
                                        {
                                            "pdf_id": "6.2",
                                            "matching_string": "example and a 'Policy Skeleton', containing additional "
                                        },
                                        {
                                            "pdf_id": "6.4",
                                            "matching_string": "With no implementation publicly available, "
                                        },
                                        {
                                            "pdf_id": "6.6",
                                            "matching_string": "of their experiments without this supervision for "
                                        },
                                        {
                                            "pdf_id": "6.7",
                                            "matching_string": "fair comparison. Despite a lesssupervised setting, "
                                        },
                                        {
                                            "pdf_id": "6.9",
                                            "matching_string": "even slightly outperforming SGPTOD in Combined "
                                        },
                                        {
                                            "pdf_id": "6.12",
                                            "matching_string": "of our model due to improvements in Inform and "
                                        },
                                        {
                                            "pdf_id": "6.13",
                                            "matching_string": "Success rate, suggesting the Dialogue acts we infer "
                                        },
                                        {
                                            "pdf_id": "6.14",
                                            "matching_string": "are of high quality."
                                        },
                                        {
                                            "pdf_id": "5.69",
                                            "matching_string": "in our fully unsupervised setting, more "
                                        },
                                        {
                                            "pdf_id": "5.73",
                                            "matching_string": "score of the GPT 3.5 Turbo baseline of "
                                        },
                                        {
                                            "pdf_id": "5.79",
                                            "matching_string": "gold delex.), we find even greater improvement "
                                        },
                                        {
                                            "pdf_id": "6.11",
                                            "matching_string": "approach also outperforms the supervised variant "
                                        },
                                        {
                                            "pdf_id": "6.0",
                                            "matching_string": "across all endtoend metrics. As discussed "
                                        },
                                        {
                                            "pdf_id": "6.1",
                                            "matching_string": "SGPTOD uses both a supervised formatting "
                                        },
                                        {
                                            "pdf_id": "6.3",
                                            "matching_string": "supervision for Policy and Response Generation. "
                                        },
                                        {
                                            "pdf_id": "6.5",
                                            "matching_string": "we were unable to run a modified version "
                                        },
                                        {
                                            "pdf_id": "6.8",
                                            "matching_string": "our method is able to perform comparably, "
                                        },
                                        {
                                            "pdf_id": "5.63",
                                            "matching_string": "E2E Performance We present E2E results for "
                                        },
                                        {
                                            "pdf_id": "5.65",
                                            "matching_string": "our unsupervised dialogue agent in . We "
                                        },
                                        {
                                            "pdf_id": "5.75",
                                            "matching_string": "When we remove the supervision "
                                        },
                                        {
                                            "pdf_id": "6.10",
                                            "matching_string": "score. Remarkably, our unsupervised EM "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec6/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 64,
                                    "key": "doc/body/sec6/par1/txl0",
                                    "block type": "txl",
                                    "content": "DST Performance Our DST results are shown in . Where possible, we distinguish between 'zeroshot' results which include a handengineered formatting example, and the same method applied without the formatting example.Due to the deprecation of OpenAI Codex, we were unable to run experiments for ICDST or RefPyDST without a formatting example on the original Codex model We find that our method significantly outperforms our GPT 3.5 Turbo baseline by 26% joint goal accuracy. Our approach performs nearly as well as the best method using OpenAI Codex with a supervised formatting example, using less than 10% of the parameters at any time (175B vs. 15B). When applying the ICDST and RefPyDST prompting methods to StarCoder, our method significantly outperforms both, with and without a formatting example.",
                                    "leftover": ". ",
                                    "matches": [
                                        {
                                            "pdf_id": "6.17",
                                            "matching_string": "'zeroshot' results which include a handengineered "
                                        },
                                        {
                                            "pdf_id": "6.27",
                                            "matching_string": "our method significantly outperforms our GPT 3.5 "
                                        },
                                        {
                                            "pdf_id": "6.29",
                                            "matching_string": "Turbo baseline by 26% joint goal accuracy. Our approach "
                                        },
                                        {
                                            "pdf_id": "6.31",
                                            "matching_string": "using OpenAI Codex with a supervised formatting "
                                        },
                                        {
                                            "pdf_id": "6.32",
                                            "matching_string": "example, using less than 10% of the parameters "
                                        },
                                        {
                                            "pdf_id": "6.33",
                                            "matching_string": "at any time (175B vs. 15B). When applying the "
                                        },
                                        {
                                            "pdf_id": "6.37",
                                            "matching_string": "ICDST and RefPyDST prompting methods to StarCoder, "
                                        },
                                        {
                                            "pdf_id": "6.41",
                                            "matching_string": "with and without a formatting example."
                                        },
                                        {
                                            "pdf_id": "6.78",
                                            "matching_string": "to run experiments for ICDST or RefPyDST without a "
                                        },
                                        {
                                            "pdf_id": "6.79",
                                            "matching_string": "formatting example on the original Codex model "
                                        },
                                        {
                                            "pdf_id": "6.15",
                                            "matching_string": "DST Performance Our DST results are shown in "
                                        },
                                        {
                                            "pdf_id": "6.18",
                                            "matching_string": "formatting example, and the same method applied "
                                        },
                                        {
                                            "pdf_id": "6.77",
                                            "matching_string": "to the deprecation of OpenAI Codex, we were unable "
                                        },
                                        {
                                            "pdf_id": "6.19",
                                            "matching_string": "without the formatting example.Due We find that "
                                        },
                                        {
                                            "pdf_id": "6.30",
                                            "matching_string": "performs nearly as well as the best method "
                                        },
                                        {
                                            "pdf_id": "6.16",
                                            "matching_string": "Where possible, we distinguish between "
                                        },
                                        {
                                            "pdf_id": "6.39",
                                            "matching_string": "our method significantly outperforms both, "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec6/par2",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 65,
                                    "key": "doc/body/sec6/par2/txl0",
                                    "block type": "txl",
                                    "content": "Ablations In, we conduct an ablation to evaluate both the impact of our noisy channel modeling and the value of iterative relabeling in our EM approach. We compare our proposed system to one in which each module is replaced by only greedily sampling from its 'direct' variant, at both labeling and endtoend inference time. We plot our Combined endtoend performance across iterations of EM, with '0' indicating our zeroshot system. We find that EM improves our endtoend performance in both our noisychannel approach and greedy ablation, and that our noisychannel inference methods are important to dialogue success, with a 30 and 33 point improvement over our greedy baseline with 1 and 2 EM steps, respectively. Ablations across Inform, Success, BLEU, and joint goal accuracy are in .",
                                    "leftover": ".",
                                    "matches": [
                                        {
                                            "pdf_id": "6.43",
                                            "matching_string": "evaluate both the impact of our noisy channel modeling "
                                        },
                                        {
                                            "pdf_id": "6.46",
                                            "matching_string": "to one in which each module is replaced by only "
                                        },
                                        {
                                            "pdf_id": "6.47",
                                            "matching_string": "greedily sampling from its 'direct' variant, at both "
                                        },
                                        {
                                            "pdf_id": "6.49",
                                            "matching_string": "our Combined endtoend performance across iterations "
                                        },
                                        {
                                            "pdf_id": "6.51",
                                            "matching_string": "system. We find that EM improves our endtoend "
                                        },
                                        {
                                            "pdf_id": "6.53",
                                            "matching_string": "and greedy ablation, and that our noisychannel "
                                        },
                                        {
                                            "pdf_id": "6.70",
                                            "matching_string": "with a 30 and 33 point improvement over our "
                                        },
                                        {
                                            "pdf_id": "6.72",
                                            "matching_string": "greedy baseline with 1 and 2 EM steps, respectively. "
                                        },
                                        {
                                            "pdf_id": "6.74",
                                            "matching_string": "Ablations across Inform, Success, BLEU, and joint "
                                        },
                                        {
                                            "pdf_id": "6.44",
                                            "matching_string": "and the value of iterative relabeling in our "
                                        },
                                        {
                                            "pdf_id": "6.45",
                                            "matching_string": "EM approach. We compare our proposed system "
                                        },
                                        {
                                            "pdf_id": "6.48",
                                            "matching_string": "labeling and endtoend inference time. We plot "
                                        },
                                        {
                                            "pdf_id": "6.52",
                                            "matching_string": "performance in both our noisychannel approach "
                                        },
                                        {
                                            "pdf_id": "6.68",
                                            "matching_string": "inference methods are important to dialogue success, "
                                        },
                                        {
                                            "pdf_id": "6.50",
                                            "matching_string": "of EM, with '0' indicating our zeroshot "
                                        },
                                        {
                                            "pdf_id": "6.76",
                                            "matching_string": "goal accuracy are in "
                                        },
                                        {
                                            "pdf_id": "6.42",
                                            "matching_string": "Ablations In, we conduct an ablation to "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 66,
                                    "key": "doc/body/sec6/par2/figure1",
                                    "block type": "figure",
                                    "content": "\\centering \\includegraphics[width=\\columnwidth]{imgs/stepplotsv3/combinedvssteps.png} Combined score (0.5(Inform + Success) + BLEU) vs. the number of steps of expectationmaximization in our Noisy Channel method vs. a Greedy Ablation. '0' is zeroshot inference",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "6.22",
                                            "matching_string": "in our Noisy Channel method vs. a "
                                        },
                                        {
                                            "pdf_id": "6.23",
                                            "matching_string": "Greedy Ablation. '0' is zeroshot inference"
                                        },
                                        {
                                            "pdf_id": "6.20",
                                            "matching_string": "Combined score (0.5(Inform + Success) + "
                                        },
                                        {
                                            "pdf_id": "6.21",
                                            "matching_string": "vs. the number of steps of expectationmaximization "
                                        },
                                        {
                                            "pdf_id": "6.28",
                                            "matching_string": "\\centering \\includegraphics[width=\\columnwidth]{imgs/stepplotsv3/combinedvssteps.png} BLEU) "
                                        },
                                        {
                                            "pdf_id": "6.35",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec7",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 67,
                            "key": "doc/body/sec7/tit",
                            "block type": "title",
                            "content": "Contamination Analysis",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "6.36",
                                    "matching_string": "Contamination Analysis"
                                }
                            ]
                        },
                        {
                            "leaf id": 68,
                            "key": "doc/body/sec7/txl0",
                            "block type": "txl",
                            "content": "Evaluation of unsupervised methods, such as ours, that use LLMs has the potential issue of task contamination, where supervised examples are seen in pretraining data . Inclusion of supervised examples of the task in LLM pretraining data would render the model no longer unsupervised and the evaluation potentially biased: tasks for which the training data has been seen may have a higher performance than truly unsupervised tasks.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "6.38",
                                    "matching_string": "Evaluation of unsupervised methods, such as ours, "
                                },
                                {
                                    "pdf_id": "6.40",
                                    "matching_string": "that use LLMs has the potential issue of task contamination, "
                                },
                                {
                                    "pdf_id": "6.56",
                                    "matching_string": "of supervised examples of the task in LLM "
                                },
                                {
                                    "pdf_id": "6.58",
                                    "matching_string": "unsupervised and the evaluation potentially biased: "
                                },
                                {
                                    "pdf_id": "6.59",
                                    "matching_string": "tasks for which the training data has been seen may "
                                },
                                {
                                    "pdf_id": "6.60",
                                    "matching_string": "have a higher performance than truly unsupervised "
                                },
                                {
                                    "pdf_id": "6.61",
                                    "matching_string": "tasks."
                                },
                                {
                                    "pdf_id": "6.54",
                                    "matching_string": "where supervised examples are seen "
                                },
                                {
                                    "pdf_id": "6.57",
                                    "matching_string": "pretraining data would render the model no longer "
                                },
                                {
                                    "pdf_id": "6.55",
                                    "matching_string": "in pretraining data . Inclusion "
                                }
                            ]
                        },
                        {
                            "leaf id": 69,
                            "key": "doc/body/sec7/txl1",
                            "block type": "txl",
                            "content": "To address this issue, we quantify the presence of contamination in LLM pretraining data, and then estimate the potential impact on our results. Fortunately, the StarCoder family of models that we use has the complete pretraining corpus publicly available for analysis.https://huggingface.co/datasets/bigcode/starcoderdata",
                            "leftover": "ttps://",
                            "matches": [
                                {
                                    "pdf_id": "6.62",
                                    "matching_string": "To address this issue, we quantify the presence "
                                },
                                {
                                    "pdf_id": "6.63",
                                    "matching_string": "of contamination in LLM pretraining data, and "
                                },
                                {
                                    "pdf_id": "6.64",
                                    "matching_string": "then estimate the potential impact on our results. "
                                },
                                {
                                    "pdf_id": "6.65",
                                    "matching_string": "Fortunately, the StarCoder family of models that we "
                                },
                                {
                                    "pdf_id": "6.66",
                                    "matching_string": "use has the complete pretraining corpus publicly "
                                },
                                {
                                    "pdf_id": "6.67",
                                    "matching_string": "available for analysis.h"
                                },
                                {
                                    "pdf_id": "6.83",
                                    "matching_string": "huggingface.co/datasets/bigcode/starcoderdata"
                                }
                            ]
                        },
                        {
                            "leaf id": 70,
                            "key": "doc/body/sec7/table2",
                            "block type": "table",
                            "content": "] \\centering \\begin{tabular}{l|r:rr} Task & Turns & Correct & Authentic Act Tagging & 42 & 21 & 5 DST & 42 & 36 & 19 \\end{tabular} Number of discovered contaminated turns per task, as well as the number which are correct or verified as being in the MultiWOZ dataset.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "7.47",
                                    "matching_string": "] \\centering \\begin{tabular}{l|r:rr} Task & Turns & Correct & Authentic Act Tagging & 42 & 21 & 5 DST & 42 & 36 & 19 \\end{tabular} Number of discovered contaminated turns per task, as well as the number which are correct or verified as being in the MultiWOZ dataset."
                                },
                                {
                                    "pdf_id": "7.37",
                                    "matching_string": ""
                                }
                            ]
                        },
                        {
                            "leaf id": 71,
                            "key": "doc/body/sec7/txl3",
                            "block type": "txl",
                            "content": "We conduct an exhaustive search for supervised pairs of our dialogue subtasks in the StarCoder pretraining data using a semiautomated search with manual review. Details of our search procedure are in . We find no complete dialogues with supervised labels. We do find 42 turns labeled with act tagging, and 42 turns labeled with DST in the pretraining corpus, categorized in .The average dialogue length in MultiWOZ is 13.9 turns. Put together, the set of contaminated turns would be roughly the length of 6 dialogues We consider a (x, y) pair to be 'Correct' if the state change/dialogue act y is actually correct for the utterance x, and to be 'Authentic' if the (x,y) pair is found verbatim in the MultiWOZ corpus.A 'Correct' pair might arise from printing training data, and an incorrect pair from discussion of a failure case. Astonishingly, we find half of the found Act Tagging pairs are incorrect, and could possibly mislead a pretrained model if the model learned from them. We also find that less than half of the turns are authentic for either task, and find a number of them derive from Github issues discussing problems with dialogue simulators.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "6.73",
                                    "matching_string": "data using a semiautomated search with "
                                },
                                {
                                    "pdf_id": "7.1",
                                    "matching_string": "consider a (x, y) pair to be 'Correct' if the state "
                                },
                                {
                                    "pdf_id": "7.2",
                                    "matching_string": "change/dialogue act y is actually correct for the "
                                },
                                {
                                    "pdf_id": "7.3",
                                    "matching_string": "utterance x, and to be 'Authentic' if the (x,y) pair "
                                },
                                {
                                    "pdf_id": "7.5",
                                    "matching_string": "we find half of the found Act Tagging "
                                },
                                {
                                    "pdf_id": "7.6",
                                    "matching_string": "pairs are incorrect, and could possibly mislead a "
                                },
                                {
                                    "pdf_id": "7.7",
                                    "matching_string": "pretrained model if the model learned from them. "
                                },
                                {
                                    "pdf_id": "7.8",
                                    "matching_string": "We also find that less than half of the turns are authentic "
                                },
                                {
                                    "pdf_id": "7.10",
                                    "matching_string": "derive from Github issues discussing problems with "
                                },
                                {
                                    "pdf_id": "7.11",
                                    "matching_string": "dialogue simulators."
                                },
                                {
                                    "pdf_id": "7.88",
                                    "matching_string": "Put together, the set of contaminated turns would be roughly "
                                },
                                {
                                    "pdf_id": "7.89",
                                    "matching_string": "the length of 6 dialogues "
                                },
                                {
                                    "pdf_id": "7.91",
                                    "matching_string": "and an incorrect pair from discussion of a failure case. "
                                },
                                {
                                    "pdf_id": "6.69",
                                    "matching_string": "We conduct an exhaustive search for supervised "
                                },
                                {
                                    "pdf_id": "6.75",
                                    "matching_string": "manual review. Details of our search procedure are "
                                },
                                {
                                    "pdf_id": "6.81",
                                    "matching_string": "supervised labels. We do find 42 turns labeled with "
                                },
                                {
                                    "pdf_id": "7.90",
                                    "matching_string": "'Correct' pair might arise from printing training data, "
                                },
                                {
                                    "pdf_id": "7.4",
                                    "matching_string": "is found verbatim in the MultiWOZ corpus.A Astonishingly, "
                                },
                                {
                                    "pdf_id": "7.9",
                                    "matching_string": "for either task, and find a number of them "
                                },
                                {
                                    "pdf_id": "7.86",
                                    "matching_string": "average dialogue length in MultiWOZ is 13.9 turns. "
                                },
                                {
                                    "pdf_id": "7.0",
                                    "matching_string": "pretraining corpus, categorized in .The We "
                                },
                                {
                                    "pdf_id": "6.71",
                                    "matching_string": "pairs of our dialogue subtasks in the StarCoder pretraining "
                                },
                                {
                                    "pdf_id": "6.80",
                                    "matching_string": "in . We find no complete dialogues with "
                                },
                                {
                                    "pdf_id": "6.82",
                                    "matching_string": "act tagging, and 42 turns labeled with DST in the "
                                }
                            ]
                        },
                        {
                            "leaf id": 72,
                            "key": "doc/body/sec7/txl4",
                            "block type": "txl",
                            "content": "Additionally, we estimate the degree to which the contamination we discover could exaggerate expected performance of our method on an unseen schema, by using contaminated (x, y) pairs as incontext examples.Ideally, one would pretrain an identical StarCoder model on a corpus without contamination, this is computationally impractical. Additionally, we are not aware of any available LLM that can be verified as not contaminated for this task.",
                            "leftover": "deally, ",
                            "matches": [
                                {
                                    "pdf_id": "7.12",
                                    "matching_string": "Additionally, we estimate the degree to which "
                                },
                                {
                                    "pdf_id": "7.13",
                                    "matching_string": "the contamination we discover could exaggerate "
                                },
                                {
                                    "pdf_id": "7.14",
                                    "matching_string": "expected performance of our method on an unseen "
                                },
                                {
                                    "pdf_id": "7.15",
                                    "matching_string": "schema, by using contaminated (x, y) pairs as incontext "
                                },
                                {
                                    "pdf_id": "7.93",
                                    "matching_string": "on a corpus without contamination, this is computationally "
                                },
                                {
                                    "pdf_id": "7.94",
                                    "matching_string": "impractical. Additionally, we are not aware of any available "
                                },
                                {
                                    "pdf_id": "7.95",
                                    "matching_string": "LLM that can be verified as not contaminated for this task."
                                },
                                {
                                    "pdf_id": "7.92",
                                    "matching_string": "one would pretrain an identical StarCoder model "
                                },
                                {
                                    "pdf_id": "7.16",
                                    "matching_string": "examples.I"
                                }
                            ]
                        },
                        {
                            "leaf id": 73,
                            "key": "doc/body/sec7/txl5",
                            "block type": "txl",
                            "content": "In, we compare our zeroshot prompt, which receives no examples of any kind, with a 'contaminated' variant which uses k=3 incontext examples derived from contamination in the pretraining corpus. The 'contaminated' model retrieves the most relevant contaminated fragments from a pool using the dense retrieval approach described in . These are inserted as a triplequoted string block, so that the prompt remains syntactically valid python. By leaving contaminated examples in their original format, we test whether their inclusion elicits memorized knowledge rather than providing guidance on input/output formatting. Surprisingly, we find including this supervision via contaminated fragments hurts performance, indicating that these examples do not provide meaningful supervision for our task. Further, the substantial gains in our noisychannel EM approach suggest our method is doing more than simply eliciting schemaspecific knowledge memorized in pretraining.",
                            "leftover": "In, ",
                            "matches": [
                                {
                                    "pdf_id": "7.18",
                                    "matching_string": "which receives no examples of any kind, with a "
                                },
                                {
                                    "pdf_id": "7.20",
                                    "matching_string": "examples derived from contamination in the pretraining "
                                },
                                {
                                    "pdf_id": "7.22",
                                    "matching_string": "the most relevant contaminated fragments "
                                },
                                {
                                    "pdf_id": "7.23",
                                    "matching_string": "from a pool using the dense retrieval approach described "
                                },
                                {
                                    "pdf_id": "7.25",
                                    "matching_string": "string block, so that the prompt remains syntactically "
                                },
                                {
                                    "pdf_id": "7.27",
                                    "matching_string": "examples in their original format, we test whether "
                                },
                                {
                                    "pdf_id": "7.29",
                                    "matching_string": "than providing guidance on input/output formatting. "
                                },
                                {
                                    "pdf_id": "7.30",
                                    "matching_string": "Surprisingly, we find including this supervision via "
                                },
                                {
                                    "pdf_id": "7.31",
                                    "matching_string": "contaminated fragments hurts performance, indicating "
                                },
                                {
                                    "pdf_id": "7.33",
                                    "matching_string": "supervision for our task. Further, the substantial "
                                },
                                {
                                    "pdf_id": "7.35",
                                    "matching_string": "suggest our method is doing more than simply eliciting "
                                },
                                {
                                    "pdf_id": "7.19",
                                    "matching_string": "'contaminated' variant which uses k=3 incontext "
                                },
                                {
                                    "pdf_id": "7.28",
                                    "matching_string": "their inclusion elicits memorized knowledge rather "
                                },
                                {
                                    "pdf_id": "7.32",
                                    "matching_string": "that these examples do not provide meaningful "
                                },
                                {
                                    "pdf_id": "7.21",
                                    "matching_string": "corpus. The 'contaminated' model retrieves "
                                },
                                {
                                    "pdf_id": "7.34",
                                    "matching_string": "gains in our noisychannel EM approach "
                                },
                                {
                                    "pdf_id": "7.36",
                                    "matching_string": "schemaspecific knowledge memorized in pretraining."
                                },
                                {
                                    "pdf_id": "7.17",
                                    "matching_string": "we compare our zeroshot prompt, "
                                },
                                {
                                    "pdf_id": "7.24",
                                    "matching_string": "in . These are inserted as a triplequoted "
                                },
                                {
                                    "pdf_id": "7.26",
                                    "matching_string": "valid python. By leaving contaminated "
                                }
                            ]
                        },
                        {
                            "leaf id": 74,
                            "key": "doc/body/sec7/table6",
                            "block type": "table",
                            "content": "] \\centering \\resizebox{\\columnwidth}{!}{ \\begin{tabular}{l|rrrr} Method & Inform & Success & BLEU & Combined Ours (zeroshot) & 49.0 & 15.0 & 3.0 & 35.0 Ours (k=3 contam ex.) & 44.5 & 14.0 & 3.8 & 33.1 Ours (Full EM) & 80.5 & 69.0 & 13.7 & 88.5 \\end{tabular} } Performance comparison when we include contaminated incontext examples. We find including this supervision hurts performance, and does not explain the strong performance of our noisychannel EM approach",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "5.17",
                                    "matching_string": "] \\centering \\resizebox{\\columnwidth}{!}{ \\begin{tabular}{l|rrrr} Method & Inform & Success & BLEU & Combined Ours (zeroshot) & 49.0 & 15.0 & 3.0 & 35.0 Ours (k=3 contam ex.) & 44.5 & 14.0 & 3.8 & 33.1 Ours (Full EM) & 80.5 & 69.0 & 13.7 & 88.5 \\end{tabular} } Performance comparison when we include contaminated incontext examples. We find including this supervision hurts performance, and does not explain the strong performance of our noisychannel EM approach"
                                },
                                {
                                    "pdf_id": "7.43",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "7.44",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "7.45",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "7.46",
                                    "matching_string": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec8",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 75,
                            "key": "doc/body/sec8/tit",
                            "block type": "title",
                            "content": "Related Work",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "7.38",
                                    "matching_string": "Related Work"
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec8/par0",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 76,
                                    "key": "doc/body/sec8/par0/txl0",
                                    "block type": "txl",
                                    "content": "Zeroshot Dialogue A few recent works have proposed zeroshot approaches to dialogue problems using LLMs. and propose DST methods which prompt code based LLMs in a texttoSQL or texttoprogram format, respectively. These methods rely on prompts tailored to the schema and the use of a supervised 'formatting' example, which requires annotation expertise. extends this approach to endtoend taskoriented dialogue by adding a policy prompter for GPT 3.5. In addition to a formatting example, their policy prompt requires a handcrafted 'policyskeleton' consisting of examples of the appropriate system act and reply in response to different user utterances or database results. Our approach differs in that we require zero labeled examples of any kind. propose a zeroshot endtoend method for prompting instructiontuned LLMs like GPT 3.5. However, this method presumes delexicalized system responses r1 ... rt1 in the conversation history as input, where entities are replaced with placeholders. Producing these inputs requires groundtruth annotations and gives a form of supervision about the entities and their attributes within a dialogue (see for a comparison for GPT 3.5 Turbo with and without delex supervision). In contrast, we only assume fullylexicalized dialogues, which do not provide this supervision and require no human annotation. We adapt the method of to use lexicalized dialogues as inputs, and use this approach as our baseline. propose an endtoend method which prompts GPT4 for interactions with a knowledge base before producing a response, however it generalizes poorly to the multidomain setting.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "7.39",
                                            "matching_string": "Zeroshot Dialogue A few recent works have "
                                        },
                                        {
                                            "pdf_id": "7.40",
                                            "matching_string": "proposed zeroshot approaches to dialogue problems "
                                        },
                                        {
                                            "pdf_id": "7.51",
                                            "matching_string": "prompt code based LLMs in a texttoSQL or texttoprogram "
                                        },
                                        {
                                            "pdf_id": "7.53",
                                            "matching_string": "rely on prompts tailored to the schema and the use "
                                        },
                                        {
                                            "pdf_id": "7.58",
                                            "matching_string": "In addition to a formatting example, their policy "
                                        },
                                        {
                                            "pdf_id": "7.59",
                                            "matching_string": "prompt requires a handcrafted 'policyskeleton' "
                                        },
                                        {
                                            "pdf_id": "7.60",
                                            "matching_string": "consisting of examples of the appropriate system "
                                        },
                                        {
                                            "pdf_id": "7.61",
                                            "matching_string": "act and reply in response to different user utterances "
                                        },
                                        {
                                            "pdf_id": "7.63",
                                            "matching_string": "that we require zero labeled examples of any kind. "
                                        },
                                        {
                                            "pdf_id": "7.65",
                                            "matching_string": "endtoend method for prompting instructiontuned "
                                        },
                                        {
                                            "pdf_id": "7.66",
                                            "matching_string": "LLMs like GPT 3.5. However, this method presumes "
                                        },
                                        {
                                            "pdf_id": "7.68",
                                            "matching_string": "the conversation history as input, where entities are "
                                        },
                                        {
                                            "pdf_id": "7.69",
                                            "matching_string": "replaced with placeholders. Producing these inputs "
                                        },
                                        {
                                            "pdf_id": "7.71",
                                            "matching_string": "of supervision about the entities and their attributes "
                                        },
                                        {
                                            "pdf_id": "7.73",
                                            "matching_string": "for GPT 3.5 Turbo with and without delex supervision). "
                                        },
                                        {
                                            "pdf_id": "7.78",
                                            "matching_string": "dialogues as inputs, and use this approach "
                                        },
                                        {
                                            "pdf_id": "7.80",
                                            "matching_string": "endtoend method which prompts GPT4 for interactions "
                                        },
                                        {
                                            "pdf_id": "7.82",
                                            "matching_string": "a response, however it generalizes poorly to the "
                                        },
                                        {
                                            "pdf_id": "7.83",
                                            "matching_string": "multidomain setting."
                                        },
                                        {
                                            "pdf_id": "7.56",
                                            "matching_string": "extends this approach to endtoend taskoriented "
                                        },
                                        {
                                            "pdf_id": "7.57",
                                            "matching_string": "dialogue by adding a policy prompter for GPT 3.5. "
                                        },
                                        {
                                            "pdf_id": "7.70",
                                            "matching_string": "requires groundtruth annotations and gives a form "
                                        },
                                        {
                                            "pdf_id": "7.74",
                                            "matching_string": "In contrast, we only assume fullylexicalized "
                                        },
                                        {
                                            "pdf_id": "7.75",
                                            "matching_string": "dialogues, which do not provide this supervision "
                                        },
                                        {
                                            "pdf_id": "7.76",
                                            "matching_string": "and require no human annotation. We adapt the "
                                        },
                                        {
                                            "pdf_id": "7.54",
                                            "matching_string": "of a supervised 'formatting' example, which requires "
                                        },
                                        {
                                            "pdf_id": "7.62",
                                            "matching_string": "or database results. Our approach differs in "
                                        },
                                        {
                                            "pdf_id": "7.72",
                                            "matching_string": "within a dialogue (see for a comparison "
                                        },
                                        {
                                            "pdf_id": "7.81",
                                            "matching_string": "with a knowledge base before producing "
                                        },
                                        {
                                            "pdf_id": "7.42",
                                            "matching_string": "and propose DST methods which "
                                        },
                                        {
                                            "pdf_id": "7.52",
                                            "matching_string": "format, respectively. These methods "
                                        },
                                        {
                                            "pdf_id": "7.67",
                                            "matching_string": "delexicalized system responses r1 ... rt1 in "
                                        },
                                        {
                                            "pdf_id": "7.55",
                                            "matching_string": "using LLMs. annotation expertise. propose a zeroshot method of to use lexicalized as our baseline. propose an "
                                        },
                                        {
                                            "pdf_id": "7.41",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "7.64",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "7.77",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec8/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 77,
                                    "key": "doc/body/sec8/par1/txl0",
                                    "block type": "txl",
                                    "content": "Semisupervised TOD Some works propose semisupervised approaches to endtoend taskoriented dialogue. propose an endtoend sequencetosequence model where the dialogue state is a latent variable. adapt this approach for use with pretrained language models, finetuning GPT2. While successful, these approaches require a nontrivial amount of supervised data. Other semisupervised works also evaluate their method in an unsupervised setting . However, these works also assume delexicalized training dialogues, which requires groundtruth annotation and gives a form a supervision to the model.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "7.85",
                                            "matching_string": "semisupervised approaches to endtoend taskoriented "
                                        },
                                        {
                                            "pdf_id": "7.96",
                                            "matching_string": "endtoend sequencetosequence model where the "
                                        },
                                        {
                                            "pdf_id": "7.98",
                                            "matching_string": "adapt this approach for use with pretrained language "
                                        },
                                        {
                                            "pdf_id": "7.100",
                                            "matching_string": "these approaches require a nontrivial amount "
                                        },
                                        {
                                            "pdf_id": "8.0",
                                            "matching_string": "also evaluate their method in an unsupervised setting "
                                        },
                                        {
                                            "pdf_id": "8.3",
                                            "matching_string": "these works also assume delexicalized training dialogues, "
                                        },
                                        {
                                            "pdf_id": "8.5",
                                            "matching_string": "gives a form a supervision to the model."
                                        },
                                        {
                                            "pdf_id": "7.101",
                                            "matching_string": "of supervised data. Other semisupervised works "
                                        },
                                        {
                                            "pdf_id": "7.84",
                                            "matching_string": "Semisupervised TOD Some works propose "
                                        },
                                        {
                                            "pdf_id": "7.99",
                                            "matching_string": "models, finetuning GPT2. While successful, "
                                        },
                                        {
                                            "pdf_id": "8.4",
                                            "matching_string": "which requires groundtruth annotation and "
                                        },
                                        {
                                            "pdf_id": "7.79",
                                            "matching_string": "dialogue. propose an dialogue state is a latent variable. . However, "
                                        },
                                        {
                                            "pdf_id": "7.97",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "8.2",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec8/par2",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 78,
                                    "key": "doc/body/sec8/par2/txl0",
                                    "block type": "txl",
                                    "content": "Noisy channel and reranking methods A few previous works have utilized noisy channel methods for taskoriented dialogue or prompting methods. pretrain a noisy channel for taskoriented dialogues as a sequence to sequence model, however their method requires significant labelled training data. propose noisy channel prompting for fewshot classification tasks, which inspires our generalization to the generative setting.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "8.6",
                                            "matching_string": "Noisy channel and reranking methods A few "
                                        },
                                        {
                                            "pdf_id": "8.7",
                                            "matching_string": "previous works have utilized noisy channel methods "
                                        },
                                        {
                                            "pdf_id": "8.10",
                                            "matching_string": "taskoriented dialogues as a sequence to sequence "
                                        },
                                        {
                                            "pdf_id": "8.11",
                                            "matching_string": "model, however their method requires significant "
                                        },
                                        {
                                            "pdf_id": "8.13",
                                            "matching_string": "noisy channel prompting for fewshot classification "
                                        },
                                        {
                                            "pdf_id": "8.15",
                                            "matching_string": "generative setting."
                                        },
                                        {
                                            "pdf_id": "8.8",
                                            "matching_string": "for taskoriented dialogue or prompting methods. "
                                        },
                                        {
                                            "pdf_id": "8.14",
                                            "matching_string": "tasks, which inspires our generalization to the "
                                        },
                                        {
                                            "pdf_id": "7.87",
                                            "matching_string": "pretrain a noisy channel for labelled training data. propose "
                                        },
                                        {
                                            "pdf_id": "8.9",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "8.12",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec9",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 79,
                            "key": "doc/body/sec9/tit",
                            "block type": "title",
                            "content": "Conclusion",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "8.16",
                                    "matching_string": "Conclusion"
                                }
                            ]
                        },
                        {
                            "leaf id": 80,
                            "key": "doc/body/sec9/txl0",
                            "block type": "txl",
                            "content": "We present a novel approach for constructing an endtoend taskoriented dialogue system by leveraging pretrained language models to infer labels from unlabeled dialogues.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "8.17",
                                    "matching_string": "We present a novel approach for constructing an "
                                },
                                {
                                    "pdf_id": "8.18",
                                    "matching_string": "endtoend taskoriented dialogue system by leveraging "
                                },
                                {
                                    "pdf_id": "8.20",
                                    "matching_string": "from unlabeled dialogues."
                                },
                                {
                                    "pdf_id": "8.19",
                                    "matching_string": "pretrained language models to infer labels "
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec10",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 81,
                            "key": "doc/body/sec10/tit",
                            "block type": "title",
                            "content": "Limitations",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "8.21",
                                    "matching_string": "Limitations"
                                }
                            ]
                        },
                        {
                            "leaf id": 82,
                            "key": "doc/body/sec10/txl0",
                            "block type": "txl",
                            "content": "Data contamination in LLM pretraining poses a hurdle for accurate benchmarking across NLP, and particularly for unsupervised methods. In an idealized setting, there would be a suitably strong taskoriented dialogue benchmark that could be verified as not belonging to the pretraining corpus of each new and more capable LLM. This is not the case for our setting or for many others, and warrants careful attention from the NLP community. For our setting, we were able to properly define problematic contamination and search for it in our LLM's pretraining corpus, thanks to the open release of the pretraining data. We found limited contamination and demonstrated that the contamination we found was not helpful in eliciting task knowledge that might have been memorized in pretraining.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "8.22",
                                    "matching_string": "Data contamination in LLM pretraining poses a "
                                },
                                {
                                    "pdf_id": "8.23",
                                    "matching_string": "hurdle for accurate benchmarking across NLP, and "
                                },
                                {
                                    "pdf_id": "8.24",
                                    "matching_string": "particularly for unsupervised methods. In an idealized "
                                },
                                {
                                    "pdf_id": "8.26",
                                    "matching_string": "dialogue benchmark that could be verified "
                                },
                                {
                                    "pdf_id": "8.27",
                                    "matching_string": "as not belonging to the pretraining corpus of each "
                                },
                                {
                                    "pdf_id": "8.28",
                                    "matching_string": "new and more capable LLM. This is not the case "
                                },
                                {
                                    "pdf_id": "8.29",
                                    "matching_string": "for our setting or for many others, and warrants "
                                },
                                {
                                    "pdf_id": "8.30",
                                    "matching_string": "careful attention from the NLP community. For our "
                                },
                                {
                                    "pdf_id": "8.31",
                                    "matching_string": "setting, we were able to properly define problematic "
                                },
                                {
                                    "pdf_id": "8.35",
                                    "matching_string": "and demonstrated that the contamination we "
                                },
                                {
                                    "pdf_id": "8.36",
                                    "matching_string": "found was not helpful in eliciting task knowledge "
                                },
                                {
                                    "pdf_id": "8.37",
                                    "matching_string": "that might have been memorized in pretraining."
                                },
                                {
                                    "pdf_id": "8.25",
                                    "matching_string": "setting, there would be a suitably strong taskoriented "
                                },
                                {
                                    "pdf_id": "8.32",
                                    "matching_string": "contamination and search for it in our LLM's "
                                },
                                {
                                    "pdf_id": "8.33",
                                    "matching_string": "pretraining corpus, thanks to the open release of "
                                },
                                {
                                    "pdf_id": "8.34",
                                    "matching_string": "the pretraining data. We found limited contamination "
                                }
                            ]
                        },
                        {
                            "leaf id": 83,
                            "key": "doc/body/sec10/txl1",
                            "block type": "txl",
                            "content": "All experiments in this paper were conducted on preexisting public dialogue corpora, collected explicitly for training taskoriented dialogue agents with the knowledge of all participants . Our use of the StarCoder model also falls within the terms of it's Responsible AI License. It is important that subsequent applications of our method also adhere to any fairuse policies governing collected dialogues or transcripts. \\bibliography{anthology,custom}",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "8.38",
                                    "matching_string": "All experiments in this paper were conducted "
                                },
                                {
                                    "pdf_id": "8.40",
                                    "matching_string": "explicitly for training taskoriented dialogue "
                                },
                                {
                                    "pdf_id": "8.43",
                                    "matching_string": "model also falls within the terms of it's Responsible "
                                },
                                {
                                    "pdf_id": "8.45",
                                    "matching_string": "applications of our method also adhere to any "
                                },
                                {
                                    "pdf_id": "8.46",
                                    "matching_string": "fairuse policies governing collected dialogues or "
                                },
                                {
                                    "pdf_id": "8.47",
                                    "matching_string": "transcripts. "
                                },
                                {
                                    "pdf_id": "8.39",
                                    "matching_string": "on preexisting public dialogue corpora, collected "
                                },
                                {
                                    "pdf_id": "8.44",
                                    "matching_string": "AI License. It is important that subsequent "
                                },
                                {
                                    "pdf_id": "8.41",
                                    "matching_string": "agents with the knowledge of all participants "
                                },
                                {
                                    "pdf_id": "8.42",
                                    "matching_string": ". Our use of the StarCoder \\bibliography{anthology,custom}"
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec11",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 84,
                            "key": "doc/body/sec11/tit",
                            "block type": "title",
                            "content": "Prompt Examples",
                            "leftover": "Prompt Examples",
                            "matches": []
                        },
                        {
                            "leaf id": 85,
                            "key": "doc/body/sec11/txl0",
                            "block type": "txl",
                            "content": "provides abridged instances of our direct prompts for DST and for Act Tagging. shows our prompt for inferring API call(s) or changes to the dialogue state from an unlabelled dialogue, as detailed in . Our prompts use python keyword arguments to provide the input variables for a given subtask, and to prompt the LLM for the next variable of interest. Using the arbitrary ordering of keyword arguments in Python function calls, our 'channel' prompts simply reorder the arguments in order to score the likelihood of the user's utterance given the predicted state change. provides a similar abridged instance of our direct prompt for tagging dialogue acts in an unlabelled dialogue. Here, we simply condition on the observed system response rt.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "10.39",
                                    "matching_string": "shows our prompt for inferring API call(s) or "
                                },
                                {
                                    "pdf_id": "10.40",
                                    "matching_string": "changes to the dialogue state from an unlabelled dialogue, "
                                },
                                {
                                    "pdf_id": "10.44",
                                    "matching_string": "the next variable of interest. Using the arbitrary "
                                },
                                {
                                    "pdf_id": "10.45",
                                    "matching_string": "ordering of keyword arguments in Python function "
                                },
                                {
                                    "pdf_id": "10.46",
                                    "matching_string": "calls, our 'channel' prompts simply reorder the "
                                },
                                {
                                    "pdf_id": "10.47",
                                    "matching_string": "arguments in order to score the likelihood of the "
                                },
                                {
                                    "pdf_id": "10.50",
                                    "matching_string": "direct prompt for tagging dialogue acts in an unlabelled "
                                },
                                {
                                    "pdf_id": "10.52",
                                    "matching_string": "observed system response rt."
                                },
                                {
                                    "pdf_id": "10.42",
                                    "matching_string": "keyword arguments to provide the input variables "
                                },
                                {
                                    "pdf_id": "10.43",
                                    "matching_string": "for a given subtask, and to prompt the LLM for "
                                },
                                {
                                    "pdf_id": "10.48",
                                    "matching_string": "user's utterance given the predicted state change. "
                                },
                                {
                                    "pdf_id": "10.37",
                                    "matching_string": "provides abridged instances of our direct "
                                },
                                {
                                    "pdf_id": "10.38",
                                    "matching_string": "prompts for DST and for Act Tagging. "
                                },
                                {
                                    "pdf_id": "10.49",
                                    "matching_string": "provides a similar abridged instance of our "
                                },
                                {
                                    "pdf_id": "10.51",
                                    "matching_string": "dialogue. Here, we simply condition on the "
                                },
                                {
                                    "pdf_id": "10.41",
                                    "matching_string": "as detailed in . Our prompts use python "
                                }
                            ]
                        },
                        {
                            "leaf id": 86,
                            "key": "doc/body/sec11/figure*1",
                            "block type": "figure*",
                            "content": "h] \\centering \\begin{subfigure}[b]{0.49\\textwidth} \\centering \\includegraphics[width=\\textwidth]{imgs/directdstpromptv6.pdf} Our 'direct' DST prompt with italicized \\textcolor{dstcolor}{{DST Module}} \\end{subfigure} \\hfill \\begin{subfigure}[b]{0.49\\textwidth} \\centering \\includegraphics[width=\\textwidth]{imgs/directdatpromptv4.pdf} Our 'direct' act tagging prompt, with italicized \\textcolor{dstcolor}{{DST Module}} \\end{subfigure} Abridged prompt and completion examples from our incontext learning approach to initial labelling for DST and DAT (Act Tagging), best viewed in color. Keyword arguments are used to include variables from the turn context and to prefix the completion",
                            "leftover": "h] \\centering \\begin{subfigure}[b]{0.49\\textwidth} \\centering \\includegraphics[width=\\textwidth]{imgs/directdstpromptv6.pdf} Our 'direct' DST prompt with italicized \\textcolor{dstcolor}{{DST Module}} \\end{subfigure} \\hfill \\begin{subfigure}[b]{0.49\\textwidth} \\centering \\includegraphics[width=\\textwidth]{imgs/directdatpromptv4.pdf} Our 'direct' act tagging prompt, with italicized \\textcolor{dstcolor}{{DST Module}} \\end{subfigure} ",
                            "matches": [
                                {
                                    "pdf_id": "12.2",
                                    "matching_string": "DST and DAT (Act Tagging), best viewed in color. Keyword arguments are used to include variables from the turn "
                                },
                                {
                                    "pdf_id": "12.3",
                                    "matching_string": "context and to prefix the completion"
                                },
                                {
                                    "pdf_id": "12.1",
                                    "matching_string": "Abridged prompt and completion examples from our incontext learning approach to initial labelling for "
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec12",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 87,
                            "key": "doc/body/sec12/tit",
                            "block type": "title",
                            "content": "Metric Details",
                            "leftover": "Metric Details",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec12/par0",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 88,
                                    "key": "doc/body/sec12/par0/txl0",
                                    "block type": "txl",
                                    "content": "EndtoEnd (E2E) Dialogue Metrics We measure endtoend dialogue performance using the Inform rate, Success rate, and BLEU, following prior works, using the automatic evaluation provided by .https://github.com/Tomiinek/MultiWOZEvaluation",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "10.53",
                                            "matching_string": "EndtoEnd (E2E) Dialogue Metrics We measure "
                                        },
                                        {
                                            "pdf_id": "10.55",
                                            "matching_string": "Inform rate, Success rate, and BLEU, following "
                                        },
                                        {
                                            "pdf_id": "10.56",
                                            "matching_string": "prior works, using the automatic evaluation provided "
                                        },
                                        {
                                            "pdf_id": "10.54",
                                            "matching_string": "endtoend dialogue performance using the "
                                        },
                                        {
                                            "pdf_id": "12.0",
                                            "matching_string": "by .https://github.com/Tomiinek/MultiWOZEvaluation"
                                        },
                                        {
                                            "pdf_id": "10.57",
                                            "matching_string": ""
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 89,
                                    "key": "doc/body/sec12/par0/txl1",
                                    "block type": "txl",
                                    "content": "A dialogue is considered Informed if the most recently mentioned result for each domain meets the user's goal constraints, and is considered Successful if it is Informed and all values for requested slots are presented to the user. For example, if a user were to ask 'Can you give me the phone number of a cheap hotel in the east part of town?', the dialogue would be Informed if we refer them to a hotel that is actually in the cheap price range and in the east, and Successful if we additionally provide the phone number, as requested. BLEU is computed against a single reference response, and the Combined score is 0.5(Inform + Success) + BLEU.",
                                    "leftover": "BLEU.",
                                    "matches": [
                                        {
                                            "pdf_id": "10.58",
                                            "matching_string": "A dialogue is considered Informed if the most recently "
                                        },
                                        {
                                            "pdf_id": "10.59",
                                            "matching_string": "mentioned result for each domain meets the "
                                        },
                                        {
                                            "pdf_id": "10.61",
                                            "matching_string": "if it is Informed and all values for requested slots "
                                        },
                                        {
                                            "pdf_id": "10.62",
                                            "matching_string": "are presented to the user. For example, if a user "
                                        },
                                        {
                                            "pdf_id": "10.64",
                                            "matching_string": "a cheap hotel in the east part of town?', the dialogue "
                                        },
                                        {
                                            "pdf_id": "10.65",
                                            "matching_string": "would be Informed if we refer them to a hotel that "
                                        },
                                        {
                                            "pdf_id": "10.66",
                                            "matching_string": "is actually in the cheap price range and in the east, "
                                        },
                                        {
                                            "pdf_id": "10.67",
                                            "matching_string": "and Successful if we additionally provide the phone "
                                        },
                                        {
                                            "pdf_id": "10.68",
                                            "matching_string": "number, as requested. BLEU is computed against a "
                                        },
                                        {
                                            "pdf_id": "10.69",
                                            "matching_string": "single reference response, and the Combined score "
                                        },
                                        {
                                            "pdf_id": "10.60",
                                            "matching_string": "user's goal constraints, and is considered Successful "
                                        },
                                        {
                                            "pdf_id": "10.63",
                                            "matching_string": "were to ask 'Can you give me the phone number of "
                                        },
                                        {
                                            "pdf_id": "10.70",
                                            "matching_string": "is 0.5(Inform + Success) + "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec12/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 90,
                                    "key": "doc/body/sec12/par1/txl0",
                                    "block type": "txl",
                                    "content": "Dialogue State Tracking Metrics Following prior works, we evaluate DST performance with jointgoal accuracy (JGA): for a turn xt, a dialogue state prediction t is considered correct only if all slot names and values match the gold annotation state yt. We again use the evaluation provided in . Following their work, we accept fuzzy matches for noncategorical string values, such as the name of a restaurant or hotel, using the fuzzywuzzy library and a fuzz ratio of 0.95.https://pypi.org/project/fuzzywuzzy/",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "10.71",
                                            "matching_string": "Dialogue State Tracking Metrics Following "
                                        },
                                        {
                                            "pdf_id": "10.72",
                                            "matching_string": "prior works, we evaluate DST performance with "
                                        },
                                        {
                                            "pdf_id": "10.73",
                                            "matching_string": "jointgoal accuracy (JGA): for a turn xt, a dialogue "
                                        },
                                        {
                                            "pdf_id": "10.75",
                                            "matching_string": "slot names and values match the gold annotation "
                                        },
                                        {
                                            "pdf_id": "10.76",
                                            "matching_string": "state yt. We again use the evaluation provided in "
                                        },
                                        {
                                            "pdf_id": "10.78",
                                            "matching_string": "we accept fuzzy matches for noncategorical string "
                                        },
                                        {
                                            "pdf_id": "10.79",
                                            "matching_string": "values, such as the name of a restaurant or hotel, "
                                        },
                                        {
                                            "pdf_id": "10.80",
                                            "matching_string": "using the fuzzywuzzy library and a fuzz ratio of "
                                        },
                                        {
                                            "pdf_id": "10.74",
                                            "matching_string": "state prediction t is considered correct only if all "
                                        },
                                        {
                                            "pdf_id": "10.81",
                                            "matching_string": "0.95.h"
                                        },
                                        {
                                            "pdf_id": "10.97",
                                            "matching_string": "pypi.org/project/fuzzywuzzy/"
                                        },
                                        {
                                            "pdf_id": "10.77",
                                            "matching_string": ". Following their work, ttps://"
                                        },
                                        {
                                            "pdf_id": "10.96",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec13",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 91,
                            "key": "doc/body/sec13/tit",
                            "block type": "title",
                            "content": "Dialogue Acts",
                            "leftover": "Dialogue Acts",
                            "matches": []
                        },
                        {
                            "leaf id": 92,
                            "key": "doc/body/sec13/txl0",
                            "block type": "txl",
                            "content": "Following, we use a universal set of dialogue acts for managing our agents communicative intents. We omit some acts for simplicity and to reduce the context length required to enumerate them in a prompt. lists each act and a description. Since our dialogue set is not directly comparable to prior works, we do not directly evaluate act tagging or policy accuracy. Instead, acts serve only as an intermediate representation for planning responses in our endtoend system.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "10.84",
                                    "matching_string": "of dialogue acts for managing our agents communicative "
                                },
                                {
                                    "pdf_id": "10.86",
                                    "matching_string": "and to reduce the context length required to enumerate "
                                },
                                {
                                    "pdf_id": "10.88",
                                    "matching_string": "a description. Since our dialogue set is not directly "
                                },
                                {
                                    "pdf_id": "10.89",
                                    "matching_string": "comparable to prior works, we do not directly evaluate "
                                },
                                {
                                    "pdf_id": "10.91",
                                    "matching_string": "serve only as an intermediate representation for "
                                },
                                {
                                    "pdf_id": "10.92",
                                    "matching_string": "planning responses in our endtoend system."
                                },
                                {
                                    "pdf_id": "10.85",
                                    "matching_string": "intents. We omit some acts for simplicity "
                                },
                                {
                                    "pdf_id": "10.90",
                                    "matching_string": "act tagging or policy accuracy. Instead, acts "
                                },
                                {
                                    "pdf_id": "10.87",
                                    "matching_string": "them in a prompt. lists each act and "
                                },
                                {
                                    "pdf_id": "11.43",
                                    "matching_string": "Following, we use a universal set "
                                }
                            ]
                        },
                        {
                            "leaf id": 93,
                            "key": "doc/body/sec13/table*1",
                            "block type": "table*",
                            "content": "] \\centering \\begin{tabular}{l p{12cm}} Act & Description (as used in our prompt) Inform(x=y) & Provide information. Offer(x=y) & System provides an offer or suggestion based on results. Confirm(x=y) & Seek confirmation of something. Affirm(x=y) & Express agreement or confirmation. Negate(x=y) & User or System denies or negates. NotifySuccess(x=y) & Notify of a successful action or result. NotifyFailure(x=y) & Notify of an error or failure. Acknowledge & Acknowledge. Goodbye & Goodbye. Greeting & Greeting. ThankYou & ThankYou. RequestAlternatives & Ask for other options, alternatives, or any additional user goals. Request(x=?) & Ask for specific information or action. & \\end{tabular} Dialogue acts supported by our system, adapted from the universal dialogue acts proposed in . ''x=y\" indicates the act can take on arbitrary keyvalue arguments, and ''x=?\" indicates the act takes on one or more unpaired arguments. We reduce the number of acts and lengths of descriptions relative to in order to fit within the LMs context length",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "8.1",
                                    "matching_string": "] \\centering \\begin{tabular}{l p{12cm}} Act & Description (as used in our prompt) Inform(x=y) & Provide information. Offer(x=y) & System provides an offer or suggestion based on results. Confirm(x=y) & Seek confirmation of something. Affirm(x=y) & Express agreement or confirmation. Negate(x=y) & User or System denies or negates. NotifySuccess(x=y) & Notify of a successful action or result. NotifyFailure(x=y) & Notify of an error or failure. Acknowledge & Acknowledge. Goodbye & Goodbye. Greeting & Greeting. ThankYou & ThankYou. RequestAlternatives & Ask for other options, alternatives, or any additional user goals. Request(x=?) & Ask for specific information or action. & \\end{tabular} Dialogue acts supported by our system, adapted from the universal dialogue acts proposed in . ''x=y\" indicates the act can take on arbitrary keyvalue arguments, and ''x=?\" indicates the act takes on one or more unpaired arguments. We reduce the number of acts and lengths of descriptions relative to in order to fit within the LMs context length"
                                },
                                {
                                    "pdf_id": "10.83",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.19",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.39",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.40",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.41",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.42",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.44",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.45",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.46",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.47",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.38",
                                    "matching_string": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec14",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 94,
                            "key": "doc/body/sec14/tit",
                            "block type": "title",
                            "content": "Offline Labeling Algorithm",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "10.93",
                                    "matching_string": "Offline Labeling Algorithm"
                                }
                            ]
                        },
                        {
                            "leaf id": 95,
                            "key": "doc/body/sec14/txl0",
                            "block type": "txl",
                            "content": "Algorithm 1 gives our algorithm for pseudolabeling of unlabelled dialogues.",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "10.94",
                                    "matching_string": "Algorithm 1 gives our algorithm for pseudolabeling "
                                },
                                {
                                    "pdf_id": "10.95",
                                    "matching_string": "of unlabelled dialogues."
                                }
                            ]
                        },
                        {
                            "leaf id": 96,
                            "key": "doc/body/sec14/algorithm*1",
                            "block type": "algorithm*",
                            "content": "\\begin{algorithmic}[1] \\Procedure{InitialOfflineLabel}{train, ret, } \\State  \\Comment{Initialize example pool} \\State [] \\Comment{Store predictions by dialogue id and turn index} \\For{t = 0 to d trainmax d train|d|} \\Comment{Loop by increasing turn index} \\ForAll{(did, ut, rt1, rt) in train} \\Comment{did is dialogue ID} \\State bt1[did][t1] or  \\Comment{Fetch bt1 if known} \\State bt OfflineDST, ret, bt1, rt1, ut \\State t OfflineActTag, ret, ut, rt \\State (rt1, ut, rt, bt, t) \\Comment{Add incontext example for future labeling} \\EndFor \\EndFor \\EndProcedure \\Procedure{OfflineDST}{, ret, bt1, rt1, ut} \\State ret (bt rt1 ut, ) \\Comment{Retrieve up to k incontext examples} \\State  bt P(fprompt (k, bt1, rt1, ut)) \\Comment{Sample w/ 'direct' prompt} \\State bt At ^*argmax At ^*P(ut | fprompt (k, bt1, rt1,  bt) \\Comment{Rerank w/ 'channel' prompt} \\State \\Return bt1 + bt \\EndProcedure \\Procedure{OfflineActTag}{, ret, ut, rt} \\State ret (ut rt, ) \\Comment{Retrieve up to k incontext examples} \\State At (P(fprompt (k, rt))) \\Comment{Sample w/ 'direct' prompt} \\State \\Return At ^*argmax At ^*P(k, At, rt) \\Comment{Rerank w/ 'channel' prompt} \\EndProcedure \\end{algorithmic} Our algorithm for initial pseudolabeling of unlabelled dialogues in train",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "11.22",
                                    "matching_string": "[] \\Comment{Store predictions by dialogue id and turn "
                                },
                                {
                                    "pdf_id": "11.20",
                                    "matching_string": " "
                                },
                                {
                                    "pdf_id": "11.21",
                                    "matching_string": "Initialize example "
                                },
                                {
                                    "pdf_id": "11.24",
                                    "matching_string": "Loop by increasing turn "
                                },
                                {
                                    "pdf_id": "11.25",
                                    "matching_string": "did, ut, rt1, rt) in train} \\Comment{did is dialogue "
                                },
                                {
                                    "pdf_id": "11.29",
                                    "matching_string": "(rt1, ut, rt, bt, t) \\Comment{Add incontext example for future "
                                },
                                {
                                    "pdf_id": "11.26",
                                    "matching_string": "\\begin{algorithmic}[1] \\Procedure{InitialOfflineLabel}{train, ret, } \\State \\Comment{pool} \\State index} \\For{t = 0 to d trainmax d train|d|} \\Comment{index} \\ForAll{(ID} \\State bt1[did][t1] or  \\Comment{Fetch bt1 if known} \\State bt OfflineDST, ret, bt1, rt1, ut \\State t OfflineActTag, ret, ut, rt \\State labeling} \\EndFor \\EndFor \\EndProcedure \\Procedure{OfflineDST}{, ret, bt1, rt1, ut} \\State ret (bt rt1 ut, ) \\Comment{Retrieve up to k incontext examples} \\State  bt P(fprompt (k, bt1, rt1, ut)) \\Comment{Sample w/ 'direct' prompt} \\State bt At ^*argmax At ^*P(ut | fprompt (k, bt1, rt1,  bt) \\Comment{Rerank w/ 'channel' prompt} \\State \\Return bt1 + bt \\EndProcedure \\Procedure{OfflineActTag}{, ret, ut, rt} \\State ret (ut rt, ) \\Comment{Retrieve up to k incontext examples} \\State At (P(fprompt (k, rt))) \\Comment{Sample w/ 'direct' prompt} \\State \\Return At ^*argmax At ^*P(k, At, rt) \\Comment{Rerank w/ 'channel' prompt} \\EndProcedure \\end{algorithmic} Our algorithm for initial pseudolabeling of unlabelled dialogues in train"
                                },
                                {
                                    "pdf_id": "11.27",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.28",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.30",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.31",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.32",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.33",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.35",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.36",
                                    "matching_string": ""
                                },
                                {
                                    "pdf_id": "11.37",
                                    "matching_string": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec15",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 97,
                            "key": "doc/body/sec15/tit",
                            "block type": "title",
                            "content": "Further results across EM Steps",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "12.4",
                                    "matching_string": "Further results across EM Steps"
                                }
                            ]
                        },
                        {
                            "leaf id": 98,
                            "key": "doc/body/sec15/txl0",
                            "block type": "txl",
                            "content": "Here we expand on our ablations in, which evaluates our method with and without our proposed noisychannel prompting across iterations of expectationmaximization (EM). In, we break down the performance gains we observed in our 'Combined' metric into Inform rate, Success rate, and BLEU, where Combined = 0.5(Inform + Success) + BLEU. '0' iterations of EM indicates our zeroshot prompting system, without any incontext examples or EM. We find that EM substantially improves performance in all cases, and particularly for our noisychannel prompting approach. We find the noisy channel prompting approach improves performance on all metrics, with the most substantial gains over the greedy baseline in Inform and Success rates. This suggests that within our algorithm, noisychannel inference may be particularly important when inferring the system's dialogue acts in order to reverseengineer an accurate policy.",
                            "leftover": "In, ",
                            "matches": [
                                {
                                    "pdf_id": "12.7",
                                    "matching_string": "evaluates our method with and without our proposed "
                                },
                                {
                                    "pdf_id": "12.10",
                                    "matching_string": "we break down the performance gains we observed "
                                },
                                {
                                    "pdf_id": "12.12",
                                    "matching_string": "Success rate, and BLEU, where Combined = "
                                },
                                {
                                    "pdf_id": "12.14",
                                    "matching_string": "of EM indicates our zeroshot prompting system, "
                                },
                                {
                                    "pdf_id": "12.16",
                                    "matching_string": "that EM substantially improves performance in "
                                },
                                {
                                    "pdf_id": "12.18",
                                    "matching_string": "prompting approach. We find the noisy channel "
                                },
                                {
                                    "pdf_id": "12.19",
                                    "matching_string": "prompting approach improves performance on all "
                                },
                                {
                                    "pdf_id": "12.20",
                                    "matching_string": "metrics, with the most substantial gains over the "
                                },
                                {
                                    "pdf_id": "12.21",
                                    "matching_string": "greedy baseline in Inform and Success rates. This "
                                },
                                {
                                    "pdf_id": "12.22",
                                    "matching_string": "suggests that within our algorithm, noisychannel "
                                },
                                {
                                    "pdf_id": "12.23",
                                    "matching_string": "inference may be particularly important when inferring "
                                },
                                {
                                    "pdf_id": "12.25",
                                    "matching_string": "an accurate policy."
                                },
                                {
                                    "pdf_id": "12.15",
                                    "matching_string": "without any incontext examples or EM. We find "
                                },
                                {
                                    "pdf_id": "12.17",
                                    "matching_string": "all cases, and particularly for our noisychannel "
                                },
                                {
                                    "pdf_id": "12.24",
                                    "matching_string": "the system's dialogue acts in order to reverseengineer "
                                },
                                {
                                    "pdf_id": "12.8",
                                    "matching_string": "noisychannel prompting across iterations "
                                },
                                {
                                    "pdf_id": "12.11",
                                    "matching_string": "in our 'Combined' metric into Inform rate, "
                                },
                                {
                                    "pdf_id": "12.6",
                                    "matching_string": "Here we expand on our ablations in, which "
                                },
                                {
                                    "pdf_id": "12.9",
                                    "matching_string": "of expectationmaximization (EM). "
                                },
                                {
                                    "pdf_id": "12.13",
                                    "matching_string": "0.5(Inform + Success) + BLEU. '0' iterations "
                                }
                            ]
                        },
                        {
                            "leaf id": 99,
                            "key": "doc/body/sec15/txl1",
                            "block type": "txl",
                            "content": "In, we analyze dialogue state tracking performance across iterations of EM using Joint Goal Accuracy (JGA). We find our noisychannel prompting approach improves the accuracy of our dialogue state tracking predictions across iterations of EM when compared to a greedy, direct prompting approach.",
                            "leftover": "In, ",
                            "matches": [
                                {
                                    "pdf_id": "12.27",
                                    "matching_string": "performance across iterations of EM using Joint "
                                },
                                {
                                    "pdf_id": "12.29",
                                    "matching_string": "prompting approach improves the accuracy of our "
                                },
                                {
                                    "pdf_id": "12.30",
                                    "matching_string": "dialogue state tracking predictions across iterations "
                                },
                                {
                                    "pdf_id": "12.31",
                                    "matching_string": "of EM when compared to a greedy, direct prompting "
                                },
                                {
                                    "pdf_id": "12.28",
                                    "matching_string": "Goal Accuracy (JGA). We find our noisychannel "
                                },
                                {
                                    "pdf_id": "12.26",
                                    "matching_string": "we analyze dialogue state tracking "
                                },
                                {
                                    "pdf_id": "12.32",
                                    "matching_string": "approach."
                                }
                            ]
                        },
                        {
                            "leaf id": 100,
                            "key": "doc/body/sec15/figure*2",
                            "block type": "figure*",
                            "content": "\\includegraphics[width=\\textwidth]{imgs/stepplotsv2/informsuccessbleucombinedmultiplot.png} Breaking down Combined = 0.5(Inform + Success) + BLEU into components Inform Rate, Success Rate, and BLEU across iterations of EM between our proposed noisychannel approach and a greedy ablation, which omits noisychannel prompting at inference time and when labeling dialogue states & system acts in the expectation step. We find improvement across all components, and particularly our Inform and Success Rates",
                            "leftover": "\\includegraphics[width=\\textwidth]{imgs/stepplotsv2/informsuccessbleucombinedmultiplot.png} ",
                            "matches": [
                                {
                                    "pdf_id": "13.1",
                                    "matching_string": "Rate, and BLEU across iterations of EM between our proposed noisychannel approach and a greedy ablation, "
                                },
                                {
                                    "pdf_id": "13.2",
                                    "matching_string": "which omits noisychannel prompting at inference time and when labeling dialogue states & system acts in the "
                                },
                                {
                                    "pdf_id": "13.3",
                                    "matching_string": "expectation step. We find improvement across all components, and particularly our Inform and Success Rates"
                                },
                                {
                                    "pdf_id": "13.0",
                                    "matching_string": "Breaking down Combined = 0.5(Inform + Success) + BLEU into components Inform Rate, Success "
                                }
                            ]
                        },
                        {
                            "leaf id": 101,
                            "key": "doc/body/sec15/figure*3",
                            "block type": "figure*",
                            "content": "\\centering \\includegraphics[width=0.5\\textwidth]{imgs/stepplotsv3/jgavssteps.png} Joint Goal Accuracy (JGA) of our inferred API call(s)/Dialogue states across iterations of EM. We find improved dialogue state tracking performance when using our noisychannel method at inference time and when labeling dialogue states offline in the expectation step for training, compared to a greedy direct prompting approach",
                            "leftover": "\\centering \\includegraphics[width=0.5\\textwidth]{imgs/stepplotsv3/jgavssteps.png} ",
                            "matches": [
                                {
                                    "pdf_id": "13.5",
                                    "matching_string": "improved dialogue state tracking performance when using our noisychannel method at inference time and when "
                                },
                                {
                                    "pdf_id": "13.6",
                                    "matching_string": "labeling dialogue states offline in the expectation step for training, compared to a greedy direct prompting approach"
                                },
                                {
                                    "pdf_id": "13.4",
                                    "matching_string": "Joint Goal Accuracy (JGA) of our inferred API call(s)/Dialogue states across iterations of EM. We find "
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec16",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 102,
                            "key": "doc/body/sec16/tit",
                            "block type": "title",
                            "content": "Contamination Search & Result Details",
                            "leftover": "",
                            "matches": [
                                {
                                    "pdf_id": "12.5",
                                    "matching_string": "Contamination Search & Result Details"
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec16/sub0",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 103,
                                    "key": "doc/body/sec16/sub0/tit",
                                    "block type": "title",
                                    "content": "Procedure",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "12.33",
                                            "matching_string": "Procedure"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 104,
                                    "key": "doc/body/sec16/sub0/txl0",
                                    "block type": "txl",
                                    "content": "We detail our method for finding instances of task contamination within the StarCoder pretraining set. We are particularly interested in supervised pairs (x, y) where y belongs to our schema of interest, for any of the dialogue subtasks used in our system. We devise a method for searching the complete pretraining corpus for contaminated (x, y) pairs, where x is an utterance we might observe from either the system or user, and y is the latent dialogue state change or dialogue act supporting . For each utterance x from either the system or user, we collect all documents from the pretraining corpus which contain the complete utterance. We use the elastic search index provided for the StarCoder pretraining data, which accounts for differences in capitalization, punctuation, and interrupting whitespace.https://github.com/bigcodeproject/search/blob/main/index.py Following this, we search matching documents for keywords from y (e.g. slot names and values) to determine which of these documents may plausibly contain a supervised label and warrant manual review. For dialogue states, these are the slot names and values, discarding extremely generic keywords like 'name'. For act tags, these are the act names, slots, and values. We then consider a document to need manual review if 40% or more of the keywords are found in the 500 characters before or after a matching x in a document. Finally, we handcheck the remaining documents and extract contaminated (x, y) pairs.",
                                    "leftover": "interest, . ",
                                    "matches": [
                                        {
                                            "pdf_id": "12.34",
                                            "matching_string": "We detail our method for finding instances of task "
                                        },
                                        {
                                            "pdf_id": "12.35",
                                            "matching_string": "contamination within the StarCoder pretraining "
                                        },
                                        {
                                            "pdf_id": "12.36",
                                            "matching_string": "set. We are particularly interested in supervised "
                                        },
                                        {
                                            "pdf_id": "12.37",
                                            "matching_string": "pairs (x, y) where y belongs to our schema of "
                                        },
                                        {
                                            "pdf_id": "12.39",
                                            "matching_string": "in our system. We devise a method for searching "
                                        },
                                        {
                                            "pdf_id": "12.41",
                                            "matching_string": "(x, y) pairs, where x is an utterance we might observe "
                                        },
                                        {
                                            "pdf_id": "12.43",
                                            "matching_string": "latent dialogue state change or dialogue act supporting "
                                        },
                                        {
                                            "pdf_id": "12.46",
                                            "matching_string": "pretraining corpus which contain the complete "
                                        },
                                        {
                                            "pdf_id": "12.47",
                                            "matching_string": "utterance. We use the elastic search index provided "
                                        },
                                        {
                                            "pdf_id": "12.49",
                                            "matching_string": "accounts for differences in capitalization, punctuation, "
                                        },
                                        {
                                            "pdf_id": "12.51",
                                            "matching_string": "this, we search matching documents for keywords "
                                        },
                                        {
                                            "pdf_id": "12.52",
                                            "matching_string": "from y (e.g. slot names and values) to determine "
                                        },
                                        {
                                            "pdf_id": "12.53",
                                            "matching_string": "which of these documents may plausibly contain a "
                                        },
                                        {
                                            "pdf_id": "12.54",
                                            "matching_string": "supervised label and warrant manual review. For "
                                        },
                                        {
                                            "pdf_id": "12.55",
                                            "matching_string": "dialogue states, these are the slot names and values, "
                                        },
                                        {
                                            "pdf_id": "12.56",
                                            "matching_string": "discarding extremely generic keywords like 'name'. "
                                        },
                                        {
                                            "pdf_id": "12.57",
                                            "matching_string": "For act tags, these are the act names, slots, and values. "
                                        },
                                        {
                                            "pdf_id": "14.1",
                                            "matching_string": "the 500 characters before or after a matching x in a "
                                        },
                                        {
                                            "pdf_id": "14.2",
                                            "matching_string": "document. Finally, we handcheck the remaining "
                                        },
                                        {
                                            "pdf_id": "14.3",
                                            "matching_string": "documents and extract contaminated (x, y) pairs."
                                        },
                                        {
                                            "pdf_id": "12.40",
                                            "matching_string": "the complete pretraining corpus for contaminated "
                                        },
                                        {
                                            "pdf_id": "12.42",
                                            "matching_string": "from either the system or user, and y is the "
                                        },
                                        {
                                            "pdf_id": "12.45",
                                            "matching_string": "system or user, we collect all documents from the for the "
                                        },
                                        {
                                            "pdf_id": "12.58",
                                            "matching_string": "We then consider a document to need manual "
                                        },
                                        {
                                            "pdf_id": "12.59",
                                            "matching_string": "github.com/bigcodeproject/s"
                                        },
                                        {
                                            "pdf_id": "14.0",
                                            "matching_string": "review if 40% or more of the keywords are found in "
                                        },
                                        {
                                            "pdf_id": "12.38",
                                            "matching_string": "for any of the dialogue subtasks used "
                                        },
                                        {
                                            "pdf_id": "12.44",
                                            "matching_string": "For each utterance x from either the "
                                        },
                                        {
                                            "pdf_id": "12.48",
                                            "matching_string": "StarCoder pretraining data, which "
                                        },
                                        {
                                            "pdf_id": "12.60",
                                            "matching_string": "blob/main/index.py "
                                        },
                                        {
                                            "pdf_id": "12.50",
                                            "matching_string": "and interrupting whitespace.https://earch/Following "
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec16/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 105,
                                    "key": "doc/body/sec16/sub1/tit",
                                    "block type": "title",
                                    "content": "Examples",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "14.4",
                                            "matching_string": "Examples"
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 106,
                                    "key": "doc/body/sec16/sub1/txl0",
                                    "block type": "txl",
                                    "content": "contains examples of contamination discovered in our search process, and the type of document in which they were found. Notably, none of the examples found closely match our output formatting.",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "14.6",
                                            "matching_string": "in our search process, and the type of document "
                                        },
                                        {
                                            "pdf_id": "14.8",
                                            "matching_string": "of the examples found closely match our output "
                                        },
                                        {
                                            "pdf_id": "14.9",
                                            "matching_string": "formatting."
                                        },
                                        {
                                            "pdf_id": "14.5",
                                            "matching_string": "contains examples of contamination discovered "
                                        },
                                        {
                                            "pdf_id": "14.7",
                                            "matching_string": "in which they were found. Notably, none "
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 107,
                                    "key": "doc/body/sec16/sub1/table*1",
                                    "block type": "table*",
                                    "content": "htbp] \\centering \\begin{tabular}{>{\\raggedright\\arraybackslash}p{0.25\\textwidth}|>{\\raggedright\\arraybackslash}p{0.25\\textwidth}|r|r} Contaminated Input & Contaminated Output & SubTask & Source I need a restaurant to dine at in Cambridge on my upcoming trip . I need info about chiquito restaurant bar restaurant . & restaurantinform<<<name===chiquito restaurant bar & DST & Jupyter Notebook i would like to book a 5 star, or closest to it, in the east part of town please . & \"<SOB> hotel { area = east, stars = 5, type = hotel } <EOB> <SOB> hotel { area = east, stars = 5 } restaurant { area = east } <EOB>\" & DST & Python [Syst] the train id is tr8292 and the price is 16.50 pounds. & [SYSDA] traininformleavetr8292 [SYSDA] traininformticket16.50 pounds & Act Tagging & Github Issue \\end{tabular} Example inputs and outputs in contaminated documents from each task, discovered in the StarCoder pretraining corpus. We include the source type of each document",
                                    "leftover": "",
                                    "matches": [
                                        {
                                            "pdf_id": "11.34",
                                            "matching_string": "htbp] \\centering \\begin{tabular}{>{\\raggedright\\arraybackslash}p{0.25\\textwidth}|>{\\raggedright\\arraybackslash}p{0.25\\textwidth}|r|r} Contaminated Input & Contaminated Output & SubTask & Source I need a restaurant to dine at in Cambridge on my upcoming trip . I need info about chiquito restaurant bar restaurant . & restaurantinform<<<name===chiquito restaurant bar & DST & Jupyter Notebook i would like to book a 5 star, or closest to it, in the east part of town please . & \"<SOB> hotel { area = east, stars = 5, type = hotel } <EOB> <SOB> hotel { area = east, stars = 5 } restaurant { area = east } <EOB>\" & DST & Python [Syst] the train id is tr8292 and the price is 16.50 pounds. & [SYSDA] traininformleavetr8292 [SYSDA] traininformticket16.50 pounds & Act Tagging & Github Issue \\end{tabular} Example inputs and outputs in contaminated documents from each task, discovered in the StarCoder pretraining corpus. We include the source type of each document"
                                        },
                                        {
                                            "pdf_id": "8.86",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "10.1",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "10.82",
                                            "matching_string": ""
                                        },
                                        {
                                            "pdf_id": "11.18",
                                            "matching_string": ""
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "leaf id": 108,
            "key": "doc/bib0",
            "block type": "bibliography",
            "content": "Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel HerbertVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language {Models} are {Few}{Shot} {Learners}. arXiv:2005.14165 [cs]. ArXiv: 2005.14165.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "8.49",
                    "matching_string": "Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind "
                },
                {
                    "pdf_id": "8.50",
                    "matching_string": "Neelakantan, Pranav Shyam, Girish Sastry, Amanda "
                },
                {
                    "pdf_id": "8.51",
                    "matching_string": "Askell, Sandhini Agarwal, Ariel HerbertVoss, "
                },
                {
                    "pdf_id": "8.52",
                    "matching_string": "Gretchen Krueger, Tom Henighan, Rewon Child, "
                },
                {
                    "pdf_id": "8.54",
                    "matching_string": "Clemens Winter, Christopher Hesse, Mark Chen, Eric "
                },
                {
                    "pdf_id": "8.55",
                    "matching_string": "Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, "
                },
                {
                    "pdf_id": "8.56",
                    "matching_string": "Jack Clark, Christopher Berner, Sam McCandlish, "
                },
                {
                    "pdf_id": "8.57",
                    "matching_string": "Alec Radford, Ilya Sutskever, and Dario Amodei. "
                },
                {
                    "pdf_id": "8.59",
                    "matching_string": "arXiv:2005.14165 [cs]. ArXiv: 2005.14165."
                },
                {
                    "pdf_id": "8.48",
                    "matching_string": "B. Brown, Benjamin Mann, Nick Ryder, Melanie "
                },
                {
                    "pdf_id": "8.53",
                    "matching_string": "Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, "
                },
                {
                    "pdf_id": "8.58",
                    "matching_string": "2020. Language {Models} are "
                },
                {
                    "pdf_id": "11.23",
                    "matching_string": "Tom~{Few}{Shot} {Learners}. "
                }
            ]
        },
        {
            "leaf id": 109,
            "key": "doc/bib1",
            "block type": "bibliography",
            "content": "Pawe{\\l} Budzianowski, TsungHsien Wen, BoHsiang Tseng, I{\\~n}igo Casanueva, Ultes Stefan, Ramadan Osman, and Milica Ga{\\v{s}}i\\'c. 2018. Multiwoz  a largescale multidomain wizardofoz dataset for taskoriented dialogue modelling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP).",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "8.63",
                    "matching_string": "multidomain wizardofoz dataset for taskoriented "
                },
                {
                    "pdf_id": "8.65",
                    "matching_string": "2018 Conference on Empirical Methods in Natural "
                },
                {
                    "pdf_id": "8.66",
                    "matching_string": "Language Processing (EMNLP)."
                },
                {
                    "pdf_id": "8.60",
                    "matching_string": "TsungHsien Wen, BoHsiang Tseng, I{\\~"
                },
                {
                    "pdf_id": "8.62",
                    "matching_string": "Milica Ga{\\v{s}}i\\'c. 2018. Multiwoz  a largescale "
                },
                {
                    "pdf_id": "8.64",
                    "matching_string": "dialogue modelling. In Proceedings of the "
                },
                {
                    "pdf_id": "8.61",
                    "matching_string": "Casanueva, Ultes Stefan, Ramadan Osman, "
                },
                {
                    "pdf_id": "10.36",
                    "matching_string": "Pawe{\\l} Budzianowski, n}igo and "
                }
            ]
        },
        {
            "leaf id": 110,
            "key": "doc/bib2",
            "block type": "bibliography",
            "content": "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe~Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel HerbertVoss, William~Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew~N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating {Large} {Language} {Models} {Trained} on {Code}. ArXiv:2107.03374 [cs].",
            "leftover": "{Large} {Language} {Models} {Trained} on {Code}. ",
            "matches": [
                {
                    "pdf_id": "8.67",
                    "matching_string": "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming "
                },
                {
                    "pdf_id": "8.69",
                    "matching_string": "Harri Edwards, Yuri Burda, Nicholas Joseph, "
                },
                {
                    "pdf_id": "8.70",
                    "matching_string": "Greg Brockman, Alex Ray, Raul Puri, Gretchen "
                },
                {
                    "pdf_id": "8.71",
                    "matching_string": "Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, "
                },
                {
                    "pdf_id": "8.73",
                    "matching_string": "Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz "
                },
                {
                    "pdf_id": "8.74",
                    "matching_string": "Kaiser, Mohammad Bavarian, Clemens Winter, "
                },
                {
                    "pdf_id": "8.76",
                    "matching_string": "Matthias Plappert, Fotios Chantzis, Elizabeth "
                },
                {
                    "pdf_id": "8.78",
                    "matching_string": "Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie "
                },
                {
                    "pdf_id": "8.79",
                    "matching_string": "Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, "
                },
                {
                    "pdf_id": "8.81",
                    "matching_string": "Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan "
                },
                {
                    "pdf_id": "8.82",
                    "matching_string": "Morikawa, Alec Radford, Matthew Knight, Miles "
                },
                {
                    "pdf_id": "8.83",
                    "matching_string": "Brundage, Mira Murati, Katie Mayer, Peter Welinder, "
                },
                {
                    "pdf_id": "8.85",
                    "matching_string": "Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating "
                },
                {
                    "pdf_id": "8.87",
                    "matching_string": "ArXiv:2107.03374 [cs]."
                },
                {
                    "pdf_id": "8.68",
                    "matching_string": "Yuan, Henrique Ponde de~Oliveira Pinto, Jared Kaplan, "
                },
                {
                    "pdf_id": "8.72",
                    "matching_string": "Pamela Mishkin, Brooke Chan, Scott Gray, "
                },
                {
                    "pdf_id": "8.75",
                    "matching_string": "Philippe Tillet, Felipe~Petroski Such, Dave Cummings, "
                },
                {
                    "pdf_id": "8.80",
                    "matching_string": "William Saunders, Christopher Hesse, Andrew~N. "
                },
                {
                    "pdf_id": "8.84",
                    "matching_string": "Bob McGrew, Dario Amodei, Sam McCandlish, "
                },
                {
                    "pdf_id": "8.77",
                    "matching_string": "Barnes, Ariel HerbertVoss, William~Hebgen "
                }
            ]
        },
        {
            "leaf id": 111,
            "key": "doc/bib3",
            "block type": "bibliography",
            "content": "Willy Chung, Samuel Cahyawijaya, Bryan Wilie, Holy Lovenia, and Pascale Fung. 2023. {InstructTODS}: {Large} {Language} {Models} for {End}to{End} {Task}{Oriented} {Dialogue} {Systems}. ArXiv:2310.08885 [cs].",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "8.88",
                    "matching_string": "Willy Chung, Samuel Cahyawijaya, Bryan Wilie, "
                },
                {
                    "pdf_id": "8.89",
                    "matching_string": "Holy Lovenia, and Pascale Fung. 2023. "
                },
                {
                    "pdf_id": "8.90",
                    "matching_string": "{InstructTODS}: {Large} {Language} {Models} for {End}to{End} {Task}{Oriented} {Dialogue} {Systems}. ArXiv:2310.08885 [cs]."
                },
                {
                    "pdf_id": "8.91",
                    "matching_string": ""
                }
            ]
        },
        {
            "leaf id": 112,
            "key": "doc/bib4",
            "block type": "bibliography",
            "content": "A.~P. Dempster, N.~M. Laird, and D.~B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):138.",
            "leftover": "A.~38.",
            "matches": [
                {
                    "pdf_id": "8.93",
                    "matching_string": "Maximum likelihood from incomplete data via the "
                },
                {
                    "pdf_id": "8.94",
                    "matching_string": "em algorithm. Journal of the Royal Statistical Society. "
                },
                {
                    "pdf_id": "8.95",
                    "matching_string": "Series B (Methodological), 39(1):1"
                },
                {
                    "pdf_id": "8.92",
                    "matching_string": "P. Dempster, N.~M. Laird, and D.~B. Rubin. 1977. "
                }
            ]
        },
        {
            "leaf id": 113,
            "key": "doc/bib5",
            "block type": "bibliography",
            "content": "Michael Heck, Nurul Lubis, Benjamin Ruppik, Renato Vukovic, Shutong Feng, Christian Geishauser, Hsienchin Lin, Carel van Niekerk, and Milica Gasic. 2023. ChatGPT for zeroshot dialogue state tracking: A solution or an opportunity? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 936950, Toronto, Canada. Association for Computational Linguistics.",
            "leftover": "936950, ",
            "matches": [
                {
                    "pdf_id": "8.96",
                    "matching_string": "Michael Heck, Nurul Lubis, Benjamin Ruppik, Renato "
                },
                {
                    "pdf_id": "8.97",
                    "matching_string": "Vukovic, Shutong Feng, Christian Geishauser, Hsienchin "
                },
                {
                    "pdf_id": "8.98",
                    "matching_string": "Lin, Carel van Niekerk, and Milica Gasic. 2023. "
                },
                {
                    "pdf_id": "8.99",
                    "matching_string": "ChatGPT for zeroshot dialogue state tracking: A "
                },
                {
                    "pdf_id": "8.100",
                    "matching_string": "solution or an opportunity? In Proceedings of the "
                },
                {
                    "pdf_id": "8.104",
                    "matching_string": "Linguistics."
                },
                {
                    "pdf_id": "8.102",
                    "matching_string": "Linguistics (Volume 2: Short Papers), pages "
                },
                {
                    "pdf_id": "8.103",
                    "matching_string": "Toronto, Canada. Association for Computational "
                },
                {
                    "pdf_id": "8.101",
                    "matching_string": "61st Annual Meeting of the Association for Computational "
                }
            ]
        },
        {
            "leaf id": 114,
            "key": "doc/bib6",
            "block type": "bibliography",
            "content": "Ari Holtzman, Jan Buys, Li~Du, Maxwell Forbes, and Yejin Choi. 2020. The {Curious} {Case} of {Neural} {Text} {Degeneration}. ArXiv:1904.09751 [cs].",
            "leftover": "{Neural} {Text} {Degeneration}. ",
            "matches": [
                {
                    "pdf_id": "9.0",
                    "matching_string": "Ari Holtzman, Jan Buys, Li~Du, Maxwell Forbes, and "
                },
                {
                    "pdf_id": "9.3",
                    "matching_string": "ArXiv:1904.09751 [cs]."
                },
                {
                    "pdf_id": "9.2",
                    "matching_string": "Yejin Choi. 2020. The {Curious} {Case} of "
                }
            ]
        },
        {
            "leaf id": 115,
            "key": "doc/bib7",
            "block type": "bibliography",
            "content": "Yushi Hu, ChiaHsuan Lee, Tianbao Xie, Tao Yu, Noah~A. Smith, and Mari Ostendorf. 2022. In{Context} {Learning} for {Few}{Shot} {Dialogue} {State} {Tracking}. Number: arXiv:2203.08568 arXiv:2203.08568 [cs].",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.4",
                    "matching_string": "Yushi Hu, ChiaHsuan Lee, Tianbao Xie, Tao Yu, "
                },
                {
                    "pdf_id": "9.7",
                    "matching_string": "Number: arXiv:2203.08568 arXiv:2203.08568 "
                },
                {
                    "pdf_id": "9.5",
                    "matching_string": "A. Smith, and Mari Ostendorf. 2022. "
                },
                {
                    "pdf_id": "9.8",
                    "matching_string": "[cs]."
                },
                {
                    "pdf_id": "9.6",
                    "matching_string": "Noah~In{Context} {Learning} for {Few}{Shot} {Dialogue} {State} {Tracking}. "
                }
            ]
        },
        {
            "leaf id": 116,
            "key": "doc/bib8",
            "block type": "bibliography",
            "content": "Vojt{\\v{e}}ch Hude{\\v{c}}ek and Ondrej Dusek. 2023. Are large language models all you need for taskoriented dialogue? In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 216228, Prague, Czechia. Association for Computational Linguistics.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.10",
                    "matching_string": "language models all you need for taskoriented dialogue? "
                },
                {
                    "pdf_id": "9.12",
                    "matching_string": "Special Interest Group on Discourse and Dialogue, "
                },
                {
                    "pdf_id": "9.27",
                    "matching_string": "Linguistics."
                },
                {
                    "pdf_id": "9.11",
                    "matching_string": "In Proceedings of the 24th Meeting of the "
                },
                {
                    "pdf_id": "9.13",
                    "matching_string": "pages 216228, Prague, Czechia. Association for "
                },
                {
                    "pdf_id": "9.9",
                    "matching_string": "Vojt{\\v{e}}ch Hude{\\v{c}}ek and Ondrej Dusek. 2023. Are large Computational "
                }
            ]
        },
        {
            "leaf id": 117,
            "key": "doc/bib9",
            "block type": "bibliography",
            "content": "Xisen Jin, Wenqiang Lei, Zhaochun Ren, Hongshen Chen, Shangsong Liang, Yihong Zhao, and Dawei Yin. 2018. Explicit {State} {Tracking} with {Semi}{Supervision} for {Neural} {Dialogue} {Generation}. In Proceedings of the 27th ACM {International} {Conference} on {Information} and {Knowledge} {Management}, pages 14031412. ArXiv:1808.10596 [cs].",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.15",
                    "matching_string": "Xisen Jin, Wenqiang Lei, Zhaochun Ren, Hongshen "
                },
                {
                    "pdf_id": "9.16",
                    "matching_string": "Chen, Shangsong Liang, Yihong Zhao, and Dawei "
                },
                {
                    "pdf_id": "9.17",
                    "matching_string": "Yin. 2018. Explicit {State} {Tracking} with "
                },
                {
                    "pdf_id": "9.21",
                    "matching_string": "ArXiv:1808.10596 [cs]."
                },
                {
                    "pdf_id": "9.18",
                    "matching_string": "for {Neural} {Dialogue} {Generation}. In Proceedings "
                },
                {
                    "pdf_id": "9.20",
                    "matching_string": "on {Information} and {Knowledge} {Management}, pages "
                },
                {
                    "pdf_id": "9.19",
                    "matching_string": "{Semi}{Supervision} of the 27th ACM {International} {Conference} 14031412. "
                }
            ]
        },
        {
            "leaf id": 118,
            "key": "doc/bib10",
            "block type": "bibliography",
            "content": "Brendan King and Jeffrey Flanigan. 2023. Diverse retrievalaugmented incontext learning for dialogue state tracking. In Findings of the Association for Computational Linguistics: ACL 2023, pages 55705585, Toronto, Canada. Association for Computational Linguistics.",
            "leftover": "55705585, ",
            "matches": [
                {
                    "pdf_id": "9.22",
                    "matching_string": "Brendan King and Jeffrey Flanigan. 2023. Diverse "
                },
                {
                    "pdf_id": "9.23",
                    "matching_string": "retrievalaugmented incontext learning for dialogue "
                },
                {
                    "pdf_id": "9.14",
                    "matching_string": "Computational Linguistics."
                },
                {
                    "pdf_id": "9.24",
                    "matching_string": "state tracking. In Findings of the Association for "
                },
                {
                    "pdf_id": "9.25",
                    "matching_string": "Computational Linguistics: ACL 2023, pages "
                },
                {
                    "pdf_id": "9.26",
                    "matching_string": "Toronto, Canada. Association for "
                }
            ]
        },
        {
            "leaf id": 119,
            "key": "doc/bib11",
            "block type": "bibliography",
            "content": "Changmao Li and Jeffrey Flanigan. 2024. Task {Contamination}: {Language} {Models} {May} {Not} {Be} {Few}{Shot} {Anymore}. Proceedings of the AAAI Conference on Artificial Intelligence, 38(16):1847118480.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.28",
                    "matching_string": "Changmao Li and Jeffrey Flanigan. 2024. Task "
                },
                {
                    "pdf_id": "9.30",
                    "matching_string": "Proceedings of the AAAI Conference on "
                },
                {
                    "pdf_id": "9.31",
                    "matching_string": "Artificial Intelligence, 38(16):1"
                },
                {
                    "pdf_id": "9.29",
                    "matching_string": "{Contamination}: {Language} {Models} {May} {Not} {Be} {Few}{Shot} {Anymore}. 847118480."
                }
            ]
        },
        {
            "leaf id": 120,
            "key": "doc/bib12",
            "block type": "bibliography",
            "content": "Raymond Li, Loubna~Ben allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia LI, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry~Yue Zhuo, Thomas Wang, Olivier Dehaene, Joel LamyPoirier, Joao Monteiro, Nicolas Gontier, MingHo Yee, Logesh~Kumar Umapathi, Jian Zhu, Ben Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason~T Stillerman, Siva~Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Urvashi Bhattacharyya, Wenhao Yu, Sasha Luccioni, Paulo Villegas, Fedor Zhdanov, Tony Lee, Nadav Timor, Jennifer Ding, Claire~S Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Carolyn~Jane Anderson, Brendan DolanGavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos~Mu{\\~n}oz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro~Von Werra, and Harm de~Vries. 2023{\\natexlab{a}}. Starcoder: may the source be with you! Transactions on Machine Learning Research. Reproducibility Certification.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.33",
                    "matching_string": "Muennighoff, Denis Kocetkov, Chenghao Mou, Marc "
                },
                {
                    "pdf_id": "9.34",
                    "matching_string": "Marone, Christopher Akiki, Jia LI, Jenny Chim, "
                },
                {
                    "pdf_id": "9.36",
                    "matching_string": "Thomas Wang, Olivier Dehaene, Joel LamyPoirier, "
                },
                {
                    "pdf_id": "9.41",
                    "matching_string": "Marco Zocca, Manan Dey, Zhihan Zhang, "
                },
                {
                    "pdf_id": "9.42",
                    "matching_string": "Urvashi Bhattacharyya, Wenhao Yu, Sasha Luccioni, "
                },
                {
                    "pdf_id": "9.43",
                    "matching_string": "Paulo Villegas, Fedor Zhdanov, Tony Lee, Nadav "
                },
                {
                    "pdf_id": "9.45",
                    "matching_string": "Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, "
                },
                {
                    "pdf_id": "9.47",
                    "matching_string": "Danish Contractor, Siva Reddy, Daniel Fried, "
                },
                {
                    "pdf_id": "9.51",
                    "matching_string": "may the source be with you! Transactions on "
                },
                {
                    "pdf_id": "9.52",
                    "matching_string": "Machine Learning Research. Reproducibility Certification."
                },
                {
                    "pdf_id": "9.37",
                    "matching_string": "Joao Monteiro, Nicolas Gontier, MingHo Yee, "
                },
                {
                    "pdf_id": "9.38",
                    "matching_string": "Kumar Umapathi, Jian Zhu, Ben Lipkin, Muhtasham "
                },
                {
                    "pdf_id": "9.46",
                    "matching_string": "Alex Gu, Carolyn~Jane Anderson, Brendan DolanGavitt, "
                },
                {
                    "pdf_id": "9.49",
                    "matching_string": "Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, "
                },
                {
                    "pdf_id": "9.32",
                    "matching_string": "Raymond Li, Loubna~Ben allal, Yangtian Zi, Niklas "
                },
                {
                    "pdf_id": "9.35",
                    "matching_string": "Qian Liu, Evgenii Zheltonozhskii, Terry~Yue Zhuo, "
                },
                {
                    "pdf_id": "9.39",
                    "matching_string": "Oblokulov, Zhiruo Wang, Rudra Murthy, "
                },
                {
                    "pdf_id": "9.40",
                    "matching_string": "T Stillerman, Siva~Sankalp Patel, Dmitry Abulkhanov, "
                },
                {
                    "pdf_id": "9.44",
                    "matching_string": "Timor, Jennifer Ding, Claire~S Schlesinger, Hailey "
                },
                {
                    "pdf_id": "9.48",
                    "matching_string": "Dzmitry Bahdanau, Yacine Jernite, "
                },
                {
                    "pdf_id": "9.50",
                    "matching_string": "Von Werra, and Harm de~Vries. 2023{\\natexlab{a}}. Starcoder: "
                },
                {
                    "pdf_id": "9.53",
                    "matching_string": "Logesh~Jason~Carlos~Mu{\\~n}oz Leandro~"
                }
            ]
        },
        {
            "leaf id": 121,
            "key": "doc/bib13",
            "block type": "bibliography",
            "content": "Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, and Xifeng Yan. 2023{\\natexlab{b}}. Guiding large language models via directional stimulus prompting. arXiv preprint arXiv:2302.11520.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.54",
                    "matching_string": "Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, "
                },
                {
                    "pdf_id": "9.56",
                    "matching_string": "language models via directional stimulus prompting. "
                },
                {
                    "pdf_id": "9.57",
                    "matching_string": "arXiv preprint arXiv:2302.11520."
                },
                {
                    "pdf_id": "9.55",
                    "matching_string": "Jianfeng Gao, and Xifeng Yan. 2023{\\natexlab{b}}. Guiding large "
                }
            ]
        },
        {
            "leaf id": 122,
            "key": "doc/bib14",
            "block type": "bibliography",
            "content": "Hong Liu, Yucheng Cai, Zhenru Lin, Zhijian Ou, Yi~Huang, and Junlan Feng. 2021{\\natexlab{a}}. Variational {Latent}{State} GPT for {Semi}{Supervised} {Task}{Oriented} {Dialog} {Systems}. ArXiv:2109.04314 [cs].",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.1",
                    "matching_string": "Hong Liu, Yucheng Cai, Zhenru Lin, Zhijian Ou, "
                },
                {
                    "pdf_id": "9.58",
                    "matching_string": "Yi~Huang, and Junlan Feng. 2021{\\natexlab{a}}. Variational {Latent}{State} GPT for {Semi}{Supervised} {Task}{Oriented} {Dialog} {Systems}. ArXiv:2109.04314 [cs]."
                },
                {
                    "pdf_id": "9.59",
                    "matching_string": ""
                },
                {
                    "pdf_id": "9.60",
                    "matching_string": ""
                }
            ]
        },
        {
            "leaf id": 123,
            "key": "doc/bib15",
            "block type": "bibliography",
            "content": "Qi~Liu, Lei Yu, Laura Rimell, and Phil Blunsom. 2021{\\natexlab{b}}. Pretraining the {Noisy} {Channel} {Model} for {Task}{Oriented} {Dialogue}. Transactions of the Association for Computational Linguistics, 9:657674.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.61",
                    "matching_string": "Liu, Lei Yu, Laura Rimell, and Phil Blunsom. "
                },
                {
                    "pdf_id": "9.64",
                    "matching_string": "for Computational Linguistics, 9:6"
                },
                {
                    "pdf_id": "9.62",
                    "matching_string": "Pretraining the {Noisy} {Channel} {Model} for "
                },
                {
                    "pdf_id": "9.63",
                    "matching_string": "Qi~2021{\\natexlab{b}}. {Task}{Oriented} {Dialogue}. Transactions of the Association 57674."
                }
            ]
        },
        {
            "leaf id": 124,
            "key": "doc/bib16",
            "block type": "bibliography",
            "content": "QingBin Liu, ShiZhu He, Cao Liu, Kang Liu, and Jun Zhao. 2023. Unsupervised {Dialogue} {State} {Tracking} for {End}to{End} {Task}{Oriented} {Dialogue} with a {Multi}{Span} {Prediction} {Network}. Journal of Computer Science and Technology, 38(4):834852.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.65",
                    "matching_string": "QingBin Liu, ShiZhu He, Cao Liu, Kang Liu, and "
                },
                {
                    "pdf_id": "9.69",
                    "matching_string": "Science and Technology, 38(4):8"
                },
                {
                    "pdf_id": "9.67",
                    "matching_string": "for {End}to{End} {Task}{Oriented} {Dialogue} with a "
                },
                {
                    "pdf_id": "9.66",
                    "matching_string": "Jun Zhao. 2023. Unsupervised {Dialogue} {State} {Tracking} {Multi}{Span} {Prediction} {Network}. Journal of Computer 34852."
                },
                {
                    "pdf_id": "9.68",
                    "matching_string": ""
                }
            ]
        },
        {
            "leaf id": 125,
            "key": "doc/bib17",
            "block type": "bibliography",
            "content": "Sewon Min, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Noisy channel language model prompting for fewshot text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 53165330, Dublin, Ireland. Association for Computational Linguistics.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.70",
                    "matching_string": "Sewon Min, Mike Lewis, Hannaneh Hajishirzi, and "
                },
                {
                    "pdf_id": "9.71",
                    "matching_string": "Luke Zettlemoyer. 2022. Noisy channel language "
                },
                {
                    "pdf_id": "9.72",
                    "matching_string": "model prompting for fewshot text classification. In "
                },
                {
                    "pdf_id": "9.74",
                    "matching_string": "for Computational Linguistics (Volume 1: "
                },
                {
                    "pdf_id": "9.76",
                    "matching_string": "for Computational Linguistics."
                },
                {
                    "pdf_id": "9.75",
                    "matching_string": "Long Papers), pages 53165330, Dublin, Ireland. Association "
                },
                {
                    "pdf_id": "9.73",
                    "matching_string": "Proceedings of the 60th Annual Meeting of the Association "
                }
            ]
        },
        {
            "leaf id": 126,
            "key": "doc/bib18",
            "block type": "bibliography",
            "content": "Tom{\\'a}{\\v{s}} Nekvinda and Ond{\\v{r}}ej Du{\\v{s}}ek. 2021. Shades of BLEU, flavours of success: The case of MultiWOZ. In Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 3446, Online. Association for Computational Linguistics.",
            "leftover": "Tom{\\'a}{\\v{s}} ",
            "matches": [
                {
                    "pdf_id": "9.78",
                    "matching_string": "BLEU, flavours of success: The case of MultiWOZ. "
                },
                {
                    "pdf_id": "9.79",
                    "matching_string": "In Proceedings of the 1st Workshop on Natural Language "
                },
                {
                    "pdf_id": "9.82",
                    "matching_string": "Linguistics."
                },
                {
                    "pdf_id": "9.80",
                    "matching_string": "Generation, Evaluation, and Metrics (GEM "
                },
                {
                    "pdf_id": "9.81",
                    "matching_string": "2021), pages 3446, Online. Association for Computational "
                },
                {
                    "pdf_id": "9.77",
                    "matching_string": "Nekvinda and Ond{\\v{r}}ej Du{\\v{s}}ek. 2021. Shades of "
                }
            ]
        },
        {
            "leaf id": 127,
            "key": "doc/bib19",
            "block type": "bibliography",
            "content": "Wenbo Pan, Qiguang Chen, Xiao Xu, Wanxiang Che, and Libo Qin. 2023. A {Preliminary} {Evaluation} of {ChatGPT} for {Zero}shot {Dialogue} {Understanding}. Publisher: arXiv Version Number: 1.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.83",
                    "matching_string": "Wenbo Pan, Qiguang Chen, Xiao Xu, Wanxiang Che, "
                },
                {
                    "pdf_id": "9.86",
                    "matching_string": "Publisher: arXiv Version Number: 1."
                },
                {
                    "pdf_id": "9.84",
                    "matching_string": "and Libo Qin. 2023. A {Preliminary} {Evaluation} of {ChatGPT} for {Zero}shot {Dialogue} {Understanding}. "
                },
                {
                    "pdf_id": "9.85",
                    "matching_string": ""
                }
            ]
        },
        {
            "leaf id": 128,
            "key": "doc/bib20",
            "block type": "bibliography",
            "content": "Shachi Paul, Rahul Goel, and Dilek HakkaniTr. 2019. {Towards Universal Dialogue Act Tagging for TaskOriented Dialogues}. In Proc. Interspeech 2019, pages 14531457.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.87",
                    "matching_string": "Shachi Paul, Rahul Goel, and Dilek HakkaniTr. 2019. "
                },
                {
                    "pdf_id": "9.88",
                    "matching_string": "Towards Universal Dialogue Act Tagging for TaskOriented "
                },
                {
                    "pdf_id": "9.90",
                    "matching_string": "pages "
                },
                {
                    "pdf_id": "9.89",
                    "matching_string": "{Dialogues}. In Proc. Interspeech 2019, 14531457."
                }
            ]
        },
        {
            "leaf id": 129,
            "key": "doc/bib21",
            "block type": "bibliography",
            "content": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu. 2020. Exploring the {Limits} of {Transfer} {Learning} with a {Unified} {Text}to{Text} {Transformer}. arXiv:1910.10683 [cs, stat]. ArXiv: 1910.10683.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.91",
                    "matching_string": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine "
                },
                {
                    "pdf_id": "9.92",
                    "matching_string": "Lee, Sharan Narang, Michael Matena, Yanqi Zhou, "
                },
                {
                    "pdf_id": "9.96",
                    "matching_string": "1910.10683."
                },
                {
                    "pdf_id": "9.93",
                    "matching_string": "Wei Li, and Peter~J. Liu. 2020. Exploring the "
                },
                {
                    "pdf_id": "9.95",
                    "matching_string": "arXiv:1910.10683 [cs, stat]. ArXiv: "
                },
                {
                    "pdf_id": "9.94",
                    "matching_string": "{Limits} of {Transfer} {Learning} with a {Unified} {Text}to{Text} {Transformer}. "
                }
            ]
        },
        {
            "leaf id": 130,
            "key": "doc/bib22",
            "block type": "bibliography",
            "content": "Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020. Towards {Scalable} {Multi}{Domain} {Conversational} {Agents}: {The} {Schema}{Guided} {Dialogue} {Dataset}. Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):86898696.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.97",
                    "matching_string": "Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, "
                },
                {
                    "pdf_id": "9.98",
                    "matching_string": "Raghav Gupta, and Pranav Khaitan. 2020. Towards "
                },
                {
                    "pdf_id": "9.101",
                    "matching_string": "of the AAAI Conference on Artificial Intelligence, "
                },
                {
                    "pdf_id": "9.102",
                    "matching_string": "34(05):8"
                },
                {
                    "pdf_id": "9.99",
                    "matching_string": "{Scalable} {Multi}{Domain} {Conversational} {Agents}: {The} {Schema}{Guided} {Dialogue} {Dataset}. Proceedings 6898696."
                },
                {
                    "pdf_id": "9.100",
                    "matching_string": ""
                }
            ]
        },
        {
            "leaf id": 131,
            "key": "doc/bib23",
            "block type": "bibliography",
            "content": "Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and TieYan Liu. 2020. {MPNet}: {Masked} and {Permuted} {Pre}training for {Language} {Understanding}. ArXiv:2004.09297 [cs].",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.106",
                    "matching_string": "ArXiv:2004.09297 [cs]."
                },
                {
                    "pdf_id": "9.103",
                    "matching_string": "Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and "
                },
                {
                    "pdf_id": "9.104",
                    "matching_string": "TieYan Liu. 2020. {MPNet}: {Masked} and "
                },
                {
                    "pdf_id": "9.105",
                    "matching_string": "{Permuted} {Pre}training for {Language} {Understanding}. "
                }
            ]
        },
        {
            "leaf id": 132,
            "key": "doc/bib24",
            "block type": "bibliography",
            "content": "Yixuan Su, Lei Shu, Elman Mansimov, Arshit Gupta, Deng Cai, YiAn Lai, and Yi~Zhang. 2022. Multitask pretraining for plugandplay taskoriented dialogue system. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 46614676, Dublin, Ireland. Association for Computational Linguistics.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "9.107",
                    "matching_string": "Yixuan Su, Lei Shu, Elman Mansimov, Arshit Gupta, "
                },
                {
                    "pdf_id": "9.109",
                    "matching_string": "pretraining for plugandplay taskoriented dialogue "
                },
                {
                    "pdf_id": "9.110",
                    "matching_string": "system. In Proceedings of the 60th Annual Meeting "
                },
                {
                    "pdf_id": "9.108",
                    "matching_string": "Deng Cai, YiAn Lai, and Yi~Zhang. 2022. Multitask "
                },
                {
                    "pdf_id": "9.111",
                    "matching_string": "of the Association for Computational Linguistics "
                },
                {
                    "pdf_id": "9.113",
                    "matching_string": "Ireland. Association for Computational Linguistics."
                },
                {
                    "pdf_id": "9.112",
                    "matching_string": "(Volume 1: Long Papers), pages 46614676, Dublin, "
                }
            ]
        },
        {
            "leaf id": 133,
            "key": "doc/bib25",
            "block type": "bibliography",
            "content": "Qingyang Wu, James Gung, Raphael Shu, and Yi~Zhang. 2023. DiactTOD: Learning generalizable latent dialogue acts for controllable taskoriented dialogue systems. In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 255267, Prague, Czechia. Association for Computational Linguistics.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "10.3",
                    "matching_string": "acts for controllable taskoriented dialogue "
                },
                {
                    "pdf_id": "10.4",
                    "matching_string": "systems. In Proceedings of the 24th Meeting of the "
                },
                {
                    "pdf_id": "10.5",
                    "matching_string": "Special Interest Group on Discourse and Dialogue, "
                },
                {
                    "pdf_id": "10.0",
                    "matching_string": "Qingyang Wu, James Gung, Raphael Shu, and Yi~Zhang. "
                },
                {
                    "pdf_id": "10.2",
                    "matching_string": "2023. DiactTOD: Learning generalizable latent dialogue "
                },
                {
                    "pdf_id": "10.7",
                    "matching_string": "Computational Linguistics."
                },
                {
                    "pdf_id": "10.6",
                    "matching_string": "pages 255267, Prague, Czechia. Association for "
                }
            ]
        },
        {
            "leaf id": 134,
            "key": "doc/bib26",
            "block type": "bibliography",
            "content": "Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, and Jindong Chen. 2020. {MultiWOZ} 2.2 : A {Dialogue} {Dataset} with {Additional} {Annotation} {Corrections} and {State} {Tracking} {Baselines}. In Proceedings of the 2nd {Workshop} on {Natural} {Language} {Processing} for {Conversational} AI, pages 109117, Online. Association for Computational Linguistics.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "10.8",
                    "matching_string": "Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, "
                },
                {
                    "pdf_id": "10.9",
                    "matching_string": "Raghav Gupta, Jianguo Zhang, and Jindong Chen. "
                },
                {
                    "pdf_id": "10.15",
                    "matching_string": "Linguistics."
                },
                {
                    "pdf_id": "10.14",
                    "matching_string": "pages 109117, Online. Association for Computational "
                },
                {
                    "pdf_id": "10.10",
                    "matching_string": "2020. {MultiWOZ} 2.2 : A {Dialogue} {Dataset} with "
                },
                {
                    "pdf_id": "10.12",
                    "matching_string": "In Proceedings of the 2nd {Workshop} on "
                },
                {
                    "pdf_id": "10.11",
                    "matching_string": "{Additional} {Annotation} {Corrections} and {State} {Tracking} {Baselines}. {Natural} {Language} {Processing} for {Conversational} AI, "
                },
                {
                    "pdf_id": "10.13",
                    "matching_string": ""
                }
            ]
        },
        {
            "leaf id": 135,
            "key": "doc/bib27",
            "block type": "bibliography",
            "content": "Xiaoying Zhang, Baolin Peng, Kun Li, Jingyan Zhou, and Helen Meng. 2023. SGPTOD: Building task bots effortlessly via schemaguided LLM prompting. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1334813369, Singapore. Association for Computational Linguistics.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "10.16",
                    "matching_string": "Xiaoying Zhang, Baolin Peng, Kun Li, Jingyan Zhou, "
                },
                {
                    "pdf_id": "10.17",
                    "matching_string": "and Helen Meng. 2023. SGPTOD: Building task "
                },
                {
                    "pdf_id": "10.18",
                    "matching_string": "bots effortlessly via schemaguided LLM prompting. "
                },
                {
                    "pdf_id": "10.19",
                    "matching_string": "In Findings of the Association for Computational "
                },
                {
                    "pdf_id": "10.21",
                    "matching_string": "Association for Computational Linguistics."
                },
                {
                    "pdf_id": "10.20",
                    "matching_string": "Linguistics: EMNLP 2023, pages 1334813369, Singapore. "
                }
            ]
        },
        {
            "leaf id": 136,
            "key": "doc/bib28",
            "block type": "bibliography",
            "content": "Yichi Zhang, Zhijian Ou, Min Hu, and Junlan Feng. 2020. A {Probabilistic} {End}{To}{End} {Task}{Oriented} {Dialog} {Model} with {Latent} {Belief} {States} towards {Semi}{Supervised} {Learning}. In Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} (EMNLP), pages 92079219, Online. Association for Computational Linguistics.",
            "leftover": "",
            "matches": [
                {
                    "pdf_id": "10.22",
                    "matching_string": "Yichi Zhang, Zhijian Ou, Min Hu, and Junlan Feng. "
                },
                {
                    "pdf_id": "10.28",
                    "matching_string": "Association for Computational Linguistics."
                },
                {
                    "pdf_id": "10.27",
                    "matching_string": "(EMNLP), pages 92079219, Online. "
                },
                {
                    "pdf_id": "10.24",
                    "matching_string": "with {Latent} {Belief} {States} towards "
                },
                {
                    "pdf_id": "10.23",
                    "matching_string": "2020. A {Probabilistic} {End}{To}{End} {Task}{Oriented} {Dialog} {Model} {Semi}{Supervised} {Learning}. In Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} "
                },
                {
                    "pdf_id": "10.25",
                    "matching_string": ""
                },
                {
                    "pdf_id": "10.26",
                    "matching_string": ""
                }
            ]
        },
        {
            "leaf id": 137,
            "key": "doc/bib29",
            "block type": "bibliography",
            "content": "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving fewshot performance of language models. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 1269712706. PMLR.",
            "leftover": "1269712706. ",
            "matches": [
                {
                    "pdf_id": "10.29",
                    "matching_string": "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and "
                },
                {
                    "pdf_id": "10.30",
                    "matching_string": "Sameer Singh. 2021. Calibrate before use: Improving "
                },
                {
                    "pdf_id": "10.32",
                    "matching_string": "Proceedings of the 38th International Conference "
                },
                {
                    "pdf_id": "10.33",
                    "matching_string": "on Machine Learning, volume 139 of Proceedings "
                },
                {
                    "pdf_id": "10.35",
                    "matching_string": "PMLR."
                },
                {
                    "pdf_id": "10.31",
                    "matching_string": "fewshot performance of language models. In "
                },
                {
                    "pdf_id": "10.34",
                    "matching_string": "of Machine Learning Research, pages "
                }
            ]
        }
    ]
}