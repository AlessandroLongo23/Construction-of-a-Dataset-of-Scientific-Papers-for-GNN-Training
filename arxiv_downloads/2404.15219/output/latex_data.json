{
    "key": "doc",
    "block_type": "document",
    "children": [
        {
            "leaf id": 0,
            "key": "doc/tit",
            "block type": "title",
            "content": "The Power of the Noisy Channel: Unsupervised EndtoEnd TaskOriented Dialogue with LLMs",
            "leftover": "The Power of the Noisy Channel: Unsupervised EndtoEnd TaskOriented Dialogue with LLMs",
            "matches": []
        },
        {
            "leaf id": 1,
            "key": "doc/aut0",
            "block type": "author",
            "content": "{Brendan King, Jeffrey Flanigan University of California, Santa Cruz {bking2,jmflanig}@ucsc.edu}",
            "leftover": "{Brendan King, Jeffrey Flanigan University of California, Santa Cruz {bking2,jmflanig}@ucsc.edu}",
            "matches": []
        },
        {
            "leaf id": 2,
            "key": "doc/abs",
            "block type": "abstract",
            "content": "Training taskoriented dialogue systems typically requires turnlevel annotations for interacting with their APIs: e.g. a dialogue state and the system actions taken at each step. These annotations can be costly to produce, errorprone, and require both domain and annotation expertise. With advances in LLMs, we hypothesize unlabelled data and a schema definition are sufficient for building a working taskoriented dialogue system, completely unsupervised. Using only (1) a welldefined API schema (2) a set of unlabelled dialogues between a user and agent, we develop a novel approach for inferring turnlevel annotations as latent variables using a noisy channel model. We iteratively improve these pseudolabels with expectationmaximization (EM), and use the inferred labels to train an endtoend dialogue agent. Evaluating our approach on the MultiWOZ benchmark, our method more than doubles the dialogue success rate of a strong GPT3.5 baseline.Our code will be available at https://github.com/jlabnlp/nclatenttod",
            "leftover": "Training taskoriented dialogue systems typically requires turnlevel annotations for interacting with their APIs: e.g. a dialogue state and the system actions taken at each step. These annotations can be costly to produce, errorprone, and require both domain and annotation expertise. With advances in LLMs, we hypothesize unlabelled data and a schema definition are sufficient for building a working taskoriented dialogue system, completely unsupervised. Using only (1) a welldefined API schema (2) a set of unlabelled dialogues between a user and agent, we develop a novel approach for inferring turnlevel annotations as latent variables using a noisy channel model. We iteratively improve these pseudolabels with expectationmaximization (EM), and use the inferred labels to train an endtoend dialogue agent. Evaluating our approach on the MultiWOZ benchmark, our method more than doubles the dialogue success rate of a strong GPT3.5 baseline.Our code will be available at https://github.com/jlabnlp/nclatenttod",
            "matches": []
        },
        {
            "key": "doc/body",
            "block_type": "body",
            "children": [
                {
                    "key": "doc/body/sec0",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 3,
                            "key": "doc/body/sec0/tit",
                            "block type": "title",
                            "content": "Introduction",
                            "leftover": "Introduction",
                            "matches": []
                        },
                        {
                            "leaf id": 4,
                            "key": "doc/body/sec0/txl0",
                            "block type": "txl",
                            "content": "Taskoriented dialogue systems, which use APIs to complete tasks on behalf of users, have been a longstanding challenge within conversational AI. Recent advances in large language models (LLMs) have further stimulated interest in taskoriented systems and LLMs which can use APIs as tools. To facilitate API use, successful taskoriented dialogue systems usually employ a modular approach: predicting a dialogue state which includes arguments to API calls, and dialogue acts for planning an appropriate response, before finally producing a natural language reply. Training such systems typically requires expert annotation of these structured intermediates for every dialogue turn. Even in settings where humanhuman dialogues are abundantly available, the high cost and expertise required to annotate the dialogues poses a significant hurdle to system development.",
                            "leftover": "Taskoriented dialogue systems, which use APIs to complete tasks on behalf of users, have been a longstanding challenge within conversational AI. Recent advances in large language models (LLMs) have further stimulated interest in taskoriented systems and LLMs which can use APIs as tools. To facilitate API use, successful taskoriented dialogue systems usually employ a modular approach: predicting a dialogue state which includes arguments to API calls, and dialogue acts for planning an appropriate response, before finally producing a natural language reply. Training such systems typically requires expert annotation of these structured intermediates for every dialogue turn. Even in settings where humanhuman dialogues are abundantly available, the high cost and expertise required to annotate the dialogues poses a significant hurdle to system development.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec0/figure1",
                            "block_type": "figure",
                            "children": [
                                {
                                    "leaf id": 5,
                                    "key": "doc/body/sec0/figure1/cpt0",
                                    "block type": "cpt",
                                    "content": "An overview of our unsupervised dialogue problem. We assume 1) unlabelled goaloriented dialogues between a user and agent and 2) a welldefined schema ùíÆ with APIs suitable for fulfilling goals. We infer the unseen interactions between the agent and API, and use this to produce an endtoend dialogue agent.",
                                    "leftover": "An overview of our unsupervised dialogue problem. We assume 1) unlabelled goaloriented dialogues between a user and agent and 2) a welldefined schema ùíÆ with APIs suitable for fulfilling goals. We infer the unseen interactions between the agent and API, and use this to produce an endtoend dialogue agent.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "leaf id": 6,
                            "key": "doc/body/sec0/txl2",
                            "block type": "txl",
                            "content": "Recent work has shown that LLMs can accomplish a broad set of useful tasks without any structured labels for a task . These include 'zeroshot' approaches to taskoriented dialogue subtasks such as Dialogue State Tracking (DST), intent detection, grounded response generation, and even zeroshot endtoend dialogue systems . Still, existing approaches generally do not perform well enough for realworld use, and none are able to make effective use of indomain unlabelled dialogues.",
                            "leftover": "Recent work has shown that LLMs can accomplish a broad set of useful tasks without any structured labels for a task . These include 'zeroshot' approaches to taskoriented dialogue subtasks such as Dialogue State Tracking (DST), intent detection, grounded response generation, and even zeroshot endtoend dialogue systems . Still, existing approaches generally do not perform well enough for realworld use, and none are able to make effective use of indomain unlabelled dialogues.",
                            "matches": []
                        },
                        {
                            "leaf id": 7,
                            "key": "doc/body/sec0/txl3",
                            "block type": "txl",
                            "content": "We ask: can we use existing unlabelled dialogues (without any labels or API calls annotated) along with an API specification, to build a working dialogue agent, without needing an expert to annotate data? This addresses a common realworld scenario. Many high value dialogue tasks are currently carried out by human agents, who interface a user with some software system. These conversations can be recorded and transcribed, and the API(s) supporting the agent typically have wellformed specifications. However, annotating the API calls and system acts needed for aligning the two is time consuming and requires annotation expertise. In lieu of this, 'zeroshot' systems have been proposed, but these still require an expert to annotate a 'formatting example', or a more detailed 'policy skeleton' .",
                            "leftover": "We ask: can we use existing unlabelled dialogues (without any labels or API calls annotated) along with an API specification, to build a working dialogue agent, without needing an expert to annotate data? This addresses a common realworld scenario. Many high value dialogue tasks are currently carried out by human agents, who interface a user with some software system. These conversations can be recorded and transcribed, and the API(s) supporting the agent typically have wellformed specifications. However, annotating the API calls and system acts needed for aligning the two is time consuming and requires annotation expertise. In lieu of this, 'zeroshot' systems have been proposed, but these still require an expert to annotate a 'formatting example', or a more detailed 'policy skeleton' .",
                            "matches": []
                        },
                        {
                            "leaf id": 8,
                            "key": "doc/body/sec0/txl4",
                            "block type": "txl",
                            "content": "We instead propose the following setting: we assume an API schema definition ùíÆ, and plenty of available humanhuman dialogues in natural language, but no annotations on these dialogues (). To the best of our knowledge, we are the first to consider this setting. We demonstrate that one can develop a conversational agent for the API schema in this setting without any assistance from an expert annotator. Our contributions are as follows:",
                            "leftover": "We instead propose the following setting: we assume an API schema definition ùíÆ, and plenty of available humanhuman dialogues in natural language, but no annotations on these dialogues (). To the best of our knowledge, we are the first to consider this setting. We demonstrate that one can develop a conversational agent for the API schema in this setting without any assistance from an expert annotator. Our contributions are as follows:",
                            "matches": []
                        },
                        {
                            "leaf id": 9,
                            "key": "doc/body/sec0/itemize5",
                            "block type": "itemize",
                            "content": "We construct an endtoend taskoriented dialogue agent with an LLM solely from unlabelled dialogues and an API definition, without any turnlevel labels or supervision from delexicalized utterances. We accomplish this by inferring all the pseudolabels necessary (API calls, system actions) to train a traditional endtoend dialogue system from unlabelled dialogues, using prompts which are automatically generated from the API schema. We propose a noisychannel 'codetotext' reranking method, which is instrumental to our pseudolabel quality and final system. We devise a novel HardEM approach which uses predictions as incontext examples for the LLM, and additionally as data for iteratively finetuning a final model.",
                            "leftover": "We construct an endtoend taskoriented dialogue agent with an LLM solely from unlabelled dialogues and an API definition, without any turnlevel labels or supervision from delexicalized utterances. We accomplish this by inferring all the pseudolabels necessary (API calls, system actions) to train a traditional endtoend dialogue system from unlabelled dialogues, using prompts which are automatically generated from the API schema. We propose a noisychannel 'codetotext' reranking method, which is instrumental to our pseudolabel quality and final system. We devise a novel HardEM approach which uses predictions as incontext examples for the LLM, and additionally as data for iteratively finetuning a final model.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec1",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 10,
                            "key": "doc/body/sec1/tit",
                            "block type": "title",
                            "content": "Preliminaries",
                            "leftover": "Preliminaries",
                            "matches": []
                        },
                        {
                            "leaf id": 11,
                            "key": "doc/body/sec1/txl0",
                            "block type": "txl",
                            "content": "A taskoriented dialogue consists of turns of utterances between a user and an agent which interfaces the user with a programmable system or API to accomplish a task. Typically the system response utterance follows the user's utterance. We denote ut as the user's utterance at turn t, and rt as the system's response. We assume the APIs supported by the system are defined in a schema ùíÆ, which gives names and descriptions for all arguments supported in each API, as well as the possible values any categorical arguments may take . This is analogous to standardized formats for API documentation, many of which could be easily converted to a schema definition.",
                            "leftover": "A taskoriented dialogue consists of turns of utterances between a user and an agent which interfaces the user with a programmable system or API to accomplish a task. Typically the system response utterance follows the user's utterance. We denote ut as the user's utterance at turn t, and rt as the system's response. We assume the APIs supported by the system are defined in a schema ùíÆ, which gives names and descriptions for all arguments supported in each API, as well as the possible values any categorical arguments may take . This is analogous to standardized formats for API documentation, many of which could be easily converted to a schema definition.",
                            "matches": []
                        },
                        {
                            "leaf id": 12,
                            "key": "doc/body/sec1/txl1",
                            "block type": "txl",
                            "content": "Taskoriented systems require some method for interacting with the APIs in ùíÆ. Modular approaches use a Dialogue State Tracking (DST) module, which predicts a belief state bt : a collection of arguments to API call(s) needed to satisfy the user's goal. A belief state is commonly represented with a set of slotvalue pairs:",
                            "leftover": "Taskoriented systems require some method for interacting with the APIs in ùíÆ. Modular approaches use a Dialogue State Tracking (DST) module, which predicts a belief state bt : a collection of arguments to API call(s) needed to satisfy the user's goal. A belief state is commonly represented with a set of slotvalue pairs:",
                            "matches": []
                        },
                        {
                            "leaf id": 13,
                            "key": "doc/body/sec1/frm2",
                            "block type": "frm",
                            "content": "bt = (s1, v1), (s2, v2), ... (sn, vn)",
                            "leftover": "bt = (s1, v1), (s2, v2), ... (sn, vn)",
                            "matches": []
                        },
                        {
                            "leaf id": 14,
                            "key": "doc/body/sec1/txl3",
                            "block type": "txl",
                            "content": "For example, if a user says 'I'm looking for a restaurant south of town', a DST system might produce the belief state {(restaurantarea, south)}, which can be used to query a restaurant API. We assume zero labeled belief states and infer them from unlabelled dialogues using the space of possible states supported by the schema definition ùíÆ.",
                            "leftover": "For example, if a user says 'I'm looking for a restaurant south of town', a DST system might produce the belief state {(restaurantarea, south)}, which can be used to query a restaurant API. We assume zero labeled belief states and infer them from unlabelled dialogues using the space of possible states supported by the schema definition ùíÆ.",
                            "matches": []
                        },
                        {
                            "leaf id": 15,
                            "key": "doc/body/sec1/txl4",
                            "block type": "txl",
                            "content": "We also make use of system dialogue acts to structure our agent's communicative intents with a policy module. Given a dialogue state and context for a turn t, the policy predicts set of dialogue acts to be communicated in the system response rt. For instance, the policy might determine that we should ask the user to narrow their search to a price range: At = Request(restaurantarea=?). An appropriate system response might be: ''Sure, are you looking for a particular price range?'' Like belief states, we assume zero supervised examples of At and infer them from unlabelled dialogues.",
                            "leftover": "We also make use of system dialogue acts to structure our agent's communicative intents with a policy module. Given a dialogue state and context for a turn t, the policy predicts set of dialogue acts to be communicated in the system response rt. For instance, the policy might determine that we should ask the user to narrow their search to a price range: At = Request(restaurantarea=?). An appropriate system response might be: ''Sure, are you looking for a particular price range?'' Like belief states, we assume zero supervised examples of At and infer them from unlabelled dialogues.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec2",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 16,
                            "key": "doc/body/sec2/tit",
                            "block type": "title",
                            "content": "Method Overview",
                            "leftover": "Method Overview",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec2/figure*0",
                            "block_type": "figure*",
                            "children": [
                                {
                                    "leaf id": 17,
                                    "key": "doc/body/sec2/figure*0/cpt0",
                                    "block type": "cpt",
                                    "content": "An overview of the latent variables annotated in our unsupervised labeling process which are used to train the dialogue model. Our \\textcolor{dstcolor}{{DST Module}} () infers the API call(s) with arguments at each turn, from which we can derive the dialogue state change. Our \\textcolor{datcolor}{{DAT or Act Tagging module}} () predicts the dialogue acts communicated in the observed system response, which can be used to infer delexicalized responses for training a response generator.",
                                    "leftover": "An overview of the latent variables annotated in our unsupervised labeling process which are used to train the dialogue model. Our \\textcolor{dstcolor}{{DST Module}} () infers the API call(s) with arguments at each turn, from which we can derive the dialogue state change. Our \\textcolor{datcolor}{{DAT or Act Tagging module}} () predicts the dialogue acts communicated in the observed system response, which can be used to infer delexicalized responses for training a response generator.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "leaf id": 18,
                            "key": "doc/body/sec2/txl1",
                            "block type": "txl",
                            "content": "We treat the turnlevel labels needed for training an endtoend dialogue system as a latent variables, and infer them from unlabelled dialogues. We assume only the fullylexicalized sequence of user and system utterances u1, r1, ... uT, rT, and the schema ùíÆ defining the system's capabilities, which defines the space of valid dialogue state and act labels. Importantly, our prompts are automatically generated from the API schema.",
                            "leftover": "We treat the turnlevel labels needed for training an endtoend dialogue system as a latent variables, and infer them from unlabelled dialogues. We assume only the fullylexicalized sequence of user and system utterances u1, r1, ... uT, rT, and the schema ùíÆ defining the system's capabilities, which defines the space of valid dialogue state and act labels. Importantly, our prompts are automatically generated from the API schema.",
                            "matches": []
                        },
                        {
                            "leaf id": 19,
                            "key": "doc/body/sec2/txl2",
                            "block type": "txl",
                            "content": "In, we outline our noisychannel prompting method for inferring the turnlevel labels necessary for training our dialogue agent. We give an overview of the latent variables we infer in . We assume we cannot query the APIs or observe results while labeling dialogues offline, as the obtained API results may have changed. In, we train a complete dialogue agent by finetuning on prompts derived from our inferred pseudolabels.",
                            "leftover": "In, we outline our noisychannel prompting method for inferring the turnlevel labels necessary for training our dialogue agent. We give an overview of the latent variables we infer in . We assume we cannot query the APIs or observe results while labeling dialogues offline, as the obtained API results may have changed. In, we train a complete dialogue agent by finetuning on prompts derived from our inferred pseudolabels.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec3",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 20,
                            "key": "doc/body/sec3/tit",
                            "block type": "title",
                            "content": "Inferring Latents via Noisy Channel",
                            "leftover": "Inferring Latents via Noisy Channel",
                            "matches": []
                        },
                        {
                            "leaf id": 21,
                            "key": "doc/body/sec3/txl0",
                            "block type": "txl",
                            "content": "In this section, we present our method for inferring latent annotations for the dialogue states b1...bT and dialogue acts A1...AT for each dialogue turn t given only the unlabelled user and system utterances (u1, r1, u2, r2, ... uT, rT). To do this, we devise a noisychannel prompting approach for DST and dialogue act tagging (DAT) using StarCoder, a codebased LLM. First, we use a texttocode prompt to infer the API call(s) made by the system in each dialogue, and build the dialogue state from inferred API call arguments (). We use a similar texttocode prompt to infer the latent act(s) communicated in each agent response, so that we can reverseengineer an agent's policy (). For both tasks, we find much better performance when reranking latent predictions according to a noisychannel model, in which we condition the observed utterance on a predicted latent in a codetotext prompt (). Finally, we leverage the incontext learning ability of LLMs by reusing our predictions as exemplars (). Given these initial pseudolabels, we iteratively improve their quality using HardEM ().",
                            "leftover": "In this section, we present our method for inferring latent annotations for the dialogue states b1...bT and dialogue acts A1...AT for each dialogue turn t given only the unlabelled user and system utterances (u1, r1, u2, r2, ... uT, rT). To do this, we devise a noisychannel prompting approach for DST and dialogue act tagging (DAT) using StarCoder, a codebased LLM. First, we use a texttocode prompt to infer the API call(s) made by the system in each dialogue, and build the dialogue state from inferred API call arguments (). We use a similar texttocode prompt to infer the latent act(s) communicated in each agent response, so that we can reverseengineer an agent's policy (). For both tasks, we find much better performance when reranking latent predictions according to a noisychannel model, in which we condition the observed utterance on a predicted latent in a codetotext prompt (). Finally, we leverage the incontext learning ability of LLMs by reusing our predictions as exemplars (). Given these initial pseudolabels, we iteratively improve their quality using HardEM ().",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec3/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 22,
                                    "key": "doc/body/sec3/sub1/tit",
                                    "block type": "title",
                                    "content": "Inferring API Calls and Dialogue State",
                                    "leftover": "Inferring API Calls and Dialogue State",
                                    "matches": []
                                },
                                {
                                    "leaf id": 23,
                                    "key": "doc/body/sec3/sub1/txl0",
                                    "block type": "txl",
                                    "content": "We prompt the LLM with a texttocode prompt for inferring the latent dialogue state as an API call. in gives an example of our prompt. We generate a prompt enumerating the intents available in the schema ùíÆ as APIs callable by our agent. Following, we predict the appropriate function call conditioned on the prior system response rt1, the current user utterance ut, and the previous belief state prediction bÃÇt1. We then extract a dialogue state change}ŒîbÃÇt from the arguments to the call, and compute the next dialogue state as bÃÇt = ŒîbÃÇt + bÃÇt1. While used offline here, this DST method is causal with respect to dialogue inputs and is the same as our method in online inference.",
                                    "leftover": "We prompt the LLM with a texttocode prompt for inferring the latent dialogue state as an API call. in gives an example of our prompt. We generate a prompt enumerating the intents available in the schema ùíÆ as APIs callable by our agent. Following, we predict the appropriate function call conditioned on the prior system response rt1, the current user utterance ut, and the previous belief state prediction bÃÇt1. We then extract a dialogue state change}ŒîbÃÇt from the arguments to the call, and compute the next dialogue state as bÃÇt = ŒîbÃÇt + bÃÇt1. While used offline here, this DST method is causal with respect to dialogue inputs and is the same as our method in online inference.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub2",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 24,
                                    "key": "doc/body/sec3/sub2/tit",
                                    "block type": "title",
                                    "content": "Inferring System Acts",
                                    "leftover": "Inferring System Acts",
                                    "matches": []
                                },
                                {
                                    "leaf id": 25,
                                    "key": "doc/body/sec3/sub2/txl0",
                                    "block type": "txl",
                                    "content": "For inferring system acts, we use a similar texttocode prompt for predicting the set of dialogue acts At communicated in a given system response rt. See in for an example of our prompt. We define each act our system could take in the prompt instructions. For input from each turn, we find best performance when conditioning only on the response to tag, rt. For our set of supported acts, we use a subset of the universal dialogue acts proposed in, where some acts such as ''Inform'' or ''Offer'' may use slots defined in ùíÆ. For example, an agent choosing to offer to book a user at a hotel named 'acorn guest house' might be represented as Offer(hotelname='acorn guest house'). See for our complete dialogue act set. Importantly, we use the schema definition ùíÆ and our act set to validate each act prediction, removing predicted keys which do not belong to ùíÆ, or acts which are not in the set. For example, the 'text' key is not valid for a 'ThankYou' act, so a prediction of ''ThankYou(text='thanks, have a good day')'' would be normalized to only ''ThankYou()''. Using the inferred system acts, we use a rulebased method to delexicalize the system responses for training the response generator (, right).",
                                    "leftover": "For inferring system acts, we use a similar texttocode prompt for predicting the set of dialogue acts At communicated in a given system response rt. See in for an example of our prompt. We define each act our system could take in the prompt instructions. For input from each turn, we find best performance when conditioning only on the response to tag, rt. For our set of supported acts, we use a subset of the universal dialogue acts proposed in, where some acts such as ''Inform'' or ''Offer'' may use slots defined in ùíÆ. For example, an agent choosing to offer to book a user at a hotel named 'acorn guest house' might be represented as Offer(hotelname='acorn guest house'). See for our complete dialogue act set. Importantly, we use the schema definition ùíÆ and our act set to validate each act prediction, removing predicted keys which do not belong to ùíÆ, or acts which are not in the set. For example, the 'text' key is not valid for a 'ThankYou' act, so a prediction of ''ThankYou(text='thanks, have a good day')'' would be normalized to only ''ThankYou()''. Using the inferred system acts, we use a rulebased method to delexicalize the system responses for training the response generator (, right).",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub3",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 26,
                                    "key": "doc/body/sec3/sub3/tit",
                                    "block type": "title",
                                    "content": "Noisy Channel LLM Prompting",
                                    "leftover": "Noisy Channel LLM Prompting",
                                    "matches": []
                                },
                                {
                                    "leaf id": 27,
                                    "key": "doc/body/sec3/sub3/txl0",
                                    "block type": "txl",
                                    "content": "We find that a noisy channel prompting method significantly the quality of our inferred dialogue states and acts. Here we describe noisy channel prompting using a simple example, and then describe its application to dialogue state tracking and system act tagging.",
                                    "leftover": "We find that a noisy channel prompting method significantly the quality of our inferred dialogue states and acts. Here we describe noisy channel prompting using a simple example, and then describe its application to dialogue state tracking and system act tagging.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 28,
                                    "key": "doc/body/sec3/sub3/txl1",
                                    "block type": "txl",
                                    "content": "A typical prompt for machine reading comprehension might be:",
                                    "leftover": "A typical prompt for machine reading comprehension might be:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 29,
                                    "key": "doc/body/sec3/sub3/Verbatim2",
                                    "block type": "Verbatim",
                                    "content": "<Optional incontext examples (c)> Passage: <Passage (z)> Question: <Question (x)> Answer:",
                                    "leftover": "<Optional incontext examples (c)> Passage: <Passage (z)> Question: <Question (x)> Answer:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 30,
                                    "key": "doc/body/sec3/sub3/txl3",
                                    "block type": "txl",
                                    "content": "Given this prompt of the incontext examples c, passage z, question x, an answer y completion is found with the language model by maximizing or sampling from Pr(y|x,z,c). We call this the direct prompt.",
                                    "leftover": "Given this prompt of the incontext examples c, passage z, question x, an answer y completion is found with the language model by maximizing or sampling from Pr(y|x,z,c). We call this the direct prompt.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 31,
                                    "key": "doc/body/sec3/sub3/txl4",
                                    "block type": "txl",
                                    "content": "The ''noisy channel'' prompt}is:",
                                    "leftover": "The ''noisy channel'' prompt}is:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 32,
                                    "key": "doc/body/sec3/sub3/Verbatim5",
                                    "block type": "Verbatim",
                                    "content": "<Optional incontext examples (c)> Passage: <Passage (z)> Answer: <Answer (y)> Question: <Question (x)>",
                                    "leftover": "<Optional incontext examples (c)> Passage: <Passage (z)> Answer: <Answer (y)> Question: <Question (x)>",
                                    "matches": []
                                },
                                {
                                    "leaf id": 33,
                                    "key": "doc/body/sec3/sub3/txl6",
                                    "block type": "txl",
                                    "content": "where the likelihood of the question now depends on the answer. To use the noisy channel LLM prompt, we first sample k samples from the direct prompt, and then pick the best output answer y according to the noisy channel prompt probability. One can choose to score the joint probability of the answer followed by the question, i.e. Pr(x|y,z,c)Pr(y|z,c), or only the conditional Pr(x|y,z,c), following .In the latter case, the prior Pr(y|z, c) is uniformly 1/k for the k samples from the direct prompt.",
                                    "leftover": "where the likelihood of the question now depends on the answer. To use the noisy channel LLM prompt, we first sample k samples from the direct prompt, and then pick the best output answer y according to the noisy channel prompt probability. One can choose to score the joint probability of the answer followed by the question, i.e. Pr(x|y,z,c)Pr(y|z,c), or only the conditional Pr(x|y,z,c), following .In the latter case, the prior Pr(y|z, c) is uniformly 1/k for the k samples from the direct prompt.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 34,
                                    "key": "doc/body/sec3/sub3/txl7",
                                    "block type": "txl",
                                    "content": "To apply this method to inferring dialogue states, we first sample a set of possible belief state changes using topp sampling from the direct DST prompt, and then pick the best dialogue state according to the noisy channel prompt (see ). We use an analogous procedure for inferring system acts. For DST, we find scoring with the joint Pr(x|y,z,c)Pr(y|z,c) to perform best, and scoring with the conditional Pr(x|y,z,c) best for act tagging.",
                                    "leftover": "To apply this method to inferring dialogue states, we first sample a set of possible belief state changes using topp sampling from the direct DST prompt, and then pick the best dialogue state according to the noisy channel prompt (see ). We use an analogous procedure for inferring system acts. For DST, we find scoring with the joint Pr(x|y,z,c)Pr(y|z,c) to perform best, and scoring with the conditional Pr(x|y,z,c) best for act tagging.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub4",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 35,
                                    "key": "doc/body/sec3/sub4/tit",
                                    "block type": "title",
                                    "content": "RetrievalAugmented Incontext Learning",
                                    "leftover": "RetrievalAugmented Incontext Learning",
                                    "matches": []
                                },
                                {
                                    "leaf id": 36,
                                    "key": "doc/body/sec3/sub4/txl0",
                                    "block type": "txl",
                                    "content": "To leverage the incontext learning abilities of LLMs, we retrieve from a pool of examples from our predictions. Because we assume no labeled examples, this pool starts with zero examples and is filled incrementally. We retrieve up to k examples for incontext learning from this pool using an unsupervised dense retriever, with examples ranked by embedding cosine distance.We use MPNet, available on Huggingface as sentencetransformers/allmpnetbasev2 We use k=8 and k=6 for DST, DAT respectively. For retriever inputs, we use (bÃÇt1 rt1 ut) and (ut rt) for DST and DAT respectively, where ¬∑ indicates concatenation. Applied naively, this incontext learning approach can suffer a majority label bias . We adjust for biases introduced in the initially small example pool by 1) not using any incontext examples until we have a minimum of n=32 examples in the pool and 2) using our API schema ùíÆ to require at least 4 distinct labels in each set of incontext examples.We consider two dialogue state change labels to be distinct if they update different slots, and two act labels to be distinct if they embody different acts or different slots Our algorithm for producing initial pseudolabels is in .",
                                    "leftover": "To leverage the incontext learning abilities of LLMs, we retrieve from a pool of examples from our predictions. Because we assume no labeled examples, this pool starts with zero examples and is filled incrementally. We retrieve up to k examples for incontext learning from this pool using an unsupervised dense retriever, with examples ranked by embedding cosine distance.We use MPNet, available on Huggingface as sentencetransformers/allmpnetbasev2 We use k=8 and k=6 for DST, DAT respectively. For retriever inputs, we use (bÃÇt1 rt1 ut) and (ut rt) for DST and DAT respectively, where ¬∑ indicates concatenation. Applied naively, this incontext learning approach can suffer a majority label bias . We adjust for biases introduced in the initially small example pool by 1) not using any incontext examples until we have a minimum of n=32 examples in the pool and 2) using our API schema ùíÆ to require at least 4 distinct labels in each set of incontext examples.We consider two dialogue state change labels to be distinct if they update different slots, and two act labels to be distinct if they embody different acts or different slots Our algorithm for producing initial pseudolabels is in .",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec3/sub4/figure1",
                                    "block_type": "figure",
                                    "children": [
                                        {
                                            "leaf id": 37,
                                            "key": "doc/body/sec3/sub4/figure1/cpt0",
                                            "block type": "cpt",
                                            "content": "Instances from our 'direct' and 'noisy channel' prompts for DST. Best viewed in color. After sampling a \\textcolor{dstcolor}{{DST Module}} from the 'direct' prompt, we score it by the likelihood of the input \\textcolor{usercolor}{{user utterance}} conditioned on it in the 'noisy channel' prompt.",
                                            "leftover": "Instances from our 'direct' and 'noisy channel' prompts for DST. Best viewed in color. After sampling a \\textcolor{dstcolor}{{DST Module}} from the 'direct' prompt, we score it by the likelihood of the input \\textcolor{usercolor}{{user utterance}} conditioned on it in the 'noisy channel' prompt.",
                                            "matches": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub5",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 38,
                                    "key": "doc/body/sec3/sub5/tit",
                                    "block type": "title",
                                    "content": "Refining the Labels with HardEM",
                                    "leftover": "Refining the Labels with HardEM",
                                    "matches": []
                                },
                                {
                                    "leaf id": 39,
                                    "key": "doc/body/sec3/sub5/txl0",
                                    "block type": "txl",
                                    "content": "While the labels we produce in can be used directly for training an endtoend dialogue system, we find their quality can be improved through expectationmaximization . For every dialogue turn in our dataset, our initial pseudolabels provide the expected dialogue state and system dialogue acts according to our zeroshot system. We then jointly finetune an LLM as a noisychannel DST & DAT system to maximize the likelihood of these expected labels. We use smaller version of our prompted LLM, StarCoder 3B .",
                                    "leftover": "While the labels we produce in can be used directly for training an endtoend dialogue system, we find their quality can be improved through expectationmaximization . For every dialogue turn in our dataset, our initial pseudolabels provide the expected dialogue state and system dialogue acts according to our zeroshot system. We then jointly finetune an LLM as a noisychannel DST & DAT system to maximize the likelihood of these expected labels. We use smaller version of our prompted LLM, StarCoder 3B .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 40,
                                    "key": "doc/body/sec3/sub5/txl1",
                                    "block type": "txl",
                                    "content": "For each turn, we derive (prompt, completion) pairs for 'direct' texttocode and 'channel' codetotext DST and DAT modules, as defined in . We then combine and shuffle these pairs into a single training set for joint finetuning. For efficient training, we shorten our prompts by removing incontext examples as well as the function definitions used in the incontext learning setting. We find upsampling the 'channel' prompts so that there is a 2:1 ratio of 'channel' to 'direct' instances for training improves performance.",
                                    "leftover": "For each turn, we derive (prompt, completion) pairs for 'direct' texttocode and 'channel' codetotext DST and DAT modules, as defined in . We then combine and shuffle these pairs into a single training set for joint finetuning. For efficient training, we shorten our prompts by removing incontext examples as well as the function definitions used in the incontext learning setting. We find upsampling the 'channel' prompts so that there is a 2:1 ratio of 'channel' to 'direct' instances for training improves performance.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 41,
                                    "key": "doc/body/sec3/sub5/txl2",
                                    "block type": "txl",
                                    "content": "After finetuning, the model can be used to produce improved pseudolabels by relabeling each dialogue, using the same noisychannel inference methods. Following this, we can repeat the finetuning process. This train and relabel process can be repeated for any number of iterations, though we find a single relabeling is sufficient.",
                                    "leftover": "After finetuning, the model can be used to produce improved pseudolabels by relabeling each dialogue, using the same noisychannel inference methods. Following this, we can repeat the finetuning process. This train and relabel process can be repeated for any number of iterations, though we find a single relabeling is sufficient.",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec4",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 42,
                            "key": "doc/body/sec4/tit",
                            "block type": "title",
                            "content": "EndtoEnd System",
                            "leftover": "EndtoEnd System",
                            "matches": []
                        },
                        {
                            "leaf id": 43,
                            "key": "doc/body/sec4/txl0",
                            "block type": "txl",
                            "content": "Following, we utilize a multitask finetuning method for training a single LLM as a complete dialogue system, consisting of a dialogue state tracker, policy, and response generator.",
                            "leftover": "Following, we utilize a multitask finetuning method for training a single LLM as a complete dialogue system, consisting of a dialogue state tracker, policy, and response generator.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec4/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 44,
                                    "key": "doc/body/sec4/par1/txl0",
                                    "block type": "txl",
                                    "content": "DST For the DST subtask, we again use both 'direct' and 'channel' (prompt, completion) pairs. This allows us to use the same noisychannel inference method presented in .",
                                    "leftover": "DST For the DST subtask, we again use both 'direct' and 'channel' (prompt, completion) pairs. This allows us to use the same noisychannel inference method presented in .",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec4/par2",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 45,
                                    "key": "doc/body/sec4/par2/txl0",
                                    "block type": "txl",
                                    "content": "Policy For the Policy subtask, we use a texttocode prompt where we simply condition on the k=5 most recent utterances in the dialogue history: Ht = (ut2, rt2, ut1, rt1, ut). The completion is the current turn's system acts At, which will be used to ground the next response rt. We do not use a noisychannel variant for Policy, and greedily decode an act prediction at inference time:",
                                    "leftover": "Policy For the Policy subtask, we use a texttocode prompt where we simply condition on the k=5 most recent utterances in the dialogue history: Ht = (ut2, rt2, ut1, rt1, ut). The completion is the current turn's system acts At, which will be used to ground the next response rt. We do not use a noisychannel variant for Policy, and greedily decode an act prediction at inference time:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 46,
                                    "key": "doc/body/sec4/par2/frm1",
                                    "block type": "frm",
                                    "content": "√Çt = At ‚ààùí±^*argmax At ‚ààùí±^* P(fprompt (Ht)))",
                                    "leftover": "√Çt = At ‚ààùí±^*argmax At ‚ààùí±^* P(fprompt (Ht)))",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec4/par3",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 47,
                                    "key": "doc/body/sec4/par3/txl0",
                                    "block type": "txl",
                                    "content": "Response Generation For Response Generation, we condition on the turn's observed system and user utterances (rt1, ut) and our policy's act prediction √Çt). The completion is the observed system response rt. We also do not use a noisychannel variant for response generation, and greedily decode the response:",
                                    "leftover": "Response Generation For Response Generation, we condition on the turn's observed system and user utterances (rt1, ut) and our policy's act prediction √Çt). The completion is the observed system response rt. We also do not use a noisychannel variant for response generation, and greedily decode the response:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 48,
                                    "key": "doc/body/sec4/par3/frm1",
                                    "block type": "frm",
                                    "content": "rÃÇt = At ‚ààùí±^*argmax At ‚ààùí±^* P(fprompt (rt1, ut, At)))",
                                    "leftover": "rÃÇt = At ‚ààùí±^*argmax At ‚ààùí±^* P(fprompt (rt1, ut, At)))",
                                    "matches": []
                                },
                                {
                                    "leaf id": 49,
                                    "key": "doc/body/sec4/par3/txl2",
                                    "block type": "txl",
                                    "content": "Following prior works, we predict delexicalized}responses, where values for slots in the system response are replaced with placeholders for the slot name. For example, instead of generating ''The phone number for acorn guest house is 5555309'' directly, we would predict ''The phone number for the [hotelname] is [hotelphone]'', where values could be filled in. Importantly, we never presume access to gold delexicalized responses. Instead, we use our predicted acts, e.g. ''Inform(name='acorn guest house', phone='5558309')'', to delexicalize the observed response for training.",
                                    "leftover": "Following prior works, we predict delexicalized}responses, where values for slots in the system response are replaced with placeholders for the slot name. For example, instead of generating ''The phone number for acorn guest house is 5555309'' directly, we would predict ''The phone number for the [hotelname] is [hotelphone]'', where values could be filled in. Importantly, we never presume access to gold delexicalized responses. Instead, we use our predicted acts, e.g. ''Inform(name='acorn guest house', phone='5558309')'', to delexicalize the observed response for training.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec4/par4",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 50,
                                    "key": "doc/body/sec4/par4/txl0",
                                    "block type": "txl",
                                    "content": "Endtoend Training For each turn, we derive (prompt, completion) pairs for 'direct' and 'channel' DST, and direct Policy, and Response Generation prompts. We then combine and shuffle these pairs into a single training set for joint finetuning. For efficient training, we shorten our prompts by removing incontext examples as well as the function definitions used in the incontext learning setting. We find upsampling the 'channel' prompts so that there is a 2:1 ratio of 'channel' to 'direct' instances for training improves performance. Finally, we finetune StarCoder 3B using crossentropy loss and AdamW with default hyperparameters.",
                                    "leftover": "Endtoend Training For each turn, we derive (prompt, completion) pairs for 'direct' and 'channel' DST, and direct Policy, and Response Generation prompts. We then combine and shuffle these pairs into a single training set for joint finetuning. For efficient training, we shorten our prompts by removing incontext examples as well as the function definitions used in the incontext learning setting. We find upsampling the 'channel' prompts so that there is a 2:1 ratio of 'channel' to 'direct' instances for training improves performance. Finally, we finetune StarCoder 3B using crossentropy loss and AdamW with default hyperparameters.",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec4/par4/table*1",
                                    "block_type": "table*",
                                    "children": [
                                        {
                                            "leaf id": 51,
                                            "key": "doc/body/sec4/par4/table*1/tabular0",
                                            "block type": "tabular",
                                            "content": "{lrrr|rrrr} Model}& Schema?}& Labels?}& Dialogues?}& Inform}& Success}& BLEU}& Combined} \\multicolumn{8}c{Supervised Results} PPTOD & ‚úì & ‚úì & ‚úì & 82.6 & 72.2 & 18.2 & 95.6 DiactTOD & ‚úì & ‚úì & ‚úì & 89.5 & 84.2 & 17.5 & 104.4 Our (supervised) & ‚úì & ‚úì & ‚úì & 67.9 & 61.7 & 14.6 & 79.4 \\multicolumn{8}c{ZeroShot with Formatting Example(s)} SGPTODGPT3.5 & ‚úì & Few (‚Ä°) & ‚úó & 82.0 & 72.5 & 9.22 & 86.5 \\multicolumn{8}c{Fully Unsupervised Results} \\multicolumn{8}l{Sees gold delexicalized conversation history} LLaMa\\textsuperscript{‚Ä†} & ‚úì & ‚úó & ‚úó &  & 4 & 1.61 &  GPT 3.5 Turbo\\textsuperscript{‚Ä†} & ‚úì & ‚úó & ‚úó & 44.8 & 31.2 & 3.3 & 41.3 \\hdashline \\multicolumn{8}l{Sees only fullylexicalized dialogues} GPT 3.5 Turbo ( gold delex.) & ‚úì & ‚úó & ‚úó & 40.7 & 26.7 & 3.7 & 37.4 Ours (StarCoder 15B  no EM) & ‚úì & ‚úó & ‚úó & 50.0 & 19.6 & 3.2 & 38 Ours (StarCoder 3B  w/ EM) & ‚úì & ‚úó & ‚úì & 78.1}& 68.3}& 13.6}& 86.8}",
                                            "leftover": "{lrrr|rrrr} Model}& Schema?}& Labels?}& Dialogues?}& Inform}& Success}& BLEU}& Combined} \\multicolumn{8}c{Supervised Results} PPTOD & ‚úì & ‚úì & ‚úì & 82.6 & 72.2 & 18.2 & 95.6 DiactTOD & ‚úì & ‚úì & ‚úì & 89.5 & 84.2 & 17.5 & 104.4 Our (supervised) & ‚úì & ‚úì & ‚úì & 67.9 & 61.7 & 14.6 & 79.4 \\multicolumn{8}c{ZeroShot with Formatting Example(s)} SGPTODGPT3.5 & ‚úì & Few (‚Ä°) & ‚úó & 82.0 & 72.5 & 9.22 & 86.5 \\multicolumn{8}c{Fully Unsupervised Results} \\multicolumn{8}l{Sees gold delexicalized conversation history} LLaMa\\textsuperscript{‚Ä†} & ‚úì & ‚úó & ‚úó &  & 4 & 1.61 &  GPT 3.5 Turbo\\textsuperscript{‚Ä†} & ‚úì & ‚úó & ‚úó & 44.8 & 31.2 & 3.3 & 41.3 \\hdashline \\multicolumn{8}l{Sees only fullylexicalized dialogues} GPT 3.5 Turbo ( gold delex.) & ‚úì & ‚úó & ‚úó & 40.7 & 26.7 & 3.7 & 37.4 Ours (StarCoder 15B  no EM) & ‚úì & ‚úó & ‚úó & 50.0 & 19.6 & 3.2 & 38 Ours (StarCoder 3B  w/ EM) & ‚úì & ‚úó & ‚úì & 78.1}& 68.3}& 13.6}& 86.8}",
                                            "matches": []
                                        },
                                        {
                                            "key": "doc/body/sec4/par4/table*1/cpt1",
                                            "block_type": "cpt",
                                            "children": [
                                                {
                                                    "leaf id": 52,
                                                    "key": "doc/body/sec4/par4/table*1/cpt1/txl0",
                                                    "block type": "txl",
                                                    "content": "Unsupervised endtoend results in MultiWOZ 2.2. (‚Ä†) indicates models from . Results for LLaMa are from, which does not report the Inform rate. (‚Ä°) SGPTOD uses a prompt with both a formatting example and a ''Policy Skeleton'', which contains an additional 1020 handcrafted instances of the correct system acts and response for an input user utterance or returned DB result. For fairer comparison in our fully unsupervised setting, we rerun the GPT 3.5 baseline without the supervision of delexicalized responses provided in the conversation history ( gold delex.). Despite far fewer parameters, we find substantial improvements in our methods which leverage unlabelled dialogues",
                                                    "leftover": "Unsupervised endtoend results in MultiWOZ 2.2. (‚Ä†) indicates models from . Results for LLaMa are from, which does not report the Inform rate. (‚Ä°) SGPTOD uses a prompt with both a formatting example and a ''Policy Skeleton'', which contains an additional 1020 handcrafted instances of the correct system acts and response for an input user utterance or returned DB result. For fairer comparison in our fully unsupervised setting, we rerun the GPT 3.5 baseline without the supervision of delexicalized responses provided in the conversation history ( gold delex.). Despite far fewer parameters, we find substantial improvements in our methods which leverage unlabelled dialogues",
                                                    "matches": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec5",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 53,
                            "key": "doc/body/sec5/tit",
                            "block type": "title",
                            "content": "Experiments",
                            "leftover": "Experiments",
                            "matches": []
                        },
                        {
                            "leaf id": 54,
                            "key": "doc/body/sec5/txl0",
                            "block type": "txl",
                            "content": "We conduct unsupervised endtoend dialogue (E2E) and dialogue state tracking (DST) experiments on the MultiWOZ 2.2 dataset, containing over ten thousand multidomain taskoriented dialogues crowdsourced in a wizardofoz setup. We use the fully lexicalized, unlabelled dialogues from the training set to build our system, and evaluate on the test set. First, we demonstrate the value of our approach in an endtoend dialogue evaluation, following prior works on taskoriented dialogue (). Second, we conduct a dialogue state tracking evaluation to more carefully evaluate the quality of our pseudoannotations ().",
                            "leftover": "We conduct unsupervised endtoend dialogue (E2E) and dialogue state tracking (DST) experiments on the MultiWOZ 2.2 dataset, containing over ten thousand multidomain taskoriented dialogues crowdsourced in a wizardofoz setup. We use the fully lexicalized, unlabelled dialogues from the training set to build our system, and evaluate on the test set. First, we demonstrate the value of our approach in an endtoend dialogue evaluation, following prior works on taskoriented dialogue (). Second, we conduct a dialogue state tracking evaluation to more carefully evaluate the quality of our pseudoannotations ().",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec5/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 55,
                                    "key": "doc/body/sec5/sub1/tit",
                                    "block type": "title",
                                    "content": "EndtoEnd (E2E) Experiments",
                                    "leftover": "EndtoEnd (E2E) Experiments",
                                    "matches": []
                                },
                                {
                                    "leaf id": 56,
                                    "key": "doc/body/sec5/sub1/txl0",
                                    "block type": "txl",
                                    "content": "In E2E experiments, we use our complete system to both predict API call arguments and generate a next system response in natural language. We evaluate our generated responses with Inform rate, Success rate, and BLEU, as well as a Combined score of 0.5(Inform + Success) + BLEU, following prior works. We provide details on these metrics in .",
                                    "leftover": "In E2E experiments, we use our complete system to both predict API call arguments and generate a next system response in natural language. We evaluate our generated responses with Inform rate, Success rate, and BLEU, as well as a Combined score of 0.5(Inform + Success) + BLEU, following prior works. We provide details on these metrics in .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 57,
                                    "key": "doc/body/sec5/sub1/txl1",
                                    "block type": "txl",
                                    "content": "We compare our approach to the previous stateoftheart unsupervised methods, a GPT3.5 zeroshot baseline, and SGPTOD . Where possible, we report results for both the original approach and modifications required to fit our fully unsupervised setting. For reference, we also run our own method in the fullysupervised setting. We train a model using the procedure in using the annotations sourced from crowdworkers in the MultiWOZ 2.2 corpus, rather than the pseudolabels predicted in . We also compare with existing supervised approaches as a reference point. We include DiactTOD, which to our knowledge is the supervised stateoftheart, and PPTOD, which uses a multitask finetuning approach similar to our own in, for T5 encoderdecoder models .",
                                    "leftover": "We compare our approach to the previous stateoftheart unsupervised methods, a GPT3.5 zeroshot baseline, and SGPTOD . Where possible, we report results for both the original approach and modifications required to fit our fully unsupervised setting. For reference, we also run our own method in the fullysupervised setting. We train a model using the procedure in using the annotations sourced from crowdworkers in the MultiWOZ 2.2 corpus, rather than the pseudolabels predicted in . We also compare with existing supervised approaches as a reference point. We include DiactTOD, which to our knowledge is the supervised stateoftheart, and PPTOD, which uses a multitask finetuning approach similar to our own in, for T5 encoderdecoder models .",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec5/sub2",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 58,
                                    "key": "doc/body/sec5/sub2/tit",
                                    "block type": "title",
                                    "content": "DST Experiments",
                                    "leftover": "DST Experiments",
                                    "matches": []
                                },
                                {
                                    "leaf id": 59,
                                    "key": "doc/body/sec5/sub2/txl0",
                                    "block type": "txl",
                                    "content": "We conduct multidomain DST experiments on the MultiWOZ Dataset in order to evaluate the quality of our pseudoannotations. We use our DST Module to predict and evaluate only latent dialogue states, which collect the arguments required for unseen API calls.",
                                    "leftover": "We conduct multidomain DST experiments on the MultiWOZ Dataset in order to evaluate the quality of our pseudoannotations. We use our DST Module to predict and evaluate only latent dialogue states, which collect the arguments required for unseen API calls.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 60,
                                    "key": "doc/body/sec5/sub2/txl1",
                                    "block type": "txl",
                                    "content": "Following prior works, we evaluate DST performance with jointgoal accuracy (JGA), or whether a given dialogue state is completely accurate. More details are available in .",
                                    "leftover": "Following prior works, we evaluate DST performance with jointgoal accuracy (JGA), or whether a given dialogue state is completely accurate. More details are available in .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 61,
                                    "key": "doc/body/sec5/sub2/txl2",
                                    "block type": "txl",
                                    "content": "We compare to our ChatGPT 3.5 Turbo baseline, as well as prior zeroshot DST methods. These include ICDST, which reframes DST as texttoSQL, and RefPyDST which reframes DST as texttopython . By default, both of these works use OpenAI Codex, and we apply their prompting approaches to StarCoder 15B for clearer comparison.",
                                    "leftover": "We compare to our ChatGPT 3.5 Turbo baseline, as well as prior zeroshot DST methods. These include ICDST, which reframes DST as texttoSQL, and RefPyDST which reframes DST as texttopython . By default, both of these works use OpenAI Codex, and we apply their prompting approaches to StarCoder 15B for clearer comparison.",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec5/sub2/table3",
                                    "block_type": "table",
                                    "children": [
                                        {
                                            "leaf id": 62,
                                            "key": "doc/body/sec5/sub2/table3/tabular0",
                                            "block type": "tabular",
                                            "content": "{l|r} \\multicolumn{2}c{With One Formatting Example} ICDST (StarCoder 15B) & 24.58 RefPyDST (StarCoder 15B) & 17.17 ICDST (Codex) & 35.02 RefPyDST (Codex) & 40.88 \\multicolumn{2}c{Fully Unsupervised} ICDST (StarCoder 15B) & 15.66 RefPyDST (StarCoder 15B) & 13.88 GPT 3.5 Turbo & 13.05 Ours (StarCoder 15B ‚Üí 3B) & 39.70}",
                                            "leftover": "{l|r} \\multicolumn{2}c{With One Formatting Example} ICDST (StarCoder 15B) & 24.58 RefPyDST (StarCoder 15B) & 17.17 ICDST (Codex) & 35.02 RefPyDST (Codex) & 40.88 \\multicolumn{2}c{Fully Unsupervised} ICDST (StarCoder 15B) & 15.66 RefPyDST (StarCoder 15B) & 13.88 GPT 3.5 Turbo & 13.05 Ours (StarCoder 15B ‚Üí 3B) & 39.70}",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 63,
                                            "key": "doc/body/sec5/sub2/table3/cpt1",
                                            "block type": "cpt",
                                            "content": "Joint Goal Accuracy (JGA) of our method's dialogue state predictions and zeroshot baselines",
                                            "leftover": "Joint Goal Accuracy (JGA) of our method's dialogue state predictions and zeroshot baselines",
                                            "matches": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec6",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 64,
                            "key": "doc/body/sec6/tit",
                            "block type": "title",
                            "content": "Results",
                            "leftover": "Results",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec6/par0",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 65,
                                    "key": "doc/body/sec6/par0/txl0",
                                    "block type": "txl",
                                    "content": "E2E Performance We present E2E results for our unsupervised dialogue agent in . We find that our method achieves stateoftheart performance in our fully unsupervised setting, more than doubling the Success Rate and Combined score of the GPT 3.5 Turbo baseline of . When we remove the supervision of delexicalization for fairer comparison ( gold delex.), we find even greater improvement across all endtoend metrics. As discussed in, SGPTOD uses both a supervised formatting example and a 'Policy Skeleton', containing additional supervision for Policy and Response Generation. With no implementation publicly available, we were unable to run a modified version of their experiments without this supervision for fair comparison. Despite a lesssupervised setting, our method is able to perform comparably, even slightly outperforming SGPTOD in Combined score. Remarkably, our unsupervised EM approach also outperforms the supervised variant of our model due to improvements in Inform and Success rate, suggesting the Dialogue acts we infer are of high quality.",
                                    "leftover": "E2E Performance We present E2E results for our unsupervised dialogue agent in . We find that our method achieves stateoftheart performance in our fully unsupervised setting, more than doubling the Success Rate and Combined score of the GPT 3.5 Turbo baseline of . When we remove the supervision of delexicalization for fairer comparison ( gold delex.), we find even greater improvement across all endtoend metrics. As discussed in, SGPTOD uses both a supervised formatting example and a 'Policy Skeleton', containing additional supervision for Policy and Response Generation. With no implementation publicly available, we were unable to run a modified version of their experiments without this supervision for fair comparison. Despite a lesssupervised setting, our method is able to perform comparably, even slightly outperforming SGPTOD in Combined score. Remarkably, our unsupervised EM approach also outperforms the supervised variant of our model due to improvements in Inform and Success rate, suggesting the Dialogue acts we infer are of high quality.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec6/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 66,
                                    "key": "doc/body/sec6/par1/txl0",
                                    "block type": "txl",
                                    "content": "DST Performance Our DST results are shown in . Where possible, we distinguish between 'zeroshot' results which include a handengineered formatting example, and the same method applied without the formatting example.Due to the deprecation of OpenAI Codex, we were unable to run experiments for ICDST or RefPyDST without a formatting example on the original Codex model We find that our method significantly outperforms our GPT 3.5 Turbo baseline by 26% joint goal accuracy. Our approach performs nearly as well as the best method using OpenAI Codex with a supervised formatting example, using less than 10% of the parameters at any time (175B vs. 15B). When applying the ICDST and RefPyDST prompting methods to StarCoder, our method significantly outperforms both, with and without a formatting example.",
                                    "leftover": "DST Performance Our DST results are shown in . Where possible, we distinguish between 'zeroshot' results which include a handengineered formatting example, and the same method applied without the formatting example.Due to the deprecation of OpenAI Codex, we were unable to run experiments for ICDST or RefPyDST without a formatting example on the original Codex model We find that our method significantly outperforms our GPT 3.5 Turbo baseline by 26% joint goal accuracy. Our approach performs nearly as well as the best method using OpenAI Codex with a supervised formatting example, using less than 10% of the parameters at any time (175B vs. 15B). When applying the ICDST and RefPyDST prompting methods to StarCoder, our method significantly outperforms both, with and without a formatting example.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec6/par2",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 67,
                                    "key": "doc/body/sec6/par2/txl0",
                                    "block type": "txl",
                                    "content": "Ablations In, we conduct an ablation to evaluate both the impact of our noisy channel modeling and the value of iterative relabeling in our EM approach. We compare our proposed system to one in which each module is replaced by only greedily sampling from its 'direct' variant, at both labeling and endtoend inference time. We plot our Combined endtoend performance across iterations of EM, with '0' indicating our zeroshot system. We find that EM improves our endtoend performance in both our noisychannel approach and greedy ablation, and that our noisychannel inference methods are important to dialogue success, with a 30 and 33 point improvement over our greedy baseline with 1 and 2 EM steps, respectively. Ablations across Inform, Success, BLEU, and joint goal accuracy are in .",
                                    "leftover": "Ablations In, we conduct an ablation to evaluate both the impact of our noisy channel modeling and the value of iterative relabeling in our EM approach. We compare our proposed system to one in which each module is replaced by only greedily sampling from its 'direct' variant, at both labeling and endtoend inference time. We plot our Combined endtoend performance across iterations of EM, with '0' indicating our zeroshot system. We find that EM improves our endtoend performance in both our noisychannel approach and greedy ablation, and that our noisychannel inference methods are important to dialogue success, with a 30 and 33 point improvement over our greedy baseline with 1 and 2 EM steps, respectively. Ablations across Inform, Success, BLEU, and joint goal accuracy are in .",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec6/par2/figure1",
                                    "block_type": "figure",
                                    "children": [
                                        {
                                            "leaf id": 68,
                                            "key": "doc/body/sec6/par2/figure1/cpt0",
                                            "block type": "cpt",
                                            "content": "Combined score (0.5(Inform + Success) + BLEU) vs. the number of steps of expectationmaximization in our Noisy Channel method vs. a Greedy Ablation. '0' is zeroshot inference",
                                            "leftover": "Combined score (0.5(Inform + Success) + BLEU) vs. the number of steps of expectationmaximization in our Noisy Channel method vs. a Greedy Ablation. '0' is zeroshot inference",
                                            "matches": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec7",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 69,
                            "key": "doc/body/sec7/tit",
                            "block type": "title",
                            "content": "Contamination Analysis",
                            "leftover": "Contamination Analysis",
                            "matches": []
                        },
                        {
                            "leaf id": 70,
                            "key": "doc/body/sec7/txl0",
                            "block type": "txl",
                            "content": "Evaluation of unsupervised methods, such as ours, that use LLMs has the potential issue of task contamination, where supervised examples are seen in pretraining data . Inclusion of supervised examples of the task in LLM pretraining data would render the model no longer unsupervised and the evaluation potentially biased: tasks for which the training data has been seen may have a higher performance than truly unsupervised tasks.",
                            "leftover": "Evaluation of unsupervised methods, such as ours, that use LLMs has the potential issue of task contamination, where supervised examples are seen in pretraining data . Inclusion of supervised examples of the task in LLM pretraining data would render the model no longer unsupervised and the evaluation potentially biased: tasks for which the training data has been seen may have a higher performance than truly unsupervised tasks.",
                            "matches": []
                        },
                        {
                            "leaf id": 71,
                            "key": "doc/body/sec7/txl1",
                            "block type": "txl",
                            "content": "To address this issue, we quantify the presence of contamination in LLM pretraining data, and then estimate the potential impact on our results. Fortunately, the StarCoder family of models that we use has the complete pretraining corpus publicly available for analysis.https://huggingface.co/datasets/bigcode/starcoderdata",
                            "leftover": "To address this issue, we quantify the presence of contamination in LLM pretraining data, and then estimate the potential impact on our results. Fortunately, the StarCoder family of models that we use has the complete pretraining corpus publicly available for analysis.https://huggingface.co/datasets/bigcode/starcoderdata",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec7/table2",
                            "block_type": "table",
                            "children": [
                                {
                                    "leaf id": 72,
                                    "key": "doc/body/sec7/table2/tabular0",
                                    "block type": "tabular",
                                    "content": "{l|r:rr} Task}& Turns}& Correct}& Authentic} Act Tagging & 42 & 21 & 5 DST & 42 & 36 & 19",
                                    "leftover": "{l|r:rr} Task}& Turns}& Correct}& Authentic} Act Tagging & 42 & 21 & 5 DST & 42 & 36 & 19",
                                    "matches": []
                                },
                                {
                                    "leaf id": 73,
                                    "key": "doc/body/sec7/table2/cpt1",
                                    "block type": "cpt",
                                    "content": "Number of discovered contaminated turns per task, as well as the number which are correct or verified as being in the MultiWOZ dataset.",
                                    "leftover": "Number of discovered contaminated turns per task, as well as the number which are correct or verified as being in the MultiWOZ dataset.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "leaf id": 74,
                            "key": "doc/body/sec7/txl3",
                            "block type": "txl",
                            "content": "We conduct an exhaustive search for supervised pairs of our dialogue subtasks in the StarCoder pretraining data using a semiautomated search with manual review. Details of our search procedure are in . We find no complete dialogues with supervised labels. We do find 42 turns labeled with act tagging, and 42 turns labeled with DST in the pretraining corpus, categorized in .The average dialogue length in MultiWOZ is 13.9 turns. Put together, the set of contaminated turns would be roughly the length of 6 dialogues We consider a (x, y) pair to be 'Correct' if the state change/dialogue act y is actually correct for the utterance x, and to be 'Authentic' if the (x,y) pair is found verbatim in the MultiWOZ corpus.A 'Correct' pair might arise from printing training data, and an incorrect pair from discussion of a failure case. Astonishingly, we find half of the found Act Tagging pairs are incorrect, and could possibly mislead a pretrained model if the model learned from them. We also find that less than half of the turns are authentic for either task, and find a number of them derive from Github issues discussing problems with dialogue simulators.",
                            "leftover": "We conduct an exhaustive search for supervised pairs of our dialogue subtasks in the StarCoder pretraining data using a semiautomated search with manual review. Details of our search procedure are in . We find no complete dialogues with supervised labels. We do find 42 turns labeled with act tagging, and 42 turns labeled with DST in the pretraining corpus, categorized in .The average dialogue length in MultiWOZ is 13.9 turns. Put together, the set of contaminated turns would be roughly the length of 6 dialogues We consider a (x, y) pair to be 'Correct' if the state change/dialogue act y is actually correct for the utterance x, and to be 'Authentic' if the (x,y) pair is found verbatim in the MultiWOZ corpus.A 'Correct' pair might arise from printing training data, and an incorrect pair from discussion of a failure case. Astonishingly, we find half of the found Act Tagging pairs are incorrect, and could possibly mislead a pretrained model if the model learned from them. We also find that less than half of the turns are authentic for either task, and find a number of them derive from Github issues discussing problems with dialogue simulators.",
                            "matches": []
                        },
                        {
                            "leaf id": 75,
                            "key": "doc/body/sec7/txl4",
                            "block type": "txl",
                            "content": "Additionally, we estimate the degree to which the contamination we discover could exaggerate expected performance of our method on an unseen schema, by using contaminated (x, y) pairs as incontext examples.Ideally, one would pretrain an identical StarCoder model on a corpus withoutcontamination, this is computationally impractical. Additionally, we are not aware of any available LLM that can be verified as not contaminated for this task.}",
                            "leftover": "Additionally, we estimate the degree to which the contamination we discover could exaggerate expected performance of our method on an unseen schema, by using contaminated (x, y) pairs as incontext examples.Ideally, one would pretrain an identical StarCoder model on a corpus withoutcontamination, this is computationally impractical. Additionally, we are not aware of any available LLM that can be verified as not contaminated for this task.}",
                            "matches": []
                        },
                        {
                            "leaf id": 76,
                            "key": "doc/body/sec7/txl5",
                            "block type": "txl",
                            "content": "In, we compare our zeroshot prompt, which receives no examples of any kind, with a 'contaminated' variant which uses k=3 incontext examples derived from contamination in the pretraining corpus. The 'contaminated' model retrieves the most relevant contaminated fragments from a pool using the dense retrieval approach described in . These are inserted as a triplequoted string block, so that the prompt remains syntactically valid python. By leaving contaminated examples in their original format, we test whether their inclusion elicits memorized knowledge rather than providing guidance on input/output formatting. Surprisingly, we find including this supervision via contaminated fragments hurts}performance, indicating that these examples do not provide meaningful supervision for our task. Further, the substantial gains in our noisychannel EM approach suggest our method is doing more than simply eliciting schemaspecific knowledge memorized in pretraining.",
                            "leftover": "In, we compare our zeroshot prompt, which receives no examples of any kind, with a 'contaminated' variant which uses k=3 incontext examples derived from contamination in the pretraining corpus. The 'contaminated' model retrieves the most relevant contaminated fragments from a pool using the dense retrieval approach described in . These are inserted as a triplequoted string block, so that the prompt remains syntactically valid python. By leaving contaminated examples in their original format, we test whether their inclusion elicits memorized knowledge rather than providing guidance on input/output formatting. Surprisingly, we find including this supervision via contaminated fragments hurts}performance, indicating that these examples do not provide meaningful supervision for our task. Further, the substantial gains in our noisychannel EM approach suggest our method is doing more than simply eliciting schemaspecific knowledge memorized in pretraining.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec7/table6",
                            "block_type": "table",
                            "children": [
                                {
                                    "leaf id": 77,
                                    "key": "doc/body/sec7/table6/tabular0",
                                    "block type": "tabular",
                                    "content": "{l|rrrr} Method}& Inform}& Success}& BLEU}& Combined} Ours (zeroshot) & 49.0}& 15.0}& 3.0 & 35.0} Ours (k=3 contam ex.) & 44.5 & 14.0 & 3.8}& 33.1 Ours (Full EM) & 80.5}& 69.0}& 13.7}& 88.5}",
                                    "leftover": "{l|rrrr} Method}& Inform}& Success}& BLEU}& Combined} Ours (zeroshot) & 49.0}& 15.0}& 3.0 & 35.0} Ours (k=3 contam ex.) & 44.5 & 14.0 & 3.8}& 33.1 Ours (Full EM) & 80.5}& 69.0}& 13.7}& 88.5}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 78,
                                    "key": "doc/body/sec7/table6/cpt1",
                                    "block type": "cpt",
                                    "content": "Performance comparison when we include contaminated incontext examples. We find including",
                                    "leftover": "Performance comparison when we include contaminated incontext examples. We find including",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec8",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 79,
                            "key": "doc/body/sec8/tit",
                            "block type": "title",
                            "content": "Related Work",
                            "leftover": "Related Work",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec8/par0",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 80,
                                    "key": "doc/body/sec8/par0/txl0",
                                    "block type": "txl",
                                    "content": "Zeroshot Dialogue A few recent works have proposed zeroshot approaches to dialogue problems using LLMs. and propose DST methods which prompt code based LLMs in a texttoSQL or texttoprogram format, respectively. These methods rely on prompts tailored to the schema and the use of a supervised 'formatting' example, which requires annotation expertise. extends this approach to endtoend taskoriented dialogue by adding a policy prompter for GPT 3.5. In addition to a formatting example, their policy prompt requires a handcrafted 'policyskeleton' consisting of examples of the appropriate system act and reply in response to different user utterances or database results. Our approach differs in that we require zero labeled examples of any kind. propose a zeroshot endtoend method for prompting instructiontuned LLMs like GPT 3.5. However, this method presumes delexicalized}system responses r1 ... rt1 in the conversation history as input, where entities are replaced with placeholders. Producing these inputs requires groundtruth annotations and gives a form of supervision about the entities and their attributes within a dialogue (see for a comparison for GPT 3.5 Turbo with and without delex supervision). In contrast, we only assume fullylexicalized dialogues, which do not provide this supervision and require no human annotation. We adapt the method of to use lexicalized dialogues as inputs, and use this approach as our baseline. propose an endtoend method which prompts GPT4 for interactions with a knowledge base before producing a response, however it generalizes poorly to the multidomain setting.",
                                    "leftover": "Zeroshot Dialogue A few recent works have proposed zeroshot approaches to dialogue problems using LLMs. and propose DST methods which prompt code based LLMs in a texttoSQL or texttoprogram format, respectively. These methods rely on prompts tailored to the schema and the use of a supervised 'formatting' example, which requires annotation expertise. extends this approach to endtoend taskoriented dialogue by adding a policy prompter for GPT 3.5. In addition to a formatting example, their policy prompt requires a handcrafted 'policyskeleton' consisting of examples of the appropriate system act and reply in response to different user utterances or database results. Our approach differs in that we require zero labeled examples of any kind. propose a zeroshot endtoend method for prompting instructiontuned LLMs like GPT 3.5. However, this method presumes delexicalized}system responses r1 ... rt1 in the conversation history as input, where entities are replaced with placeholders. Producing these inputs requires groundtruth annotations and gives a form of supervision about the entities and their attributes within a dialogue (see for a comparison for GPT 3.5 Turbo with and without delex supervision). In contrast, we only assume fullylexicalized dialogues, which do not provide this supervision and require no human annotation. We adapt the method of to use lexicalized dialogues as inputs, and use this approach as our baseline. propose an endtoend method which prompts GPT4 for interactions with a knowledge base before producing a response, however it generalizes poorly to the multidomain setting.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec8/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 81,
                                    "key": "doc/body/sec8/par1/txl0",
                                    "block type": "txl",
                                    "content": "Semisupervised TOD Some works propose semisupervised approaches to endtoend taskoriented dialogue. propose an endtoend sequencetosequence model where the dialogue state is a latent variable. adapt this approach for use with pretrained language models, finetuning GPT2. While successful, these approaches require a nontrivial amount of supervised data. Other semisupervised works also evaluate their method in an unsupervised setting . However, these works also assume delexicalized training dialogues, which requires groundtruth annotation and gives a form a supervision to the model.",
                                    "leftover": "Semisupervised TOD Some works propose semisupervised approaches to endtoend taskoriented dialogue. propose an endtoend sequencetosequence model where the dialogue state is a latent variable. adapt this approach for use with pretrained language models, finetuning GPT2. While successful, these approaches require a nontrivial amount of supervised data. Other semisupervised works also evaluate their method in an unsupervised setting . However, these works also assume delexicalized training dialogues, which requires groundtruth annotation and gives a form a supervision to the model.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec8/par2",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 82,
                                    "key": "doc/body/sec8/par2/txl0",
                                    "block type": "txl",
                                    "content": "Noisy channel and reranking methods A few previous works have utilized noisy channel methods for taskoriented dialogue or prompting methods. pretrain a noisy channel for taskoriented dialogues as a sequence to sequence model, however their method requires significant labelled training data. propose noisy channel prompting for fewshot classification tasks, which inspires our generalization to the generative setting.",
                                    "leftover": "Noisy channel and reranking methods A few previous works have utilized noisy channel methods for taskoriented dialogue or prompting methods. pretrain a noisy channel for taskoriented dialogues as a sequence to sequence model, however their method requires significant labelled training data. propose noisy channel prompting for fewshot classification tasks, which inspires our generalization to the generative setting.",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec9",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 83,
                            "key": "doc/body/sec9/tit",
                            "block type": "title",
                            "content": "Conclusion",
                            "leftover": "Conclusion",
                            "matches": []
                        },
                        {
                            "leaf id": 84,
                            "key": "doc/body/sec9/txl0",
                            "block type": "txl",
                            "content": "We present a novel approach for constructing an endtoend taskoriented dialogue system by leveraging pretrained language models to infer labels from unlabeled dialogues.",
                            "leftover": "We present a novel approach for constructing an endtoend taskoriented dialogue system by leveraging pretrained language models to infer labels from unlabeled dialogues.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec10",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 85,
                            "key": "doc/body/sec10/tit",
                            "block type": "title",
                            "content": "Limitations",
                            "leftover": "Limitations",
                            "matches": []
                        },
                        {
                            "leaf id": 86,
                            "key": "doc/body/sec10/txl0",
                            "block type": "txl",
                            "content": "Data contamination in LLM pretraining poses a hurdle for accurate benchmarking across NLP, and particularly for unsupervised methods. In an idealized setting, there would be a suitably strong taskoriented dialogue benchmark that could be verified as not belonging to the pretraining corpus of each new and more capable LLM. This is not the case for our setting or for many others, and warrants careful attention from the NLP community. For our setting, we were able to properly define problematic contamination and search for it in our LLM's pretraining corpus, thanks to the open release of the pretraining data. We found limited contamination and demonstrated that the contamination we found was not helpful in eliciting task knowledge that might have been memorized in pretraining.",
                            "leftover": "Data contamination in LLM pretraining poses a hurdle for accurate benchmarking across NLP, and particularly for unsupervised methods. In an idealized setting, there would be a suitably strong taskoriented dialogue benchmark that could be verified as not belonging to the pretraining corpus of each new and more capable LLM. This is not the case for our setting or for many others, and warrants careful attention from the NLP community. For our setting, we were able to properly define problematic contamination and search for it in our LLM's pretraining corpus, thanks to the open release of the pretraining data. We found limited contamination and demonstrated that the contamination we found was not helpful in eliciting task knowledge that might have been memorized in pretraining.",
                            "matches": []
                        },
                        {
                            "leaf id": 87,
                            "key": "doc/body/sec10/txl1",
                            "block type": "txl",
                            "content": "All experiments in this paper were conducted on preexisting public dialogue corpora, collected explicitly for training taskoriented dialogue agents with the knowledge of all participants . Our use of the StarCoder model also falls within the terms of it's Responsible AI License. It is important that subsequent applications of our method also adhere to any fairuse policies governing collected dialogues or transcripts. \\bibliography{anthology,custom}",
                            "leftover": "All experiments in this paper were conducted on preexisting public dialogue corpora, collected explicitly for training taskoriented dialogue agents with the knowledge of all participants . Our use of the StarCoder model also falls within the terms of it's Responsible AI License. It is important that subsequent applications of our method also adhere to any fairuse policies governing collected dialogues or transcripts. \\bibliography{anthology,custom}",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec11",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 88,
                            "key": "doc/body/sec11/tit",
                            "block type": "title",
                            "content": "Prompt Examples",
                            "leftover": "Prompt Examples",
                            "matches": []
                        },
                        {
                            "leaf id": 89,
                            "key": "doc/body/sec11/txl0",
                            "block type": "txl",
                            "content": "provides abridged instances of our direct prompts for DST and for Act Tagging. shows our prompt for inferring API call(s) or changes to the dialogue state from an unlabelled dialogue, as detailed in . Our prompts use python keyword arguments to provide the input variables for a given subtask, and to prompt the LLM for the next variable of interest. Using the arbitrary ordering of keyword arguments in Python function calls, our 'channel' prompts simply reorder the arguments in order to score the likelihood of the user's utterance given the predicted state change. provides a similar abridged instance of our direct prompt for tagging dialogue acts in an unlabelled dialogue. Here, we simply condition on the observed system response rt.",
                            "leftover": "provides abridged instances of our direct prompts for DST and for Act Tagging. shows our prompt for inferring API call(s) or changes to the dialogue state from an unlabelled dialogue, as detailed in . Our prompts use python keyword arguments to provide the input variables for a given subtask, and to prompt the LLM for the next variable of interest. Using the arbitrary ordering of keyword arguments in Python function calls, our 'channel' prompts simply reorder the arguments in order to score the likelihood of the user's utterance given the predicted state change. provides a similar abridged instance of our direct prompt for tagging dialogue acts in an unlabelled dialogue. Here, we simply condition on the observed system response rt.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec11/figure*1",
                            "block_type": "figure*",
                            "children": [
                                {
                                    "key": "doc/body/sec11/figure*1/subfigure0",
                                    "block_type": "subfigure",
                                    "children": [
                                        {
                                            "leaf id": 90,
                                            "key": "doc/body/sec11/figure*1/subfigure0/txl0",
                                            "block type": "txl",
                                            "content": "{0.49} \\includegraphics[width=]{imgs/directdstpromptv6.pdf}",
                                            "leftover": "{0.49} \\includegraphics[width=]{imgs/directdstpromptv6.pdf}",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 91,
                                            "key": "doc/body/sec11/figure*1/subfigure0/cpt1",
                                            "block type": "cpt",
                                            "content": "Our 'direct' DST prompt with italicized \\textcolor{dstcolor}{{DST Module}}",
                                            "leftover": "Our 'direct' DST prompt with italicized \\textcolor{dstcolor}{{DST Module}}",
                                            "matches": []
                                        }
                                    ]
                                },
                                {
                                    "key": "doc/body/sec11/figure*1/subfigure1",
                                    "block_type": "subfigure",
                                    "children": [
                                        {
                                            "leaf id": 92,
                                            "key": "doc/body/sec11/figure*1/subfigure1/txl0",
                                            "block type": "txl",
                                            "content": "{0.49} \\includegraphics[width=]{imgs/directdatpromptv4.pdf}",
                                            "leftover": "{0.49} \\includegraphics[width=]{imgs/directdatpromptv4.pdf}",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 93,
                                            "key": "doc/body/sec11/figure*1/subfigure1/cpt1",
                                            "block type": "cpt",
                                            "content": "Our 'direct' act tagging prompt, with italicized \\textcolor{dstcolor}{{DST Module}}",
                                            "leftover": "Our 'direct' act tagging prompt, with italicized \\textcolor{dstcolor}{{DST Module}}",
                                            "matches": []
                                        }
                                    ]
                                },
                                {
                                    "leaf id": 94,
                                    "key": "doc/body/sec11/figure*1/cpt2",
                                    "block type": "cpt",
                                    "content": "Abridged prompt and completion examples from our incontext learning approach to initial labelling for DST and DAT (Act Tagging), best viewed in color. Keyword arguments are used to include variables from the turn context and to prefix the completion",
                                    "leftover": "Abridged prompt and completion examples from our incontext learning approach to initial labelling for DST and DAT (Act Tagging), best viewed in color. Keyword arguments are used to include variables from the turn context and to prefix the completion",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec12",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 95,
                            "key": "doc/body/sec12/tit",
                            "block type": "title",
                            "content": "Metric Details",
                            "leftover": "Metric Details",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec12/par0",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 96,
                                    "key": "doc/body/sec12/par0/txl0",
                                    "block type": "txl",
                                    "content": "EndtoEnd (E2E) Dialogue Metrics We measure endtoend dialogue performance using the Inform rate, Success rate, and BLEU, following prior works, using the automatic evaluation provided by .https://github.com/Tomiinek/MultiWOZEvaluation",
                                    "leftover": "EndtoEnd (E2E) Dialogue Metrics We measure endtoend dialogue performance using the Inform rate, Success rate, and BLEU, following prior works, using the automatic evaluation provided by .https://github.com/Tomiinek/MultiWOZEvaluation",
                                    "matches": []
                                },
                                {
                                    "leaf id": 97,
                                    "key": "doc/body/sec12/par0/txl1",
                                    "block type": "txl",
                                    "content": "A dialogue is considered Informed if the most recently mentioned result for each domain meets the user's goal constraints, and is considered Successful if it is Informed and all values for requested slots are presented to the user. For example, if a user were to ask 'Can you give me the phone number of a cheap hotel in the east part of town?', the dialogue would be Informed if we refer them to a hotel that is actually in the cheap price range and in the east, and Successful if we additionally provide the phone number, as requested. BLEU is computed against a single reference response, and the Combined score is 0.5(Inform + Success) + BLEU.",
                                    "leftover": "A dialogue is considered Informed if the most recently mentioned result for each domain meets the user's goal constraints, and is considered Successful if it is Informed and all values for requested slots are presented to the user. For example, if a user were to ask 'Can you give me the phone number of a cheap hotel in the east part of town?', the dialogue would be Informed if we refer them to a hotel that is actually in the cheap price range and in the east, and Successful if we additionally provide the phone number, as requested. BLEU is computed against a single reference response, and the Combined score is 0.5(Inform + Success) + BLEU.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec12/par1",
                            "block_type": "par",
                            "children": [
                                {
                                    "leaf id": 98,
                                    "key": "doc/body/sec12/par1/txl0",
                                    "block type": "txl",
                                    "content": "Dialogue State Tracking Metrics Following prior works, we evaluate DST performance with jointgoal accuracy (JGA): for a turn xt, a dialogue state prediction ≈∑t is considered correct only if all slot names and values match the gold annotation state yt. We again use the evaluation provided in . Following their work, we accept fuzzy matches for noncategorical string values, such as the name of a restaurant or hotel, using the fuzzywuzzy}library and a fuzz ratio of 0.95.https://pypi.org/project/fuzzywuzzy/",
                                    "leftover": "Dialogue State Tracking Metrics Following prior works, we evaluate DST performance with jointgoal accuracy (JGA): for a turn xt, a dialogue state prediction ≈∑t is considered correct only if all slot names and values match the gold annotation state yt. We again use the evaluation provided in . Following their work, we accept fuzzy matches for noncategorical string values, such as the name of a restaurant or hotel, using the fuzzywuzzy}library and a fuzz ratio of 0.95.https://pypi.org/project/fuzzywuzzy/",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec13",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 99,
                            "key": "doc/body/sec13/tit",
                            "block type": "title",
                            "content": "Dialogue Acts",
                            "leftover": "Dialogue Acts",
                            "matches": []
                        },
                        {
                            "leaf id": 100,
                            "key": "doc/body/sec13/txl0",
                            "block type": "txl",
                            "content": "Following, we use a universal set of dialogue acts for managing our agents communicative intents. We omit some acts for simplicity and to reduce the context length required to enumerate them in a prompt. lists each act and a description. Since our dialogue set is not directly comparable to prior works, we do not directly evaluate act tagging or policy accuracy. Instead, acts serve only as an intermediate representation for planning responses in our endtoend system.",
                            "leftover": "Following, we use a universal set of dialogue acts for managing our agents communicative intents. We omit some acts for simplicity and to reduce the context length required to enumerate them in a prompt. lists each act and a description. Since our dialogue set is not directly comparable to prior works, we do not directly evaluate act tagging or policy accuracy. Instead, acts serve only as an intermediate representation for planning responses in our endtoend system.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec13/table*1",
                            "block_type": "table*",
                            "children": [
                                {
                                    "leaf id": 101,
                                    "key": "doc/body/sec13/table*1/tabular0",
                                    "block type": "tabular",
                                    "content": "{l p{12cm}} Act}& Description (as used in our prompt)} Inform(x=y) & Provide information. Offer(x=y) & System provides an offer or suggestion based on results. Confirm(x=y) & Seek confirmation of something. Affirm(x=y) & Express agreement or confirmation. Negate(x=y) & User or System denies or negates. NotifySuccess(x=y) & Notify of a successful action or result. NotifyFailure(x=y) & Notify of an error or failure. Acknowledge & Acknowledge. Goodbye & Goodbye. Greeting & Greeting. ThankYou & ThankYou. RequestAlternatives & Ask for other options, alternatives, or any additional user goals. Request(x=?) & Ask for specific information or action. &",
                                    "leftover": "{l p{12cm}} Act}& Description (as used in our prompt)} Inform(x=y) & Provide information. Offer(x=y) & System provides an offer or suggestion based on results. Confirm(x=y) & Seek confirmation of something. Affirm(x=y) & Express agreement or confirmation. Negate(x=y) & User or System denies or negates. NotifySuccess(x=y) & Notify of a successful action or result. NotifyFailure(x=y) & Notify of an error or failure. Acknowledge & Acknowledge. Goodbye & Goodbye. Greeting & Greeting. ThankYou & ThankYou. RequestAlternatives & Ask for other options, alternatives, or any additional user goals. Request(x=?) & Ask for specific information or action. &",
                                    "matches": []
                                },
                                {
                                    "leaf id": 102,
                                    "key": "doc/body/sec13/table*1/cpt1",
                                    "block type": "cpt",
                                    "content": "Dialogue acts supported by our system, adapted from the universal dialogue acts proposed in . ''x=y'' indicates the act can take on arbitrary keyvalue arguments, and ''x=?'' indicates the act takes on one or more unpaired arguments. We reduce the number of acts and lengths of descriptions relative to in order to fit within the LMs context length",
                                    "leftover": "Dialogue acts supported by our system, adapted from the universal dialogue acts proposed in . ''x=y'' indicates the act can take on arbitrary keyvalue arguments, and ''x=?'' indicates the act takes on one or more unpaired arguments. We reduce the number of acts and lengths of descriptions relative to in order to fit within the LMs context length",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec14",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 103,
                            "key": "doc/body/sec14/tit",
                            "block type": "title",
                            "content": "Offline Labeling Algorithm",
                            "leftover": "Offline Labeling Algorithm",
                            "matches": []
                        },
                        {
                            "leaf id": 104,
                            "key": "doc/body/sec14/txl0",
                            "block type": "txl",
                            "content": "Algorithm 1}gives our algorithm for pseudolabeling of unlabelled dialogues.",
                            "leftover": "Algorithm 1}gives our algorithm for pseudolabeling of unlabelled dialogues.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec14/algorithm*1",
                            "block_type": "algorithm*",
                            "children": [
                                {
                                    "leaf id": 105,
                                    "key": "doc/body/sec14/algorithm*1/algorithmic0",
                                    "block type": "algorithmic",
                                    "content": "InitialOfflineLabeltrain, Œ∏ret, Œ∏ ‚àÖ Initialize example pool ‚Ñ¨ [] Store predictions by dialogue id and turn index t = 0 tod ‚ààtrainmax d ‚ààtrain|d| Loop by increasing turn index (did, ut, rt1, rt) intrain did is dialogue ID bÃÇt1‚Ñ¨[did][t1] or ‚àÖ Fetch bÃÇt1 if known bÃÇt OfflineDSTùí´, Œ∏ret, bÃÇt1, rt1, ut √Çt OfflineActTagùí´, Œ∏ret, ut, rt ‚à™(rt1, ut, rt, bÃÇt, √Çt) Add incontext example for future labeling OfflineDSTùí´, Œ∏ret, bÃÇt1, rt1, ut Œ∏ret (bÃÇt rt1 ut, ùí´ ) Retrieve up to k incontext examples Œî bt P(fprompt (‚Ñ∞k, bÃÇt1, rt1, ut)) Sample w/ 'direct' prompt ŒîbÃÇt At ‚ààùí±^*argmax At ‚ààùí±^*P(ut | fprompt (‚Ñ∞k, bÃÇt1, rt1, Œî bt) Rerank w/ 'channel' prompt bÃÇt1 + ŒîbÃÇt OfflineActTagùí´, Œ∏ret, ut, rt Œ∏ret (ut rt, ùí´ ) Retrieve up to k incontext examples At (P(fprompt (‚Ñ∞k, rt))) Sample w/ 'direct' prompt At ‚ààùí±^*argmax At ‚ààùí±^*P(‚Ñ∞k, At, rt) Rerank w/ 'channel' prompt",
                                    "leftover": "InitialOfflineLabeltrain, Œ∏ret, Œ∏ ‚àÖ Initialize example pool ‚Ñ¨ [] Store predictions by dialogue id and turn index t = 0 tod ‚ààtrainmax d ‚ààtrain|d| Loop by increasing turn index (did, ut, rt1, rt) intrain did is dialogue ID bÃÇt1‚Ñ¨[did][t1] or ‚àÖ Fetch bÃÇt1 if known bÃÇt OfflineDSTùí´, Œ∏ret, bÃÇt1, rt1, ut √Çt OfflineActTagùí´, Œ∏ret, ut, rt ‚à™(rt1, ut, rt, bÃÇt, √Çt) Add incontext example for future labeling OfflineDSTùí´, Œ∏ret, bÃÇt1, rt1, ut Œ∏ret (bÃÇt rt1 ut, ùí´ ) Retrieve up to k incontext examples Œî bt P(fprompt (‚Ñ∞k, bÃÇt1, rt1, ut)) Sample w/ 'direct' prompt ŒîbÃÇt At ‚ààùí±^*argmax At ‚ààùí±^*P(ut | fprompt (‚Ñ∞k, bÃÇt1, rt1, Œî bt) Rerank w/ 'channel' prompt bÃÇt1 + ŒîbÃÇt OfflineActTagùí´, Œ∏ret, ut, rt Œ∏ret (ut rt, ùí´ ) Retrieve up to k incontext examples At (P(fprompt (‚Ñ∞k, rt))) Sample w/ 'direct' prompt At ‚ààùí±^*argmax At ‚ààùí±^*P(‚Ñ∞k, At, rt) Rerank w/ 'channel' prompt",
                                    "matches": []
                                },
                                {
                                    "leaf id": 106,
                                    "key": "doc/body/sec14/algorithm*1/cpt1",
                                    "block type": "cpt",
                                    "content": "Our algorithm for initial pseudolabeling of unlabelled dialogues in train",
                                    "leftover": "Our algorithm for initial pseudolabeling of unlabelled dialogues in train",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec15",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 107,
                            "key": "doc/body/sec15/tit",
                            "block type": "title",
                            "content": "Further results across EM Steps",
                            "leftover": "Further results across EM Steps",
                            "matches": []
                        },
                        {
                            "leaf id": 108,
                            "key": "doc/body/sec15/txl0",
                            "block type": "txl",
                            "content": "Here we expand on our ablations in, which evaluates our method with and without our proposed noisychannel prompting across iterations of expectationmaximization (EM). In, we break down the performance gains we observed in our 'Combined' metric into Inform rate, Success rate, and BLEU, where Combined = 0.5(Inform + Success) + BLEU. '0' iterations of EM indicates our zeroshot prompting system, without any incontext examples or EM. We find that EM substantially improves performance in all cases, and particularly for our noisychannel prompting approach. We find the noisy channel prompting approach improves performance on all metrics, with the most substantial gains over the greedy baseline in Inform and Success rates. This suggests that within our algorithm, noisychannel inference may be particularly important when inferring the system's dialogue acts in order to reverseengineer an accurate policy.",
                            "leftover": "Here we expand on our ablations in, which evaluates our method with and without our proposed noisychannel prompting across iterations of expectationmaximization (EM). In, we break down the performance gains we observed in our 'Combined' metric into Inform rate, Success rate, and BLEU, where Combined = 0.5(Inform + Success) + BLEU. '0' iterations of EM indicates our zeroshot prompting system, without any incontext examples or EM. We find that EM substantially improves performance in all cases, and particularly for our noisychannel prompting approach. We find the noisy channel prompting approach improves performance on all metrics, with the most substantial gains over the greedy baseline in Inform and Success rates. This suggests that within our algorithm, noisychannel inference may be particularly important when inferring the system's dialogue acts in order to reverseengineer an accurate policy.",
                            "matches": []
                        },
                        {
                            "leaf id": 109,
                            "key": "doc/body/sec15/txl1",
                            "block type": "txl",
                            "content": "In, we analyze dialogue state tracking performance across iterations of EM using Joint Goal Accuracy (JGA). We find our noisychannel prompting approach improves the accuracy of our dialogue state tracking predictions across iterations of EM when compared to a greedy, direct prompting approach.",
                            "leftover": "In, we analyze dialogue state tracking performance across iterations of EM using Joint Goal Accuracy (JGA). We find our noisychannel prompting approach improves the accuracy of our dialogue state tracking predictions across iterations of EM when compared to a greedy, direct prompting approach.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec15/figure*2",
                            "block_type": "figure*",
                            "children": [
                                {
                                    "leaf id": 110,
                                    "key": "doc/body/sec15/figure*2/cpt0",
                                    "block type": "cpt",
                                    "content": "Breaking down Combined = 0.5(Inform + Success) + BLEU into components Inform Rate, Success Rate, and BLEU across iterations of EM between our proposed noisychannel approach and a greedy ablation, which omits noisychannel prompting at inference time and when labeling dialogue states & system acts in the expectation step. We find improvement across all components, and particularly our Inform and Success Rates",
                                    "leftover": "Breaking down Combined = 0.5(Inform + Success) + BLEU into components Inform Rate, Success Rate, and BLEU across iterations of EM between our proposed noisychannel approach and a greedy ablation, which omits noisychannel prompting at inference time and when labeling dialogue states & system acts in the expectation step. We find improvement across all components, and particularly our Inform and Success Rates",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec15/figure*3",
                            "block_type": "figure*",
                            "children": [
                                {
                                    "leaf id": 111,
                                    "key": "doc/body/sec15/figure*3/cpt0",
                                    "block type": "cpt",
                                    "content": "Joint Goal Accuracy (JGA) of our inferred API call(s)/Dialogue states across iterations of EM. We find improved dialogue state tracking performance when using our noisychannel method at inference time and when labeling dialogue states offline in the expectation step for training, compared to a greedy direct prompting approach",
                                    "leftover": "Joint Goal Accuracy (JGA) of our inferred API call(s)/Dialogue states across iterations of EM. We find improved dialogue state tracking performance when using our noisychannel method at inference time and when labeling dialogue states offline in the expectation step for training, compared to a greedy direct prompting approach",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec16",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 112,
                            "key": "doc/body/sec16/tit",
                            "block type": "title",
                            "content": "Contamination Search & Result Details",
                            "leftover": "Contamination Search & Result Details",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec16/sub0",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 113,
                                    "key": "doc/body/sec16/sub0/tit",
                                    "block type": "title",
                                    "content": "Procedure",
                                    "leftover": "Procedure",
                                    "matches": []
                                },
                                {
                                    "leaf id": 114,
                                    "key": "doc/body/sec16/sub0/txl0",
                                    "block type": "txl",
                                    "content": "We detail our method for finding instances of task contamination within the StarCoder pretraining set. We are particularly interested in supervised pairs (x, y)}where y belongs to our schema of interest ùíÆ, for any of the dialogue subtasks used in our system. We devise a method for searching the complete pretraining corpus for contaminated (x, y) pairs, where x is an utterance we might observe from either the system or user, and y is the latent dialogue state change or dialogue act supporting ùíÆ. For each utterance x from either the system or user, we collect all documents from the pretraining corpus which contain the complete utterance. We use the elastic search index provided for the StarCoder pretraining data, which accounts for differences in capitalization, punctuation, and interrupting whitespace.https://github.com/bigcodeproject/search/blob/main/index.py Following this, we search matching documents for keywords from y (e.g. slot names and values) to determine which of these documents may plausibly contain a supervised label and warrant manual review. For dialogue states, these are the slot names and values, discarding extremely generic keywords like 'name'. For act tags, these are the act names, slots, and values. We then consider a document to need manual review if 40% or more of the keywords are found in the 500 characters before or after a matching x in a document. Finally, we handcheck the remaining documents and extract contaminated (x, y) pairs.",
                                    "leftover": "We detail our method for finding instances of task contamination within the StarCoder pretraining set. We are particularly interested in supervised pairs (x, y)}where y belongs to our schema of interest ùíÆ, for any of the dialogue subtasks used in our system. We devise a method for searching the complete pretraining corpus for contaminated (x, y) pairs, where x is an utterance we might observe from either the system or user, and y is the latent dialogue state change or dialogue act supporting ùíÆ. For each utterance x from either the system or user, we collect all documents from the pretraining corpus which contain the complete utterance. We use the elastic search index provided for the StarCoder pretraining data, which accounts for differences in capitalization, punctuation, and interrupting whitespace.https://github.com/bigcodeproject/search/blob/main/index.py Following this, we search matching documents for keywords from y (e.g. slot names and values) to determine which of these documents may plausibly contain a supervised label and warrant manual review. For dialogue states, these are the slot names and values, discarding extremely generic keywords like 'name'. For act tags, these are the act names, slots, and values. We then consider a document to need manual review if 40% or more of the keywords are found in the 500 characters before or after a matching x in a document. Finally, we handcheck the remaining documents and extract contaminated (x, y) pairs.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec16/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 115,
                                    "key": "doc/body/sec16/sub1/tit",
                                    "block type": "title",
                                    "content": "Examples",
                                    "leftover": "Examples",
                                    "matches": []
                                },
                                {
                                    "leaf id": 116,
                                    "key": "doc/body/sec16/sub1/txl0",
                                    "block type": "txl",
                                    "content": "contains examples of contamination discovered in our search process, and the type of document in which they were found. Notably, none of the examples found closely match our output formatting.",
                                    "leftover": "contains examples of contamination discovered in our search process, and the type of document in which they were found. Notably, none of the examples found closely match our output formatting.",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec16/sub1/table*1",
                                    "block_type": "table*",
                                    "children": [
                                        {
                                            "leaf id": 117,
                                            "key": "doc/body/sec16/sub1/table*1/tabular0",
                                            "block type": "tabular",
                                            "content": "{>{\\raggedright\\arraybackslash}p{0.25}|>{\\raggedright\\arraybackslash}p{0.25}|r|r} Contaminated Input}& Contaminated Output}& SubTask}& Source} I need a restaurant to dine at in Cambridge on my upcoming trip . I need info about chiquito restaurant bar restaurant . & restaurantinform<<<name===chiquito restaurant bar & DST & Jupyter Notebook i would like to book a 5 star, or closest to it, in the east part of town please . & ''<SOB> hotel { area = east, stars = 5, type = hotel } <EOB> <SOB> hotel { area = east, stars = 5 } restaurant { area = east } <EOB>'' & DST & Python [Syst] the train id is tr8292 and the price is 16.50 pounds. & [SYSDA] traininformleavetr8292 [SYSDA] traininformticket16.50 pounds & Act Tagging & Github Issue",
                                            "leftover": "{>{\\raggedright\\arraybackslash}p{0.25}|>{\\raggedright\\arraybackslash}p{0.25}|r|r} Contaminated Input}& Contaminated Output}& SubTask}& Source} I need a restaurant to dine at in Cambridge on my upcoming trip . I need info about chiquito restaurant bar restaurant . & restaurantinform<<<name===chiquito restaurant bar & DST & Jupyter Notebook i would like to book a 5 star, or closest to it, in the east part of town please . & ''<SOB> hotel { area = east, stars = 5, type = hotel } <EOB> <SOB> hotel { area = east, stars = 5 } restaurant { area = east } <EOB>'' & DST & Python [Syst] the train id is tr8292 and the price is 16.50 pounds. & [SYSDA] traininformleavetr8292 [SYSDA] traininformticket16.50 pounds & Act Tagging & Github Issue",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 118,
                                            "key": "doc/body/sec16/sub1/table*1/cpt1",
                                            "block type": "cpt",
                                            "content": "Example inputs and outputs in contaminated documents from each task, discovered in the StarCoder pretraining corpus. We include the source type of each document",
                                            "leftover": "Example inputs and outputs in contaminated documents from each task, discovered in the StarCoder pretraining corpus. We include the source type of each document",
                                            "matches": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "leaf id": 119,
            "key": "doc/bib0",
            "block type": "bibliography",
            "content": "Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel HerbertVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are FewShot Learners. arXiv:2005.14165 [cs]. ArXiv: 2005.14165.",
            "leftover": "Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel HerbertVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are FewShot Learners. arXiv:2005.14165 [cs]. ArXiv: 2005.14165.",
            "matches": []
        },
        {
            "leaf id": 120,
            "key": "doc/bib1",
            "block type": "bibliography",
            "content": "Pawe{\\l} Budzianowski, TsungHsien Wen, BoHsiang Tseng, I{\\~n}igo Casanueva, Ultes Stefan, Ramadan Osman, and Milica Ga{\\vs}i\\'c. 2018. Multiwoz  a largescale multidomain wizardofoz dataset for taskoriented dialogue modelling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP).",
            "leftover": "Pawe{\\l} Budzianowski, TsungHsien Wen, BoHsiang Tseng, I{\\~n}igo Casanueva, Ultes Stefan, Ramadan Osman, and Milica Ga{\\vs}i\\'c. 2018. Multiwoz  a largescale multidomain wizardofoz dataset for taskoriented dialogue modelling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP).",
            "matches": []
        },
        {
            "leaf id": 121,
            "key": "doc/bib2",
            "block type": "bibliography",
            "content": "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe~Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel HerbertVoss, William~Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew~N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code. ArXiv:2107.03374 [cs].",
            "leftover": "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe~Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel HerbertVoss, William~Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew~N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models Trained on Code. ArXiv:2107.03374 [cs].",
            "matches": []
        },
        {
            "leaf id": 122,
            "key": "doc/bib3",
            "block type": "bibliography",
            "content": "Willy Chung, Samuel Cahyawijaya, Bryan Wilie, Holy Lovenia, and Pascale Fung. 2023. InstructTODS: Large Language Models for EndtoEnd TaskOriented Dialogue Systems. ArXiv:2310.08885 [cs].",
            "leftover": "Willy Chung, Samuel Cahyawijaya, Bryan Wilie, Holy Lovenia, and Pascale Fung. 2023. InstructTODS: Large Language Models for EndtoEnd TaskOriented Dialogue Systems. ArXiv:2310.08885 [cs].",
            "matches": []
        },
        {
            "leaf id": 123,
            "key": "doc/bib4",
            "block type": "bibliography",
            "content": "A.~P. Dempster, N.~M. Laird, and D.~B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):138.",
            "leftover": "A.~P. Dempster, N.~M. Laird, and D.~B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):138.",
            "matches": []
        },
        {
            "leaf id": 124,
            "key": "doc/bib5",
            "block type": "bibliography",
            "content": "Michael Heck, Nurul Lubis, Benjamin Ruppik, Renato Vukovic, Shutong Feng, Christian Geishauser, Hsienchin Lin, Carel van Niekerk, and Milica Gasic. 2023. ChatGPT for zeroshot dialogue state tracking: A solution or an opportunity? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 936950, Toronto, Canada. Association for Computational Linguistics.",
            "leftover": "Michael Heck, Nurul Lubis, Benjamin Ruppik, Renato Vukovic, Shutong Feng, Christian Geishauser, Hsienchin Lin, Carel van Niekerk, and Milica Gasic. 2023. ChatGPT for zeroshot dialogue state tracking: A solution or an opportunity? In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 936950, Toronto, Canada. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 125,
            "key": "doc/bib6",
            "block type": "bibliography",
            "content": "Ari Holtzman, Jan Buys, Li~Du, Maxwell Forbes, and Yejin Choi. 2020. The Curious Case of Neural Text Degeneration. ArXiv:1904.09751 [cs].",
            "leftover": "Ari Holtzman, Jan Buys, Li~Du, Maxwell Forbes, and Yejin Choi. 2020. The Curious Case of Neural Text Degeneration. ArXiv:1904.09751 [cs].",
            "matches": []
        },
        {
            "leaf id": 126,
            "key": "doc/bib7",
            "block type": "bibliography",
            "content": "Yushi Hu, ChiaHsuan Lee, Tianbao Xie, Tao Yu, Noah~A. Smith, and Mari Ostendorf. 2022. InContext Learning for FewShot Dialogue State Tracking. Number: arXiv:2203.08568 arXiv:2203.08568 [cs].",
            "leftover": "Yushi Hu, ChiaHsuan Lee, Tianbao Xie, Tao Yu, Noah~A. Smith, and Mari Ostendorf. 2022. InContext Learning for FewShot Dialogue State Tracking. Number: arXiv:2203.08568 arXiv:2203.08568 [cs].",
            "matches": []
        },
        {
            "leaf id": 127,
            "key": "doc/bib8",
            "block type": "bibliography",
            "content": "Vojt{\\ve}ch Hude{\\vc}ek and Ondrej Dusek. 2023. Are large language models all you need for taskoriented dialogue? In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 216228, Prague, Czechia. Association for Computational Linguistics.",
            "leftover": "Vojt{\\ve}ch Hude{\\vc}ek and Ondrej Dusek. 2023. Are large language models all you need for taskoriented dialogue? In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 216228, Prague, Czechia. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 128,
            "key": "doc/bib9",
            "block type": "bibliography",
            "content": "Xisen Jin, Wenqiang Lei, Zhaochun Ren, Hongshen Chen, Shangsong Liang, Yihong Zhao, and Dawei Yin. 2018. Explicit State Tracking with SemiSupervision for Neural Dialogue Generation. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pages 14031412. ArXiv:1808.10596 [cs].",
            "leftover": "Xisen Jin, Wenqiang Lei, Zhaochun Ren, Hongshen Chen, Shangsong Liang, Yihong Zhao, and Dawei Yin. 2018. Explicit State Tracking with SemiSupervision for Neural Dialogue Generation. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pages 14031412. ArXiv:1808.10596 [cs].",
            "matches": []
        },
        {
            "leaf id": 129,
            "key": "doc/bib10",
            "block type": "bibliography",
            "content": "Brendan King and Jeffrey Flanigan. 2023. Diverse retrievalaugmented incontext learning for dialogue state tracking. In Findings of the Association for Computational Linguistics: ACL 2023, pages 55705585, Toronto, Canada. Association for Computational Linguistics.",
            "leftover": "Brendan King and Jeffrey Flanigan. 2023. Diverse retrievalaugmented incontext learning for dialogue state tracking. In Findings of the Association for Computational Linguistics: ACL 2023, pages 55705585, Toronto, Canada. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 130,
            "key": "doc/bib11",
            "block type": "bibliography",
            "content": "Changmao Li and Jeffrey Flanigan. 2024. Task Contamination: Language Models May Not Be FewShot Anymore. Proceedings of the AAAI Conference on Artificial Intelligence, 38(16):1847118480.",
            "leftover": "Changmao Li and Jeffrey Flanigan. 2024. Task Contamination: Language Models May Not Be FewShot Anymore. Proceedings of the AAAI Conference on Artificial Intelligence, 38(16):1847118480.",
            "matches": []
        },
        {
            "leaf id": 131,
            "key": "doc/bib12",
            "block type": "bibliography",
            "content": "Raymond Li, Loubna~Ben allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia LI, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry~Yue Zhuo, Thomas Wang, Olivier Dehaene, Joel LamyPoirier, Joao Monteiro, Nicolas Gontier, MingHo Yee, Logesh~Kumar Umapathi, Jian Zhu, Ben Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason~T Stillerman, Siva~Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Urvashi Bhattacharyya, Wenhao Yu, Sasha Luccioni, Paulo Villegas, Fedor Zhdanov, Tony Lee, Nadav Timor, Jennifer Ding, Claire~S Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Carolyn~Jane Anderson, Brendan DolanGavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos~Mu{\\~n}oz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro~Von Werra, and Harm de~Vries. 2023{\\natexlaba}. Starcoder: may the source be with you! Transactions on Machine Learning Research. Reproducibility Certification.",
            "leftover": "Raymond Li, Loubna~Ben allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia LI, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry~Yue Zhuo, Thomas Wang, Olivier Dehaene, Joel LamyPoirier, Joao Monteiro, Nicolas Gontier, MingHo Yee, Logesh~Kumar Umapathi, Jian Zhu, Ben Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason~T Stillerman, Siva~Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Urvashi Bhattacharyya, Wenhao Yu, Sasha Luccioni, Paulo Villegas, Fedor Zhdanov, Tony Lee, Nadav Timor, Jennifer Ding, Claire~S Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Carolyn~Jane Anderson, Brendan DolanGavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos~Mu{\\~n}oz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro~Von Werra, and Harm de~Vries. 2023{\\natexlaba}. Starcoder: may the source be with you! Transactions on Machine Learning Research. Reproducibility Certification.",
            "matches": []
        },
        {
            "leaf id": 132,
            "key": "doc/bib13",
            "block type": "bibliography",
            "content": "Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, and Xifeng Yan. 2023{\\natexlabb}. Guiding large language models via directional stimulus prompting. arXiv preprint arXiv:2302.11520.",
            "leftover": "Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, and Xifeng Yan. 2023{\\natexlabb}. Guiding large language models via directional stimulus prompting. arXiv preprint arXiv:2302.11520.",
            "matches": []
        },
        {
            "leaf id": 133,
            "key": "doc/bib14",
            "block type": "bibliography",
            "content": "Hong Liu, Yucheng Cai, Zhenru Lin, Zhijian Ou, Yi~Huang, and Junlan Feng. 2021{\\natexlaba}. Variational LatentState GPT for SemiSupervised TaskOriented Dialog Systems. ArXiv:2109.04314 [cs].",
            "leftover": "Hong Liu, Yucheng Cai, Zhenru Lin, Zhijian Ou, Yi~Huang, and Junlan Feng. 2021{\\natexlaba}. Variational LatentState GPT for SemiSupervised TaskOriented Dialog Systems. ArXiv:2109.04314 [cs].",
            "matches": []
        },
        {
            "leaf id": 134,
            "key": "doc/bib15",
            "block type": "bibliography",
            "content": "Qi~Liu, Lei Yu, Laura Rimell, and Phil Blunsom. 2021{\\natexlabb}. Pretraining the Noisy Channel Model for TaskOriented Dialogue. Transactions of the Association for Computational Linguistics, 9:657674.",
            "leftover": "Qi~Liu, Lei Yu, Laura Rimell, and Phil Blunsom. 2021{\\natexlabb}. Pretraining the Noisy Channel Model for TaskOriented Dialogue. Transactions of the Association for Computational Linguistics, 9:657674.",
            "matches": []
        },
        {
            "leaf id": 135,
            "key": "doc/bib16",
            "block type": "bibliography",
            "content": "QingBin Liu, ShiZhu He, Cao Liu, Kang Liu, and Jun Zhao. 2023. Unsupervised Dialogue State Tracking for EndtoEnd TaskOriented Dialogue with a MultiSpan Prediction Network. Journal of Computer Science and Technology, 38(4):834852.",
            "leftover": "QingBin Liu, ShiZhu He, Cao Liu, Kang Liu, and Jun Zhao. 2023. Unsupervised Dialogue State Tracking for EndtoEnd TaskOriented Dialogue with a MultiSpan Prediction Network. Journal of Computer Science and Technology, 38(4):834852.",
            "matches": []
        },
        {
            "leaf id": 136,
            "key": "doc/bib17",
            "block type": "bibliography",
            "content": "Sewon Min, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Noisy channel language model prompting for fewshot text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 53165330, Dublin, Ireland. Association for Computational Linguistics.",
            "leftover": "Sewon Min, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Noisy channel language model prompting for fewshot text classification. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 53165330, Dublin, Ireland. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 137,
            "key": "doc/bib18",
            "block type": "bibliography",
            "content": "Tom{\\'a}{\\vs} Nekvinda and Ond{\\vr}ej Du{\\vs}ek. 2021. Shades of BLEU, flavours of success: The case of MultiWOZ. In Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 3446, Online. Association for Computational Linguistics.",
            "leftover": "Tom{\\'a}{\\vs} Nekvinda and Ond{\\vr}ej Du{\\vs}ek. 2021. Shades of BLEU, flavours of success: The case of MultiWOZ. In Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 3446, Online. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 138,
            "key": "doc/bib19",
            "block type": "bibliography",
            "content": "Wenbo Pan, Qiguang Chen, Xiao Xu, Wanxiang Che, and Libo Qin. 2023. A Preliminary Evaluation of ChatGPT for Zeroshot Dialogue Understanding. Publisher: arXiv Version Number: 1.",
            "leftover": "Wenbo Pan, Qiguang Chen, Xiao Xu, Wanxiang Che, and Libo Qin. 2023. A Preliminary Evaluation of ChatGPT for Zeroshot Dialogue Understanding. Publisher: arXiv Version Number: 1.",
            "matches": []
        },
        {
            "leaf id": 139,
            "key": "doc/bib20",
            "block type": "bibliography",
            "content": "Shachi Paul, Rahul Goel, and Dilek HakkaniT√ºr. 2019. {Towards Universal Dialogue Act Tagging for TaskOriented Dialogues}. In Proc. Interspeech 2019, pages 14531457.",
            "leftover": "Shachi Paul, Rahul Goel, and Dilek HakkaniT√ºr. 2019. {Towards Universal Dialogue Act Tagging for TaskOriented Dialogues}. In Proc. Interspeech 2019, pages 14531457.",
            "matches": []
        },
        {
            "leaf id": 140,
            "key": "doc/bib21",
            "block type": "bibliography",
            "content": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu. 2020. Exploring the Limits of Transfer Learning with a Unified TexttoText Transformer. arXiv:1910.10683 [cs, stat]. ArXiv: 1910.10683.",
            "leftover": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu. 2020. Exploring the Limits of Transfer Learning with a Unified TexttoText Transformer. arXiv:1910.10683 [cs, stat]. ArXiv: 1910.10683.",
            "matches": []
        },
        {
            "leaf id": 141,
            "key": "doc/bib22",
            "block type": "bibliography",
            "content": "Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020. Towards Scalable MultiDomain Conversational Agents: The SchemaGuided Dialogue Dataset. Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):86898696.",
            "leftover": "Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020. Towards Scalable MultiDomain Conversational Agents: The SchemaGuided Dialogue Dataset. Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):86898696.",
            "matches": []
        },
        {
            "leaf id": 142,
            "key": "doc/bib23",
            "block type": "bibliography",
            "content": "Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and TieYan Liu. 2020. MPNet: Masked and Permuted Pretraining for Language Understanding. ArXiv:2004.09297 [cs].",
            "leftover": "Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and TieYan Liu. 2020. MPNet: Masked and Permuted Pretraining for Language Understanding. ArXiv:2004.09297 [cs].",
            "matches": []
        },
        {
            "leaf id": 143,
            "key": "doc/bib24",
            "block type": "bibliography",
            "content": "Yixuan Su, Lei Shu, Elman Mansimov, Arshit Gupta, Deng Cai, YiAn Lai, and Yi~Zhang. 2022. Multitask pretraining for plugandplay taskoriented dialogue system. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 46614676, Dublin, Ireland. Association for Computational Linguistics.",
            "leftover": "Yixuan Su, Lei Shu, Elman Mansimov, Arshit Gupta, Deng Cai, YiAn Lai, and Yi~Zhang. 2022. Multitask pretraining for plugandplay taskoriented dialogue system. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 46614676, Dublin, Ireland. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 144,
            "key": "doc/bib25",
            "block type": "bibliography",
            "content": "Qingyang Wu, James Gung, Raphael Shu, and Yi~Zhang. 2023. DiactTOD: Learning generalizable latent dialogue acts for controllable taskoriented dialogue systems. In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 255267, Prague, Czechia. Association for Computational Linguistics.",
            "leftover": "Qingyang Wu, James Gung, Raphael Shu, and Yi~Zhang. 2023. DiactTOD: Learning generalizable latent dialogue acts for controllable taskoriented dialogue systems. In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 255267, Prague, Czechia. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 145,
            "key": "doc/bib26",
            "block type": "bibliography",
            "content": "Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, and Jindong Chen. 2020. MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines. In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, pages 109117, Online. Association for Computational Linguistics.",
            "leftover": "Xiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, and Jindong Chen. 2020. MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines. In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, pages 109117, Online. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 146,
            "key": "doc/bib27",
            "block type": "bibliography",
            "content": "Xiaoying Zhang, Baolin Peng, Kun Li, Jingyan Zhou, and Helen Meng. 2023. SGPTOD: Building task bots effortlessly via schemaguided LLM prompting. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1334813369, Singapore. Association for Computational Linguistics.",
            "leftover": "Xiaoying Zhang, Baolin Peng, Kun Li, Jingyan Zhou, and Helen Meng. 2023. SGPTOD: Building task bots effortlessly via schemaguided LLM prompting. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1334813369, Singapore. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 147,
            "key": "doc/bib28",
            "block type": "bibliography",
            "content": "Yichi Zhang, Zhijian Ou, Min Hu, and Junlan Feng. 2020. A Probabilistic EndToEnd TaskOriented Dialog Model with Latent Belief States towards SemiSupervised Learning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 92079219, Online. Association for Computational Linguistics.",
            "leftover": "Yichi Zhang, Zhijian Ou, Min Hu, and Junlan Feng. 2020. A Probabilistic EndToEnd TaskOriented Dialog Model with Latent Belief States towards SemiSupervised Learning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 92079219, Online. Association for Computational Linguistics.",
            "matches": []
        },
        {
            "leaf id": 148,
            "key": "doc/bib29",
            "block type": "bibliography",
            "content": "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving fewshot performance of language models. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 1269712706. PMLR.",
            "leftover": "Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving fewshot performance of language models. In Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 1269712706. PMLR.",
            "matches": []
        }
    ]
}