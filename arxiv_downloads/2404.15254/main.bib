% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})



@misc{Anonymous24,
 author = {Anonymous},
 title = {The frobnicatable foo filter},
 note = {{ECCV} submission ID 00324, supplied as supplemental material {\tt 00324.pdf}},
 year = 2024
}

@misc{Anonymous24b,
 author = {Anonymous},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2024
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@book{ECCV2022,
    editor = {Shai Avidan and Gabriel Brostow and Moustapha Ciss√© and Giovanni Maria Farinella and Tal Hassner},
    title = {Computer Vision -- ECCV 2022},
    year = {2022},
    publisher = {Springer},
    doi = {10.1007/978-3-031-19769-7}
}

%=============================================================================================================
# ABBV
@String(ECCV = {European Conference on Computer Vision (ECCV)})
@String(NIPS = {Advances in neural information processing systems (NIPS)})
@String(NCAI = {National Conference on Artificial Intelligence (NCAI)})
@String(ICML = {International Conference on Machine Learning (ICML)})
@String(IJCV = {International Journal of Computer Vision (IJCV)})
@String(ICFHR = {International Conference on Frontiers in Handwriting Recognition (ICFHR)})
@String(ICDAR = {International Conference on Document Analysis and Recognition (ICDAR)})
@String(AAAI = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)})
@String(CVPR = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)})
@STRING(ICPR = {Proc. of the International Conf. on Pattern Recognition (ICPR)})

@String(ACL = {Proceedings of the 40th annual meeting of the Association for Computational Linguistics})
@String(DOCENG = {Proceedings of the 2003 ACM symposium on Document engineering})

@String(PR   = {Pattern Recognition})
@String(PRL  = {Pattern Recognition Letters})
@String(DOKLPHYS = {{Soviet physics doklady}})

@STRING{ARXIV = {arXiv.org}}


# 1. ML-based MER 
@inproceedings{anderson1967syntax,
  title={Syntax-directed recognition of hand-printed two-dimensional mathematics},
  author={Anderson, Robert H},
  booktitle={Symposium on interactive systems for experimental applied mathematics: Proceedings of the Association for Computing Machinery Inc. Symposium},
  pages={436--459},
  year={1967}
}

@article{Miller_Viola_1998,  
 title={Ambiguity and constraint in mathematical expression recognition}, 
 journal=NCAI, 
 author={Miller, E.G. and Viola, PaulA.}, 
 year={1998}, 
 month={Jul}, 
 language={en-US} 
 }

 @article{Chan_Yeung_1999,  
 title={Error detection, error correction and performance evaluation in on-line mathematical expression recognition}, 
 author={Chan, KamFai and Yeung, DitYan}, 
 year={1999}, 
 month={Jan}, 
 language={en-US} 
 }

 @inproceedings{suzuki2003infty,
  title={Infty: an integrated ocr system for mathematical documents},
  author={Suzuki, Masakazu and Tamari, Fumikazu and Fukuda, Ryoji and Uchida, Seiichi and Kanahori, Toshihiro},
  booktitle=DOCENG,
  pages={95--104},
  year={2003}
}



# 2. DL-based MER

@inproceedings{deng2017image,
  title={Image-to-markup generation with coarse-to-fine attention},
  author={Deng, Yuntian and Kanervisto, Anssi and Ling, Jeffrey and Rush, Alexander M},
  booktitle=ICML,
  pages={980--989},
  year={2017},
  organization={PMLR}
}

@article{zhang2017watch,
  title={Watch, attend and parse: An end-to-end neural network based approach to handwritten mathematical expression recognition},
  author={Zhang, Jianshu and Du, Jun and Zhang, Shiliang and Liu, Dan and Hu, Yulong and Hu, Jinshui and Wei, Si and Dai, Lirong},
  journal=PR,
  volume={71},
  pages={196--206},
  year={2017},
  publisher={Elsevier}
}


@article{le2019pattern,
  title={Pattern generation strategies for improving recognition of handwritten mathematical expressions},
  author={Le, Anh Duc and Indurkhya, Bipin and Nakagawa, Masaki},
  journal=PRL,
  volume={128},
  pages={255--262},
  year={2019},
  publisher={Elsevier}
}

@article{wu2020handwritten,
  title={Handwritten mathematical expression recognition via paired adversarial learning},
  author={Wu, Jin-Wen and Yin, Fei and Zhang, Yan-Ming and Zhang, Xu-Yao and Liu, Cheng-Lin},
  journal=IJCV,
  volume={128},
  pages={2386--2401},
  year={2020},
  publisher={Springer}
}

@inproceedings{zhang2020tree,
  title={A tree-structured decoder for image-to-markup generation},
  author={Zhang, Jianshu and Du, Jun and Yang, Yongxin and Song, Yi-Zhe and Wei, Si and Dai, Lirong},
  booktitle=ICML,
  pages={11076--11085},
  year={2020},
  organization={PMLR}
}

@inproceedings{li2020improving,
  title={Improving attention-based handwritten mathematical expression recognition with scale augmentation and drop attention},
  author={Li, Zhe and Jin, Lianwen and Lai, Songxuan and Zhu, Yecheng},
  booktitle=ICFHR,
  pages={175--180},
  year={2020},
  organization={IEEE}
}

@inproceedings{zhao2021handwritten,
  title={Handwritten mathematical expression recognition with bidirectionally trained transformer},
  author={Zhao, Wenqi and Gao, Liangcai and Yan, Zuoyu and Peng, Shuai and Du, Lin and Zhang, Ziyin},
  booktitle=ICDAR,
  pages={570--584},
  year={2021},
  organization={Springer}
}

@inproceedings{bian2022handwritten,
  title={Handwritten mathematical expression recognition via attention aggregation based bi-directional mutual learning},
  author={Bian, Xiaohang and Qin, Bo and Xin, Xiaozhe and Li, Jianwu and Su, Xuefeng and Wang, Yanfeng},
  booktitle=AAAI,
  volume={36},
  number={1},
  pages={113--121},
  year={2022}
}

@inproceedings{li2022counting,
  title={When counting meets HMER: counting-aware network for handwritten mathematical expression recognition},
  author={Li, Bohan and Yuan, Ye and Liang, Dingkang and Liu, Xiao and Ji, Zhilong and Bai, Jinfeng and Liu, Wenyu and Bai, Xiang},
  booktitle=ECCV,
  pages={197--214},
  year={2022},
  organization={Springer}
}

@inproceedings{yuan2022syntax,
  title={Syntax-aware network for handwritten mathematical expression recognition},
  author={Yuan, Ye and Liu, Xiao and Dikubab, Wondimu and Liu, Hui and Ji, Zhilong and Wu, Zhongqin and Bai, Xiang},
  booktitle=CVPR,
  pages={4553--4562},
  year={2022}
}

@inproceedings{zhao2022comer,
  title={Comer: Modeling coverage for transformer-based handwritten mathematical expression recognition},
  author={Zhao, Wenqi and Gao, Liangcai},
  booktitle=ECCV,
  pages={392--408},
  year={2022},
  organization={Springer}
}

@inproceedings{zhang2018multi,
  title={Multi-scale attention with dense encoder for handwritten mathematical expression recognition},
  author={Zhang, Jianshu and Du, Jun and Dai, Lirong},
  booktitle=ICPR,
  pages={2245--2250},
  year={2018},
  organization={IEEE}
}


# 3. Dataset and Metric

CROHME2014

@inproceedings{mouchere2014icfhr,
  title={ICFHR 2014 competition on recognition of on-line handwritten mathematical expressions (CROHME 2014)},
  author={Mouchere, Harold and Viard-Gaudin, Christian and Zanibbi, Richard and Garain, Utpal},
  booktitle=ICFHR,
  pages={791--796},
  year={2014},
  organization={IEEE}
}

@inproceedings{mouchere2016icfhr2016,
  title={ICFHR2016 CROHME: Competition on recognition of online handwritten mathematical expressions},
  author={Mouch{\`e}re, Harold and Viard-Gaudin, Christian and Zanibbi, Richard and Garain, Utpal},
  booktitle=ICFHR,
  pages={607--612},
  year={2016},
  organization={IEEE}
}

@inproceedings{mahdavi2019icdar,
  title={ICDAR 2019 CROHME+ TFD: Competition on recognition of handwritten mathematical expressions and typeset formula detection},
  author={Mahdavi, Mahshad and Zanibbi, Richard and Mouchere, Harold and Viard-Gaudin, Christian and Garain, Utpal},
  booktitle=ICDAR,
  pages={1533--1538},
  year={2019},
  organization={IEEE}
}


@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle=ACL,
  pages={311--318},
  year={2002}
}

% Edit Distance
@inproceedings{levenshtein1966binary,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I and others},
  booktitle=DOKLPHYS,
  volume={10},
  number={8},
  pages={707--710},
  year={1966},
  organization={Soviet Union}
}




# 4. LLM-based 
% donut
@inproceedings{kim2022ocr,
  title={Ocr-free document understanding transformer},
  author={Kim, Geewook and Hong, Teakgyu and Yim, Moonbin and Nam, JeongYeon and Park, Jinyoung and Yim, Jinyeong and Hwang, Wonseok and Yun, Sangdoo and Han, Dongyoon and Park, Seunghyun},
  booktitle=ECCV,
  pages={498--517},
  year={2022},
  organization={Springer}
}

@article{blecher2023nougat,
  title={Nougat: Neural optical understanding for academic documents},
  author={Blecher, Lukas and Cucurull, Guillem and Scialom, Thomas and Stojnic, Robert},
  journal=ARXIV,
  volume={2308.13418},
  year={2023}
}

@article{wei2023vary,
  title={Vary: Scaling up the vision vocabulary for large vision-language models},
  author={Wei, Haoran and Kong, Lingyu and Chen, Jinyue and Zhao, Liang and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},
  journal=ARXIV,
  volume={2312.06109},
  year={2023}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal=ARXIV,
  volume={2304.10592},
  year={2023}
}

@inproceedings{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal=NeurIPS,
  volume={36},
  year={2024}
}

@article{dong2024internlm,
  title={InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model},
  author={Dong, Xiaoyi and Zhang, Pan and Zang, Yuhang and Cao, Yuhang and Wang, Bin and Ouyang, Linke and Wei, Xilin and Zhang, Songyang and Duan, Haodong and Cao, Maosong and others},
  journal=ARXIV,
  volume={2401.16420},
  year={2024}
}

@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal=ARXIV,
  volume={2310.03744},
  year={2023}
}

@misc{conghui2022opendatalab,
  author={He, Conghui and Li, Wei and Jin, Zhenjiang and Wang, Bin and Xu, Chao and Lin, Dahua},
  title={OpenDataLab: Empowering General Artificial Intelligence with Open Datasets},
  howpublished = {\url{https://opendatalab.com}},
  year={2022},
  note = {Accessed: 2023-12-22}
}

@misc{chatgpt,
   author = {OpenAI},
   title = {ChatGPT},
   howpublished = {\url{https://openai.com/blog/chatgpt}},
   year={2023},
   note = {Accessed: 2023-12-22}
}

@misc{pix2tex2022,
  author={Blecher, Lukas},
  title={pix2tex - LaTeX OCR},
  howpublished = {\url{https://github.com/lukas-blecher/LaTeX-OCR}},
  year={2022},
  note = {Accessed: 2024-2-29}
}

@misc{texify2023,
  author={Paruchuri, Vik},
  title={Texify},
  howpublished = {\url{https://github.com/VikParuchuri/texify}},
  year={2023},
  note = {Accessed: 2024-2-29}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal=NeurIPS,
  volume={30},
  year={2017}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle=ICCV,
  pages={10012--10022},
  year={2021}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal=ARXIV,
  year={2019}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal=NeurIPS,
  volume={25},
  year={2012}
}

@inproceedings{simonyan2015very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, K and Zisserman, A},
  booktitle={ICLR},
  year={2015},
  organization={Computational and Biological Learning Society}
}