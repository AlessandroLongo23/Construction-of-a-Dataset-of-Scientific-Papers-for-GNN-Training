\section{Related works}
\label{sec:related}

\subsection{Video object detection.} 
% add object detection
Object detection, one of the most fundamental problems in computer vision, aims to predict the location and class of objects of interest within an input image. Neural networks for object detection can be roughly categorized into one-stage and two-stage detectors \cite{zou2023object}. Two-stage detectors, represented by Faster RCNN \cite{faster_rcnn} and FPN \cite{lin2017feature}, predict the feature proposals and detection results in a two-step, coarse-to-fine manner. These detectors generally exhibit good performance and are relatively easy to train. In contrast, one-stage detectors, such as YOLO \cite{YOLOv1}, SSD \cite{liu2016ssd}, and DETR \cite{carion2020end}, predict all detections in a single inference stage, making them faster and easier to deploy in real-world applications. However, training one-stage detectors often requires more tricks, and they may struggle when detecting dense and small targets.

% video object detection
Video object detection (VOD) presents a unique set of challenges distinct from still image object detection, primarily due to the dynamic nature of video content. In VOD, temporal consistency across frames in the same sequence can be exploited to enhance the robustness of features and reduce the potential ambiguity of the object information in a single image. 
Given an image sequence $\mathbf{I}\in \mathbb{R}^{H\times W \times T}$ where $H$, $W$ and $T$ are image height, image width, and temporal length of the sequence. Most recent VOD algorithms predict the object location $\{y^{loc}\}$ and category $\{y^{cls}\}$ by extracting spatial features via a single-frame backbone and temporal aggregation \cite{wu2019sequence}.
Those solutions are customized for two-stage image object detectors \cite{faster_rcnn, gong2021temporal} or transformers \cite{wang2022ptseformer, VSformer, zhou2022transvod}. These detectors, while effective, often incur high computational costs due to their model size or complex processing pipeline \cite{li2021free}.

In contrast, YOLOV \cite{li2021free} integrates the one-stage object detector YOLOX \cite{ge2021yolox} as its spatial backbone. This configuration benefits from a cost-effective temporal aggregation module, which significantly enhances YOLOX's performance, endowing YOLOV with both superior performance and efficiency. YOLOV's methodology involves selecting key regions from the dense prediction map produced by the detection head, minimizing the processing of numerous low-quality candidates. Furthermore, it assesses the affinity between extracted features from both target and reference frames, facilitating a lightweight feature aggregation process. This strategy presents an efficient alternative to more cumbersome methods, particularly advantageous in scenarios demanding real-time responsiveness.

\subsection{Source-free domain adaptation} 
% add domain adaptation for object detection
Domain adaptation for object detection involves data from two domains with different data distributions: the source domain, in which the detector is initially trained, and the target domain, where the detector will be ultimately deployed. Typically, labeling in the target domain is relatively scarce \cite{adp_vp}. In addition to supervised domain adaptation, methods for semi-supervised \cite{inoue2018cross, saito2019semi} and unsupervised domain adaptation \cite{chen2018domain, saito2019strong, cai2019exploring, vs2021mega} for object detection have been studied based on the availability of labels. These methods have achieved significant success in domain adaptation, regardless of whether labeling is available in the target domain data. However, they all require access to source domain data, which may not always be available due to privacy or storage constraints. To address this issue, methodologies for source-free domain adaptation (SFDA) have been recently proposed \cite{liang2020we, tarvainen2017mean, kundu2020universal, yang2021generalized, liu2021source, yang2022attracting, xu2022source}. 

SFDA aims to adapt the detector to the target domain using only the pre-trained model and target domain data, without requiring access to the source domain data, making it a promising approach for real-world applications where source data may be unavailable or inaccessible. Initial SFDA strategies have harnessed self-supervised techniques and pseudo-labeling \cite{liang2020we}. The mean-teacher method \cite{tarvainen2017mean} employs a student-teacher paradigm where the teacher model's parameters are an exponential moving average of the student model's parameters. This approach has shown effectiveness in stabilizing training and improving robustness as the teacher model accumulates and refines knowledge over time, aiding in generating more reliable pseudo-labels. Such methods underscore the essence of SFDA: leveraging target domain intrinsic properties while circumventing the need for source data, thereby aligning domain-specific feature distributions.

Mean-teacher has been a fundamental technique in SFDA for object detection. Most existing works \cite{vibashan2023instance, li2022source, run_and_chase, chen2023exploiting, liu2023periodically, chu2023adversarial, cao2023contrastive} employ the mean-teacher as part of their frameworks. Besides mean-teacher, other methodologies include self-entropy descent and pseudo-label refinement \cite{li2021free}, style enhancement and graph alignment constraint \cite{li2022source}, adversarial alignment \cite{chu2023adversarial}, instance relation graph \cite{vibashan2023instance} and contrastive representation learning \cite{vibashan2023instance, cao2023contrastive}. However, most existing algorithms are designed for two-stage detectors, particularly the Faster RCNN \cite{faster_rcnn}, and cannot be directly applied to the domain adaptation for one-stage detectors such as the YOLO series. This is partially because the region proposals in two-stage detectors could provide high-quality semantic information for additional feature alignment, providing meaningful additional training signals for SFDA. Another reason is that one-stage detectors usually need complicated training tricks; their feature space is more intractable and vulnerable to fine-tuning. Recently, YOLOV \cite{shi2023yolov} provided an efficient feature selection and fusion mechanism for the one-stage detector YOLOX \cite{ge2021yolox} among multiple frames, SFDA for YOLOV would provide valuable experience in both domain adaptation for one-stage detectors and VOD tasks.
