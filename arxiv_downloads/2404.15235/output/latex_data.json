{
    "key": "doc",
    "block_type": "document",
    "children": [
        {
            "leaf id": 0,
            "key": "doc/tit",
            "block type": "title",
            "content": "Runtimecoherence tradeoffs for hybrid SATsolvers",
            "leftover": "Runtimecoherence tradeoffs for hybrid SATsolvers",
            "matches": []
        },
        {
            "leaf id": 1,
            "key": "doc/aut0",
            "block type": "author",
            "content": "{ Vahideh Eshaghian^(1), S\"oren Wilkening^(2), (3), Johan {\\AA}berg^(1), David Gross^(1) } vahideh@thp.unikoeln.de (1) Institute for Theoretical Physics, University of Cologne, Germany; (2) Institut f\"ur Theoretische Physik, Leibniz Universit\"at Hannover, Germany; (3) Volkswagen AG, Berliner Ring 2, 38440 Wolfsburg;",
            "leftover": "{ Vahideh Eshaghian^(1), S\"oren Wilkening^(2), (3), Johan {\\AA}berg^(1), David Gross^(1) } vahideh@thp.unikoeln.de (1) Institute for Theoretical Physics, University of Cologne, Germany; (2) Institut f\"ur Theoretische Physik, Leibniz Universit\"at Hannover, Germany; (3) Volkswagen AG, Berliner Ring 2, 38440 Wolfsburg;",
            "matches": []
        },
        {
            "leaf id": 2,
            "key": "doc/abs",
            "block type": "abstract",
            "content": "Many searchbased quantum algorithms that achieve a theoretical speedup are not practically relevant since they require extraordinarily long coherence times, or lack the parallelizability of their classical counterparts. This raises the question of how to divide computational tasks into a collection of parallelizable subproblems, each of which can be solved by a quantum computer with limited coherence time. Here, we approach this question via hybrid algorithms for the kSAT problem. Our analysis is based on Sch\"oning's algorithm, which solves instances of kSAT by performing random walks in the space of potential assignments. The search space of the walk allows for ''natural'' partitions, where we subject only one part of the partition to a Grover search, while the rest is sampled classically, thus resulting in a hybrid scheme. In this setting, we argue that there exists a simple tradeoff relation between the total runtime and the coherencetime, which no such partition based hybridscheme can surpass. For several concrete choices of partitions, we explicitly determine the specific runtime coherencetime relations, and show saturation of the ideal tradeoff. Finally, we present numerical simulations which suggest additional flexibility in implementing hybrid algorithms with optimal tradeoff.",
            "leftover": "Many searchbased quantum algorithms that achieve a theoretical speedup are not practically relevant since they require extraordinarily long coherence times, or lack the parallelizability of their classical counterparts. This raises the question of how to divide computational tasks into a collection of parallelizable subproblems, each of which can be solved by a quantum computer with limited coherence time. Here, we approach this question via hybrid algorithms for the kSAT problem. Our analysis is based on Sch\"oning's algorithm, which solves instances of kSAT by performing random walks in the space of potential assignments. The search space of the walk allows for ''natural'' partitions, where we subject only one part of the partition to a Grover search, while the rest is sampled classically, thus resulting in a hybrid scheme. In this setting, we argue that there exists a simple tradeoff relation between the total runtime and the coherencetime, which no such partition based hybridscheme can surpass. For several concrete choices of partitions, we explicitly determine the specific runtime coherencetime relations, and show saturation of the ideal tradeoff. Finally, we present numerical simulations which suggest additional flexibility in implementing hybrid algorithms with optimal tradeoff.",
            "matches": []
        },
        {
            "key": "doc/body",
            "block_type": "body",
            "children": [
                {
                    "key": "doc/body/sec0",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 3,
                            "key": "doc/body/sec0/tit",
                            "block type": "title",
                            "content": "Introduction",
                            "leftover": "Introduction",
                            "matches": []
                        },
                        {
                            "leaf id": 4,
                            "key": "doc/body/sec0/txl0",
                            "block type": "txl",
                            "content": "Consider a quantum algorithm that takes exponential time to run, but still offers a polynomial speedup over the best classical method. Examples include Grover searches to bruteforce a password or for finding the solution for a combinatorial optimization problem for which no classical heuristics exist. Fully quantum implementations might not be desirable for two reasons: (1) Quantum hardware that can sustain very long computations might not be available, and (2) quantum algorithms, like Grover's search, might not be easily amenable to parallelization. One is thus lead to the question of how to best break up such instances into a set of smaller, parallelizable subproblems that can individually be solved on quantum hardware.",
                            "leftover": "Consider a quantum algorithm that takes exponential time to run, but still offers a polynomial speedup over the best classical method. Examples include Grover searches to bruteforce a password or for finding the solution for a combinatorial optimization problem for which no classical heuristics exist. Fully quantum implementations might not be desirable for two reasons: (1) Quantum hardware that can sustain very long computations might not be available, and (2) quantum algorithms, like Grover's search, might not be easily amenable to parallelization. One is thus lead to the question of how to best break up such instances into a set of smaller, parallelizable subproblems that can individually be solved on quantum hardware.",
                            "matches": []
                        },
                        {
                            "leaf id": 5,
                            "key": "doc/body/sec0/txl1",
                            "block type": "txl",
                            "content": "We consider the wellknown satisfiability problem with k the number of literals in each clause, (kSAT) and focus particularly on 3SAT since it provides an attractive test bed to investigate such questions. kSAT is the archetypical combinatorial optimization problem and represents a class of use cases with considerable practical relevance. Moreover, there is a classical randomized algorithm due to Sch\"oning, with a performance close to the bestknown algorithms with provable performance, and which furthermore allows for a closedform asymptotic runtime analysis. And indeed, the algorithm obtained by replacing the classical search of the Sch\"oningprocedure by a Grover search yields a quantumSch\"oning algorithm with a quadratic improvement visàvis its classical counterpart . (Below, we will refer to quantum algorithms that arise this way as Groverizations of their classical versions).",
                            "leftover": "We consider the wellknown satisfiability problem with k the number of literals in each clause, (kSAT) and focus particularly on 3SAT since it provides an attractive test bed to investigate such questions. kSAT is the archetypical combinatorial optimization problem and represents a class of use cases with considerable practical relevance. Moreover, there is a classical randomized algorithm due to Sch\"oning, with a performance close to the bestknown algorithms with provable performance, and which furthermore allows for a closedform asymptotic runtime analysis. And indeed, the algorithm obtained by replacing the classical search of the Sch\"oningprocedure by a Grover search yields a quantumSch\"oning algorithm with a quadratic improvement visàvis its classical counterpart . (Below, we will refer to quantum algorithms that arise this way as Groverizations of their classical versions).",
                            "matches": []
                        },
                        {
                            "leaf id": 6,
                            "key": "doc/body/sec0/txl2",
                            "block type": "txl",
                            "content": "However, such 'fully quantized' Sch\"oning's SATsolvers cannot be performed in parallel, which arguably is a relevant feature for algorithms that run in exponential time. Hybrid schemes, based on 'partial' Groverizations of Sch\"oning's algorithm, where Grover search procedures are applied only to certain subroutines, usually do allow for parallelizations.",
                            "leftover": "However, such 'fully quantized' Sch\"oning's SATsolvers cannot be performed in parallel, which arguably is a relevant feature for algorithms that run in exponential time. Hybrid schemes, based on 'partial' Groverizations of Sch\"oning's algorithm, where Grover search procedures are applied only to certain subroutines, usually do allow for parallelizations.",
                            "matches": []
                        },
                        {
                            "leaf id": 7,
                            "key": "doc/body/sec0/txl3",
                            "block type": "txl",
                            "content": "Starting point of our analysis is the stochastic nature of Sch\"oning's algorithm as a random walk. This point of view yields two classes of hybrid algorithms, where one class Groverizes the random choice of the initial state of the walk, while the other class Groverizes the randomness in the walk itself. Within an established model of Sch\"oning's algorithm, we optimize the resulting runtimes by balancing the resources allocated to the subroutines.",
                            "leftover": "Starting point of our analysis is the stochastic nature of Sch\"oning's algorithm as a random walk. This point of view yields two classes of hybrid algorithms, where one class Groverizes the random choice of the initial state of the walk, while the other class Groverizes the randomness in the walk itself. Within an established model of Sch\"oning's algorithm, we optimize the resulting runtimes by balancing the resources allocated to the subroutines.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec0/sub4",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 8,
                                    "key": "doc/body/sec0/sub4/tit",
                                    "block type": "title",
                                    "content": "RuntimeCoherence Time TradeOffs",
                                    "leftover": "RuntimeCoherence Time TradeOffs",
                                    "matches": []
                                },
                                {
                                    "leaf id": 9,
                                    "key": "doc/body/sec0/sub4/txl0",
                                    "block type": "txl",
                                    "content": "Before specializing the Sch\"oning process, let us briefly outline the tradeoffs between runtime and coherence time that can be expected for quantum search problems. Consider an algorithm that solves instances of size n with runtime T(n). For exponentialtime algorithms, we work with a somewhat coarser measure, the (asymptotic) runtime rate",
                                    "leftover": "Before specializing the Sch\"oning process, let us briefly outline the tradeoffs between runtime and coherence time that can be expected for quantum search problems. Consider an algorithm that solves instances of size n with runtime T(n). For exponentialtime algorithms, we work with a somewhat coarser measure, the (asymptotic) runtime rate",
                                    "matches": []
                                },
                                {
                                    "leaf id": 10,
                                    "key": "doc/body/sec0/sub4/align*1",
                                    "block type": "align*",
                                    "content": "γ=limn→∞ n logT(n),",
                                    "leftover": "γ=limn→∞ n logT(n),",
                                    "matches": []
                                },
                                {
                                    "leaf id": 11,
                                    "key": "doc/body/sec0/sub4/txl2",
                                    "block type": "txl",
                                    "content": "where we drop the base of the logarithm from here on; the base is 2 unless explicitly stated otherwise. In other words, T∈ O^*(2^γ n), where O^* denotes scaling behavior up to polynomial factors. The aim is to trade it off against the coherence time required to run the algorithm. If C(n) is the longest time over which coherence has to be maintained while running the algorithm, then the coherence time rate is",
                                    "leftover": "where we drop the base of the logarithm from here on; the base is 2 unless explicitly stated otherwise. In other words, T∈ O^*(2^γ n), where O^* denotes scaling behavior up to polynomial factors. The aim is to trade it off against the coherence time required to run the algorithm. If C(n) is the longest time over which coherence has to be maintained while running the algorithm, then the coherence time rate is",
                                    "matches": []
                                },
                                {
                                    "leaf id": 12,
                                    "key": "doc/body/sec0/sub4/align*3",
                                    "block type": "align*",
                                    "content": "χ=limn→∞ n logC(n).",
                                    "leftover": "χ=limn→∞ n logC(n).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 13,
                                    "key": "doc/body/sec0/sub4/txl4",
                                    "block type": "txl",
                                    "content": "Now restrict attention to search algorithms with classical runtime rate γC. A completely Groverized version runs with rate γG=γC/2. All of its runtime will be spent coherently, specifically executing Grover iterations. Therefore, χG=γC/2 as well. We can visualize these two points in a ''runtime rate vs coherence time rate''chart, a mode of visualization that we will employ frequently (Fig.~).",
                                    "leftover": "Now restrict attention to search algorithms with classical runtime rate γC. A completely Groverized version runs with rate γG=γC/2. All of its runtime will be spent coherently, specifically executing Grover iterations. Therefore, χG=γC/2 as well. We can visualize these two points in a ''runtime rate vs coherence time rate''chart, a mode of visualization that we will employ frequently (Fig.~).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 14,
                                    "key": "doc/body/sec0/sub4/txl5",
                                    "block type": "txl",
                                    "content": "To achieve a tradeoff between total runtime and coherence time, we will consider algorithms that apply Grover's procedure only to a subset of the search space. It is easy to see that any algorithm which results from such a procedure must have coordinates (χ,γ) that lie on or above the line segment",
                                    "leftover": "To achieve a tradeoff between total runtime and coherence time, we will consider algorithms that apply Grover's procedure only to a subset of the search space. It is easy to see that any algorithm which results from such a procedure must have coordinates (χ,γ) that lie on or above the line segment",
                                    "matches": []
                                },
                                {
                                    "leaf id": 15,
                                    "key": "doc/body/sec0/sub4/align*6",
                                    "block type": "align*",
                                    "content": "L= (χ, γC  χ) | χ∈[0,γC/2]",
                                    "leftover": "L= (χ, γC  χ) | χ∈[0,γC/2]",
                                    "matches": []
                                },
                                {
                                    "leaf id": 16,
                                    "key": "doc/body/sec0/sub4/txl7",
                                    "block type": "txl",
                                    "content": "that connects the purely classical point (0,γC) to the completely Groverized one ( γC/2, γC/2).",
                                    "leftover": "that connects the purely classical point (0,γC) to the completely Groverized one ( γC/2, γC/2).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 17,
                                    "key": "doc/body/sec0/sub4/txl8",
                                    "block type": "txl",
                                    "content": "Indeed, take a partial Groverization that achieves parameters (χ,γ). Then one can replace the Grover part by a classical search. The resulting classical algorithm will have parameters (0,γ+χ), because the Grover search contributed χ to the runtime rate, but its classical simulation will contribute 2χ instead. But if the initial parameters were below the line, i.e.\\ if γ < γC  χ, then the resulting classical algorithm runtime rate is γ + χ < γC, contradicting the assumption that γC describes the classical complexity of the search.",
                                    "leftover": "Indeed, take a partial Groverization that achieves parameters (χ,γ). Then one can replace the Grover part by a classical search. The resulting classical algorithm will have parameters (0,γ+χ), because the Grover search contributed χ to the runtime rate, but its classical simulation will contribute 2χ instead. But if the initial parameters were below the line, i.e.\\ if γ < γC  χ, then the resulting classical algorithm runtime rate is γ + χ < γC, contradicting the assumption that γC describes the classical complexity of the search.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 18,
                                    "key": "doc/body/sec0/sub4/figure9",
                                    "block type": "figure",
                                    "content": "ht] \\begin{center} \\includegraphics[scale=.65]{images/chart} \\end{center} We will frequently visualize the behavior of algorithms by indicating their position in a ''runtime rate vs coherence time rate''chart. Classical algorithms require no coherence, and thus lie on the yaxis. In the example given, the point on the upper left hand side represents a classical probabilistic search with runtime rate γC. A completely Groverized version has coordinates ( γC/2, γC/2) (bottom right), meaning that it will spend its entire runtime coherently. Hybrid algorithms that use Grover only for a subset of the search space must lie in the shaded area above or on the dashed line segment connecting these two points.",
                                    "leftover": "ht] \\begin{center} \\includegraphics[scale=.65]{images/chart} \\end{center} We will frequently visualize the behavior of algorithms by indicating their position in a ''runtime rate vs coherence time rate''chart. Classical algorithms require no coherence, and thus lie on the yaxis. In the example given, the point on the upper left hand side represents a classical probabilistic search with runtime rate γC. A completely Groverized version has coordinates ( γC/2, γC/2) (bottom right), meaning that it will spend its entire runtime coherently. Hybrid algorithms that use Grover only for a subset of the search space must lie in the shaded area above or on the dashed line segment connecting these two points.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 19,
                                    "key": "doc/body/sec0/sub4/txl10",
                                    "block type": "txl",
                                    "content": "It is not obvious that, conversely, every point on this optimal line segment can actually be realized, much less with an algorithm that is ''natural'' or easy to implement. Deciding the parameter ranges for natural partial Groverizations of Sch\"oning's procedure is the main goal of this paper.",
                                    "leftover": "It is not obvious that, conversely, every point on this optimal line segment can actually be realized, much less with an algorithm that is ''natural'' or easy to implement. Deciding the parameter ranges for natural partial Groverizations of Sch\"oning's procedure is the main goal of this paper.",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec0/sub4/ssb11",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 20,
                                            "key": "doc/body/sec0/sub4/ssb11/tit",
                                            "block type": "title",
                                            "content": "Related work",
                                            "leftover": "Related work",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 21,
                                            "key": "doc/body/sec0/sub4/ssb11/txl0",
                                            "block type": "txl",
                                            "content": "Dunjko et al.\\ have previously considered partial Groverizations of Sch\"oning's algorithm. They aimed to minimize a different metric: total number of clean qubits, rather than coherence time. In fact, they work in a highly constrained regime, where the number of available clean qubits only scales as cn, with 0< c <1 and n the number of variables of the given 3SAT formula. Surprisingly, they show that even this meager allotment of qubits in principle yields a speedup compared to the classical Sch\"oning's algorithm According to, Supplemental Material Section~B.4, the relative speedup to the classical Sch\"oning's rate is f(c)= (1log√(3))β(c), where the Beta function up to O(log n n) is implicitly given as Aβ(c)ln1β(c)+Bβ(c) = c. As mentioned in using a straightforward encoding of each trit into two qubits, one can assume A= 10 and B=50. To be consistent with our encoding, we consider log23 qubits to encode a trit and then, calculate the maximum speedup in the rate, i.e. f(1)≈ 0.0028..",
                                            "leftover": "Dunjko et al.\\ have previously considered partial Groverizations of Sch\"oning's algorithm. They aimed to minimize a different metric: total number of clean qubits, rather than coherence time. In fact, they work in a highly constrained regime, where the number of available clean qubits only scales as cn, with 0< c <1 and n the number of variables of the given 3SAT formula. Surprisingly, they show that even this meager allotment of qubits in principle yields a speedup compared to the classical Sch\"oning's algorithm According to, Supplemental Material Section~B.4, the relative speedup to the classical Sch\"oning's rate is f(c)= (1log√(3))β(c), where the Beta function up to O(log n n) is implicitly given as Aβ(c)ln1β(c)+Bβ(c) = c. As mentioned in using a straightforward encoding of each trit into two qubits, one can assume A= 10 and B=50. To be consistent with our encoding, we consider log23 qubits to encode a trit and then, calculate the maximum speedup in the rate, i.e. f(1)≈ 0.0028..",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 22,
                                            "key": "doc/body/sec0/sub4/ssb11/txl1",
                                            "block type": "txl",
                                            "content": "Despite the superficial similarities, their and our papers are quite different. We allow for qubitcounts that are quasilinear in n, i.e.\\ O (nlog n), reasoning that for exponentialtime algorithms, coherence time and parallelizability might be more limiting than the number of available qubits. As it will turn out, the setting considered here can interpolate between the classical and the fully Groverized performance, while the runtime rates obtainable in stay close to the classical ones. While uses derandomization techniques, our approach builds more directly on the original Sch\"oning's algorithm. This makes our approach technically less involved, and it also makes the lessons learned more widely applicable, since the basic technique of using Grover search over a subset of all variables, directly generalizes to any NP problem, whereas derandomizations to a larger extent rely on the particular structure of the problem at hand.",
                                            "leftover": "Despite the superficial similarities, their and our papers are quite different. We allow for qubitcounts that are quasilinear in n, i.e.\\ O (nlog n), reasoning that for exponentialtime algorithms, coherence time and parallelizability might be more limiting than the number of available qubits. As it will turn out, the setting considered here can interpolate between the classical and the fully Groverized performance, while the runtime rates obtainable in stay close to the classical ones. While uses derandomization techniques, our approach builds more directly on the original Sch\"oning's algorithm. This makes our approach technically less involved, and it also makes the lessons learned more widely applicable, since the basic technique of using Grover search over a subset of all variables, directly generalizes to any NP problem, whereas derandomizations to a larger extent rely on the particular structure of the problem at hand.",
                                            "matches": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec1",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 23,
                            "key": "doc/body/sec1/tit",
                            "block type": "title",
                            "content": "Setting the stage",
                            "leftover": "Setting the stage",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec1/sub0",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 24,
                                    "key": "doc/body/sec1/sub0/tit",
                                    "block type": "title",
                                    "content": "Sch\"oning's algorithm",
                                    "leftover": "Sch\"oning's algorithm",
                                    "matches": []
                                },
                                {
                                    "leaf id": 25,
                                    "key": "doc/body/sec1/sub0/txl0",
                                    "block type": "txl",
                                    "content": "Here we provide a very brief introduction to the pertinent aspects of Sch\"oning's 3SAT solver. For a more thorough review, we refer the reader to . In the 3SAT problem, we are given a collection of clauses C1,…, CL on n binary variables, where each clause is of the form Cj = l0^(j)∨ l1^(j)∨ l2^(j), and where each of the literals l0^(j), l1^(j), l2^(j) is one of the binary variables or its negation. The 3SAT formula is the conjunction of all the given clauses, C:= ∧j=1^LCj, and the computational task is to determine whether there exists an assignment of the n binary variables that satisfies C. According to Sch\"oning, an algorithm exists that, although with runtime that is exponential in n, can perform better than an exhaustive search through all potential assignments.",
                                    "leftover": "Here we provide a very brief introduction to the pertinent aspects of Sch\"oning's 3SAT solver. For a more thorough review, we refer the reader to . In the 3SAT problem, we are given a collection of clauses C1,…, CL on n binary variables, where each clause is of the form Cj = l0^(j)∨ l1^(j)∨ l2^(j), and where each of the literals l0^(j), l1^(j), l2^(j) is one of the binary variables or its negation. The 3SAT formula is the conjunction of all the given clauses, C:= ∧j=1^LCj, and the computational task is to determine whether there exists an assignment of the n binary variables that satisfies C. According to Sch\"oning, an algorithm exists that, although with runtime that is exponential in n, can perform better than an exhaustive search through all potential assignments.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 26,
                                    "key": "doc/body/sec1/sub0/txl1",
                                    "block type": "txl",
                                    "content": "Sch\"oning's algorithm (Alg.~) depends on two parameters N, m to be determined later. It begins by choosing an assignment x∈0,1^× n uniformly at random. The algorithm then performs an mstep random walk over the space of nbit strings (the inner loop in Alg.~, from Line~). In every step, it checks (according to a predetermined order) all the clauses C1,…, CL. If all are satisfied, then x is a solution and the algorithm terminates. Otherwise, it finds the first unsatisfied clause, chooses one of the three variables corresponding to the literals of that clause uniformly at random. The value of x is then updated, by negating that variable. This concludes the step. If no solution is found after m steps, the walk is terminated. Up to N such walks are attempted (the outer loop in Alg.~), each time using a fresh uniformly random starting point x.",
                                    "leftover": "Sch\"oning's algorithm (Alg.~) depends on two parameters N, m to be determined later. It begins by choosing an assignment x∈0,1^× n uniformly at random. The algorithm then performs an mstep random walk over the space of nbit strings (the inner loop in Alg.~, from Line~). In every step, it checks (according to a predetermined order) all the clauses C1,…, CL. If all are satisfied, then x is a solution and the algorithm terminates. Otherwise, it finds the first unsatisfied clause, chooses one of the three variables corresponding to the literals of that clause uniformly at random. The value of x is then updated, by negating that variable. This concludes the step. If no solution is found after m steps, the walk is terminated. Up to N such walks are attempted (the outer loop in Alg.~), each time using a fresh uniformly random starting point x.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 27,
                                    "key": "doc/body/sec1/sub0/algorithm2",
                                    "block type": "algorithm",
                                    "content": "H] Sch\"oning's Algorithm \\begin{algorithmic}[1] \\Function{Schoening}{C1, …, CL, N, m} \\For{i=1 ... N} \\State x← uniformly random value from 0,1^× n \\For{j=1...m} \\If{x satisfies C1, …, CL} \\State\\Return x \\Else \\State k← index of first unsatisfied clause \\State l← index of one of the three variables occurring in Ck, chosen uniformly at random \\State x← x, with the lth bit of x flipped \\EndIf \\EndFor \\EndFor \\State \\Return False \\EndFunction \\end{algorithmic}",
                                    "leftover": "H] Sch\"oning's Algorithm \\begin{algorithmic}[1] \\Function{Schoening}{C1, …, CL, N, m} \\For{i=1 ... N} \\State x← uniformly random value from 0,1^× n \\For{j=1...m} \\If{x satisfies C1, …, CL} \\State\\Return x \\Else \\State k← index of first unsatisfied clause \\State l← index of one of the three variables occurring in Ck, chosen uniformly at random \\State x← x, with the lth bit of x flipped \\EndIf \\EndFor \\EndFor \\State \\Return False \\EndFunction \\end{algorithmic}",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec1/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 28,
                                    "key": "doc/body/sec1/sub1/tit",
                                    "block type": "title",
                                    "content": "Analysis of the runtime of Sch\"oning's algorithm",
                                    "leftover": "Analysis of the runtime of Sch\"oning's algorithm",
                                    "matches": []
                                },
                                {
                                    "leaf id": 29,
                                    "key": "doc/body/sec1/sub1/txl0",
                                    "block type": "txl",
                                    "content": "The analysis of the runtime of Sch\"oning's algorithm is sketched in and a more indepth analysis can be found in . Here we follow a very similar line of reasoning, with our particular ansatz in mind. In the following, we present an overview, see Appendix~ for a more detailed account.",
                                    "leftover": "The analysis of the runtime of Sch\"oning's algorithm is sketched in and a more indepth analysis can be found in . Here we follow a very similar line of reasoning, with our particular ansatz in mind. In the following, we present an overview, see Appendix~ for a more detailed account.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 30,
                                    "key": "doc/body/sec1/sub1/txl1",
                                    "block type": "txl",
                                    "content": "Assume that there is at least one satisfying assignment x^⋆. We first aim to lowerbound the probability that a given random walk finds a solution. Let x0 be the (random) initial configuration, and xl the one attained after the lth step of the random walk. The probability that any solution is found during any step of the walk is certainly at least as large as the probability P(xm = x^⋆) that the walk finds x^⋆ at the mth step. To analyze P(xm=x^⋆), we follow in the steps of Sch\"oning, and focus on the evolution of the Hammingdistance dH(xl, x^⋆) between the current configuration and the selected satisfying assignment x^⋆.",
                                    "leftover": "Assume that there is at least one satisfying assignment x^⋆. We first aim to lowerbound the probability that a given random walk finds a solution. Let x0 be the (random) initial configuration, and xl the one attained after the lth step of the random walk. The probability that any solution is found during any step of the walk is certainly at least as large as the probability P(xm = x^⋆) that the walk finds x^⋆ at the mth step. To analyze P(xm=x^⋆), we follow in the steps of Sch\"oning, and focus on the evolution of the Hammingdistance dH(xl, x^⋆) between the current configuration and the selected satisfying assignment x^⋆.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 31,
                                    "key": "doc/body/sec1/sub1/txl2",
                                    "block type": "txl",
                                    "content": "The fundamental insight is that if a clause Ck is violated at the lth step, then at least one of the three variables that appear in Ck must differ between xl and the satisfying assignment x^⋆. Thus, the random flip decreases the Hamming distance to the solution with probability at least 1/3:",
                                    "leftover": "The fundamental insight is that if a clause Ck is violated at the lth step, then at least one of the three variables that appear in Ck must differ between xl and the satisfying assignment x^⋆. Thus, the random flip decreases the Hamming distance to the solution with probability at least 1/3:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 32,
                                    "key": "doc/body/sec1/sub1/align3",
                                    "block type": "align",
                                    "content": "P( dH(xl+1, x^⋆) = dH(xl, x^⋆)  1 )≥3.",
                                    "leftover": "P( dH(xl+1, x^⋆) = dH(xl, x^⋆)  1 )≥3.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 33,
                                    "key": "doc/body/sec1/sub1/txl4",
                                    "block type": "txl",
                                    "content": "This suggests to pass from a description of the process on bit strings to its projection xl ↦ dH(xl,x^⋆) onto . However, this would generally yield a process that would be no easier to analyze than the original one. One may for example note that although Sch\"oningprocess (xl)l is Markovian on the space of bitstrings 0,1^× n, one cannot generally expect its projection (dH(xl,x^⋆))l to be Markovian on .",
                                    "leftover": "This suggests to pass from a description of the process on bit strings to its projection xl ↦ dH(xl,x^⋆) onto . However, this would generally yield a process that would be no easier to analyze than the original one. One may for example note that although Sch\"oningprocess (xl)l is Markovian on the space of bitstrings 0,1^× n, one cannot generally expect its projection (dH(xl,x^⋆))l to be Markovian on .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 34,
                                    "key": "doc/body/sec1/sub1/txl5",
                                    "block type": "txl",
                                    "content": "The general idea for the analysis is to replace (via a coupling) the true projection (dH(xl,x^⋆))l with another process (dl)l on, which is Markovian and which moreover upperbounds the true Hammingdistance,",
                                    "leftover": "The general idea for the analysis is to replace (via a coupling) the true projection (dH(xl,x^⋆))l with another process (dl)l on, which is Markovian and which moreover upperbounds the true Hammingdistance,",
                                    "matches": []
                                },
                                {
                                    "leaf id": 35,
                                    "key": "doc/body/sec1/sub1/equation6",
                                    "block type": "equation",
                                    "content": "dH(xl,x^⋆)≤dl.",
                                    "leftover": "dH(xl,x^⋆)≤dl.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 36,
                                    "key": "doc/body/sec1/sub1/txl7",
                                    "block type": "txl",
                                    "content": "More precisely, the Markov process (dl)l is defined by the transition probabilities",
                                    "leftover": "More precisely, the Markov process (dl)l is defined by the transition probabilities",
                                    "matches": []
                                },
                                {
                                    "leaf id": 37,
                                    "key": "doc/body/sec1/sub1/equation8",
                                    "block type": "equation",
                                    "content": "P(dl+1 = dl +1) = 23, P(dl+1 = dl 1) = 13.",
                                    "leftover": "P(dl+1 = dl +1) = 23, P(dl+1 = dl 1) = 13.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 38,
                                    "key": "doc/body/sec1/sub1/txl9",
                                    "block type": "txl",
                                    "content": "The transition probabilities () can be interpreted as worstcase scenarios of each step in the Sch\"oning process.",
                                    "leftover": "The transition probabilities () can be interpreted as worstcase scenarios of each step in the Sch\"oning process.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 39,
                                    "key": "doc/body/sec1/sub1/txl10",
                                    "block type": "txl",
                                    "content": "From the bound () it follows that P(xl = x^⋆) ≥ P(dl ≤ 0). In other words, the success probability of the Sch\"oningprocess is lowerbounded by the probability that the substituteprocess dl reaches 0.",
                                    "leftover": "From the bound () it follows that P(xl = x^⋆) ≥ P(dl ≤ 0). In other words, the success probability of the Sch\"oningprocess is lowerbounded by the probability that the substituteprocess dl reaches 0.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 40,
                                    "key": "doc/body/sec1/sub1/txl11",
                                    "block type": "txl",
                                    "content": "Given the lower bound P(dm ≤ 0) on the probability of success of each given walk, we expect at least one out of N=1/P(dm ≤ 0) walks to find x^⋆. More precisely, if ϵ is the tolerated probability for failure, then the number of repetitions needed in order to find an existing solution satisfies",
                                    "leftover": "Given the lower bound P(dm ≤ 0) on the probability of success of each given walk, we expect at least one out of N=1/P(dm ≤ 0) walks to find x^⋆. More precisely, if ϵ is the tolerated probability for failure, then the number of repetitions needed in order to find an existing solution satisfies",
                                    "matches": []
                                },
                                {
                                    "leaf id": 41,
                                    "key": "doc/body/sec1/sub1/align12",
                                    "block type": "align",
                                    "content": "N≥logϵlog(1P(dm≤0)).",
                                    "leftover": "N≥logϵlog(1P(dm≤0)).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 42,
                                    "key": "doc/body/sec1/sub1/txl13",
                                    "block type": "txl",
                                    "content": "The required number N of repetitions will be exponential in n. It is then common to take a coarser point of view, and only analyze the corresponding rate",
                                    "leftover": "The required number N of repetitions will be exponential in n. It is then common to take a coarser point of view, and only analyze the corresponding rate",
                                    "matches": []
                                },
                                {
                                    "leaf id": 43,
                                    "key": "doc/body/sec1/sub1/align14",
                                    "block type": "align",
                                    "content": "γ:= limn→∞1n logP(dm≤0), that N=O^*(2^γn),",
                                    "leftover": "γ:= limn→∞1n logP(dm≤0), that N=O^*(2^γn),",
                                    "matches": []
                                },
                                {
                                    "leaf id": 44,
                                    "key": "doc/body/sec1/sub1/txl15",
                                    "block type": "txl",
                                    "content": "where O^* denotes scaling behavior up to polynomial factors in order to achieve any constant probability of failure ϵ. With the choice m = n (i.e., the termination time is equal to the number of variables) it turns out that γ≤log43≈ 0.415.",
                                    "leftover": "where O^* denotes scaling behavior up to polynomial factors in order to achieve any constant probability of failure ϵ. With the choice m = n (i.e., the termination time is equal to the number of variables) it turns out that γ≤log43≈ 0.415.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 45,
                                    "key": "doc/body/sec1/sub1/txl16",
                                    "block type": "txl",
                                    "content": "It is surprisingly technically difficult to rigorously derive the ''global bound'' P(xl=x^⋆)≥ P(dl ≤ 0) from the ''local bound'' (). However, the Markovian version (dl)l of the Hamming distance random walk is commonly accepted as a good (in fact, conservative) model of the Sch\"oningprocess. In the main body of this paper, we will therefore phrase our arguments in terms of that model. More technical details on the relation between the two processes are given in Appendix~.",
                                    "leftover": "It is surprisingly technically difficult to rigorously derive the ''global bound'' P(xl=x^⋆)≥ P(dl ≤ 0) from the ''local bound'' (). However, the Markovian version (dl)l of the Hamming distance random walk is commonly accepted as a good (in fact, conservative) model of the Sch\"oningprocess. In the main body of this paper, we will therefore phrase our arguments in terms of that model. More technical details on the relation between the two processes are given in Appendix~.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec1/sub2",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 46,
                                    "key": "doc/body/sec1/sub2/tit",
                                    "block type": "title",
                                    "content": "Partial Groverizations: The general idea",
                                    "leftover": "Partial Groverizations: The general idea",
                                    "matches": []
                                },
                                {
                                    "leaf id": 47,
                                    "key": "doc/body/sec1/sub2/txl0",
                                    "block type": "txl",
                                    "content": "For random walks we naturally tend to think of the randomness as being generated whenever needed, like when we assign the initial state, or make the random choices along the path. However, we can alternatively picture the walk as a deterministic process that is fed with an external random string S; a list from which it picks the next entry whenever a random choice is to be made. When the purpose of the walk is to find (an efficiently recognizable) solution to some computational problem, one can thus view the walk as a (deterministic) map that designates each input string S as being ''successful'' or ''unsuccessful'', in the sense of the walk reaching the satisfying solution x^⋆ or not. To this mapping, we can in principle apply a Groversearch procedure, since the walk (as well as the solutionrecognition procedure) can be performed via reversible circuitry, and can thus also be implemented coherently.",
                                    "leftover": "For random walks we naturally tend to think of the randomness as being generated whenever needed, like when we assign the initial state, or make the random choices along the path. However, we can alternatively picture the walk as a deterministic process that is fed with an external random string S; a list from which it picks the next entry whenever a random choice is to be made. When the purpose of the walk is to find (an efficiently recognizable) solution to some computational problem, one can thus view the walk as a (deterministic) map that designates each input string S as being ''successful'' or ''unsuccessful'', in the sense of the walk reaching the satisfying solution x^⋆ or not. To this mapping, we can in principle apply a Groversearch procedure, since the walk (as well as the solutionrecognition procedure) can be performed via reversible circuitry, and can thus also be implemented coherently.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 48,
                                    "key": "doc/body/sec1/sub2/txl1",
                                    "block type": "txl",
                                    "content": "As described in the previous section, Sch\"oning's algorithm proceeds with an initialization, followed by a random walk on the space of 2^n assignments. The initialization requires n bits of randomness, SI, since the initial state is selected uniformly over all 2^n strings. A walk of length m requires a string SW of mlog3 bits to encode the needed randomness. The log3factor is due to the fact that, at each step, the algorithm randomly selects which one of the three literals (of the first violated clause) should be flipped. An mstep Sch\"oningwalk can thus be viewed as a map from S = (SI,SW) to a binary variable that tells us whether a satisfying assignment has been reached or not.",
                                    "leftover": "As described in the previous section, Sch\"oning's algorithm proceeds with an initialization, followed by a random walk on the space of 2^n assignments. The initialization requires n bits of randomness, SI, since the initial state is selected uniformly over all 2^n strings. A walk of length m requires a string SW of mlog3 bits to encode the needed randomness. The log3factor is due to the fact that, at each step, the algorithm randomly selects which one of the three literals (of the first violated clause) should be flipped. An mstep Sch\"oningwalk can thus be viewed as a map from S = (SI,SW) to a binary variable that tells us whether a satisfying assignment has been reached or not.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 49,
                                    "key": "doc/body/sec1/sub2/txl2",
                                    "block type": "txl",
                                    "content": "With a coherent circuit that implements this map, we can thus replace the uniformly distributed random variable S, with a uniform superposition over a corresponding number of qubits, and proceed via standard Groveriterations . We would expect such a procedure to yield a satisfying assignment at a runtime that scales as O^*(2^nγG) iterations, with γG = 12log43≈ 0.208, i.e., the standard quadratic speedup. Up to a few constant qubits, one needs n + (log3 + log L)m qubits to encode this map as a quantum circuit, where L is the number of clauses in the 3SAT formula (more details are given in Section ). Since the number of clauses grows linearly in n for the regime of interest by the SAT phasetransition conjecture, and for the Sch\"oning walk m = n, the space complexity of such encoding is O(nlog n).",
                                    "leftover": "With a coherent circuit that implements this map, we can thus replace the uniformly distributed random variable S, with a uniform superposition over a corresponding number of qubits, and proceed via standard Groveriterations . We would expect such a procedure to yield a satisfying assignment at a runtime that scales as O^*(2^nγG) iterations, with γG = 12log43≈ 0.208, i.e., the standard quadratic speedup. Up to a few constant qubits, one needs n + (log3 + log L)m qubits to encode this map as a quantum circuit, where L is the number of clauses in the 3SAT formula (more details are given in Section ). Since the number of clauses grows linearly in n for the regime of interest by the SAT phasetransition conjecture, and for the Sch\"oning walk m = n, the space complexity of such encoding is O(nlog n).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 50,
                                    "key": "doc/body/sec1/sub2/txl3",
                                    "block type": "txl",
                                    "content": "The view of random walks as maps on random input strings opens up for the concept of partial Groverizations. Nothing would in principle prevent us from regarding only a part of the input string S as the input of the Groverprocedure, while keeping the rest of the string classical. Needless to say, one would generally expect the result to be less efficient than the ''full'' Groverization. However, the gain would be that the partial Groverization breaks the tasks into a collection of subproblems, each of which can be run in parallel on a quantum device that requires shorter coherence time.",
                                    "leftover": "The view of random walks as maps on random input strings opens up for the concept of partial Groverizations. Nothing would in principle prevent us from regarding only a part of the input string S as the input of the Groverprocedure, while keeping the rest of the string classical. Needless to say, one would generally expect the result to be less efficient than the ''full'' Groverization. However, the gain would be that the partial Groverization breaks the tasks into a collection of subproblems, each of which can be run in parallel on a quantum device that requires shorter coherence time.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 51,
                                    "key": "doc/body/sec1/sub2/txl4",
                                    "block type": "txl",
                                    "content": "Although it seems reasonable to expect that such a division in principle is always possible, one may also expect that it in general would be challenging to find a quantum circuit that implements it in an economical manner. (We can always resort to a full coherent circuit for S in its entirety, putting the ''classical part'' in a diagonal state.) However, there may be ''natural'' divisions of the process, which can be exploited. For Sch\"oning's algorithm it is close to hand to consider the division S = (SI, SW), i.e., the division of the required randomness into the initializationpart and the walkpart. One can thus consider two particularly natural classes of ''partial'' Groverizations of Sch\"oning's algorithm. For one of these, the Groverized Initialization (GI), the choice of the initial state is implemented coherently, while the walk is kept ''classical''. For the Groverized Walk (GW), the choice of initial state is kept classical, while the walk itself is performed coherently.",
                                    "leftover": "Although it seems reasonable to expect that such a division in principle is always possible, one may also expect that it in general would be challenging to find a quantum circuit that implements it in an economical manner. (We can always resort to a full coherent circuit for S in its entirety, putting the ''classical part'' in a diagonal state.) However, there may be ''natural'' divisions of the process, which can be exploited. For Sch\"oning's algorithm it is close to hand to consider the division S = (SI, SW), i.e., the division of the required randomness into the initializationpart and the walkpart. One can thus consider two particularly natural classes of ''partial'' Groverizations of Sch\"oning's algorithm. For one of these, the Groverized Initialization (GI), the choice of the initial state is implemented coherently, while the walk is kept ''classical''. For the Groverized Walk (GW), the choice of initial state is kept classical, while the walk itself is performed coherently.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 52,
                                    "key": "doc/body/sec1/sub2/txl5",
                                    "block type": "txl",
                                    "content": "As described in Section, the actual analysis is based on the random walk (dl)l on, rather than the true Sch\"oning walk on strings in 0,1^× n. The idea is nevertheless the same; the required randomness is divided into the initialization and the walk per se, resulting in GI and GWprocesses. As described in Section, the rate of the true Sch\"oningprocess can be bounded by the rate of the substitute process (dl)l. It turns out that a similar argument can be made for GW (see Appendix ), thus yielding a rigorous bound for the rate also in this case. However, for the other processes we rather regard the (dl)l process as a model of the genuine Sch\"oningwalk, without rigorous guarantees of analogous bounds.",
                                    "leftover": "As described in Section, the actual analysis is based on the random walk (dl)l on, rather than the true Sch\"oning walk on strings in 0,1^× n. The idea is nevertheless the same; the required randomness is divided into the initialization and the walk per se, resulting in GI and GWprocesses. As described in Section, the rate of the true Sch\"oningprocess can be bounded by the rate of the substitute process (dl)l. It turns out that a similar argument can be made for GW (see Appendix ), thus yielding a rigorous bound for the rate also in this case. However, for the other processes we rather regard the (dl)l process as a model of the genuine Sch\"oningwalk, without rigorous guarantees of analogous bounds.",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec2",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 53,
                            "key": "doc/body/sec2/tit",
                            "block type": "title",
                            "content": "Partial Groverizations",
                            "leftover": "Partial Groverizations",
                            "matches": []
                        },
                        {
                            "leaf id": 54,
                            "key": "doc/body/sec2/txl0",
                            "block type": "txl",
                            "content": "The previous section introduced two types of partial Groverizations of Sch\"oning's algorithm, GI and GW, based on the division S = (SI, SW), i.e. the initial and the walk randomness. In this section, we describe these schemes in detail and further discuss their ''tional'' cases.",
                            "leftover": "The previous section introduced two types of partial Groverizations of Sch\"oning's algorithm, GI and GW, based on the division S = (SI, SW), i.e. the initial and the walk randomness. In this section, we describe these schemes in detail and further discuss their ''tional'' cases.",
                            "matches": []
                        },
                        {
                            "leaf id": 55,
                            "key": "doc/body/sec2/txl1",
                            "block type": "txl",
                            "content": "In the GI scheme, there is an outer loop that classically samples SW, and is followed by a Groversearch inner loop over the space of all possible SI. Similarly, GW starts with a classical outer loop that samples SI and is followed by a Groversearch inner loop over the space of all possible SW (this space is welldefined as the walk length is fixed). We obtain Fractional Groverized Initialization (FGI) by adapting GI to a regime where only a tion z of the variables in the initialization can be searched coherently, with 0≤ z ≤1. Fractional Groverized Walk (FGW) is similarly an adaption of GW to a regime where Groversearch can be performed on the randomness of walks of at most mq steps, with 0 ≤ mq. In both these tional schemes, two classical outer loops contain a Groversearch inner loop. The algorithms introduced here depend on parameters (N1, N2, etc), that will be specified explicitly in Section .",
                            "leftover": "In the GI scheme, there is an outer loop that classically samples SW, and is followed by a Groversearch inner loop over the space of all possible SI. Similarly, GW starts with a classical outer loop that samples SI and is followed by a Groversearch inner loop over the space of all possible SW (this space is welldefined as the walk length is fixed). We obtain Fractional Groverized Initialization (FGI) by adapting GI to a regime where only a tion z of the variables in the initialization can be searched coherently, with 0≤ z ≤1. Fractional Groverized Walk (FGW) is similarly an adaption of GW to a regime where Groversearch can be performed on the randomness of walks of at most mq steps, with 0 ≤ mq. In both these tional schemes, two classical outer loops contain a Groversearch inner loop. The algorithms introduced here depend on parameters (N1, N2, etc), that will be specified explicitly in Section .",
                            "matches": []
                        },
                        {
                            "leaf id": 56,
                            "key": "doc/body/sec2/txl2",
                            "block type": "txl",
                            "content": "All Grover searches will use an oracle derived from the function shown in Alg.~: It tests whether a Sch\"oningwalk with initial configuration x∈0,1^n and walk randomness w∈1,2,3^m will lead to a satisfying assignment. For notational convenience, we let the elements of w take ternary in values, with the interpretation that wl determines which of the three literals occurring in the first violated clause (if any) in step l of the walk is flipped. For a qubitbased implementation, it is not difficult to relabel the decision variables using ⌈ m log 3⌉ binary variables.",
                            "leftover": "All Grover searches will use an oracle derived from the function shown in Alg.~: It tests whether a Sch\"oningwalk with initial configuration x∈0,1^n and walk randomness w∈1,2,3^m will lead to a satisfying assignment. For notational convenience, we let the elements of w take ternary in values, with the interpretation that wl determines which of the three literals occurring in the first violated clause (if any) in step l of the walk is flipped. For a qubitbased implementation, it is not difficult to relabel the decision variables using ⌈ m log 3⌉ binary variables.",
                            "matches": []
                        },
                        {
                            "leaf id": 57,
                            "key": "doc/body/sec2/algorithm3",
                            "block type": "algorithm",
                            "content": "H] Sch\"oning Walk & Oracle \\begin{algorithmic}[1] \\Function{Oracle}{x0,w} \\State \\Return \\textsc{True} if SchoeningWalk(x0,w) satisfies all clauses, else \\textsc{False} \\EndFunction \\State \\Function{SchoeningWalk}{x,w} \\For{j=1...m} \\If{x violates one of C1, …, CL} \\State k← index of first unsatisfied clause \\State l← index of the wjth variable occurring in Ck \\State x← x, with the lth bit of x flipped \\EndIf \\EndFor \\State \\Return x \\EndFunction \\end{algorithmic}",
                            "leftover": "H] Sch\"oning Walk & Oracle \\begin{algorithmic}[1] \\Function{Oracle}{x0,w} \\State \\Return \\textsc{True} if SchoeningWalk(x0,w) satisfies all clauses, else \\textsc{False} \\EndFunction \\State \\Function{SchoeningWalk}{x,w} \\For{j=1...m} \\If{x violates one of C1, …, CL} \\State k← index of first unsatisfied clause \\State l← index of the wjth variable occurring in Ck \\State x← x, with the lth bit of x flipped \\EndIf \\EndFor \\State \\Return x \\EndFunction \\end{algorithmic}",
                            "matches": []
                        },
                        {
                            "leaf id": 58,
                            "key": "doc/body/sec2/txl4",
                            "block type": "txl",
                            "content": "For the different variants of partial Groverizations discussed below, we will fix a subset of arguments to the oracle, and consider it as a function of the remaining ones. Fixed arguments will be denoted as subscripts, e.g.\\ Oraclew: x↦Oracle(x,w). With these conventions, we have:",
                            "leftover": "For the different variants of partial Groverizations discussed below, we will fix a subset of arguments to the oracle, and consider it as a function of the remaining ones. Fixed arguments will be denoted as subscripts, e.g.\\ Oraclew: x↦Oracle(x,w). With these conventions, we have:",
                            "matches": []
                        },
                        {
                            "leaf id": 59,
                            "key": "doc/body/sec2/algorithm5",
                            "block type": "algorithm",
                            "content": "H] Groverized Initialization \\begin{algorithmic}[1] \\For{i=1 ... N2} \\State w← uniformly random value from 1, 2, 3^× m \\State x← Groversearch for ⌊√(N1)⌋ iterations using \\textsc{Oraclew}() \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\end{algorithmic}",
                            "leftover": "H] Groverized Initialization \\begin{algorithmic}[1] \\For{i=1 ... N2} \\State w← uniformly random value from 1, 2, 3^× m \\State x← Groversearch for ⌊√(N1)⌋ iterations using \\textsc{Oraclew}() \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\end{algorithmic}",
                            "matches": []
                        },
                        {
                            "leaf id": 60,
                            "key": "doc/body/sec2/algorithm6",
                            "block type": "algorithm",
                            "content": "H] Groverized Walk \\begin{algorithmic}[1] \\For{i=1 ... N1} \\State x0← uniformly random value from 0,1^× n \\State w← Groversearch for ⌊√(N2)⌋ iterations using \\textsc{Oraclex0}() \\State x←SchoeningWalk(x0,w) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\State \\Return False \\end{algorithmic}",
                            "leftover": "H] Groverized Walk \\begin{algorithmic}[1] \\For{i=1 ... N1} \\State x0← uniformly random value from 0,1^× n \\State w← Groversearch for ⌊√(N2)⌋ iterations using \\textsc{Oraclex0}() \\State x←SchoeningWalk(x0,w) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\State \\Return False \\end{algorithmic}",
                            "matches": []
                        },
                        {
                            "leaf id": 61,
                            "key": "doc/body/sec2/txl7",
                            "block type": "txl",
                            "content": "One may note that the Grover search in the Groverized walk only is guaranteed to succeed (with high probability) for a specific collection of initial states. The number of rounds N1 of the outer loop is selected in such a way that it with high probability hits the set of advantageous initial states at least once, thus allowing the Groverprocedure to reach the satisfying assignment. Similar remarks apply to the other partial Groverizations.",
                            "leftover": "One may note that the Grover search in the Groverized walk only is guaranteed to succeed (with high probability) for a specific collection of initial states. The number of rounds N1 of the outer loop is selected in such a way that it with high probability hits the set of advantageous initial states at least once, thus allowing the Groverprocedure to reach the satisfying assignment. Similar remarks apply to the other partial Groverizations.",
                            "matches": []
                        },
                        {
                            "leaf id": 62,
                            "key": "doc/body/sec2/txl8",
                            "block type": "txl",
                            "content": "Next, we discuss the ''tional searches''. In the first one, the argument x of the oracle is broken up as x=(xc, xq) with xq taking ⌊ z· n ⌋ bits and xc being ⌈ (1z)· n ⌉ bits long. Here, z∈[0,1] is a free parameter whose value will be determined below.",
                            "leftover": "Next, we discuss the ''tional searches''. In the first one, the argument x of the oracle is broken up as x=(xc, xq) with xq taking ⌊ z· n ⌋ bits and xc being ⌈ (1z)· n ⌉ bits long. Here, z∈[0,1] is a free parameter whose value will be determined below.",
                            "matches": []
                        },
                        {
                            "leaf id": 63,
                            "key": "doc/body/sec2/algorithm9",
                            "block type": "algorithm",
                            "content": "H] Fractional Groverized Initialization \\begin{algorithmic}[1] \\For{i=1 ... N2} \\State w← uniformly random value from 1, 2, 3^× m \\For{j=1 ... N1^(c)} \\State xc← uniformly random value from 0,1^×⌈(1z)n⌉ \\State xq← Groversearch for ⌊√(N1^(q))⌋ iterations using \\textsc{Oracle(xc, w)}() \\State x=(xc,xq) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\EndFor \\State \\Return False \\end{algorithmic}",
                            "leftover": "H] Fractional Groverized Initialization \\begin{algorithmic}[1] \\For{i=1 ... N2} \\State w← uniformly random value from 1, 2, 3^× m \\For{j=1 ... N1^(c)} \\State xc← uniformly random value from 0,1^×⌈(1z)n⌉ \\State xq← Groversearch for ⌊√(N1^(q))⌋ iterations using \\textsc{Oracle(xc, w)}() \\State x=(xc,xq) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\EndFor \\State \\Return False \\end{algorithmic}",
                            "matches": []
                        },
                        {
                            "leaf id": 64,
                            "key": "doc/body/sec2/txl10",
                            "block type": "txl",
                            "content": "The second tional algorithm breaks up the walk randomness as w=(wc, wq) with wc∈1,2,3^mc and wq∈1,2,3^mq respectively. Again, the values of mc, mq are chosen later.",
                            "leftover": "The second tional algorithm breaks up the walk randomness as w=(wc, wq) with wc∈1,2,3^mc and wq∈1,2,3^mq respectively. Again, the values of mc, mq are chosen later.",
                            "matches": []
                        },
                        {
                            "leaf id": 65,
                            "key": "doc/body/sec2/algorithm11",
                            "block type": "algorithm",
                            "content": "H] Fractional Groverized Walk \\begin{algorithmic}[1] \\For{i=1 ... N1} \\State x0← uniformly random value from 0,1^× n \\For{j=1 ... N2^(c)} \\State wc← uniformly random value from 1, 2, 3^× mc \\State wq← Groversearch for ⌊√(N2^(q))⌋ iterations using \\textsc{Oracle(x0,wc)}() \\State w=(wc,wq) \\State x←SchoeningWalk(x0,w) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\EndFor \\State \\Return False \\end{algorithmic}",
                            "leftover": "H] Fractional Groverized Walk \\begin{algorithmic}[1] \\For{i=1 ... N1} \\State x0← uniformly random value from 0,1^× n \\For{j=1 ... N2^(c)} \\State wc← uniformly random value from 1, 2, 3^× mc \\State wq← Groversearch for ⌊√(N2^(q))⌋ iterations using \\textsc{Oracle(x0,wc)}() \\State w=(wc,wq) \\State x←SchoeningWalk(x0,w) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\EndFor \\State \\Return False \\end{algorithmic}",
                            "matches": []
                        },
                        {
                            "leaf id": 66,
                            "key": "doc/body/sec2/txl12",
                            "block type": "txl",
                            "content": "In the final algorithm, a tion of z∈[0,1] of both types of variables, the ones corresponding to the initialization and the ones corresponding to the walk, will be treated quantum mechanically.",
                            "leftover": "In the final algorithm, a tion of z∈[0,1] of both types of variables, the ones corresponding to the initialization and the ones corresponding to the walk, will be treated quantum mechanically.",
                            "matches": []
                        },
                        {
                            "leaf id": 67,
                            "key": "doc/body/sec2/algorithm13",
                            "block type": "algorithm",
                            "content": "H] Evenly Fractionalized Grover \\begin{algorithmic}[1] \\For{i=1 ... N^(c)} \\State xc← uniformly random value from 0,1^×⌈ (1z) n⌉ \\State wc← uniformly random value from 1, 2, 3^×⌈(1z)m⌉ \\State (xq,wq)← Groversearch for ⌊√(N^(q))⌋ iterations using \\textsc{Oracle(xc,wc)}() \\State w=(wc,wq) \\State x0=(xc,xq) \\State x←SchoeningWalk(x0,w) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\State \\Return False \\end{algorithmic}",
                            "leftover": "H] Evenly Fractionalized Grover \\begin{algorithmic}[1] \\For{i=1 ... N^(c)} \\State xc← uniformly random value from 0,1^×⌈ (1z) n⌉ \\State wc← uniformly random value from 1, 2, 3^×⌈(1z)m⌉ \\State (xq,wq)← Groversearch for ⌊√(N^(q))⌋ iterations using \\textsc{Oracle(xc,wc)}() \\State w=(wc,wq) \\State x0=(xc,xq) \\State x←SchoeningWalk(x0,w) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\State \\Return False \\end{algorithmic}",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec3",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 68,
                            "key": "doc/body/sec3/tit",
                            "block type": "title",
                            "content": "Runtime Analysis",
                            "leftover": "Runtime Analysis",
                            "matches": []
                        },
                        {
                            "leaf id": 69,
                            "key": "doc/body/sec3/txl0",
                            "block type": "txl",
                            "content": "We will now lowerbound the probability of success of the various approaches. As a preparation, in Sec.~, we give a brief account of the analysis of the classical case, before moving on to the Groverized versions in Sec.~.",
                            "leftover": "We will now lowerbound the probability of success of the various approaches. As a preparation, in Sec.~, we give a brief account of the analysis of the classical case, before moving on to the Groverized versions in Sec.~.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec3/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 70,
                                    "key": "doc/body/sec3/sub1/tit",
                                    "block type": "title",
                                    "content": "The classical Sch\"oning process",
                                    "leftover": "The classical Sch\"oning process",
                                    "matches": []
                                },
                                {
                                    "leaf id": 71,
                                    "key": "doc/body/sec3/sub1/txl0",
                                    "block type": "txl",
                                    "content": "The main ideas of the classical analysis are close to their presentation in Refs.. We work in the Markovian model (dl)l for the behavior of the Hamming distances, as laid out in Sec.~. Frequently, it will be convenient to measure quantities ''in units of n or m''. For example, we will soon choose a number κ∈[0,1] and assume that the initial value d0 is equal to κ n. Of course, this only makes sense if κ n is an integer. In order to keep the notation clean, we will implicitly assume that such expressions have been rounded to the next integer.",
                                    "leftover": "The main ideas of the classical analysis are close to their presentation in Refs.. We work in the Markovian model (dl)l for the behavior of the Hamming distances, as laid out in Sec.~. Frequently, it will be convenient to measure quantities ''in units of n or m''. For example, we will soon choose a number κ∈[0,1] and assume that the initial value d0 is equal to κ n. Of course, this only makes sense if κ n is an integer. In order to keep the notation clean, we will implicitly assume that such expressions have been rounded to the next integer.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 72,
                                    "key": "doc/body/sec3/sub1/txl1",
                                    "block type": "txl",
                                    "content": "Choose numbers κ, ν∈[0,1]. A given walk (dl)l is certainly successful (in the sense that dm≤ 0) if",
                                    "leftover": "Choose numbers κ, ν∈[0,1]. A given walk (dl)l is certainly successful (in the sense that dm≤ 0) if",
                                    "matches": []
                                },
                                {
                                    "leaf id": 73,
                                    "key": "doc/body/sec3/sub1/enumerate2",
                                    "block type": "enumerate",
                                    "content": "The initial value is d0=κ n, the random walk decreases the Hamming distance in exactly ν m of its m steps, and the condition \\begin{align} \\kappa n \\leq (2\\nu 1)m \\end{align} holds.",
                                    "leftover": "The initial value is d0=κ n, the random walk decreases the Hamming distance in exactly ν m of its m steps, and the condition \\begin{align} \\kappa n \\leq (2\\nu 1)m \\end{align} holds.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 74,
                                    "key": "doc/body/sec3/sub1/txl3",
                                    "block type": "txl",
                                    "content": "Indeed, the right hand side of () is the difference between the number of steps where the Hamming distance has been decreased, ν m, and the number of steps where the Hamming distance has been increased, (1ν )m.",
                                    "leftover": "Indeed, the right hand side of () is the difference between the number of steps where the Hamming distance has been decreased, ν m, and the number of steps where the Hamming distance has been increased, (1ν )m.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 75,
                                    "key": "doc/body/sec3/sub1/txl4",
                                    "block type": "txl",
                                    "content": "For any fixed pair of values κ,ν subject to (), we will now compute the probability of this particular route to success. Denote the first event by E1 and the second event by E2. They occur with respective probabilities",
                                    "leftover": "For any fixed pair of values κ,ν subject to (), we will now compute the probability of this particular route to success. Denote the first event by E1 and the second event by E2. They occur with respective probabilities",
                                    "matches": []
                                },
                                {
                                    "leaf id": 76,
                                    "key": "doc/body/sec3/sub1/align5",
                                    "block type": "align",
                                    "content": "P(E1) = 12^nnκn, P(E2) = mνm(3)^νm(3)^(1ν)m.",
                                    "leftover": "P(E1) = 12^nnκn, P(E2) = mνm(3)^νm(3)^(1ν)m.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 77,
                                    "key": "doc/body/sec3/sub1/txl6",
                                    "block type": "txl",
                                    "content": "Since the two events are independent, the success probability of the walk is lowerbounded by",
                                    "leftover": "Since the two events are independent, the success probability of the walk is lowerbounded by",
                                    "matches": []
                                },
                                {
                                    "leaf id": 78,
                                    "key": "doc/body/sec3/sub1/align7",
                                    "block type": "align",
                                    "content": "P(xm=x^⋆|κ)≥P(dm≤0|x) ≥P(E1E2) = P(E1)P(E2) = 12^nnκn mνm(3)^νm(3)^(1ν)m.",
                                    "leftover": "P(xm=x^⋆|κ)≥P(dm≤0|x) ≥P(E1E2) = P(E1)P(E2) = 12^nnκn mνm(3)^νm(3)^(1ν)m.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 79,
                                    "key": "doc/body/sec3/sub1/txl8",
                                    "block type": "txl",
                                    "content": "The various binomial coefficients can be conveniently related to entropies. To this end, recall the definition of the binary entropy function",
                                    "leftover": "The various binomial coefficients can be conveniently related to entropies. To this end, recall the definition of the binary entropy function",
                                    "matches": []
                                },
                                {
                                    "leaf id": 80,
                                    "key": "doc/body/sec3/sub1/equation*9",
                                    "block type": "equation*",
                                    "content": "H(p) = plogp  (1p) log(1p) for p ∈[0,1],",
                                    "leftover": "H(p) = plogp  (1p) log(1p) for p ∈[0,1],",
                                    "matches": []
                                },
                                {
                                    "leaf id": 81,
                                    "key": "doc/body/sec3/sub1/txl10",
                                    "block type": "txl",
                                    "content": "and the relative entropy",
                                    "leftover": "and the relative entropy",
                                    "matches": []
                                },
                                {
                                    "leaf id": 82,
                                    "key": "doc/body/sec3/sub1/equation*11",
                                    "block type": "equation*",
                                    "content": "D(p∥q) =  plogq  (1p)log(1q)  H(p) for p,q ∈[0,1].",
                                    "leftover": "D(p∥q) =  plogq  (1p)log(1q)  H(p) for p,q ∈[0,1].",
                                    "matches": []
                                },
                                {
                                    "leaf id": 83,
                                    "key": "doc/body/sec3/sub1/txl12",
                                    "block type": "txl",
                                    "content": "Then using the wellknown estimate \\cite[Chapter 11.1]{cover}",
                                    "leftover": "Then using the wellknown estimate \\cite[Chapter 11.1]{cover}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 84,
                                    "key": "doc/body/sec3/sub1/equation*13",
                                    "block type": "equation*",
                                    "content": "1n+12^nH(κ) ≤nκn ≤2^nH(κ),",
                                    "leftover": "1n+12^nH(κ) ≤nκn ≤2^nH(κ),",
                                    "matches": []
                                },
                                {
                                    "leaf id": 85,
                                    "key": "doc/body/sec3/sub1/txl14",
                                    "block type": "txl",
                                    "content": "Equation () can, after some straightforward calculations, be concisely rewritten as",
                                    "leftover": "Equation () can, after some straightforward calculations, be concisely rewritten as",
                                    "matches": []
                                },
                                {
                                    "leaf id": 86,
                                    "key": "doc/body/sec3/sub1/align15",
                                    "block type": "align",
                                    "content": "P(dm≤0|x) ≳2^(1H(κ))n2^D(ν∥3)m,",
                                    "leftover": "P(dm≤0|x) ≳2^(1H(κ))n2^D(ν∥3)m,",
                                    "matches": []
                                },
                                {
                                    "leaf id": 87,
                                    "key": "doc/body/sec3/sub1/txl16",
                                    "block type": "txl",
                                    "content": "where ≳ denotes an inequality holds asymptotically, up to a polynomial factor. Equation~() directly gives an upper bound on the rate γ defined in (). Since the rate expresses the logarithm of the complexity ''in units of n'', it makes sense to also express the length of the walk in terms of μ := m/n. Then:",
                                    "leftover": "where ≳ denotes an inequality holds asymptotically, up to a polynomial factor. Equation~() directly gives an upper bound on the rate γ defined in (). Since the rate expresses the logarithm of the complexity ''in units of n'', it makes sense to also express the length of the walk in terms of μ := m/n. Then:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 88,
                                    "key": "doc/body/sec3/sub1/align17",
                                    "block type": "align",
                                    "content": "γ=  limn →∞n logP(dm≤0|x) ≤1 H(κ) + μD(ν∥1/3) =: γ(μ,κ,ν).",
                                    "leftover": "γ=  limn →∞n logP(dm≤0|x) ≤1 H(κ) + μD(ν∥1/3) =: γ(μ,κ,ν).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 89,
                                    "key": "doc/body/sec3/sub1/txl18",
                                    "block type": "txl",
                                    "content": "In particular, the infimum of γ(μ,κ,ν) subject to the constraints () and 0 ≤μ, 0≤ν,κ≤ 1 is a valid bound for γ. We will perform such optimizations explicitly for the partially Groverized versions in Sec.~. For the classical procedure, we just state the final result:",
                                    "leftover": "In particular, the infimum of γ(μ,κ,ν) subject to the constraints () and 0 ≤μ, 0≤ν,κ≤ 1 is a valid bound for γ. We will perform such optimizations explicitly for the partially Groverized versions in Sec.~. For the classical procedure, we just state the final result:",
                                    "matches": []
                                },
                                {
                                    "leaf id": 90,
                                    "key": "doc/body/sec3/sub1/align19",
                                    "block type": "align",
                                    "content": "μ= 1, κ=3, ν=3, γC = log3≃0.4150.",
                                    "leftover": "μ= 1, κ=3, ν=3, γC = log3≃0.4150.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 91,
                                    "key": "doc/body/sec3/sub1/txl20",
                                    "block type": "txl",
                                    "content": "Remark: One might be tempted to search a tighter bound by summing the contributions to the probability of success that arise from all consistent values for μ,κ,ν, instead of just considering the extremal value. However, the rate of a sum of exponentially processes is asymptotically determined by the rate of the dominating summand alone, i.e.\\ for all collections of γi>0, it holds that",
                                    "leftover": "Remark: One might be tempted to search a tighter bound by summing the contributions to the probability of success that arise from all consistent values for μ,κ,ν, instead of just considering the extremal value. However, the rate of a sum of exponentially processes is asymptotically determined by the rate of the dominating summand alone, i.e.\\ for all collections of γi>0, it holds that",
                                    "matches": []
                                },
                                {
                                    "leaf id": 92,
                                    "key": "doc/body/sec3/sub1/align*21",
                                    "block type": "align*",
                                    "content": "limn→∞n log∑i 2^γi n = supi γi",
                                    "leftover": "limn→∞n log∑i 2^γi n = supi γi",
                                    "matches": []
                                },
                                {
                                    "leaf id": 93,
                                    "key": "doc/body/sec3/sub1/txl22",
                                    "block type": "txl",
                                    "content": "(assuming convergence). Therefore, considering only the dominating term does not affect the overall asymptotic rate.",
                                    "leftover": "(assuming convergence). Therefore, considering only the dominating term does not affect the overall asymptotic rate.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub2",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 94,
                                    "key": "doc/body/sec3/sub2/tit",
                                    "block type": "title",
                                    "content": "Partially Groverized processes",
                                    "leftover": "Partially Groverized processes",
                                    "matches": []
                                },
                                {
                                    "leaf id": 95,
                                    "key": "doc/body/sec3/sub2/txl0",
                                    "block type": "txl",
                                    "content": "In this section, we derive the main results of this paper: Bounds on the asymptotic rates for partially Groverized versions of Sch\"oning's scheme.",
                                    "leftover": "In this section, we derive the main results of this paper: Bounds on the asymptotic rates for partially Groverized versions of Sch\"oning's scheme.",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec3/sub2/ssb1",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 96,
                                            "key": "doc/body/sec3/sub2/ssb1/tit",
                                            "block type": "title",
                                            "content": "Groverized Initialization, Algorithm~",
                                            "leftover": "Groverized Initialization, Algorithm~",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 97,
                                            "key": "doc/body/sec3/sub2/ssb1/txl0",
                                            "block type": "txl",
                                            "content": "For the parameters N1, N2, we choose constant multiples of 1/P(E1), 1/P(E2) respectively. The value of the constant depends on the acceptable probability ϵ of failure, as exhibited in Eq.~(). Since this constant does not effect the rate, we will not specify it here. The probabilities do depend essentially on the parameters μ,κ,ν, though. We will therefore write N1(κ) and N2(μ,ν). Because the asymptotic complexity of a Grover search is the square root of the classical complexity, the rate function of GI is then given by",
                                            "leftover": "For the parameters N1, N2, we choose constant multiples of 1/P(E1), 1/P(E2) respectively. The value of the constant depends on the acceptable probability ϵ of failure, as exhibited in Eq.~(). Since this constant does not effect the rate, we will not specify it here. The probabilities do depend essentially on the parameters μ,κ,ν, though. We will therefore write N1(κ) and N2(μ,ν). Because the asymptotic complexity of a Grover search is the square root of the classical complexity, the rate function of GI is then given by",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 98,
                                            "key": "doc/body/sec3/sub2/ssb1/align1",
                                            "block type": "align",
                                            "content": "γ(μ,κ,ν) = limn →∞n log(√(N1(κ))N2(ν,μ)) = 1  H(κ)2 + μD(ν∥1/3).",
                                            "leftover": "γ(μ,κ,ν) = limn →∞n log(√(N1(κ))N2(ν,μ)) = 1  H(κ)2 + μD(ν∥1/3).",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 99,
                                            "key": "doc/body/sec3/sub2/ssb1/txl2",
                                            "block type": "txl",
                                            "content": "Likewise, the required coherence time scales with the number of Grover iterations, i.e.\\ as O^*(2^χ n), for",
                                            "leftover": "Likewise, the required coherence time scales with the number of Grover iterations, i.e.\\ as O^*(2^χ n), for",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 100,
                                            "key": "doc/body/sec3/sub2/ssb1/align3",
                                            "block type": "align",
                                            "content": "χ(κ) := limn →∞n log√(N1(κ)) = 1  H(κ)2.",
                                            "leftover": "χ(κ) := limn →∞n log√(N1(κ)) = 1  H(κ)2.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 101,
                                            "key": "doc/body/sec3/sub2/ssb1/txl4",
                                            "block type": "txl",
                                            "content": "The parameters are constrained by",
                                            "leftover": "The parameters are constrained by",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 102,
                                            "key": "doc/body/sec3/sub2/ssb1/equation5",
                                            "block type": "equation",
                                            "content": "0 ≤κ≤1, 0 ≤μ, 0 ≤ν≤1, κ2ν1 ≤μ,",
                                            "leftover": "0 ≤κ≤1, 0 ≤μ, 0 ≤ν≤1, κ2ν1 ≤μ,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 103,
                                            "key": "doc/body/sec3/sub2/ssb1/txl6",
                                            "block type": "txl",
                                            "content": "where the final condition is a rearranged version of the success criterion ().",
                                            "leftover": "where the final condition is a rearranged version of the success criterion ().",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 104,
                                            "key": "doc/body/sec3/sub2/ssb1/txl7",
                                            "block type": "txl",
                                            "content": "We now determine the minimal rate γGI over the consistent parameters. Because relative entropy is nonnegative, it is always advantageous to reduce the value of μ until it is minimal subject to the constraints. This is achieved by changing the final inequality in () to equality. Rearranging, we arrive at",
                                            "leftover": "We now determine the minimal rate γGI over the consistent parameters. Because relative entropy is nonnegative, it is always advantageous to reduce the value of μ until it is minimal subject to the constraints. This is achieved by changing the final inequality in () to equality. Rearranging, we arrive at",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 105,
                                            "key": "doc/body/sec3/sub2/ssb1/equation8",
                                            "block type": "equation",
                                            "content": "0 ≤κ≤1, 0 ≤μ, ν= 2+κ2μ,",
                                            "leftover": "0 ≤κ≤1, 0 ≤μ, ν= 2+κ2μ,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 106,
                                            "key": "doc/body/sec3/sub2/ssb1/txl9",
                                            "block type": "txl",
                                            "content": "which allows us to eliminate ν=ν(κ,μ) from the problem. Varying γ with respect to μ gives rise to the criticality condition",
                                            "leftover": "which allows us to eliminate ν=ν(κ,μ) from the problem. Varying γ with respect to μ gives rise to the criticality condition",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 107,
                                            "key": "doc/body/sec3/sub2/ssb1/align10",
                                            "block type": "align",
                                            "content": "0 != ∂μγ(κ,μ) = ∂μ μD(1/2+κ/(2μ) ∥1/3) = 2log(μ+κμ) +2log(μκμ)+log32.",
                                            "leftover": "0 != ∂μγ(κ,μ) = ∂μ μD(1/2+κ/(2μ) ∥1/3) = 2log(μ+κμ) +2log(μκμ)+log32.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 108,
                                            "key": "doc/body/sec3/sub2/ssb1/txl11",
                                            "block type": "txl",
                                            "content": "This can be solved explicitly e.g.\\ using a computer algebra system, leading to",
                                            "leftover": "This can be solved explicitly e.g.\\ using a computer algebra system, leading to",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 109,
                                            "key": "doc/body/sec3/sub2/ssb1/align12",
                                            "block type": "align",
                                            "content": "μ= 3κ ⇒ ν=3, μD(ν∥1/3) = κ.",
                                            "leftover": "μ= 3κ ⇒ ν=3, μD(ν∥1/3) = κ.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 110,
                                            "key": "doc/body/sec3/sub2/ssb1/txl13",
                                            "block type": "txl",
                                            "content": "Eliminating μ, we get",
                                            "leftover": "Eliminating μ, we get",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 111,
                                            "key": "doc/body/sec3/sub2/ssb1/align14",
                                            "block type": "align",
                                            "content": "γ(κ) = 1H(κ)2 + κ, χGI(κ) = 1H(κ)2.",
                                            "leftover": "γ(κ) = 1H(κ)2 + κ, χGI(κ) = 1H(κ)2.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 112,
                                            "key": "doc/body/sec3/sub2/ssb1/txl15",
                                            "block type": "txl",
                                            "content": "The pair of equations () contain all information about the asymptotic behavior of the Groverized Initialization procedure. Each value of κ gives a solution for the two undetermined constants N1(κ), N2(μ=3κ, ν=3) in Alg.~, in such a way that it will run with a small probability of returning a false negative. Varying κ, we thus obtain a family of algorithms that find different compromises between the required coherence time and the total runtime. The achievable pairs of values are shown in Fig.~.",
                                            "leftover": "The pair of equations () contain all information about the asymptotic behavior of the Groverized Initialization procedure. Each value of κ gives a solution for the two undetermined constants N1(κ), N2(μ=3κ, ν=3) in Alg.~, in such a way that it will run with a small probability of returning a false negative. Varying κ, we thus obtain a family of algorithms that find different compromises between the required coherence time and the total runtime. The achievable pairs of values are shown in Fig.~.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 113,
                                            "key": "doc/body/sec3/sub2/ssb1/figure16",
                                            "block type": "figure",
                                            "content": "ht] \\begin{center} \\includegraphics[scale=.75]{images/gitradeoffszoom} \\end{center} Rates (χGI(κ), γGI(κ)) for the required coherence time and the total runtime of the Groverized Initialization algorithm, as the parameter κ is varied. The horizontal bar denotes the runtime rate achieved by the classical Sch\"oning process. In other words, points above this line are uninteresting. The vertical bar denotes the coherence rate that allows one to run a completely Groverized version of the Sch\"oning process. This, arguably, makes points to the right of this line uninteresting as well. Points to the left of the minimum (at (γ,χ)≃ (0.339, 0.139)) can represent advantageous choices if either the total coherence time of a quantum computer is limited, or a larger degree of parallelization is desired. The dashed line is the lower bound on the runtime rate given the coherence time, as introduced in Fig.~. It is achieved for κ=3.",
                                            "leftover": "ht] \\begin{center} \\includegraphics[scale=.75]{images/gitradeoffszoom} \\end{center} Rates (χGI(κ), γGI(κ)) for the required coherence time and the total runtime of the Groverized Initialization algorithm, as the parameter κ is varied. The horizontal bar denotes the runtime rate achieved by the classical Sch\"oning process. In other words, points above this line are uninteresting. The vertical bar denotes the coherence rate that allows one to run a completely Groverized version of the Sch\"oning process. This, arguably, makes points to the right of this line uninteresting as well. Points to the left of the minimum (at (γ,χ)≃ (0.339, 0.139)) can represent advantageous choices if either the total coherence time of a quantum computer is limited, or a larger degree of parallelization is desired. The dashed line is the lower bound on the runtime rate given the coherence time, as introduced in Fig.~. It is achieved for κ=3.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 114,
                                            "key": "doc/body/sec3/sub2/ssb1/txl17",
                                            "block type": "txl",
                                            "content": "Finally, we explicitly determine the minimal rate achievable in the Groverized Initialization scheme. With the help of a computer algebra system, one easily finds",
                                            "leftover": "Finally, we explicitly determine the minimal rate achievable in the Groverized Initialization scheme. With the help of a computer algebra system, one easily finds",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 115,
                                            "key": "doc/body/sec3/sub2/ssb1/align18",
                                            "block type": "align",
                                            "content": "0 != ∂κγ(κ)=2logκ1κ+1 ⇔ log(κ1) = 2 ⇒ κ= 5",
                                            "leftover": "0 != ∂κγ(κ)=2logκ1κ+1 ⇔ log(κ1) = 2 ⇒ κ= 5",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 116,
                                            "key": "doc/body/sec3/sub2/ssb1/txl19",
                                            "block type": "txl",
                                            "content": "which gives",
                                            "leftover": "which gives",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 117,
                                            "key": "doc/body/sec3/sub2/ssb1/align20",
                                            "block type": "align",
                                            "content": "μ= 5, γ = 3log52≈0.339, χ ≃0.139.",
                                            "leftover": "μ= 5, γ = 3log52≈0.339, χ ≃0.139.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 118,
                                            "key": "doc/body/sec3/sub2/ssb1/txl21",
                                            "block type": "txl",
                                            "content": "Remark: One can cast the final minimization into the form",
                                            "leftover": "Remark: One can cast the final minimization into the form",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 119,
                                            "key": "doc/body/sec3/sub2/ssb1/align*22",
                                            "block type": "align*",
                                            "content": "γ = infκ γ(κ) = infκ ( 1H(κ)2 + κ) =  supκ ( κ H(κ)12 ).",
                                            "leftover": "γ = infκ γ(κ) = infκ ( 1H(κ)2 + κ) =  supκ ( κ H(κ)12 ).",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 120,
                                            "key": "doc/body/sec3/sub2/ssb1/txl23",
                                            "block type": "txl",
                                            "content": "This expression shows that the optimization amounts to computing a Legendre transform. Indeed, with f(κ):=1/2(H(κ)1), the right hand side equals f^*(1). For physicist readers, it might be amusing to note that S(n κ)=n H(n κ) formally equals the entropy of an nspin paramagnet as a function of the total magnetization. The Legendre transform of the entropy is a Massieu thermodynamic potential, equal to F/T (with F the free energy) expressed as a function of the inverse temperature \\cite[Chapter~5.4]{callen}. We will, however, not pursue this analogy here.",
                                            "leftover": "This expression shows that the optimization amounts to computing a Legendre transform. Indeed, with f(κ):=1/2(H(κ)1), the right hand side equals f^*(1). For physicist readers, it might be amusing to note that S(n κ)=n H(n κ) formally equals the entropy of an nspin paramagnet as a function of the total magnetization. The Legendre transform of the entropy is a Massieu thermodynamic potential, equal to F/T (with F the free energy) expressed as a function of the inverse temperature \\cite[Chapter~5.4]{callen}. We will, however, not pursue this analogy here.",
                                            "matches": []
                                        }
                                    ]
                                },
                                {
                                    "key": "doc/body/sec3/sub2/ssb2",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 121,
                                            "key": "doc/body/sec3/sub2/ssb2/tit",
                                            "block type": "title",
                                            "content": "Groverized Walk, Algorithm~",
                                            "leftover": "Groverized Walk, Algorithm~",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 122,
                                            "key": "doc/body/sec3/sub2/ssb2/txl0",
                                            "block type": "txl",
                                            "content": "The analysis proceeds in close analogy to the above case. The asymptotic rate function of GW is",
                                            "leftover": "The analysis proceeds in close analogy to the above case. The asymptotic rate function of GW is",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 123,
                                            "key": "doc/body/sec3/sub2/ssb2/align1",
                                            "block type": "align",
                                            "content": "γ(κ,μ,ν) = limn →∞n log(N1(κ)√(N2(ν,μ))) = 1  H(κ) + μ2 D(ν∥1/3),",
                                            "leftover": "γ(κ,μ,ν) = limn →∞n log(N1(κ)√(N2(ν,μ))) = 1  H(κ) + μ2 D(ν∥1/3),",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 124,
                                            "key": "doc/body/sec3/sub2/ssb2/txl2",
                                            "block type": "txl",
                                            "content": "subject to the set of constraints (). The parameters ν, μ can be treated in exactly the same way as before, leading again to (). In particular, the coherence time rate takes the simple form χ=κ/2, which allows us to eliminate κ in favor of χ. We immediately obtain",
                                            "leftover": "subject to the set of constraints (). The parameters ν, μ can be treated in exactly the same way as before, leading again to (). In particular, the coherence time rate takes the simple form χ=κ/2, which allows us to eliminate κ in favor of χ. We immediately obtain",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 125,
                                            "key": "doc/body/sec3/sub2/ssb2/align3",
                                            "block type": "align",
                                            "content": "γ(χ) = 1H(2χ) + χ.",
                                            "leftover": "γ(χ) = 1H(2χ) + χ.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 126,
                                            "key": "doc/body/sec3/sub2/ssb2/txl4",
                                            "block type": "txl",
                                            "content": "Again, it is not difficult to solve for the lowest runtime :",
                                            "leftover": "Again, it is not difficult to solve for the lowest runtime :",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 127,
                                            "key": "doc/body/sec3/sub2/ssb2/align5",
                                            "block type": "align",
                                            "content": "μ= 3(√(2)1), κ= √(2)1, γ ≈0.228, χ ≃0.2071.",
                                            "leftover": "μ= 3(√(2)1), κ= √(2)1, γ ≈0.228, χ ≃0.2071.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 128,
                                            "key": "doc/body/sec3/sub2/ssb2/txl6",
                                            "block type": "txl",
                                            "content": "At the optimal point, the runtime scales with a rate that is very close to the one of a full Groverization of Sch\"oning's process, namely γFG=γC/2≃ .2075. The flip side is that the required coherence times are basically identical:",
                                            "leftover": "At the optimal point, the runtime scales with a rate that is very close to the one of a full Groverization of Sch\"oning's process, namely γFG=γC/2≃ .2075. The flip side is that the required coherence times are basically identical:",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 129,
                                            "key": "doc/body/sec3/sub2/ssb2/align*7",
                                            "block type": "align*",
                                            "content": "χ  χ ≃0.0004.",
                                            "leftover": "χ  χ ≃0.0004.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 130,
                                            "key": "doc/body/sec3/sub2/ssb2/txl8",
                                            "block type": "txl",
                                            "content": "The findings are summarized in Fig.~.",
                                            "leftover": "The findings are summarized in Fig.~.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 131,
                                            "key": "doc/body/sec3/sub2/ssb2/figure9",
                                            "block type": "figure",
                                            "content": "ht] \\begin{center} \\includegraphics[scale=.6]{images/gwtradeoffs2.pdf} \\end{center} The runtime rate vs coherence time rate curves for Groverized Initialization (GI, blue) and Groverized Walk (GW, red). The point marked ''CG'' at the bottom right of the diagram represents the complete Groverization of the Sch\"oning process. For long coherence times, GW is preferable, while for shorter coherence times GI achieves a lower total runtime.",
                                            "leftover": "ht] \\begin{center} \\includegraphics[scale=.6]{images/gwtradeoffs2.pdf} \\end{center} The runtime rate vs coherence time rate curves for Groverized Initialization (GI, blue) and Groverized Walk (GW, red). The point marked ''CG'' at the bottom right of the diagram represents the complete Groverization of the Sch\"oning process. For long coherence times, GW is preferable, while for shorter coherence times GI achieves a lower total runtime.",
                                            "matches": []
                                        }
                                    ]
                                },
                                {
                                    "key": "doc/body/sec3/sub2/ssb3",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 132,
                                            "key": "doc/body/sec3/sub2/ssb3/tit",
                                            "block type": "title",
                                            "content": "Fractional Groverized Initialization, Algorithm~",
                                            "leftover": "Fractional Groverized Initialization, Algorithm~",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 133,
                                            "key": "doc/body/sec3/sub2/ssb3/txl0",
                                            "block type": "txl",
                                            "content": "In the case of Alg.~, the initial Hamming distance is the sum of two terms d0 = κc (1z)n + κq z n, which model dH(xc,xc^⋆) and dH(xq,xq^⋆) respectively. Define the analogues",
                                            "leftover": "In the case of Alg.~, the initial Hamming distance is the sum of two terms d0 = κc (1z)n + κq z n, which model dH(xc,xc^⋆) and dH(xq,xq^⋆) respectively. Define the analogues",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 134,
                                            "key": "doc/body/sec3/sub2/ssb3/align*1",
                                            "block type": "align*",
                                            "content": "P(E1^c) = 12^(1z)n(1z)nκc (1z)n, P(E1^q) = 12^z nz nκq zn",
                                            "leftover": "P(E1^c) = 12^(1z)n(1z)nκc (1z)n, P(E1^q) = 12^z nz nκq zn",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 135,
                                            "key": "doc/body/sec3/sub2/ssb3/txl2",
                                            "block type": "txl",
                                            "content": "of P(E1) introduced in Eq.~(). Analogous to the discussion in Sec.~, the parameters N1^c, N1^q are defined as the reciprocals of these probabilities, times a constant that influences the probability of a false negative, but will not be discussed as it has no impact on the asymptotic rates. The success criterion is now",
                                            "leftover": "of P(E1) introduced in Eq.~(). Analogous to the discussion in Sec.~, the parameters N1^c, N1^q are defined as the reciprocals of these probabilities, times a constant that influences the probability of a false negative, but will not be discussed as it has no impact on the asymptotic rates. The success criterion is now",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 136,
                                            "key": "doc/body/sec3/sub2/ssb3/align*3",
                                            "block type": "align*",
                                            "content": "(1z)κc + zκq ≤(2ν1)μ",
                                            "leftover": "(1z)κc + zκq ≤(2ν1)μ",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 137,
                                            "key": "doc/body/sec3/sub2/ssb3/txl4",
                                            "block type": "txl",
                                            "content": "and the other constraints are",
                                            "leftover": "and the other constraints are",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 138,
                                            "key": "doc/body/sec3/sub2/ssb3/align*5",
                                            "block type": "align*",
                                            "content": "0 ≤κc, κq, ν, z ≤1, 0 ≤μ.",
                                            "leftover": "0 ≤κc, κq, ν, z ≤1, 0 ≤μ.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 139,
                                            "key": "doc/body/sec3/sub2/ssb3/txl6",
                                            "block type": "txl",
                                            "content": "The asymptotic rate function for the runtime of FGI reads",
                                            "leftover": "The asymptotic rate function for the runtime of FGI reads",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 140,
                                            "key": "doc/body/sec3/sub2/ssb3/align7",
                                            "block type": "align",
                                            "content": "γ(κc,κq,ν,μ;z) = limn→∞ nlog(N1^c(κc;z)√(N1^q(κq;z))N2(ν,μ)) = (1z)(1 H(κc)) + z2(1 H(κq)) + μD(ν∥1/3)",
                                            "leftover": "γ(κc,κq,ν,μ;z) = limn→∞ nlog(N1^c(κc;z)√(N1^q(κq;z))N2(ν,μ)) = (1z)(1 H(κc)) + z2(1 H(κq)) + μD(ν∥1/3)",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 141,
                                            "key": "doc/body/sec3/sub2/ssb3/txl8",
                                            "block type": "txl",
                                            "content": "Arguing as in Sec.~, the inequality in the success criterion may be replaced by an equality. Solving for ν gives",
                                            "leftover": "Arguing as in Sec.~, the inequality in the success criterion may be replaced by an equality. Solving for ν gives",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 142,
                                            "key": "doc/body/sec3/sub2/ssb3/align*9",
                                            "block type": "align*",
                                            "content": "ν= 2 + (1z)κc + zκq2μ.",
                                            "leftover": "ν= 2 + (1z)κc + zκq2μ.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 143,
                                            "key": "doc/body/sec3/sub2/ssb3/txl10",
                                            "block type": "txl",
                                            "content": "We proceed as in the first two cases. Criticality of ∂μγ with respect to μ occurs at",
                                            "leftover": "We proceed as in the first two cases. Criticality of ∂μγ with respect to μ occurs at",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 144,
                                            "key": "doc/body/sec3/sub2/ssb3/align*11",
                                            "block type": "align*",
                                            "content": "μ= 3((1z)κc + z κq) ⇒ μD(ν∥1/3) = (1z)κc + z κq, ν=3.",
                                            "leftover": "μ= 3((1z)κc + z κq) ⇒ μD(ν∥1/3) = (1z)κc + z κq, ν=3.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 145,
                                            "key": "doc/body/sec3/sub2/ssb3/txl12",
                                            "block type": "txl",
                                            "content": "Plugging in, we arrive at",
                                            "leftover": "Plugging in, we arrive at",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 146,
                                            "key": "doc/body/sec3/sub2/ssb3/align13",
                                            "block type": "align",
                                            "content": "γ(κc, κq;z) = (1z) ( 1 H(κc) + κc ) + z( 1 H(κq)2 + κq ).",
                                            "leftover": "γ(κc, κq;z) = (1z) ( 1 H(κc) + κc ) + z( 1 H(κq)2 + κq ).",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 147,
                                            "key": "doc/body/sec3/sub2/ssb3/txl14",
                                            "block type": "txl",
                                            "content": "In other words, the runtime rate function is a convex combination of the ones for the classical Sch\"oning process and for the GI scheme, with weights (1z), z respectively. Because the classical part does not affect the coherence time, we may set κc to its optimal value κc^*=1/3 (c.f.\\ Eq.~()). Geometrically, as we vary z∈[0,1], Eq.~() describes a line connection (χGI(κq), γGI(κq)) with the parameters of the classical Sch\"oning process (0,γC). By the convexity of the GI curve, the tional algorithm will have a better runtime rate to the left of the value of κq at which the line becomes tangent to the curve. In other words, the critical κq is defined by the condition",
                                            "leftover": "In other words, the runtime rate function is a convex combination of the ones for the classical Sch\"oning process and for the GI scheme, with weights (1z), z respectively. Because the classical part does not affect the coherence time, we may set κc to its optimal value κc^*=1/3 (c.f.\\ Eq.~()). Geometrically, as we vary z∈[0,1], Eq.~() describes a line connection (χGI(κq), γGI(κq)) with the parameters of the classical Sch\"oning process (0,γC). By the convexity of the GI curve, the tional algorithm will have a better runtime rate to the left of the value of κq at which the line becomes tangent to the curve. In other words, the critical κq is defined by the condition",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 148,
                                            "key": "doc/body/sec3/sub2/ssb3/align*15",
                                            "block type": "align*",
                                            "content": "∂γGI∂χ = γGIγCχ.",
                                            "leftover": "∂γGI∂χ = γGIγCχ.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 149,
                                            "key": "doc/body/sec3/sub2/ssb3/txl16",
                                            "block type": "txl",
                                            "content": "By a computer calculation, this happens for κq=3 (i.e.\\ equal to κc), resulting in the following curve:",
                                            "leftover": "By a computer calculation, this happens for κq=3 (i.e.\\ equal to κc), resulting in the following curve:",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 150,
                                            "key": "doc/body/sec3/sub2/ssb3/figure17",
                                            "block type": "figure",
                                            "content": "H] \\begin{center} \\includegraphics[scale=.75]{images/fgitradeoffs} \\end{center} The runtime rate vs coherence time rate for the FGI algorithm. This tional scheme's performance is the convex combination of the classical point (0,γC), and GI at the tangent point to the theoretical lower bound. One can note that the FGI partially saturates the optimal performance relation.",
                                            "leftover": "H] \\begin{center} \\includegraphics[scale=.75]{images/fgitradeoffs} \\end{center} The runtime rate vs coherence time rate for the FGI algorithm. This tional scheme's performance is the convex combination of the classical point (0,γC), and GI at the tangent point to the theoretical lower bound. One can note that the FGI partially saturates the optimal performance relation.",
                                            "matches": []
                                        }
                                    ]
                                },
                                {
                                    "key": "doc/body/sec3/sub2/ssb4",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 151,
                                            "key": "doc/body/sec3/sub2/ssb4/tit",
                                            "block type": "title",
                                            "content": "Fractional Groverized Walk, Algorithm~",
                                            "leftover": "Fractional Groverized Walk, Algorithm~",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 152,
                                            "key": "doc/body/sec3/sub2/ssb4/txl0",
                                            "block type": "txl",
                                            "content": "In the FGW scheme, we assume that the classical and Groverized walks decrease the Hamming distance in exactly νcmc and νqmq steps, respectively, where we have used a subscript to differentiate between the classical and Groverized random walks. The probabilities of such walks occurring is given by:",
                                            "leftover": "In the FGW scheme, we assume that the classical and Groverized walks decrease the Hamming distance in exactly νcmc and νqmq steps, respectively, where we have used a subscript to differentiate between the classical and Groverized random walks. The probabilities of such walks occurring is given by:",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 153,
                                            "key": "doc/body/sec3/sub2/ssb4/align1",
                                            "block type": "align",
                                            "content": "P(E^c2) = mcνc mc(3)^νc mc(3)^(1νc)mc, P(E^q2) = mqνq mq(3)^νq mq(3)^(1νq)mq",
                                            "leftover": "P(E^c2) = mcνc mc(3)^νc mc(3)^(1νc)mc, P(E^q2) = mqνq mq(3)^νq mq(3)^(1νq)mq",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 154,
                                            "key": "doc/body/sec3/sub2/ssb4/txl2",
                                            "block type": "txl",
                                            "content": "Analogous to the discussion in Sec.~, the parameters N2^c, N2^q are defined as the reciprocals of the probabilities P(E^c2),P(E^q2), times a constant that influences the probability failure, but will not be discussed as it has no impact on the asymptotic rates. We further parameterize the walk lengths as mc = μcn and mq = μqn. The runtime rate is",
                                            "leftover": "Analogous to the discussion in Sec.~, the parameters N2^c, N2^q are defined as the reciprocals of the probabilities P(E^c2),P(E^q2), times a constant that influences the probability failure, but will not be discussed as it has no impact on the asymptotic rates. We further parameterize the walk lengths as mc = μcn and mq = μqn. The runtime rate is",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 155,
                                            "key": "doc/body/sec3/sub2/ssb4/align3",
                                            "block type": "align",
                                            "content": "γ(κ,νc,μc,νq,μq) = limn →∞ n log(N1(κ)N2^c(νc,μc)√(N2^q(νq,μq))) = 1 H(κ) + μcD(νc∥1/3) + μq2D(νq∥1/3)",
                                            "leftover": "γ(κ,νc,μc,νq,μq) = limn →∞ n log(N1(κ)N2^c(νc,μc)√(N2^q(νq,μq))) = 1 H(κ) + μcD(νc∥1/3) + μq2D(νq∥1/3)",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 156,
                                            "key": "doc/body/sec3/sub2/ssb4/txl4",
                                            "block type": "txl",
                                            "content": "with parameters subject to the constraints",
                                            "leftover": "with parameters subject to the constraints",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 157,
                                            "key": "doc/body/sec3/sub2/ssb4/equation5",
                                            "block type": "equation",
                                            "content": "0 ≤κ≤1, 0 ≤μc,μq, 0 ≤νc,νq ≤1, κ ≤(2νc1)μc + (2νq1)μq.",
                                            "leftover": "0 ≤κ≤1, 0 ≤μc,μq, 0 ≤νc,νq ≤1, κ ≤(2νc1)μc + (2νq1)μq.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 158,
                                            "key": "doc/body/sec3/sub2/ssb4/txl6",
                                            "block type": "txl",
                                            "content": "The first steps of the analysis should now be familiar. There is no loss of generality in assuming that the final inequality is tight, which can be rearranged to give",
                                            "leftover": "The first steps of the analysis should now be familiar. There is no loss of generality in assuming that the final inequality is tight, which can be rearranged to give",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 159,
                                            "key": "doc/body/sec3/sub2/ssb4/align*7",
                                            "block type": "align*",
                                            "content": "νq = κ (2νc1)μc2μq + 2.",
                                            "leftover": "νq = κ (2νc1)μc2μq + 2.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 160,
                                            "key": "doc/body/sec3/sub2/ssb4/txl8",
                                            "block type": "txl",
                                            "content": "The rate γFGW is stationary as a function of μq if",
                                            "leftover": "The rate γFGW is stationary as a function of μq if",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 161,
                                            "key": "doc/body/sec3/sub2/ssb4/align*9",
                                            "block type": "align*",
                                            "content": "μq = 3 (κ (2νc1)μc ) ⇒ νq = 3, μq2D(νq∥1/3) = 1/2 (κ (2νc1)μc ) = χ(κ,νc,μc).",
                                            "leftover": "μq = 3 (κ (2νc1)μc ) ⇒ νq = 3, μq2D(νq∥1/3) = 1/2 (κ (2νc1)μc ) = χ(κ,νc,μc).",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 162,
                                            "key": "doc/body/sec3/sub2/ssb4/txl10",
                                            "block type": "txl",
                                            "content": "Eliminating κ in favor of the coherence rate χ gives",
                                            "leftover": "Eliminating κ in favor of the coherence rate χ gives",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 163,
                                            "key": "doc/body/sec3/sub2/ssb4/align*11",
                                            "block type": "align*",
                                            "content": "κ= 2χ+ (2νc1)μc",
                                            "leftover": "κ= 2χ+ (2νc1)μc",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 164,
                                            "key": "doc/body/sec3/sub2/ssb4/txl12",
                                            "block type": "txl",
                                            "content": "and thus",
                                            "leftover": "and thus",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 165,
                                            "key": "doc/body/sec3/sub2/ssb4/align*13",
                                            "block type": "align*",
                                            "content": "μq = 6χ, γ(νc,μc;χ) = 1 H( 2 χ+ (2νc1)μc ) + μc D(νc∥1/3) + χ.",
                                            "leftover": "μq = 6χ, γ(νc,μc;χ) = 1 H( 2 χ+ (2νc1)μc ) + μc D(νc∥1/3) + χ.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 166,
                                            "key": "doc/body/sec3/sub2/ssb4/txl14",
                                            "block type": "txl",
                                            "content": "We now need to minimize γ for fixed χ as a function of μc, νc, subject to",
                                            "leftover": "We now need to minimize γ for fixed χ as a function of μc, νc, subject to",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 167,
                                            "key": "doc/body/sec3/sub2/ssb4/align*15",
                                            "block type": "align*",
                                            "content": "0 ≤2χ+ (2νc1)μc ≤1, 0 ≤μc, 0 ≤νc ≤1.",
                                            "leftover": "0 ≤2χ+ (2νc1)μc ≤1, 0 ≤μc, 0 ≤νc ≤1.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 168,
                                            "key": "doc/body/sec3/sub2/ssb4/txl16",
                                            "block type": "txl",
                                            "content": "We may assume that μc≠ 0, for else we are just replicating the GW scheme. A computer calculation gives",
                                            "leftover": "We may assume that μc≠ 0, for else we are just replicating the GW scheme. A computer calculation gives",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 169,
                                            "key": "doc/body/sec3/sub2/ssb4/align*17",
                                            "block type": "align*",
                                            "content": "∂μc (γln2) + 24νc4μc ∂νc (γln2) = arctan(12νc) + ln(33νc)  2ln2,",
                                            "leftover": "∂μc (γln2) + 24νc4μc ∂νc (γln2) = arctan(12νc) + ln(33νc)  2ln2,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 170,
                                            "key": "doc/body/sec3/sub2/ssb4/txl18",
                                            "block type": "txl",
                                            "content": "which has zeros at νc=3 and νc=3.",
                                            "leftover": "which has zeros at νc=3 and νc=3.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 171,
                                            "key": "doc/body/sec3/sub2/ssb4/txl19",
                                            "block type": "txl",
                                            "content": "For νc=3, one finds",
                                            "leftover": "For νc=3, one finds",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 172,
                                            "key": "doc/body/sec3/sub2/ssb4/align*20",
                                            "block type": "align*",
                                            "content": "∂μc (γln2) = 3 arctan(14χ+2/3 μc)",
                                            "leftover": "∂μc (γln2) = 3 arctan(14χ+2/3 μc)",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 173,
                                            "key": "doc/body/sec3/sub2/ssb4/txl21",
                                            "block type": "txl",
                                            "content": "which has one zero, at μc = 2(4χ1). The constraint μc≥ 0 then implies χ≥4. But this is larger than the coherence time rate γC/2≃ 0.208 sufficient to implement a completely Groverized version of Sch\"oning's process, so this solution is not of interest.",
                                            "leftover": "which has one zero, at μc = 2(4χ1). The constraint μc≥ 0 then implies χ≥4. But this is larger than the coherence time rate γC/2≃ 0.208 sufficient to implement a completely Groverized version of Sch\"oning's process, so this solution is not of interest.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 174,
                                            "key": "doc/body/sec3/sub2/ssb4/txl22",
                                            "block type": "txl",
                                            "content": "We turn to the other solution, νc=3. For it,",
                                            "leftover": "We turn to the other solution, νc=3. For it,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 175,
                                            "key": "doc/body/sec3/sub2/ssb4/align*23",
                                            "block type": "align*",
                                            "content": "∂μc (γln2) = 1/3 (2 arctanh(1  4 χ (2 μc)/3) + ln(2)),",
                                            "leftover": "∂μc (γln2) = 1/3 (2 arctanh(1  4 χ (2 μc)/3) + ln(2)),",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 176,
                                            "key": "doc/body/sec3/sub2/ssb4/txl24",
                                            "block type": "txl",
                                            "content": "which has one zero:",
                                            "leftover": "which has one zero:",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 177,
                                            "key": "doc/body/sec3/sub2/ssb4/align*25",
                                            "block type": "align*",
                                            "content": "μc=16χ ⇒ μq=6χ, νc=νq=3, γFGW = γC  χ.",
                                            "leftover": "μc=16χ ⇒ μq=6χ, νc=νq=3, γFGW = γC  χ.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 178,
                                            "key": "doc/body/sec3/sub2/ssb4/txl26",
                                            "block type": "txl",
                                            "content": "The runtime vs coherence rate curve for the FGW scheme is given in the following figure:",
                                            "leftover": "The runtime vs coherence rate curve for the FGW scheme is given in the following figure:",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 179,
                                            "key": "doc/body/sec3/sub2/ssb4/figure27",
                                            "block type": "figure",
                                            "content": "H] \\begin{center} \\includegraphics[scale=.75]{images/fgwtradeoffs} \\end{center} The runtime rate vs coherence time rate for the FGW algorithm. This tional scheme's performance connects the GW curve to the classical Sch\"oning point and is tangent to the curve. It achieves the optimal performance relation partially for a larger regime than FGI and for low coherence times, it comes to lie on top of the FGI line.",
                                            "leftover": "H] \\begin{center} \\includegraphics[scale=.75]{images/fgwtradeoffs} \\end{center} The runtime rate vs coherence time rate for the FGW algorithm. This tional scheme's performance connects the GW curve to the classical Sch\"oning point and is tangent to the curve. It achieves the optimal performance relation partially for a larger regime than FGI and for low coherence times, it comes to lie on top of the FGI line.",
                                            "matches": []
                                        }
                                    ]
                                },
                                {
                                    "key": "doc/body/sec3/sub2/ssb5",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 180,
                                            "key": "doc/body/sec3/sub2/ssb5/tit",
                                            "block type": "title",
                                            "content": "Evenly Fractionalized Grover",
                                            "leftover": "Evenly Fractionalized Grover",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 181,
                                            "key": "doc/body/sec3/sub2/ssb5/txl0",
                                            "block type": "txl",
                                            "content": "The runtime rate is",
                                            "leftover": "The runtime rate is",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 182,
                                            "key": "doc/body/sec3/sub2/ssb5/align1",
                                            "block type": "align",
                                            "content": "γ = (1z)( 1 H(κc) + μc D(νc ∥1/3) ) + z/2( 1 H(κq) + μq D(νq ∥1/3) )",
                                            "leftover": "γ = (1z)( 1 H(κc) + μc D(νc ∥1/3) ) + z/2( 1 H(κq) + μq D(νq ∥1/3) )",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 183,
                                            "key": "doc/body/sec3/sub2/ssb5/txl2",
                                            "block type": "txl",
                                            "content": "with success criterion",
                                            "leftover": "with success criterion",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 184,
                                            "key": "doc/body/sec3/sub2/ssb5/align*3",
                                            "block type": "align*",
                                            "content": "(1z)κc + zκq = (1z)(2νc1)μc + z(2νq1)μq,",
                                            "leftover": "(1z)κc + zκq = (1z)(2νc1)μc + z(2νq1)μq,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 185,
                                            "key": "doc/body/sec3/sub2/ssb5/txl4",
                                            "block type": "txl",
                                            "content": "which is in particular true if the following two equations hold",
                                            "leftover": "which is in particular true if the following two equations hold",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 186,
                                            "key": "doc/body/sec3/sub2/ssb5/align*5",
                                            "block type": "align*",
                                            "content": "κc = (2νc1)μc, κq = (2νq1)μq.",
                                            "leftover": "κc = (2νc1)μc, κq = (2νq1)μq.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 187,
                                            "key": "doc/body/sec3/sub2/ssb5/txl6",
                                            "block type": "txl",
                                            "content": "But this is just the convex interpolation between a completely classical and a completely Groverized process. In particular, by choosing the parameters as for the original Sch\"oning process",
                                            "leftover": "But this is just the convex interpolation between a completely classical and a completely Groverized process. In particular, by choosing the parameters as for the original Sch\"oning process",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 188,
                                            "key": "doc/body/sec3/sub2/ssb5/align*7",
                                            "block type": "align*",
                                            "content": "νc=νq=3, κc=κq=3, μc=μq=1,",
                                            "leftover": "νc=νq=3, κc=κq=3, μc=μq=1,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 189,
                                            "key": "doc/body/sec3/sub2/ssb5/txl8",
                                            "block type": "txl",
                                            "content": "we obtain a coherence timeruntime rate curve that linearly connects the classical point (0,γC) to the completely Groverized one (γC/2, γC/2) (Fig.~).",
                                            "leftover": "we obtain a coherence timeruntime rate curve that linearly connects the classical point (0,γC) to the completely Groverized one (γC/2, γC/2) (Fig.~).",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 190,
                                            "key": "doc/body/sec3/sub2/ssb5/figure9",
                                            "block type": "figure",
                                            "content": "ht] \\begin{center} \\includegraphics[scale=.75]{images/alltradeoffs} \\end{center} Runtimecoherence time rate curves for the covered algorithms. The linear interpolation between the classical and the completely Groverized points are realizable using an increasing number of methods  first only EFG, then also FGW, finally also FGI  as the coherence time decreases.",
                                            "leftover": "ht] \\begin{center} \\includegraphics[scale=.75]{images/alltradeoffs} \\end{center} Runtimecoherence time rate curves for the covered algorithms. The linear interpolation between the classical and the completely Groverized points are realizable using an increasing number of methods  first only EFG, then also FGW, finally also FGI  as the coherence time decreases.",
                                            "matches": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec3/sub3",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 191,
                                    "key": "doc/body/sec3/sub3/tit",
                                    "block type": "title",
                                    "content": "A heuristic derandomization of the GI schemes",
                                    "leftover": "A heuristic derandomization of the GI schemes",
                                    "matches": []
                                },
                                {
                                    "leaf id": 192,
                                    "key": "doc/body/sec3/sub3/txl0",
                                    "block type": "txl",
                                    "content": "In this section, we provide evidence that the Groverized initialization schemes can reach further into the γχ chart than what the Markovian model suggests. To see why this is plausible, note that the role of randomness for the initial configuration x is very different from the role of randomness for the walk decisions w. In the first case, there is an ''absolute measures of the quality of the initial configuration'', namely the Hamming distance to the solution. The probability that the walk does find the solution is quite obviously a function of that metric. Therefore, baring major algorithmic insights, it is unavoidable to consider many different initial configurations before encountering one that will likely lead to a solution.",
                                    "leftover": "In this section, we provide evidence that the Groverized initialization schemes can reach further into the γχ chart than what the Markovian model suggests. To see why this is plausible, note that the role of randomness for the initial configuration x is very different from the role of randomness for the walk decisions w. In the first case, there is an ''absolute measures of the quality of the initial configuration'', namely the Hamming distance to the solution. The probability that the walk does find the solution is quite obviously a function of that metric. Therefore, baring major algorithmic insights, it is unavoidable to consider many different initial configurations before encountering one that will likely lead to a solution.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 193,
                                    "key": "doc/body/sec3/sub3/txl1",
                                    "block type": "txl",
                                    "content": "In contrast, it is not implausible that ''every walk works for equally many initial configurations'', i.e.\\ that there are no choices for w that are ''intrinsically better than others''. More precisely, it seems reasonable to assume that for sufficiently large n, and generic SAT formulas, it holds that with high probability in w",
                                    "leftover": "In contrast, it is not implausible that ''every walk works for equally many initial configurations'', i.e.\\ that there are no choices for w that are ''intrinsically better than others''. More precisely, it seems reasonable to assume that for sufficiently large n, and generic SAT formulas, it holds that with high probability in w",
                                    "matches": []
                                },
                                {
                                    "leaf id": 194,
                                    "key": "doc/body/sec3/sub3/align2",
                                    "block type": "align",
                                    "content": "n log( x[ SchoeningWalk(x, w) = x^⋆ | dH(x,x^⋆)=h,w] ) ≃n log( x,w'[ SchoeningWalk(x, w') = x^⋆ | dH(x,x^⋆)=h] ).",
                                    "leftover": "n log( x[ SchoeningWalk(x, w) = x^⋆ | dH(x,x^⋆)=h,w] ) ≃n log( x,w'[ SchoeningWalk(x, w') = x^⋆ | dH(x,x^⋆)=h] ).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 195,
                                    "key": "doc/body/sec3/sub3/txl3",
                                    "block type": "txl",
                                    "content": "The right hand side can be easily calculated, as by Ref., for μ=3,",
                                    "leftover": "The right hand side can be easily calculated, as by Ref., for μ=3,",
                                    "matches": []
                                },
                                {
                                    "leaf id": 196,
                                    "key": "doc/body/sec3/sub3/align*4",
                                    "block type": "align*",
                                    "content": "x,w[ SchoeningWalk(x, w) = x^⋆ | dH(x,x^⋆)=h] = 2^h.",
                                    "leftover": "x,w[ SchoeningWalk(x, w) = x^⋆ | dH(x,x^⋆)=h] = 2^h.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 197,
                                    "key": "doc/body/sec3/sub3/txl5",
                                    "block type": "txl",
                                    "content": "Under Assumption (), one can restrict the outer loop over w's from Alg.~ to N2=1 iteration, and compensate by increasing the number of Grover iterations for x to N1=O^*(2^γC/2n). In other words, the Groverized Initialization scheme with these parameters would lie on the optimal point (χ,γ) = (γC/2, γC/2).",
                                    "leftover": "Under Assumption (), one can restrict the outer loop over w's from Alg.~ to N2=1 iteration, and compensate by increasing the number of Grover iterations for x to N1=O^*(2^γC/2n). In other words, the Groverized Initialization scheme with these parameters would lie on the optimal point (χ,γ) = (γC/2, γC/2).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 198,
                                    "key": "doc/body/sec3/sub3/txl6",
                                    "block type": "txl",
                                    "content": "Being even bolder, one could then speculate that the analysis of Sec.~ carries over and that, as one varies the tion of initialization bits that are subjected to a Grover search, one could trace out the optimal (χ,γ)line. In other words, it does not seem impossible that the following Alg.~, with parameter choice",
                                    "leftover": "Being even bolder, one could then speculate that the analysis of Sec.~ carries over and that, as one varies the tion of initialization bits that are subjected to a Grover search, one could trace out the optimal (χ,γ)line. In other words, it does not seem impossible that the following Alg.~, with parameter choice",
                                    "matches": []
                                },
                                {
                                    "leaf id": 199,
                                    "key": "doc/body/sec3/sub3/align*7",
                                    "block type": "align*",
                                    "content": "N1^(c) = O^*(2^γC(1z)n), N1^(q) = O^*(2^γCzn/2),",
                                    "leftover": "N1^(c) = O^*(2^γC(1z)n), N1^(q) = O^*(2^γCzn/2),",
                                    "matches": []
                                },
                                {
                                    "leaf id": 200,
                                    "key": "doc/body/sec3/sub3/txl8",
                                    "block type": "txl",
                                    "content": "achieves the optimal tradeoff.",
                                    "leftover": "achieves the optimal tradeoff.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 201,
                                    "key": "doc/body/sec3/sub3/algorithm9",
                                    "block type": "algorithm",
                                    "content": "H] Heuristically DeRandomized Fractional Groverized Initialization \\begin{algorithmic}[1] \\State w← uniformly random value from 1, 2, 3^× m \\For{j=1 ... N1^(c)} \\State xc← uniformly random value from 0,1^×⌈(1z)n⌉ \\State xq← Groversearch for ⌊√(N1^(q))⌋ iterations using \\textsc{Oracle(xc, w)}() \\State x=(xc,xq) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\State \\Return False \\end{algorithmic}",
                                    "leftover": "H] Heuristically DeRandomized Fractional Groverized Initialization \\begin{algorithmic}[1] \\State w← uniformly random value from 1, 2, 3^× m \\For{j=1 ... N1^(c)} \\State xc← uniformly random value from 0,1^×⌈(1z)n⌉ \\State xq← Groversearch for ⌊√(N1^(q))⌋ iterations using \\textsc{Oracle(xc, w)}() \\State x=(xc,xq) \\If{x satisfies all clauses} \\State\\Return x \\EndIf \\EndFor \\State \\Return False \\end{algorithmic}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 202,
                                    "key": "doc/body/sec3/sub3/txl10",
                                    "block type": "txl",
                                    "content": "To gather evidence in favor of Assumption~(), we have resorted to numerical methods. A first ansatz is to compute the l.h.s.\\ of Eq.~() exactly, which is possible for small values of n by iterating over all 2^n assignments to x. Results are shown in Fig.~ for a randomly chosen set of 3SAT formulas with n=20 variables, L=91 clauses. The number of satisfying assignments t0 of the formulas are varied. Only the case t0=1 can be directly compared to the analytic bounds. However, note that even for this case, the empirically observed rate of γGI≃ .12 ± .02 is much lower than the value γC/2 ≃ .208 that we would expect theoretically. Presumably, n=20 is still too small to show the asymptotic behavior.",
                                    "leftover": "To gather evidence in favor of Assumption~(), we have resorted to numerical methods. A first ansatz is to compute the l.h.s.\\ of Eq.~() exactly, which is possible for small values of n by iterating over all 2^n assignments to x. Results are shown in Fig.~ for a randomly chosen set of 3SAT formulas with n=20 variables, L=91 clauses. The number of satisfying assignments t0 of the formulas are varied. Only the case t0=1 can be directly compared to the analytic bounds. However, note that even for this case, the empirically observed rate of γGI≃ .12 ± .02 is much lower than the value γC/2 ≃ .208 that we would expect theoretically. Presumably, n=20 is still too small to show the asymptotic behavior.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 203,
                                    "key": "doc/body/sec3/sub3/figure11",
                                    "block type": "figure",
                                    "content": "ht] \\centering \\includegraphics[width=.45\\textwidth]{images/gammasamechoicesperstep.pdf} Plot of the runtime rate for the heuristically derandomzied GI scheme. Error bars indicate variation as a function of the formulas and the walk variables w. On the xaxis, we show the number of satisfying assignments in the formula. Only the case of t0=1 should be directly comparable to the analytic bounds. The empirically observed behavior is much better than the analytic results, suggesting that n=20 is too small to capture the asymptotic behavior.",
                                    "leftover": "ht] \\centering \\includegraphics[width=.45\\textwidth]{images/gammasamechoicesperstep.pdf} Plot of the runtime rate for the heuristically derandomzied GI scheme. Error bars indicate variation as a function of the formulas and the walk variables w. On the xaxis, we show the number of satisfying assignments in the formula. Only the case of t0=1 should be directly comparable to the analytic bounds. The empirically observed behavior is much better than the analytic results, suggesting that n=20 is too small to capture the asymptotic behavior.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 204,
                                    "key": "doc/body/sec3/sub3/txl12",
                                    "block type": "txl",
                                    "content": "To test this assumption, we had to turn to numerical heuristics, to at least probe the behavior for much larger values of n, where an exact computation is no longer possible. The results are shown in Fig.~. We used a SAT instance with n=1414 variables that we believe to have a single satisfying assignment x^⋆ which is explicitly known. To generate the instance, a 128bit plain text was encoded by a 128bit key using the XTEA block cipher truncated to three rounds. The formula represents the conditions on an input key to map the known plain text to the known ciphertext. The clauses are designed such that they enforce the correct evaluation of bitwise operations of the algorithm with respect to the given input and output. XTEA was restricted to three rounds in order to keep the size of the formula manageable. While we have no formal proof, it is reasonable to assume that there is a unique key that satisfies the formula. This is supported by consistency checks in terms of running SAT solvers on a version of this problems with even fewer rounds .",
                                    "leftover": "To test this assumption, we had to turn to numerical heuristics, to at least probe the behavior for much larger values of n, where an exact computation is no longer possible. The results are shown in Fig.~. We used a SAT instance with n=1414 variables that we believe to have a single satisfying assignment x^⋆ which is explicitly known. To generate the instance, a 128bit plain text was encoded by a 128bit key using the XTEA block cipher truncated to three rounds. The formula represents the conditions on an input key to map the known plain text to the known ciphertext. The clauses are designed such that they enforce the correct evaluation of bitwise operations of the algorithm with respect to the given input and output. XTEA was restricted to three rounds in order to keep the size of the formula manageable. While we have no formal proof, it is reasonable to assume that there is a unique key that satisfies the formula. This is supported by consistency checks in terms of running SAT solvers on a version of this problems with even fewer rounds .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 205,
                                    "key": "doc/body/sec3/sub3/txl13",
                                    "block type": "txl",
                                    "content": "Let us denote the sphere of strings with Hamming distance h from x^⋆ by M^h(x^⋆). For a fixed walk randomness w, and for h=1, … 11, we have drawn x uniformly from M^h(x^⋆). In order to compare the numerical results to the theory prediction, we have to use the value of the right hand side of Assumption~() for nonasymptotic values of n. The following plot shows the empirically estimated probabilities of Sch\"oning's walk (with μ=3) arriving at the solution, when starting from a random initial configuration of given Hamming distance. The findings show the expected behavior of averaging over w, already for a fixed random value of w. In this sense, they are compatible with Assumption~(). We note, however, that we were not able to probe the assumption for larger values of h. Garnering a better understanding for the concentration properties of the Sch\"oning walk as a function of the walk choices remains therefore an open question.",
                                    "leftover": "Let us denote the sphere of strings with Hamming distance h from x^⋆ by M^h(x^⋆). For a fixed walk randomness w, and for h=1, … 11, we have drawn x uniformly from M^h(x^⋆). In order to compare the numerical results to the theory prediction, we have to use the value of the right hand side of Assumption~() for nonasymptotic values of n. The following plot shows the empirically estimated probabilities of Sch\"oning's walk (with μ=3) arriving at the solution, when starting from a random initial configuration of given Hamming distance. The findings show the expected behavior of averaging over w, already for a fixed random value of w. In this sense, they are compatible with Assumption~(). We note, however, that we were not able to probe the assumption for larger values of h. Garnering a better understanding for the concentration properties of the Sch\"oning walk as a function of the walk choices remains therefore an open question.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 206,
                                    "key": "doc/body/sec3/sub3/figure14",
                                    "block type": "figure",
                                    "content": "ht] \\centering \\includegraphics[width=.45\\textwidth]{images/runtime1414samechoiceforeveryclause.pdf} Estimated probability for a uniformly random initial configuration x with Hamming distance h to be mapped to x^⋆ under a Sch\"oning walk, for a fixed, randomly chosen set of walk decisions w (c.f.\\ Alg.~). The SAT instance has n=1414 variables and is believed to have a unique satisfying assignment . For each data point, 10^4 initial configurations x, were sampled uniformly from the Hamming distance sphere M^h(x^⋆). The results agree well with the theoretical prediction under Assumption~() (orange line).",
                                    "leftover": "ht] \\centering \\includegraphics[width=.45\\textwidth]{images/runtime1414samechoiceforeveryclause.pdf} Estimated probability for a uniformly random initial configuration x with Hamming distance h to be mapped to x^⋆ under a Sch\"oning walk, for a fixed, randomly chosen set of walk decisions w (c.f.\\ Alg.~). The SAT instance has n=1414 variables and is believed to have a unique satisfying assignment . For each data point, 10^4 initial configurations x, were sampled uniformly from the Hamming distance sphere M^h(x^⋆). The results agree well with the theoretical prediction under Assumption~() (orange line).",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec4",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 207,
                            "key": "doc/body/sec4/tit",
                            "block type": "title",
                            "content": "Circuits",
                            "leftover": "Circuits",
                            "matches": []
                        },
                        {
                            "leaf id": 208,
                            "key": "doc/body/sec4/txl0",
                            "block type": "txl",
                            "content": "In this section, we discuss an implementation of the partial Groverization schemes and present the main building blocks of their quantum circuits. Given n variables and the length of Sch\"oning's walk m, the quantum implementation requires n + m log3 qubits to encode the initializations and walk randomness. The oracles of the partial Groverization schemes are some adaptation of one or more Sch\"oning walks, and regardless of the search space they act on, the label of the violated clause at each step needs to be stored in their workspaces. This is necessary since such oracles are typically realized using uncomputation, therefore, log L extra auxiliary qubits are needed at each step, amounting to mlog L qubits in total for the workspace. As a result, encoding any Groverization of Sch\"oning's algorithm asymptotically needs n+(log3+log L)m qubits.",
                            "leftover": "In this section, we discuss an implementation of the partial Groverization schemes and present the main building blocks of their quantum circuits. Given n variables and the length of Sch\"oning's walk m, the quantum implementation requires n + m log3 qubits to encode the initializations and walk randomness. The oracles of the partial Groverization schemes are some adaptation of one or more Sch\"oning walks, and regardless of the search space they act on, the label of the violated clause at each step needs to be stored in their workspaces. This is necessary since such oracles are typically realized using uncomputation, therefore, log L extra auxiliary qubits are needed at each step, amounting to mlog L qubits in total for the workspace. As a result, encoding any Groverization of Sch\"oning's algorithm asymptotically needs n+(log3+log L)m qubits.",
                            "matches": []
                        },
                        {
                            "leaf id": 209,
                            "key": "doc/body/sec4/txl1",
                            "block type": "txl",
                            "content": "Figure represents a single step of Sch\"oning walk, schematically. The first register encodes the space of all possible initialization. The gates evj, for j ∈1,..,L, act on the first two registers. Each gate consists of a few controlledgates where the control qubits correspond to the three variables in the jth clause, and the target qubit is the second register. The second register is an auxiliary qubit, initially set to | {0} \\rangle, and is negated as soon as the first violated clause is detected. The third register consists of log L auxiliary qubits that are used to count the number of clauses from where the first violated clause has happened. The last register is a qutrit providing the randomness of the corresponding walk step. The controlledgates chj, for j ∈1,..,L act on the first three registers, and take care of variable flipping wherever the first violated clause is detected. The 012 block represents a triple controlledgate where the control qutrit is the subspaces corresponding to the computational basis states | {0} \\rangle,| {0} \\rangle,| {0} \\rangle. Figure depicts the controlledgates including chj, in detail. The subfigure on the right shows the corresponding controlledgate for GI, where the walk randomness is fed classically to the last register.",
                            "leftover": "Figure represents a single step of Sch\"oning walk, schematically. The first register encodes the space of all possible initialization. The gates evj, for j ∈1,..,L, act on the first two registers. Each gate consists of a few controlledgates where the control qubits correspond to the three variables in the jth clause, and the target qubit is the second register. The second register is an auxiliary qubit, initially set to | {0} \\rangle, and is negated as soon as the first violated clause is detected. The third register consists of log L auxiliary qubits that are used to count the number of clauses from where the first violated clause has happened. The last register is a qutrit providing the randomness of the corresponding walk step. The controlledgates chj, for j ∈1,..,L act on the first three registers, and take care of variable flipping wherever the first violated clause is detected. The 012 block represents a triple controlledgate where the control qutrit is the subspaces corresponding to the computational basis states | {0} \\rangle,| {0} \\rangle,| {0} \\rangle. Figure depicts the controlledgates including chj, in detail. The subfigure on the right shows the corresponding controlledgate for GI, where the walk randomness is fed classically to the last register.",
                            "matches": []
                        },
                        {
                            "leaf id": 210,
                            "key": "doc/body/sec4/txl2",
                            "block type": "txl",
                            "content": "All partial Groverization of Sch\"oning algorithm can be implemented using slight modifications. For the GW algorithm, the nqubit variable register will not be initialized in the uniform superposition of all possible assignments | {0} \\rangle^⊗ n, but rather in a state with classically randomly defined variables | {0} \\rangle. For the GI algorithm the qutrit within every Sch\"oning's step can be removed since we can, for every Sch\"oning's step, generate a random number r∈0, 1, 2 and apply only the X gates based on the classically determined r (see figure ).",
                            "leftover": "All partial Groverization of Sch\"oning algorithm can be implemented using slight modifications. For the GW algorithm, the nqubit variable register will not be initialized in the uniform superposition of all possible assignments | {0} \\rangle^⊗ n, but rather in a state with classically randomly defined variables | {0} \\rangle. For the GI algorithm the qutrit within every Sch\"oning's step can be removed since we can, for every Sch\"oning's step, generate a random number r∈0, 1, 2 and apply only the X gates based on the classically determined r (see figure ).",
                            "matches": []
                        },
                        {
                            "leaf id": 211,
                            "key": "doc/body/sec4/figure3",
                            "block type": "figure",
                            "content": "t] \\begin{center} {\\textwidth} \\resizebox{\\textwidth}{!}{ \\begin{quantikz} \\lstick{| {0} \\rangle^⊗ n} & [3mm] \\qwbundle{n} & \\gate[2]{ev1} & \\gate{ch1} & \\qw & \\gate[2]{ev2} & \\gate{ch2} & \\qw & \\qw & & & \\gate[2]{evL} & \\gate{chL} & \\qw \\lstick{| {0} \\rangle} & \\qw & \\qw & \\ctrl{1} & \\ctrl{1} & \\qw & \\ctrl{1} & \\ctrl{1} & \\qw & \\cdots & & \\qw & \\ctrl{1} & \\qw \\lstick{| {0} \\rangle^⊗log L} & \\qwbundle{\\log L} & \\qw & \\octrl{1} & \\gate{+1} & \\octrl{1} & \\octrl{1} & \\gate{+1} & \\qw & & & \\octrl{1} & \\octrl{1} & \\qw \\lstick{ } & \\qw & \\qw & \\gate{0\\lor1\\lor2}\\vqw{1} & \\qw & \\qw & \\gate{0\\lor1\\lor2}\\vqw{1} & \\qw & \\qw & & & \\qw & \\gate{0\\lor1\\lor2}\\vqw{1} & \\qw \\end{quantikz} } \\end{center} The quantum implementation of a single Sch\"oning's step for a general implementation of the partial Groverization of Sch\"oning's algorithm. The evj gates evaluate the jth clause on the corresponding variables and the controlledgates containing chi and 012 act on all the registers and check if the jth clause is the first violated clause and if so, flip one of three variables in it based on the randomness provided by the ifstatement, 012. Here 012 represents a triple controlledgate where the control qutrit is the subspaces of the computational basis (visualized in figure ). The log L auxiliary qubits are needed for uncomputation.",
                            "leftover": "t] \\begin{center} {\\textwidth} \\resizebox{\\textwidth}{!}{ \\begin{quantikz} \\lstick{| {0} \\rangle^⊗ n} & [3mm] \\qwbundle{n} & \\gate[2]{ev1} & \\gate{ch1} & \\qw & \\gate[2]{ev2} & \\gate{ch2} & \\qw & \\qw & & & \\gate[2]{evL} & \\gate{chL} & \\qw \\lstick{| {0} \\rangle} & \\qw & \\qw & \\ctrl{1} & \\ctrl{1} & \\qw & \\ctrl{1} & \\ctrl{1} & \\qw & \\cdots & & \\qw & \\ctrl{1} & \\qw \\lstick{| {0} \\rangle^⊗log L} & \\qwbundle{\\log L} & \\qw & \\octrl{1} & \\gate{+1} & \\octrl{1} & \\octrl{1} & \\gate{+1} & \\qw & & & \\octrl{1} & \\octrl{1} & \\qw \\lstick{ } & \\qw & \\qw & \\gate{0\\lor1\\lor2}\\vqw{1} & \\qw & \\qw & \\gate{0\\lor1\\lor2}\\vqw{1} & \\qw & \\qw & & & \\qw & \\gate{0\\lor1\\lor2}\\vqw{1} & \\qw \\end{quantikz} } \\end{center} The quantum implementation of a single Sch\"oning's step for a general implementation of the partial Groverization of Sch\"oning's algorithm. The evj gates evaluate the jth clause on the corresponding variables and the controlledgates containing chi and 012 act on all the registers and check if the jth clause is the first violated clause and if so, flip one of three variables in it based on the randomness provided by the ifstatement, 012. Here 012 represents a triple controlledgate where the control qutrit is the subspaces of the computational basis (visualized in figure ). The log L auxiliary qubits are needed for uncomputation.",
                            "matches": []
                        },
                        {
                            "leaf id": 212,
                            "key": "doc/body/sec4/figure4",
                            "block type": "figure",
                            "content": "t] {\\textwidth} \\resizebox{\\textwidth}{!}{ \\begin{quantikz} \\lstick{| {0} \\rangle} & \\gate[3]{chj} & \\qw & [3.3mm] \\lstick{| {0} \\rangle} & \\qw & \\qw & [3.3mm] \\lstick{| {0} \\rangle} & \\qw & \\qw & \\lstick{| {0} \\rangle} & \\ctrl{1} & \\qw & \\lstick{| {0} \\rangle} & \\octrl{3} &\\qw & \\lstick{ } & \\gate{0\\lor1\\lor2}\\vqw{1} &\\qw \\end{quantikz} = \\begin{quantikz} \\lstick{| {0} \\rangle} & \\gateX & \\qw & \\qw & \\qw& \\lstick{| {0} \\rangle} & \\qw & \\gateX & \\qw & \\qw& \\lstick{| {0} \\rangle} & \\qw & \\qw & \\gateX & \\qw& \\lstick{| {0} \\rangle} & \\ctrl{3} & \\ctrl{2} & \\ctrl{1} & \\qw & \\lstick{| {0} \\rangle} & \\octrl{1} & \\octrl{1} & \\octrl{1} &\\qw & \\lstick{ } & \\gate{0}\\vqw{1} & \\gate{1}\\vqw{1} & \\gate{2}\\vqw{1} & \\qw & \\end{quantikz} \\begin{quantikz} \\lstick{| {0} \\rangle} & \\gateX & \\qw & \\qw & \\qw \\lstick{| {0} \\rangle} & \\qw & \\gateX & \\qw & \\qw \\lstick{| {0} \\rangle} & \\qw & \\qw & \\gateX & \\qw \\lstick{| {0} \\rangle} & \\ctrl{3} & \\ctrl{2} & \\ctrl{1} & \\qw& \\lstick{| {0} \\rangle} & \\octrl{3} & \\octrl{2} &\\octrl{1} &\\qw \\lstick{r} & \\gate{0}\\vcw{1} & \\gate{1}\\vcw{1} & \\gate{2}\\vcw{1}&\\qw [.66cm] \\lstick{} &\\qw & \\qw & \\qw & \\qw & \\end{quantikz} } Implementation of the variable flips of Sch\"oning's walk within amplitude amplification. Here, xi1, xi2 and xi3 are the variables of the jth clause. The 012 block represents a triple controlledgate where the control qutrit is the subspaces of the basis | {0} \\rangle,| {0} \\rangle,| {0} \\rangle. For the GI algorithm, the walk randomness can be provided by fixing a random number r ∈0,1,2 for every walk step.",
                            "leftover": "t] {\\textwidth} \\resizebox{\\textwidth}{!}{ \\begin{quantikz} \\lstick{| {0} \\rangle} & \\gate[3]{chj} & \\qw & [3.3mm] \\lstick{| {0} \\rangle} & \\qw & \\qw & [3.3mm] \\lstick{| {0} \\rangle} & \\qw & \\qw & \\lstick{| {0} \\rangle} & \\ctrl{1} & \\qw & \\lstick{| {0} \\rangle} & \\octrl{3} &\\qw & \\lstick{ } & \\gate{0\\lor1\\lor2}\\vqw{1} &\\qw \\end{quantikz} = \\begin{quantikz} \\lstick{| {0} \\rangle} & \\gateX & \\qw & \\qw & \\qw& \\lstick{| {0} \\rangle} & \\qw & \\gateX & \\qw & \\qw& \\lstick{| {0} \\rangle} & \\qw & \\qw & \\gateX & \\qw& \\lstick{| {0} \\rangle} & \\ctrl{3} & \\ctrl{2} & \\ctrl{1} & \\qw & \\lstick{| {0} \\rangle} & \\octrl{1} & \\octrl{1} & \\octrl{1} &\\qw & \\lstick{ } & \\gate{0}\\vqw{1} & \\gate{1}\\vqw{1} & \\gate{2}\\vqw{1} & \\qw & \\end{quantikz} \\begin{quantikz} \\lstick{| {0} \\rangle} & \\gateX & \\qw & \\qw & \\qw \\lstick{| {0} \\rangle} & \\qw & \\gateX & \\qw & \\qw \\lstick{| {0} \\rangle} & \\qw & \\qw & \\gateX & \\qw \\lstick{| {0} \\rangle} & \\ctrl{3} & \\ctrl{2} & \\ctrl{1} & \\qw& \\lstick{| {0} \\rangle} & \\octrl{3} & \\octrl{2} &\\octrl{1} &\\qw \\lstick{r} & \\gate{0}\\vcw{1} & \\gate{1}\\vcw{1} & \\gate{2}\\vcw{1}&\\qw [.66cm] \\lstick{} &\\qw & \\qw & \\qw & \\qw & \\end{quantikz} } Implementation of the variable flips of Sch\"oning's walk within amplitude amplification. Here, xi1, xi2 and xi3 are the variables of the jth clause. The 012 block represents a triple controlledgate where the control qutrit is the subspaces of the basis | {0} \\rangle,| {0} \\rangle,| {0} \\rangle. For the GI algorithm, the walk randomness can be provided by fixing a random number r ∈0,1,2 for every walk step.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec5",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 213,
                            "key": "doc/body/sec5/tit",
                            "block type": "title",
                            "content": "Summary & Outlook",
                            "leftover": "Summary & Outlook",
                            "matches": []
                        },
                        {
                            "leaf id": 214,
                            "key": "doc/body/sec5/txl0",
                            "block type": "txl",
                            "content": "This work considers hybrid schemes for searchbased quantum algorithms, with the aim to allow for parallelizability, and to reduce the need for long coherence times. The basic gist is to partition the randomness of an underlying classical probabilistic algorithm into a part that is subject to Grover search, while the rest is sampled classically. Such 'partial Groverizations' allow for parallelization of the classical sampling, as well as enable adaption to available coherence times. We consider exponentialtime algorithms, why our analysis focuses on the asymptotic runtime rates and coherencetime rates. We argue that these two types of rates are bounded by a general tradeoff relation that no hybridscheme can beat. For our concrete analysis, we consider hybrid schemes based on Sch\"oning's algorithm, where the latter solves 3SAT (or more generally kSAT) problems by random walks in the space of assignments. The walkprocedure allows for several partial Groverizationschemes. We determine the corresponding runtimes and coherencetimes of these schemes, and demonstrate saturation of the general tradeoff relation. Many of these partial Groverizations intuitively lend themselves for efficient circuit implementations, and we provide the main building blocks of these. On a more speculative note, we present numerical evidence that the GI scheme can be partially derandomized, in the sense that a single 'typical' instance of the classical randomness of the walk appears to mimic the effects of the repeated sampling. This would open for an additional flexibility in the implementation of these hybridschemes, still maintaining the optional tradeoff.",
                            "leftover": "This work considers hybrid schemes for searchbased quantum algorithms, with the aim to allow for parallelizability, and to reduce the need for long coherence times. The basic gist is to partition the randomness of an underlying classical probabilistic algorithm into a part that is subject to Grover search, while the rest is sampled classically. Such 'partial Groverizations' allow for parallelization of the classical sampling, as well as enable adaption to available coherence times. We consider exponentialtime algorithms, why our analysis focuses on the asymptotic runtime rates and coherencetime rates. We argue that these two types of rates are bounded by a general tradeoff relation that no hybridscheme can beat. For our concrete analysis, we consider hybrid schemes based on Sch\"oning's algorithm, where the latter solves 3SAT (or more generally kSAT) problems by random walks in the space of assignments. The walkprocedure allows for several partial Groverizationschemes. We determine the corresponding runtimes and coherencetimes of these schemes, and demonstrate saturation of the general tradeoff relation. Many of these partial Groverizations intuitively lend themselves for efficient circuit implementations, and we provide the main building blocks of these. On a more speculative note, we present numerical evidence that the GI scheme can be partially derandomized, in the sense that a single 'typical' instance of the classical randomness of the walk appears to mimic the effects of the repeated sampling. This would open for an additional flexibility in the implementation of these hybridschemes, still maintaining the optional tradeoff.",
                            "matches": []
                        },
                        {
                            "leaf id": 215,
                            "key": "doc/body/sec5/txl1",
                            "block type": "txl",
                            "content": "In this investigation, we have focused on partial Groverizations of Sch\"oning's algorithm. However, this approach should in principle be applicable to any classical probabilistic search scheme, since it essentially only rests on partitions of the underlying randomness. The main concern would be to find 'natural' partitions that are algorithmically accessible, in the sense that the partial Groverization can be implemented efficiently. Explicit runtime and coherencetime rates would also require a classical scheme, as well as partitions, that are sufficiently tractable for analysis, unless one would resort to numerical estimates.",
                            "leftover": "In this investigation, we have focused on partial Groverizations of Sch\"oning's algorithm. However, this approach should in principle be applicable to any classical probabilistic search scheme, since it essentially only rests on partitions of the underlying randomness. The main concern would be to find 'natural' partitions that are algorithmically accessible, in the sense that the partial Groverization can be implemented efficiently. Explicit runtime and coherencetime rates would also require a classical scheme, as well as partitions, that are sufficiently tractable for analysis, unless one would resort to numerical estimates.",
                            "matches": []
                        },
                        {
                            "leaf id": 216,
                            "key": "doc/body/sec5/txl2",
                            "block type": "txl",
                            "content": "The partial derandomization of GIscheme that is suggested by our numerical explorations, would deserve further investigations. In particular, the question is to what extent, and in what sense, the hypothetical relation would be true. Moreover, one may ask if something similar also would apply to tional GI. For numerical investigations, it would be relevant to extend to larger Hamming distances, further classes of 3SAT instances, as well as problem sizes. This would likely involve challenges to design reliable numerical estimates, since exact calculations by the very nature of the problem quickly becomes intractable. For purely analytical approaches, some notion of concentration of measure of walks, would be interesting.",
                            "leftover": "The partial derandomization of GIscheme that is suggested by our numerical explorations, would deserve further investigations. In particular, the question is to what extent, and in what sense, the hypothetical relation would be true. Moreover, one may ask if something similar also would apply to tional GI. For numerical investigations, it would be relevant to extend to larger Hamming distances, further classes of 3SAT instances, as well as problem sizes. This would likely involve challenges to design reliable numerical estimates, since exact calculations by the very nature of the problem quickly becomes intractable. For purely analytical approaches, some notion of concentration of measure of walks, would be interesting.",
                            "matches": []
                        },
                        {
                            "leaf id": 217,
                            "key": "doc/body/sec5/txl3",
                            "block type": "txl",
                            "content": "In the spirit of we have in this investigation employed 'the walk on ' as a model of the true Sch\"oningprocedure. In Appendix (see also ) we in additionally provide bounds for the true rates of Sch\"oningprocedure and the GWprocedure, in terms of the mirroring processes on . It would be relevant to obtain similar bounds also for the GIprocess, as well as for the various tional schemes.",
                            "leftover": "In the spirit of we have in this investigation employed 'the walk on ' as a model of the true Sch\"oningprocedure. In Appendix (see also ) we in additionally provide bounds for the true rates of Sch\"oningprocedure and the GWprocedure, in terms of the mirroring processes on . It would be relevant to obtain similar bounds also for the GIprocess, as well as for the various tional schemes.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec6",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 218,
                            "key": "doc/body/sec6/tit",
                            "block type": "title",
                            "content": "Acknowledgement",
                            "leftover": "Acknowledgement",
                            "matches": []
                        },
                        {
                            "leaf id": 219,
                            "key": "doc/body/sec6/txl0",
                            "block type": "txl",
                            "content": "We thank Phillip Keldenich for kindly providing us with the SAT instance that was used for numerical simulations resulted in figure (). We acknowledge support from Bundesministerium für Bildung und Forschung  BMBF under project QuBRA. The UzK team was also supported by Germany's Excellence Strategy – Cluster of Excellence Matter and Light for Quantum Computing (ML4Q) EXC 2004/1 (390534769).",
                            "leftover": "We thank Phillip Keldenich for kindly providing us with the SAT instance that was used for numerical simulations resulted in figure (). We acknowledge support from Bundesministerium für Bildung und Forschung  BMBF under project QuBRA. The UzK team was also supported by Germany's Excellence Strategy – Cluster of Excellence Matter and Light for Quantum Computing (ML4Q) EXC 2004/1 (390534769).",
                            "matches": []
                        },
                        {
                            "leaf id": 220,
                            "key": "doc/body/sec6/thebibliography1",
                            "block type": "thebibliography",
                            "content": "99} \\bibitem{Schoening99} U. Sch\"oning, A probabilistic algorithm for kSAT and constraint satisfaction problems, in Proceedings of the 40th Annual Symposium on Foundations of Computer Science (IEEE, New York, 1999). \\bibitem{SchoeningToranBook} U. Sch\"oning and J. Tor\\'an, The Satisfiability Problem: Algorithms and Analyses (Lehmanns, Berlin, 2013). \\bibitem{Grover96} L. K. Grover, A fast quantum mechanical algorithm for database search, in Proceedings of the 28th ACM Annual Symposium on the Theory of Computing, STOC 96, p. 212 (ACM, NewYork, 1996). \\bibitem{Ambainis04} A. Ambainis, Quantum search algorithms, ACM SIGACT News, { 35}, 22 (2004). \\bibitem{Dunjko18} V. Dunjko, Y. Ge and J. I. Cirac, Computational speedups using small quantum devices, PRL { 121}, 250501 (2018). \\bibitem{SwissPhDThesis} R.A. Moser, Exact Algorithms for Constraint Satisfaction Problems, Doctoral thesis, ETH Zürich (2012) \\bibitem{SATtransition} P. Cheeseman, B. Kanefsky and W.M. Taylor, Where the Really Hard Problems Are. in Proceedings of the 12th international joint conference on Artificial intelligence  Volume 1, Pages 331–337 (1991) \\bibitem{cover} T. M. Cover and J. A. Thomas, Elements of Information Theory, 2nd Edition (WileyInterscience, New Jersey, 2006) \\bibitem{ourdata} V.\\ Eshaghian, S.\\ Wilkening, J.\\ {\\AA}berg, D.\\ Gross, Data for explicit runtimes for hybrid SATsolvers, https://github.com/SoerenWilkening/QuantumSchoening. \\bibitem{callen} H. Callen, Thermodynamics and an introduction to thermostatistics, John Wiley, New York, 1985. \\bibitem{philippprivatecommutation}{Dr. Phillip Keldenich, personal communication, March 2024.}",
                            "leftover": "99} \\bibitem{Schoening99} U. Sch\"oning, A probabilistic algorithm for kSAT and constraint satisfaction problems, in Proceedings of the 40th Annual Symposium on Foundations of Computer Science (IEEE, New York, 1999). \\bibitem{SchoeningToranBook} U. Sch\"oning and J. Tor\\'an, The Satisfiability Problem: Algorithms and Analyses (Lehmanns, Berlin, 2013). \\bibitem{Grover96} L. K. Grover, A fast quantum mechanical algorithm for database search, in Proceedings of the 28th ACM Annual Symposium on the Theory of Computing, STOC 96, p. 212 (ACM, NewYork, 1996). \\bibitem{Ambainis04} A. Ambainis, Quantum search algorithms, ACM SIGACT News, { 35}, 22 (2004). \\bibitem{Dunjko18} V. Dunjko, Y. Ge and J. I. Cirac, Computational speedups using small quantum devices, PRL { 121}, 250501 (2018). \\bibitem{SwissPhDThesis} R.A. Moser, Exact Algorithms for Constraint Satisfaction Problems, Doctoral thesis, ETH Zürich (2012) \\bibitem{SATtransition} P. Cheeseman, B. Kanefsky and W.M. Taylor, Where the Really Hard Problems Are. in Proceedings of the 12th international joint conference on Artificial intelligence  Volume 1, Pages 331–337 (1991) \\bibitem{cover} T. M. Cover and J. A. Thomas, Elements of Information Theory, 2nd Edition (WileyInterscience, New Jersey, 2006) \\bibitem{ourdata} V.\\ Eshaghian, S.\\ Wilkening, J.\\ {\\AA}berg, D.\\ Gross, Data for explicit runtimes for hybrid SATsolvers, https://github.com/SoerenWilkening/QuantumSchoening. \\bibitem{callen} H. Callen, Thermodynamics and an introduction to thermostatistics, John Wiley, New York, 1985. \\bibitem{philippprivatecommutation}{Dr. Phillip Keldenich, personal communication, March 2024.}",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec7",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 221,
                            "key": "doc/body/sec7/tit",
                            "block type": "title",
                            "content": "From the true Sch\"oningprocess to the Markov process on",
                            "leftover": "From the true Sch\"oningprocess to the Markov process on",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec7/sub0",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 222,
                                    "key": "doc/body/sec7/sub0/tit",
                                    "block type": "title",
                                    "content": "The purpose of this appendix",
                                    "leftover": "The purpose of this appendix",
                                    "matches": []
                                },
                                {
                                    "leaf id": 223,
                                    "key": "doc/body/sec7/sub0/txl0",
                                    "block type": "txl",
                                    "content": "For the calculation of rates, we replace the genuine searches of solutions for 3SATproblems (the 'true Sch\"oning process'), with a Markovian random walk on the 'Hamming distance' (although we strictly speaking consider a walk on ). This is analogous to Sch\"onings analysis of the performance of Sch\"onings algorithm, where it is argued that this substituteprocess yields an upper bound on the rates of the runtime of the algorithm. The purpose of this appendix is to give a more detailed argument for why the success probability of Sch\"onings algorithm is lower bounded by the successprobability of the substitute walk on . The reader may also wish to consult for a previous analysis along these lines. Apart from obtaining from bounding the success probability for the true Sch\"oningprocess, we also provide the analogous bound for the GW process.",
                                    "leftover": "For the calculation of rates, we replace the genuine searches of solutions for 3SATproblems (the 'true Sch\"oning process'), with a Markovian random walk on the 'Hamming distance' (although we strictly speaking consider a walk on ). This is analogous to Sch\"onings analysis of the performance of Sch\"onings algorithm, where it is argued that this substituteprocess yields an upper bound on the rates of the runtime of the algorithm. The purpose of this appendix is to give a more detailed argument for why the success probability of Sch\"onings algorithm is lower bounded by the successprobability of the substitute walk on . The reader may also wish to consult for a previous analysis along these lines. Apart from obtaining from bounding the success probability for the true Sch\"oningprocess, we also provide the analogous bound for the GW process.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub1",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 224,
                                    "key": "doc/body/sec7/sub1/tit",
                                    "block type": "title",
                                    "content": "The Sch\"oningprocess",
                                    "leftover": "The Sch\"oningprocess",
                                    "matches": []
                                },
                                {
                                    "leaf id": 225,
                                    "key": "doc/body/sec7/sub1/txl0",
                                    "block type": "txl",
                                    "content": "As described in the main text, the 3SAT problem consists of a collection of clauses C1,…, CL on n binary variables, where each clause is of the form Cj = l0^(j)∨ l1^(j)∨ l2^(j), and where each of the literals l0^(j), l1^(j), l2^(j) is one of the binary variables, or its negation. The 3SAT formula is the conjunction of all the given clauses, C := ∧j=1^LCj, and the task is to determine whether there exists an assignment x∈0,1^× n of the n binary variables, which satisfies C. In the following analysis we assume that C either has a unique satisfying assignment x^⋆∈0,1^× n, or alternatively, that x^⋆ is selected among a set of solutions. Sch\"onings procedure can be regarded as a stochastic process (xl)l=0^m with xl ∈0,1^× n.",
                                    "leftover": "As described in the main text, the 3SAT problem consists of a collection of clauses C1,…, CL on n binary variables, where each clause is of the form Cj = l0^(j)∨ l1^(j)∨ l2^(j), and where each of the literals l0^(j), l1^(j), l2^(j) is one of the binary variables, or its negation. The 3SAT formula is the conjunction of all the given clauses, C := ∧j=1^LCj, and the task is to determine whether there exists an assignment x∈0,1^× n of the n binary variables, which satisfies C. In the following analysis we assume that C either has a unique satisfying assignment x^⋆∈0,1^× n, or alternatively, that x^⋆ is selected among a set of solutions. Sch\"onings procedure can be regarded as a stochastic process (xl)l=0^m with xl ∈0,1^× n.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 226,
                                    "key": "doc/body/sec7/sub1/txl1",
                                    "block type": "txl",
                                    "content": "The process is initialized by a random assignment x0 of the bit string, drawn uniformly over all of 0,1^× n. On this state it checks all the clauses C1,…,CL (according to a predetermined order). If all are satisfied, then the initial string satisfies C and the algorithm terminates. Otherwise, it finds the first unsatisfied clause, and randomly negates one of the three variables corresponding to the literals of that clause. The algorithm continues according to this random walk until it either finds a satisfying assignment, or it reaches a predetermined terminationtime K. For our purposes, it is convenient to think of the state xl of the process as a function of a collection of random variables. The initialization is represented by the random variable A, which takes values in 0,1^× n. The randomness in the walk is captured by the variables B = (B1,…, Bm) be random variables where each Bl takes values in 0,1,2 (and thus B takes values in 0,1,2^× m). Hence, Bl represents one of the three possible choices of which literal to flip at step l. We assume that A,B1,⋯, Bm are independent and uniformly distributed, i.e., for b = (b1,…, bm) we have",
                                    "leftover": "The process is initialized by a random assignment x0 of the bit string, drawn uniformly over all of 0,1^× n. On this state it checks all the clauses C1,…,CL (according to a predetermined order). If all are satisfied, then the initial string satisfies C and the algorithm terminates. Otherwise, it finds the first unsatisfied clause, and randomly negates one of the three variables corresponding to the literals of that clause. The algorithm continues according to this random walk until it either finds a satisfying assignment, or it reaches a predetermined terminationtime K. For our purposes, it is convenient to think of the state xl of the process as a function of a collection of random variables. The initialization is represented by the random variable A, which takes values in 0,1^× n. The randomness in the walk is captured by the variables B = (B1,…, Bm) be random variables where each Bl takes values in 0,1,2 (and thus B takes values in 0,1,2^× m). Hence, Bl represents one of the three possible choices of which literal to flip at step l. We assume that A,B1,⋯, Bm are independent and uniformly distributed, i.e., for b = (b1,…, bm) we have",
                                    "matches": []
                                },
                                {
                                    "leaf id": 227,
                                    "key": "doc/body/sec7/sub1/equation2",
                                    "block type": "equation",
                                    "content": "P(A= a,B=b) = P(A=a)P(B=b) = P(A = a)P(B1 = b1)⋯P(Bm = bm), P(A = a) = 12^n, ∀a∈0,1^×n P(Bl=bl) = 13, ∀bl∈0,1,2.",
                                    "leftover": "P(A= a,B=b) = P(A=a)P(B=b) = P(A = a)P(B1 = b1)⋯P(Bm = bm), P(A = a) = 12^n, ∀a∈0,1^×n P(Bl=bl) = 13, ∀bl∈0,1,2.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 228,
                                    "key": "doc/body/sec7/sub1/txl3",
                                    "block type": "txl",
                                    "content": "Hence, we can write the Sch\"oning process as (xl)l = (xl(A,B))l, where",
                                    "leftover": "Hence, we can write the Sch\"oning process as (xl)l = (xl(A,B))l, where",
                                    "matches": []
                                },
                                {
                                    "leaf id": 229,
                                    "key": "doc/body/sec7/sub1/equation4",
                                    "block type": "equation",
                                    "content": "x0(a,b) := a,",
                                    "leftover": "x0(a,b) := a,",
                                    "matches": []
                                },
                                {
                                    "leaf id": 230,
                                    "key": "doc/body/sec7/sub1/txl5",
                                    "block type": "txl",
                                    "content": "i.e., a the initial state. At the l:th step of Sch\"oning's process is based on the state xl1 of the previous step. On this state, all the clauses C1,…,CL (according to a predetermined order) are checked. If all are satisfied, then xl1 = x^⋆ and the process remains in that state, i.e., xl = x^⋆. (In other words, t x^⋆ is an absorbing state for the Sch\"oningprocess.) Otherwise, it finds the first unsatisfied clause, which we refer to as Cjl. The selected clause, Cjl, contains the three literals (l0^(j),l1^(j),l2^(j)). The process constructs xl by negating the variable corresponding to literal l^(j)bl. In other words, it is the l:th component of b that determines which of these three choices that is selected. One may note that the process, by construction, satisfies",
                                    "leftover": "i.e., a the initial state. At the l:th step of Sch\"oning's process is based on the state xl1 of the previous step. On this state, all the clauses C1,…,CL (according to a predetermined order) are checked. If all are satisfied, then xl1 = x^⋆ and the process remains in that state, i.e., xl = x^⋆. (In other words, t x^⋆ is an absorbing state for the Sch\"oningprocess.) Otherwise, it finds the first unsatisfied clause, which we refer to as Cjl. The selected clause, Cjl, contains the three literals (l0^(j),l1^(j),l2^(j)). The process constructs xl by negating the variable corresponding to literal l^(j)bl. In other words, it is the l:th component of b that determines which of these three choices that is selected. One may note that the process, by construction, satisfies",
                                    "matches": []
                                },
                                {
                                    "leaf id": 231,
                                    "key": "doc/body/sec7/sub1/equation6",
                                    "block type": "equation",
                                    "content": "xl(a,b) = xl(a,b1,…,bl).",
                                    "leftover": "xl(a,b) = xl(a,b1,…,bl).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 232,
                                    "key": "doc/body/sec7/sub1/txl7",
                                    "block type": "txl",
                                    "content": "Hence, the value of xl(a,b) only depends on the values of b1,…, bl, not any of the 'later' variables bl+1,bl+1,…. One may also note that A,B1,B2,…, BK encompasses all the randomness in the process. In other words, the state xl is uniquely determined by a,b1,…,bl.",
                                    "leftover": "Hence, the value of xl(a,b) only depends on the values of b1,…, bl, not any of the 'later' variables bl+1,bl+1,…. One may also note that A,B1,B2,…, BK encompasses all the randomness in the process. In other words, the state xl is uniquely determined by a,b1,…,bl.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub2",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 233,
                                    "key": "doc/body/sec7/sub2/tit",
                                    "block type": "title",
                                    "content": "The proof idea",
                                    "leftover": "The proof idea",
                                    "matches": []
                                },
                                {
                                    "leaf id": 234,
                                    "key": "doc/body/sec7/sub2/txl0",
                                    "block type": "txl",
                                    "content": "As described above, the true Sch\"oningprocess (xl)l is a walk on bitstrings. However, for the analysis of the optimal rates, we follow in the steps of Sch\"oning, and instead focus on the Hammingdistance to the (selected) solution x^⋆. In principle, nothing prevents us from projecting the state xl of the Sch\"oningprocess, to the Hamming distance dH(xl,x^⋆) (i.e. projecting onto ). However, this would generally yield a process that would be no easier to analyze than the original Sch\"oningprocess. One may for example note that although Sch\"oningsprocess (xl)l is Markovian on the space of bitstrings, one cannot generally expect its projection (dH(xl,x^⋆))l to be Markovian on . The general idea for the analysis is to replace (via a coupling) the true projection (dH(xl,x^⋆))l with another process (d̃l)l on, which is Markovian and which moreover upperbounds the true Hammingdistance, dH(xl,x^⋆)≤d̃l. One may note that the Sch\"oningprocess is 'successful' if it finds the solution x^⋆. Hence, we can express the success probability at step l as P(xl = x^⋆) = P(dH(xl,x^⋆) = 0). From the bound dH(xl,x^⋆)≤d̃l it follows that P(xl = x^⋆) ≥ P(d̃l = 0). In other words, the successprobability of the Sch\"oningprocess is lowerbounded by the probability that the substituteprocess d̃l reaches 0. The fact that (d̃l)l is Markovian makes the analysis more tractable. However, the value 0 corresponds to an absorbing boundary. (If we find the solution at an earlier stage, we should terminate the process rather than walking on.) To further ease the analysis, we remove this boundary and instead introduce yet another walk (dl)l on, which we regard as 'successful' whenever dl≤ 0. For this process we moreover establish the bound P(d̃l = 0)≥ P(dl≤ 0), and thus P(xl = x^⋆)≥ P(dl≤ 0). By the trivial bound P(dl≤ 0)≥ P(dl = 0), we thus ultimately get the bound P(xl = x^⋆)≥ P(dl = 0). For the calculation of the optimal rates, our starting point is an expression for P(dl = 0). By the inequality P(xl = x^⋆)≥ P(dl = 0) it follows that the calculated rates are upper bounds to the true rates of the Sch\"oningprocess.",
                                    "leftover": "As described above, the true Sch\"oningprocess (xl)l is a walk on bitstrings. However, for the analysis of the optimal rates, we follow in the steps of Sch\"oning, and instead focus on the Hammingdistance to the (selected) solution x^⋆. In principle, nothing prevents us from projecting the state xl of the Sch\"oningprocess, to the Hamming distance dH(xl,x^⋆) (i.e. projecting onto ). However, this would generally yield a process that would be no easier to analyze than the original Sch\"oningprocess. One may for example note that although Sch\"oningsprocess (xl)l is Markovian on the space of bitstrings, one cannot generally expect its projection (dH(xl,x^⋆))l to be Markovian on . The general idea for the analysis is to replace (via a coupling) the true projection (dH(xl,x^⋆))l with another process (d̃l)l on, which is Markovian and which moreover upperbounds the true Hammingdistance, dH(xl,x^⋆)≤d̃l. One may note that the Sch\"oningprocess is 'successful' if it finds the solution x^⋆. Hence, we can express the success probability at step l as P(xl = x^⋆) = P(dH(xl,x^⋆) = 0). From the bound dH(xl,x^⋆)≤d̃l it follows that P(xl = x^⋆) ≥ P(d̃l = 0). In other words, the successprobability of the Sch\"oningprocess is lowerbounded by the probability that the substituteprocess d̃l reaches 0. The fact that (d̃l)l is Markovian makes the analysis more tractable. However, the value 0 corresponds to an absorbing boundary. (If we find the solution at an earlier stage, we should terminate the process rather than walking on.) To further ease the analysis, we remove this boundary and instead introduce yet another walk (dl)l on, which we regard as 'successful' whenever dl≤ 0. For this process we moreover establish the bound P(d̃l = 0)≥ P(dl≤ 0), and thus P(xl = x^⋆)≥ P(dl≤ 0). By the trivial bound P(dl≤ 0)≥ P(dl = 0), we thus ultimately get the bound P(xl = x^⋆)≥ P(dl = 0). For the calculation of the optimal rates, our starting point is an expression for P(dl = 0). By the inequality P(xl = x^⋆)≥ P(dl = 0) it follows that the calculated rates are upper bounds to the true rates of the Sch\"oningprocess.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub3",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 235,
                                    "key": "doc/body/sec7/sub3/tit",
                                    "block type": "title",
                                    "content": "Constructing a walk (d̃l)l on such that dH(xl,x^⋆)≤d̃l",
                                    "leftover": "Constructing a walk (d̃l)l on such that dH(xl,x^⋆)≤d̃l",
                                    "matches": []
                                },
                                {
                                    "leaf id": 236,
                                    "key": "doc/body/sec7/sub3/txl0",
                                    "block type": "txl",
                                    "content": "Related to the Sch\"oningprocess (xl)l, we here wish to construct another process (d̃l)l, where d̃l takes values in for all l∈, and is such that",
                                    "leftover": "Related to the Sch\"oningprocess (xl)l, we here wish to construct another process (d̃l)l, where d̃l takes values in for all l∈, and is such that",
                                    "matches": []
                                },
                                {
                                    "leaf id": 237,
                                    "key": "doc/body/sec7/sub3/equation1",
                                    "block type": "equation",
                                    "content": "dH(xl(a,b1,…, bl),x^⋆) ≤d̃l(a,b1,…, bl), ∀a∈0,1, ∀b∈0,1,2^×m, l = 0,1,2,…,m.",
                                    "leftover": "dH(xl(a,b1,…, bl),x^⋆) ≤d̃l(a,b1,…, bl), ∀a∈0,1, ∀b∈0,1,2^×m, l = 0,1,2,…,m.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 238,
                                    "key": "doc/body/sec7/sub3/txl2",
                                    "block type": "txl",
                                    "content": "In other words, we want to make sure that d̃l always is an upper bound to the Hamming distance between xl and x^⋆. This requires a considerable coordination between the two processes. In particular, whenever xl moves in the 'wrong' direction (i.e, increases the Hamming distance to x^⋆) then d̃l also has to increase. To this end, we consider the list of clauses C1,…, CL. For each clause Cj it is the case that Cj(x^⋆) = 1. Hence, for each j, at least one of the literals l0^(j),l1^(j),l2^(j) is satisfied by x^⋆. Among these satisfied clauses we select one of these satisfied literals, and let rj∈0,1,2 be its index. In other words, we are guaranteed that lj^(rj)(x^⋆) = 1.",
                                    "leftover": "In other words, we want to make sure that d̃l always is an upper bound to the Hamming distance between xl and x^⋆. This requires a considerable coordination between the two processes. In particular, whenever xl moves in the 'wrong' direction (i.e, increases the Hamming distance to x^⋆) then d̃l also has to increase. To this end, we consider the list of clauses C1,…, CL. For each clause Cj it is the case that Cj(x^⋆) = 1. Hence, for each j, at least one of the literals l0^(j),l1^(j),l2^(j) is satisfied by x^⋆. Among these satisfied clauses we select one of these satisfied literals, and let rj∈0,1,2 be its index. In other words, we are guaranteed that lj^(rj)(x^⋆) = 1.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 239,
                                    "key": "doc/body/sec7/sub3/txl3",
                                    "block type": "txl",
                                    "content": "As already described above, the Sch\"oningprocess (xl(a,b))l is uniquely determined by (a,b1,…,bl), and does in turn uniquely determines the unsatisfied clauses Cjl, as long as xl(a,b1,…, bl)≠ x^⋆. Consequently, it also uniquely determines a sequence of 'selected' literals rjl, whenever xl(a,b1,…, bl)≠ x^⋆. For each l ∈ 1,2,…, we define a mapping (a,b1,… bl1)↦ fl(a,b1,…,bl1)∈0,1,2 by",
                                    "leftover": "As already described above, the Sch\"oningprocess (xl(a,b))l is uniquely determined by (a,b1,…,bl), and does in turn uniquely determines the unsatisfied clauses Cjl, as long as xl(a,b1,…, bl)≠ x^⋆. Consequently, it also uniquely determines a sequence of 'selected' literals rjl, whenever xl(a,b1,…, bl)≠ x^⋆. For each l ∈ 1,2,…, we define a mapping (a,b1,… bl1)↦ fl(a,b1,…,bl1)∈0,1,2 by",
                                    "matches": []
                                },
                                {
                                    "leaf id": 240,
                                    "key": "doc/body/sec7/sub3/equation4",
                                    "block type": "equation",
                                    "content": "f1(a) := 0 if x0 ≡a = x^⋆, rj1 if x0≡a ≠x^⋆. . fl(a,b1,…,bl1) := 0 if xl1(a,b1,…, bl1) = x^⋆, rjl if xl1(a,b1,…, bl1) ≠x^⋆. . l = 2,3,…",
                                    "leftover": "f1(a) := 0 if x0 ≡a = x^⋆, rj1 if x0≡a ≠x^⋆. . fl(a,b1,…,bl1) := 0 if xl1(a,b1,…, bl1) = x^⋆, rjl if xl1(a,b1,…, bl1) ≠x^⋆. . l = 2,3,…",
                                    "matches": []
                                },
                                {
                                    "leaf id": 241,
                                    "key": "doc/body/sec7/sub3/txl5",
                                    "block type": "txl",
                                    "content": "The purpose of fl(a,b1,…,bl1) is to determine which value of bl that should correspond to a 'successful' move for the (d̃l)lprocess. More precisely, we define (d̃l(a,b))l by",
                                    "leftover": "The purpose of fl(a,b1,…,bl1) is to determine which value of bl that should correspond to a 'successful' move for the (d̃l)lprocess. More precisely, we define (d̃l(a,b))l by",
                                    "matches": []
                                },
                                {
                                    "leaf id": 242,
                                    "key": "doc/body/sec7/sub3/equation6",
                                    "block type": "equation",
                                    "content": "d̃0(a,b) := dH(x0(a,b),x^⋆) = dH(a,x^⋆), d̃l(a,b1,…, bl) := 0 if d̃l1(a,b1,…,bl1) = 0 d̃l1(a,b1,…, bl1) + 1 if d̃l1(a,b1,…, bl1) ≠0, bl ≠fl(a,b1,…, bl1) d̃l1(a,b1,…, bl1)  1 if d̃l1(a,b1,…, bl1) ≠0, bl = fl(a,b1,…,bl1) . l = 1,2,…",
                                    "leftover": "d̃0(a,b) := dH(x0(a,b),x^⋆) = dH(a,x^⋆), d̃l(a,b1,…, bl) := 0 if d̃l1(a,b1,…,bl1) = 0 d̃l1(a,b1,…, bl1) + 1 if d̃l1(a,b1,…, bl1) ≠0, bl ≠fl(a,b1,…, bl1) d̃l1(a,b1,…, bl1)  1 if d̃l1(a,b1,…, bl1) ≠0, bl = fl(a,b1,…,bl1) . l = 1,2,…",
                                    "matches": []
                                },
                                {
                                    "leaf id": 243,
                                    "key": "doc/body/sec7/sub3/txl7",
                                    "block type": "txl",
                                    "content": "In words, the first condition in the bracket means that 0 is an absorbing state, i.e., if d̃l(a,b) = 0 for some l, then d̃l'(a,b) = 0 for all l'≥ l. The other two cases make sure that the d̃l moves in 'coordination' with the Sch\"oningprocess (xl(a,b))l, in such a manner that it is guaranteed that dH(xl(a,b1,…,bl),x^⋆) does not increase above d̃l(a,b1,…,bl).",
                                    "leftover": "In words, the first condition in the bracket means that 0 is an absorbing state, i.e., if d̃l(a,b) = 0 for some l, then d̃l'(a,b) = 0 for all l'≥ l. The other two cases make sure that the d̃l moves in 'coordination' with the Sch\"oningprocess (xl(a,b))l, in such a manner that it is guaranteed that dH(xl(a,b1,…,bl),x^⋆) does not increase above d̃l(a,b1,…,bl).",
                                    "matches": []
                                },
                                {
                                    "leaf id": 244,
                                    "key": "doc/body/sec7/sub3/lemma8",
                                    "block type": "lemma",
                                    "content": "The Sch\"oning process (xl)l∈ and the process (d̃l)l∈ as defined by () and () satisfy \\begin{equation} dH\\big(xl(a,b{1},\\ldots,b{l}),x^{\\star}\\big) \\leq \\tilde{d}l(a,b{1},\\ldots,b{l}),\\quad \\forall a\\in{0,1}^{\\times n},\\quad \\forall b\\in{0,1,2}^{\\times l},\\quad l = 0,1,2,\\ldots. \\end{equation}",
                                    "leftover": "The Sch\"oning process (xl)l∈ and the process (d̃l)l∈ as defined by () and () satisfy \\begin{equation} dH\\big(xl(a,b{1},\\ldots,b{l}),x^{\\star}\\big) \\leq \\tilde{d}l(a,b{1},\\ldots,b{l}),\\quad \\forall a\\in{0,1}^{\\times n},\\quad \\forall b\\in{0,1,2}^{\\times l},\\quad l = 0,1,2,\\ldots. \\end{equation}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 245,
                                    "key": "doc/body/sec7/sub3/txl9",
                                    "block type": "txl",
                                    "content": "One may note that () holds for every single element in the eventspace, and Lemma does thus not depend on the actual probability distribution of A,B1,…, Bl. However, there are other steps in our proofs that do depend crucially on these variables being independent and uniformly distributed.",
                                    "leftover": "One may note that () holds for every single element in the eventspace, and Lemma does thus not depend on the actual probability distribution of A,B1,…, Bl. However, there are other steps in our proofs that do depend crucially on these variables being independent and uniformly distributed.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 246,
                                    "key": "doc/body/sec7/sub3/proof10",
                                    "block type": "proof",
                                    "content": "We first note that \\begin{equation} \\begin{split} x0(a,b) = a,\\quad \\tilde{d}0 = dH(a,x^{\\star}) \\end{split} \\end{equation} and thus () is satisfied for l=0 for all a,b. Now, assume that () holds for some l1,a,b. We have the following cases: \\begin{itemize} { Case xl1(a,b) = x^⋆:} Since we assume that x^⋆ is absorbing, it follows that xl(a,b) = x^⋆ and consequently dH(xl(a,b1,…,bl),x^⋆) = 0. Concerning d̃l1, we can distinguish yet two subcases: \\begin{itemize} { Case d̃l1(a,b1,…,bl1) = 0:} By construction (first case in ()) d̃l(a,b1,…,bl) = 0, and () is thus satisfied for l,a,b. { Case d̃l1(a,b1,…,bl1) ≠ 0:} Then d̃l1(a,b1,…,bl1) ≥ 1. Since the process d can change at most one step, it follows that d̃l1(a,b1,…,bl1) ≥ 0, and thus () is satisfied for l,a,b. \\end{itemize} { Case xl1(a,b) ≠ x^⋆:} Since we assume that () holds for l1,a,b it follows that d̃l1(a,b1,…,bl1) ≥ 1. Moreover, since xl1(a,b) ≠ x^⋆, we have fl(a,b1,…,bl1) = rjl. Again, we can distinguish two subcases: \\begin{itemize} { Case fl(a,b1,…,bl1) = bl:} In this case, the dprocess decreases one step. However, by construction rjl is one of the 'successful' flips for the Sch\"oningprocess, hence the xprocess also decreases one step. By assumption the inequality () is satisfied for l1,a,b, and since both the xprocess and the dprocess decrease one step, () remains satisfied for l,a,b. { Case fl(a,b1,…,bl1)≠ bl:} In this case, the dprocess increases one step. The xprocess may increase or decrease, but with at most one step, so () remains satisfied for l,a,b. \\end{itemize} \\end{itemize} By induction, we can conclude that () is satisfied for all l,a,b.",
                                    "leftover": "We first note that \\begin{equation} \\begin{split} x0(a,b) = a,\\quad \\tilde{d}0 = dH(a,x^{\\star}) \\end{split} \\end{equation} and thus () is satisfied for l=0 for all a,b. Now, assume that () holds for some l1,a,b. We have the following cases: \\begin{itemize} { Case xl1(a,b) = x^⋆:} Since we assume that x^⋆ is absorbing, it follows that xl(a,b) = x^⋆ and consequently dH(xl(a,b1,…,bl),x^⋆) = 0. Concerning d̃l1, we can distinguish yet two subcases: \\begin{itemize} { Case d̃l1(a,b1,…,bl1) = 0:} By construction (first case in ()) d̃l(a,b1,…,bl) = 0, and () is thus satisfied for l,a,b. { Case d̃l1(a,b1,…,bl1) ≠ 0:} Then d̃l1(a,b1,…,bl1) ≥ 1. Since the process d can change at most one step, it follows that d̃l1(a,b1,…,bl1) ≥ 0, and thus () is satisfied for l,a,b. \\end{itemize} { Case xl1(a,b) ≠ x^⋆:} Since we assume that () holds for l1,a,b it follows that d̃l1(a,b1,…,bl1) ≥ 1. Moreover, since xl1(a,b) ≠ x^⋆, we have fl(a,b1,…,bl1) = rjl. Again, we can distinguish two subcases: \\begin{itemize} { Case fl(a,b1,…,bl1) = bl:} In this case, the dprocess decreases one step. However, by construction rjl is one of the 'successful' flips for the Sch\"oningprocess, hence the xprocess also decreases one step. By assumption the inequality () is satisfied for l1,a,b, and since both the xprocess and the dprocess decrease one step, () remains satisfied for l,a,b. { Case fl(a,b1,…,bl1)≠ bl:} In this case, the dprocess increases one step. The xprocess may increase or decrease, but with at most one step, so () remains satisfied for l,a,b. \\end{itemize} \\end{itemize} By induction, we can conclude that () is satisfied for all l,a,b.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub4",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 247,
                                    "key": "doc/body/sec7/sub4/tit",
                                    "block type": "title",
                                    "content": "(d̃l)l is a Markov chain",
                                    "leftover": "(d̃l)l is a Markov chain",
                                    "matches": []
                                },
                                {
                                    "leaf id": 248,
                                    "key": "doc/body/sec7/sub4/txl0",
                                    "block type": "txl",
                                    "content": "In the following we wish to show that (d̃l)l is a Markov chain. Recall that both the genuine Sch\"oningprocess (xl)l, as well as the walk (d̃l)l, are determined by a sequence of 'walk variables' (Bl)l (and initialstate variable A). The Sch\"oningwalk itself is Markovian, but it is a priori not obvious that the process (d̃l)l also is Markovian, particularly since the lth step of the latter is determined by a complicated function of all the walkvariables up to the lth step, as described by (). However, in spite appearances, it turns out that () defines a mapping from the original set of random variables (Bl)l to a new set of variables (l)l, in such a manner that the change from d̃m1 to d̃m is determined by m, and only by m. Moreover, it turns out that (l)l is an iid sequence. Since all the l are independent, it follows that (d̃l)l must be a Markov chain. In order to show that the new sequence of variables (l)l is iid, what we actually do is to show that () induces a bijection on 0,1^× n×0,1,2^l. Since (A, (Bl)l) is uniformly distributed (see ()) it follows by the bijection that (A, (l)l) also is uniformly distributed, and thus in particular that (l)l is iid.",
                                    "leftover": "In the following we wish to show that (d̃l)l is a Markov chain. Recall that both the genuine Sch\"oningprocess (xl)l, as well as the walk (d̃l)l, are determined by a sequence of 'walk variables' (Bl)l (and initialstate variable A). The Sch\"oningwalk itself is Markovian, but it is a priori not obvious that the process (d̃l)l also is Markovian, particularly since the lth step of the latter is determined by a complicated function of all the walkvariables up to the lth step, as described by (). However, in spite appearances, it turns out that () defines a mapping from the original set of random variables (Bl)l to a new set of variables (l)l, in such a manner that the change from d̃m1 to d̃m is determined by m, and only by m. Moreover, it turns out that (l)l is an iid sequence. Since all the l are independent, it follows that (d̃l)l must be a Markov chain. In order to show that the new sequence of variables (l)l is iid, what we actually do is to show that () induces a bijection on 0,1^× n×0,1,2^l. Since (A, (Bl)l) is uniformly distributed (see ()) it follows by the bijection that (A, (l)l) also is uniformly distributed, and thus in particular that (l)l is iid.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub5",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 249,
                                    "key": "doc/body/sec7/sub5/tit",
                                    "block type": "title",
                                    "content": "A bijection",
                                    "leftover": "A bijection",
                                    "matches": []
                                },
                                {
                                    "leaf id": 250,
                                    "key": "doc/body/sec7/sub5/txl0",
                                    "block type": "txl",
                                    "content": "The following lemma introduces functions fs. Later, in the proof of Proposition, we will let these mappings be the functions fl(a,b1,…,bl1) in (). Since the latter are algorithmically defined, via the Sch\"oningprocess (xl)l, it is challenging to get a hold on the properties of these mappings. It is thus worth noting that (apart from domains and ranges) Lemma (and Lemma ) makes no assumptions on the properties of the mappings fs. Hence, our lack of control over the mappings fl(a,b1,…,bl1) will not be an issue in the subsequent proofs.",
                                    "leftover": "The following lemma introduces functions fs. Later, in the proof of Proposition, we will let these mappings be the functions fl(a,b1,…,bl1) in (). Since the latter are algorithmically defined, via the Sch\"oningprocess (xl)l, it is challenging to get a hold on the properties of these mappings. It is thus worth noting that (apart from domains and ranges) Lemma (and Lemma ) makes no assumptions on the properties of the mappings fs. Hence, our lack of control over the mappings fl(a,b1,…,bl1) will not be an issue in the subsequent proofs.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 251,
                                    "key": "doc/body/sec7/sub5/txl1",
                                    "block type": "txl",
                                    "content": "As preparation, we make the following observations.",
                                    "leftover": "As preparation, we make the following observations.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 252,
                                    "key": "doc/body/sec7/sub5/lemma2",
                                    "block type": "lemma",
                                    "content": "If t,t',r∈0,1,2, then \\begin{equation} (tr)mod\\, 3 = (t'r)mod\\, 3\\quad\\Leftrightarrow\\quad t = t'. \\end{equation} Moreover, if t,r∈0,1,2, then \\begin{equation} \\big((t+r)mod\\,3  r\\big)mod\\, 3 = t. \\end{equation}",
                                    "leftover": "If t,t',r∈0,1,2, then \\begin{equation} (tr)mod\\, 3 = (t'r)mod\\, 3\\quad\\Leftrightarrow\\quad t = t'. \\end{equation} Moreover, if t,r∈0,1,2, then \\begin{equation} \\big((t+r)mod\\,3  r\\big)mod\\, 3 = t. \\end{equation}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 253,
                                    "key": "doc/body/sec7/sub5/lemma3",
                                    "block type": "lemma",
                                    "content": "Let f1:0,1^× n→0,1,2 and fs:0,1^× n×0,1,2^× (s1)→0,1,2 for s = 2,…, l be given. Define the mapping 0,1^× n×0,1,2^× l∋ (b1,…, bl) ↦ Q(a,b1,…, bl) = (ã,b̃1,…, b̃l)∈0,1^× n×0,1,2^× l by \\begin{equation} \\begin{split} \\tilde{a} := & a, \\tilde{b}1 := & \\big(b1f1(a)\\big)mod\\, 3, \\tilde{b}2 := & \\big(b2f2(a,b1)\\big)mod\\, 3, \\tilde{b}3 := & \\big( b3f3(a,b1,b2)\\big)mod\\, 3, \\vdots & \\tilde{b}l := & \\big( blfl(a,b1,\\ldots,b{l1})\\big)mod\\, 3. \\end{split} \\end{equation} Then Q is a bijection on 0,1^× n×0,1,2^× l.",
                                    "leftover": "Let f1:0,1^× n→0,1,2 and fs:0,1^× n×0,1,2^× (s1)→0,1,2 for s = 2,…, l be given. Define the mapping 0,1^× n×0,1,2^× l∋ (b1,…, bl) ↦ Q(a,b1,…, bl) = (ã,b̃1,…, b̃l)∈0,1^× n×0,1,2^× l by \\begin{equation} \\begin{split} \\tilde{a} := & a, \\tilde{b}1 := & \\big(b1f1(a)\\big)mod\\, 3, \\tilde{b}2 := & \\big(b2f2(a,b1)\\big)mod\\, 3, \\tilde{b}3 := & \\big( b3f3(a,b1,b2)\\big)mod\\, 3, \\vdots & \\tilde{b}l := & \\big( blfl(a,b1,\\ldots,b{l1})\\big)mod\\, 3. \\end{split} \\end{equation} Then Q is a bijection on 0,1^× n×0,1,2^× l.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 254,
                                    "key": "doc/body/sec7/sub5/proof4",
                                    "block type": "proof",
                                    "content": "To show that Q is a bijection, we first show that it is injective, and then that it is surjective. Let (a,b1,…,bl),(a',b'1,…,b'l)∈0,1^× n×0,1,2^× l be such that \\begin{equation} Q(a,b1,\\ldots,bl)= Q(a',b'1,\\ldots,b'l). \\end{equation} By the first line of () it follows that \\begin{equation} a= \\tilde{a} = a'. \\end{equation} By the second line of () it follows that \\begin{equation} \\big(b1f1(a)\\big)mod\\, 3 = \\big(b'1f1(a')\\big)mod\\, 3, \\end{equation} which combined with () yields \\begin{equation} \\big(b1f1(a)\\big)mod\\, 3 = \\big(b'1f1(a)\\big)mod\\, 3. \\end{equation} Since f1(a),b1,b'1∈0,1,2 it follows by () that \\begin{equation} b1 = b'1. \\end{equation} As an induction hypothesis, assume that for some s≥ 2, it is the case that \\begin{equation} a = a',\\quad b{j} = b'{j},\\quad j = 1,\\ldots, s1. \\end{equation} The sth line of () implies \\begin{equation} \\begin{split} & \\big(bs  fs(a,b1,\\ldots, b{s1}) \\big)mod\\, 3= \\big(b's fs(a',b'1,\\ldots,b'{s1})\\big)mod\\, 3. \\end{split} \\end{equation} By the induction hypothesis, this implies \\begin{equation} \\begin{split} & \\big(bs  fs(a,b1,\\ldots, b{s1}) \\big)mod\\, 3= \\big(b's fs(a,b1,\\ldots,b{s1})\\big)mod\\, 3. \\end{split} \\end{equation} Since bs,b's,fs(a,b1,…,bs1) ∈0,1,2, it follows by () that \\begin{equation} bs = b's. \\end{equation} Since the induction hypothesis is true for s= 2, we can conclude that it is true for all s = 2,…, l. We can thus conclude that Q is injective. Next we wish to show that Q is surjective onto 0,1^× n×0,1,2^× l. Let (ã',b̃'1,…,b̃'l)∈0,1^× n×0,1,2^× l. Define \\begin{equation} \\begin{split} a :=& \\tilde{a}', b1 := & \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3 = \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3, \\end{split} \\end{equation} and the sequence (bj)j=2^l recursively by \\begin{equation} b{j} := \\big(\\tilde{b}'j + fj(a,b{j1},\\ldots, b1)\\big)mod\\, 3,\\quad j = 2,\\ldots, l, \\end{equation} for a' and b1' as defined in (). In the following, we wish to show that Q(a,b1,…,bl) = (ã',b̃'1,…,b̃'l). For notational convenience, we introduce the components Q0(a,b1,…,bl) := ã and Qj(a,b1,…,bl) := b̃j, quad j =m2,…,l. By the first line of () we have \\begin{equation} \\begin{split} Q0(a,b1,\\ldots,bl) = & a = \\tilde{a}'. \\end{split} \\end{equation} By the second line of () \\begin{equation} \\begin{split} Q1(a,b1,\\ldots,bl) = & \\big(b1f1(a)\\big)mod\\, 3 = & \\Big( \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3 f1(a)\\Big)mod\\, 3 = & \\Big( \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3 f1(\\tilde{a}')\\Big)mod\\, 3 & [\\textrm{By ()}] = & \\tilde{b}'1. \\end{split} \\end{equation} For all j≥ 2 we moreover have \\begin{equation} \\begin{split} Qj(a,b1,\\ldots,bl) = & \\big( bjfj(a,b1,\\ldots,b{j1})\\big)mod\\, 3 & [\\textrm{By ()}] = & \\Big( \\big(\\tilde{b}'j + fj(a,b{j1},\\ldots, b1)\\big) fj(a,b1,\\ldots,b{j1})\\Big)mod\\, 3 & [\\textrm{By ()}] = & \\tilde{b}'j. \\end{split} \\end{equation} Hence, we can conclude that Q(a,b1,…,bl) = (ã',b̃'1,…,b̃'l). Hence Q is surjective, and thus bijective.",
                                    "leftover": "To show that Q is a bijection, we first show that it is injective, and then that it is surjective. Let (a,b1,…,bl),(a',b'1,…,b'l)∈0,1^× n×0,1,2^× l be such that \\begin{equation} Q(a,b1,\\ldots,bl)= Q(a',b'1,\\ldots,b'l). \\end{equation} By the first line of () it follows that \\begin{equation} a= \\tilde{a} = a'. \\end{equation} By the second line of () it follows that \\begin{equation} \\big(b1f1(a)\\big)mod\\, 3 = \\big(b'1f1(a')\\big)mod\\, 3, \\end{equation} which combined with () yields \\begin{equation} \\big(b1f1(a)\\big)mod\\, 3 = \\big(b'1f1(a)\\big)mod\\, 3. \\end{equation} Since f1(a),b1,b'1∈0,1,2 it follows by () that \\begin{equation} b1 = b'1. \\end{equation} As an induction hypothesis, assume that for some s≥ 2, it is the case that \\begin{equation} a = a',\\quad b{j} = b'{j},\\quad j = 1,\\ldots, s1. \\end{equation} The sth line of () implies \\begin{equation} \\begin{split} & \\big(bs  fs(a,b1,\\ldots, b{s1}) \\big)mod\\, 3= \\big(b's fs(a',b'1,\\ldots,b'{s1})\\big)mod\\, 3. \\end{split} \\end{equation} By the induction hypothesis, this implies \\begin{equation} \\begin{split} & \\big(bs  fs(a,b1,\\ldots, b{s1}) \\big)mod\\, 3= \\big(b's fs(a,b1,\\ldots,b{s1})\\big)mod\\, 3. \\end{split} \\end{equation} Since bs,b's,fs(a,b1,…,bs1) ∈0,1,2, it follows by () that \\begin{equation} bs = b's. \\end{equation} Since the induction hypothesis is true for s= 2, we can conclude that it is true for all s = 2,…, l. We can thus conclude that Q is injective. Next we wish to show that Q is surjective onto 0,1^× n×0,1,2^× l. Let (ã',b̃'1,…,b̃'l)∈0,1^× n×0,1,2^× l. Define \\begin{equation} \\begin{split} a :=& \\tilde{a}', b1 := & \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3 = \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3, \\end{split} \\end{equation} and the sequence (bj)j=2^l recursively by \\begin{equation} b{j} := \\big(\\tilde{b}'j + fj(a,b{j1},\\ldots, b1)\\big)mod\\, 3,\\quad j = 2,\\ldots, l, \\end{equation} for a' and b1' as defined in (). In the following, we wish to show that Q(a,b1,…,bl) = (ã',b̃'1,…,b̃'l). For notational convenience, we introduce the components Q0(a,b1,…,bl) := ã and Qj(a,b1,…,bl) := b̃j, quad j =m2,…,l. By the first line of () we have \\begin{equation} \\begin{split} Q0(a,b1,\\ldots,bl) = & a = \\tilde{a}'. \\end{split} \\end{equation} By the second line of () \\begin{equation} \\begin{split} Q1(a,b1,\\ldots,bl) = & \\big(b1f1(a)\\big)mod\\, 3 = & \\Big( \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3 f1(a)\\Big)mod\\, 3 = & \\Big( \\big(\\tilde{b}'1 +f1(\\tilde{a}')\\big)mod\\, 3 f1(\\tilde{a}')\\Big)mod\\, 3 & [\\textrm{By ()}] = & \\tilde{b}'1. \\end{split} \\end{equation} For all j≥ 2 we moreover have \\begin{equation} \\begin{split} Qj(a,b1,\\ldots,bl) = & \\big( bjfj(a,b1,\\ldots,b{j1})\\big)mod\\, 3 & [\\textrm{By ()}] = & \\Big( \\big(\\tilde{b}'j + fj(a,b{j1},\\ldots, b1)\\big) fj(a,b1,\\ldots,b{j1})\\Big)mod\\, 3 & [\\textrm{By ()}] = & \\tilde{b}'j. \\end{split} \\end{equation} Hence, we can conclude that Q(a,b1,…,bl) = (ã',b̃'1,…,b̃'l). Hence Q is surjective, and thus bijective.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub6",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 255,
                                    "key": "doc/body/sec7/sub6/tit",
                                    "block type": "title",
                                    "content": "Transformations that preserve uniformity",
                                    "leftover": "Transformations that preserve uniformity",
                                    "matches": []
                                },
                                {
                                    "leaf id": 256,
                                    "key": "doc/body/sec7/sub6/txl0",
                                    "block type": "txl",
                                    "content": "We make the following basic observation",
                                    "leftover": "We make the following basic observation",
                                    "matches": []
                                },
                                {
                                    "leaf id": 257,
                                    "key": "doc/body/sec7/sub6/lemma1",
                                    "block type": "lemma",
                                    "content": "Let be some finite set. Let Q:→ be invertible. Let R be some random variable on . If R is uniformly distributed over, the Q(R) is also uniformly distributed over .",
                                    "leftover": "Let be some finite set. Let Q:→ be invertible. Let R be some random variable on . If R is uniformly distributed over, the Q(R) is also uniformly distributed over .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 258,
                                    "key": "doc/body/sec7/sub6/proof2",
                                    "block type": "proof",
                                    "content": "\\begin{equation} \\begin{split} P\\big(Q(R) = s\\big) = & P\\big(R = Q^{1}(s)\\big) = {1}{|\\mathcalS|}. \\end{split} \\end{equation}",
                                    "leftover": "\\begin{equation} \\begin{split} P\\big(Q(R) = s\\big) = & P\\big(R = Q^{1}(s)\\big) = {1}{|\\mathcalS|}. \\end{split} \\end{equation}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 259,
                                    "key": "doc/body/sec7/sub6/lemma3",
                                    "block type": "lemma",
                                    "content": "Let f1:0,1^× n→0,1,2 and fs:0,1^× n×0,1,2^× (s1)→0,1,2 for s = 2,…, l be given. Assume that B1,…,Bl are random variables that take values in 0,1,2, A be a random variable that takes values in 0,1^× n, and that these are distributed as \\begin{equation} P(A = a, B1 = b1,\\ldots, Bl = bl) = {1}{2^n3^l},\\quad\\forall a\\in {0,1}^{\\times n},\\quad \\forall (b1,\\ldots, bl)\\in{0,1,2}^{\\times l}. \\end{equation} Define 1,…, l by \\begin{equation} \\begin{split} \\tildeB1 := & \\big(B1f1(A)\\big)mod\\, 3, \\tildeB2 := & \\big(B2  f2(A, B1)\\big)mod\\, 3, \\tildeB3 := & \\big(B3  f3(A, B1,B2)\\big)mod\\, 3, \\vdots & \\tildeBl := & \\big(Bl  fl(A,B1,\\ldots, B{l1})\\big)mod\\, 3. \\end{split} \\end{equation} Then \\begin{equation} P(A = a, \\tildeB1 = \\tilde{b}1,\\ldots, \\tildeBl = \\tilde{b}l) = {1}{2^n3^l},\\quad\\forall a\\in {0,1}^{\\times n},\\quad \\forall (\\tilde{b}1,\\ldots, \\tilde{b}l)\\in{0,1,2}^{\\times l}. \\end{equation} Consequently, A,1,…,l are independent and uniformly distributed.",
                                    "leftover": "Let f1:0,1^× n→0,1,2 and fs:0,1^× n×0,1,2^× (s1)→0,1,2 for s = 2,…, l be given. Assume that B1,…,Bl are random variables that take values in 0,1,2, A be a random variable that takes values in 0,1^× n, and that these are distributed as \\begin{equation} P(A = a, B1 = b1,\\ldots, Bl = bl) = {1}{2^n3^l},\\quad\\forall a\\in {0,1}^{\\times n},\\quad \\forall (b1,\\ldots, bl)\\in{0,1,2}^{\\times l}. \\end{equation} Define 1,…, l by \\begin{equation} \\begin{split} \\tildeB1 := & \\big(B1f1(A)\\big)mod\\, 3, \\tildeB2 := & \\big(B2  f2(A, B1)\\big)mod\\, 3, \\tildeB3 := & \\big(B3  f3(A, B1,B2)\\big)mod\\, 3, \\vdots & \\tildeBl := & \\big(Bl  fl(A,B1,\\ldots, B{l1})\\big)mod\\, 3. \\end{split} \\end{equation} Then \\begin{equation} P(A = a, \\tildeB1 = \\tilde{b}1,\\ldots, \\tildeBl = \\tilde{b}l) = {1}{2^n3^l},\\quad\\forall a\\in {0,1}^{\\times n},\\quad \\forall (\\tilde{b}1,\\ldots, \\tilde{b}l)\\in{0,1,2}^{\\times l}. \\end{equation} Consequently, A,1,…,l are independent and uniformly distributed.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 260,
                                    "key": "doc/body/sec7/sub6/proof4",
                                    "block type": "proof",
                                    "content": "By () we know that (A,B1,…,Bl) is uniformly distributed on 0,1^× n×0,1,2^× l. With the additional definition := A, we note that () can be rewritten as \\begin{equation} (\\tildeA,\\tildeB1,\\ldots,\\tildeBl) := Q(A,B1,\\ldots,Bl), \\end{equation} where Q:0,1^× n×0,1,2^× l→0,1^× n×0,1,2^× l is as defined in Lemma . By Lemma, we moreover know that Q is a bijection on 0,1^× n×0,1,2^× l and thus invertible. Hence, by Lemma, we know that (,1,…,l) also is uniformly distributed over 0,1^× n×0,1,2^× l. Since = A, we can conclude that () holds. By () i follows that \\begin{equation} \\begin{split} & P(A = a, \\tildeB1 = \\tilde{b}1,\\ldots, \\tildeBl = \\tilde{b}l) = P(A = a)P(\\tildeB1 = \\tilde{b}1)\\cdots P(\\tildeBl = \\tilde{b}l), & P(A =a) = {1}{2^n},\\quad P(\\tildeB1 = \\tilde{b}1) = {1}{3},\\ldots,P(\\tildeBl = \\tilde{b}l) = {1}{3}. \\end{split} \\end{equation} and thus A, 1,…,l are independent and uniformly distributed.",
                                    "leftover": "By () we know that (A,B1,…,Bl) is uniformly distributed on 0,1^× n×0,1,2^× l. With the additional definition := A, we note that () can be rewritten as \\begin{equation} (\\tildeA,\\tildeB1,\\ldots,\\tildeBl) := Q(A,B1,\\ldots,Bl), \\end{equation} where Q:0,1^× n×0,1,2^× l→0,1^× n×0,1,2^× l is as defined in Lemma . By Lemma, we moreover know that Q is a bijection on 0,1^× n×0,1,2^× l and thus invertible. Hence, by Lemma, we know that (,1,…,l) also is uniformly distributed over 0,1^× n×0,1,2^× l. Since = A, we can conclude that () holds. By () i follows that \\begin{equation} \\begin{split} & P(A = a, \\tildeB1 = \\tilde{b}1,\\ldots, \\tildeBl = \\tilde{b}l) = P(A = a)P(\\tildeB1 = \\tilde{b}1)\\cdots P(\\tildeBl = \\tilde{b}l), & P(A =a) = {1}{2^n},\\quad P(\\tildeB1 = \\tilde{b}1) = {1}{3},\\ldots,P(\\tildeBl = \\tilde{b}l) = {1}{3}. \\end{split} \\end{equation} and thus A, 1,…,l are independent and uniformly distributed.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub7",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 261,
                                    "key": "doc/body/sec7/sub7/tit",
                                    "block type": "title",
                                    "content": "The process (d̃l)l is a Markov chain",
                                    "leftover": "The process (d̃l)l is a Markov chain",
                                    "matches": []
                                },
                                {
                                    "leaf id": 262,
                                    "key": "doc/body/sec7/sub7/proposition0",
                                    "block type": "proposition",
                                    "content": "Let (d̃l)l be the process as defined by () and (), with respect to the variables A, B1,B2,… distributed as in (). For each m there exist variables 1,⋯,m that are iid and uniformly distributed on 0,1,2, and are independent of A, such that \\begin{equation} \\begin{split} \\tilde{d}0 := & dH(A,x^{\\star}), \\tilde{d}{l} := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1} = 0 \\tilde{d}{l1} + 1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl \\neq 0 \\tilde{d}{l1}  1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots,m \\end{split} \\end{equation} Hence, (d̃l)l is a Markov chain described by the transition probabilities \\begin{equation} P(\\tilde{d}{l+1} = j|\\tilde{d}{l} = k) = \\delta{j,0}\\delta{k,0} + (1\\delta{k,0})\\big({1}{3}\\delta{j,k1} +{2}{3}\\delta{j,k+1}\\big),\\quad \\forall j,k\\in\\mathbbN,\\quad \\forall l \\end{equation} with initial distribution \\begin{equation} P(\\tilde{d}0 = j) = P\\big(dH(A,x^{\\star})= j\\big). \\end{equation} Moreover, for the distribution of A as in () we have \\begin{equation} P(\\tilde{d}0 = j) = \\left{\\begin{matrix} {1}{2^n}\\binom{n}{j}&,\\quad 0\\leq j\\leq n 0& otherwise \\end{matrix}\\right. \\end{equation}",
                                    "leftover": "Let (d̃l)l be the process as defined by () and (), with respect to the variables A, B1,B2,… distributed as in (). For each m there exist variables 1,⋯,m that are iid and uniformly distributed on 0,1,2, and are independent of A, such that \\begin{equation} \\begin{split} \\tilde{d}0 := & dH(A,x^{\\star}), \\tilde{d}{l} := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1} = 0 \\tilde{d}{l1} + 1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl \\neq 0 \\tilde{d}{l1}  1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots,m \\end{split} \\end{equation} Hence, (d̃l)l is a Markov chain described by the transition probabilities \\begin{equation} P(\\tilde{d}{l+1} = j|\\tilde{d}{l} = k) = \\delta{j,0}\\delta{k,0} + (1\\delta{k,0})\\big({1}{3}\\delta{j,k1} +{2}{3}\\delta{j,k+1}\\big),\\quad \\forall j,k\\in\\mathbbN,\\quad \\forall l \\end{equation} with initial distribution \\begin{equation} P(\\tilde{d}0 = j) = P\\big(dH(A,x^{\\star})= j\\big). \\end{equation} Moreover, for the distribution of A as in () we have \\begin{equation} P(\\tilde{d}0 = j) = \\left{\\begin{matrix} {1}{2^n}\\binom{n}{j}&,\\quad 0\\leq j\\leq n 0& otherwise \\end{matrix}\\right. \\end{equation}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 263,
                                    "key": "doc/body/sec7/sub7/txl1",
                                    "block type": "txl",
                                    "content": "In (), the term δj,0δk,0 signifies d = 0 being an absorbing state. In the second term, the effect of the factor (1δk,0) is that if the chain is not in the absorbing state, then the transition probabilities are given by 13δj,k1 +23δj,k+1. Hence, with probability 1/3, it takes a step 'down', and with probability 2/3 it takes a step 'up'.",
                                    "leftover": "In (), the term δj,0δk,0 signifies d = 0 being an absorbing state. In the second term, the effect of the factor (1δk,0) is that if the chain is not in the absorbing state, then the transition probabilities are given by 13δj,k1 +23δj,k+1. Hence, with probability 1/3, it takes a step 'down', and with probability 2/3 it takes a step 'up'.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 264,
                                    "key": "doc/body/sec7/sub7/proof2",
                                    "block type": "proof",
                                    "content": "For t,r∈0,1,2 it is the case that \\begin{equation} t = r \\quad\\Leftrightarrow \\quad (tr)mod\\,3 = 0. \\end{equation} By this observation, it follows that () can be rewritten as \\begin{equation} \\begin{split} \\tilde{d}0(a,b) := & dH(a,x^{\\star}), \\tilde{d}{l}(a,b{1},\\ldots, b{l}) := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1}(a,b{1},\\ldots,b{l1}) = 0 \\tilde{d}{l1}(a,b{1},\\ldots, b{l1}) + 1 & if & \\tilde{d}{l1}(a,b{1},\\ldots, b{l1}) \\neq 0,\\quad \\big(bl fl(a,b{1},\\ldots, b{l1})\\big)mod\\,3 \\neq 0 \\tilde{d}{l1}(a,b{1},\\ldots, b{l1})  1 & if & \\tilde{d}{l1}(a,b{1},\\ldots, b{l1}) \\neq 0,\\quad \\big(bl fl(a,b{1},\\ldots, b{l1})\\big)mod\\,3 = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots \\end{split} \\end{equation} Next, we rewrite () such that we suppress the explicit dependence on the elementary events (a,b). \\begin{equation} \\begin{split} \\tilde{d}0 := & dH(A,x^{\\star}), \\tilde{d}{l} := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1} = 0 \\tilde{d}{l1} + 1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\big(Bl fl(A,B{1},\\ldots, B{l1})\\big)mod\\,3 \\neq 0 \\tilde{d}{l1}  1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\big(Bl fl(A,B{1},\\ldots, B{l1})\\big)mod\\,3 = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots \\end{split} \\end{equation} If we define 1,…, l by \\begin{equation} \\begin{split} \\tildeB1 := & f1(A), \\tildeB2 := & \\big(B2  f2(A, B1)\\big)mod\\, 3, \\tildeB3 := & \\big(B3  f3(A, B1, B2)\\big)mod\\, 3, \\vdots & \\tildeBl := & \\big(Bl  fl(A,B1,\\ldots, B{l1})\\big)mod\\, 3, \\end{split} \\end{equation} then we can rewrite () as \\begin{equation} \\begin{split} \\tilde{d}0 := & dH(A,x^{\\star}), \\tilde{d}{l} := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1} = 0 \\tilde{d}{l1} + 1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl \\neq 0 \\tilde{d}{l1}  1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots \\end{split} \\end{equation} By Lemma we know that A,1,…,l are independent and uniformly distributed. Since the l:th step is determined solely by l, and these are independent of each other, and of A, it follows that (d̃l)l is a Markov chain. By inspecting () we first see that \\begin{equation} \\begin{split} P(\\tilde{d}l = j|\\tilde{d}{l1} = 0) = \\delta{j,0}, \\end{split} \\end{equation} while for d̃l1 = k≠ 0 we have \\begin{equation} \\begin{split} P(\\tilde{d}l = j|\\tilde{d}{l1} = k) = & \\delta{j,k+1} P(\\tildeBl \\neq 0) + \\delta{j,k1}P(\\tildeBl = 0) = & {2}{3}\\delta{j,k+1} + {1}{3}\\delta{j,k1}, \\end{split} \\end{equation} where the last step follows since each l is uniformly distributed over 0,1,2. By combining the cases () and () we obtain (). By () it moreover follows that P(d̃0 = j) = P(dH(A,x^⋆)= j). Since A is uniformly distributed over 0,1^× n, it means that dH(A,x^⋆) is binomially distributed. Thus for 0≤ j ≤ n, we have P(d̃0 = j) =12^nnj.",
                                    "leftover": "For t,r∈0,1,2 it is the case that \\begin{equation} t = r \\quad\\Leftrightarrow \\quad (tr)mod\\,3 = 0. \\end{equation} By this observation, it follows that () can be rewritten as \\begin{equation} \\begin{split} \\tilde{d}0(a,b) := & dH(a,x^{\\star}), \\tilde{d}{l}(a,b{1},\\ldots, b{l}) := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1}(a,b{1},\\ldots,b{l1}) = 0 \\tilde{d}{l1}(a,b{1},\\ldots, b{l1}) + 1 & if & \\tilde{d}{l1}(a,b{1},\\ldots, b{l1}) \\neq 0,\\quad \\big(bl fl(a,b{1},\\ldots, b{l1})\\big)mod\\,3 \\neq 0 \\tilde{d}{l1}(a,b{1},\\ldots, b{l1})  1 & if & \\tilde{d}{l1}(a,b{1},\\ldots, b{l1}) \\neq 0,\\quad \\big(bl fl(a,b{1},\\ldots, b{l1})\\big)mod\\,3 = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots \\end{split} \\end{equation} Next, we rewrite () such that we suppress the explicit dependence on the elementary events (a,b). \\begin{equation} \\begin{split} \\tilde{d}0 := & dH(A,x^{\\star}), \\tilde{d}{l} := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1} = 0 \\tilde{d}{l1} + 1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\big(Bl fl(A,B{1},\\ldots, B{l1})\\big)mod\\,3 \\neq 0 \\tilde{d}{l1}  1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\big(Bl fl(A,B{1},\\ldots, B{l1})\\big)mod\\,3 = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots \\end{split} \\end{equation} If we define 1,…, l by \\begin{equation} \\begin{split} \\tildeB1 := & f1(A), \\tildeB2 := & \\big(B2  f2(A, B1)\\big)mod\\, 3, \\tildeB3 := & \\big(B3  f3(A, B1, B2)\\big)mod\\, 3, \\vdots & \\tildeBl := & \\big(Bl  fl(A,B1,\\ldots, B{l1})\\big)mod\\, 3, \\end{split} \\end{equation} then we can rewrite () as \\begin{equation} \\begin{split} \\tilde{d}0 := & dH(A,x^{\\star}), \\tilde{d}{l} := & \\left{\\begin{matrix} 0 & if & \\tilde{d}{l1} = 0 \\tilde{d}{l1} + 1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl \\neq 0 \\tilde{d}{l1}  1 & if & \\tilde{d}{l1} \\neq 0,\\quad \\tildeBl = 0 \\end{matrix}\\right. \\quad l = 1,2,\\ldots \\end{split} \\end{equation} By Lemma we know that A,1,…,l are independent and uniformly distributed. Since the l:th step is determined solely by l, and these are independent of each other, and of A, it follows that (d̃l)l is a Markov chain. By inspecting () we first see that \\begin{equation} \\begin{split} P(\\tilde{d}l = j|\\tilde{d}{l1} = 0) = \\delta{j,0}, \\end{split} \\end{equation} while for d̃l1 = k≠ 0 we have \\begin{equation} \\begin{split} P(\\tilde{d}l = j|\\tilde{d}{l1} = k) = & \\delta{j,k+1} P(\\tildeBl \\neq 0) + \\delta{j,k1}P(\\tildeBl = 0) = & {2}{3}\\delta{j,k+1} + {1}{3}\\delta{j,k1}, \\end{split} \\end{equation} where the last step follows since each l is uniformly distributed over 0,1,2. By combining the cases () and () we obtain (). By () it moreover follows that P(d̃0 = j) = P(dH(A,x^⋆)= j). Since A is uniformly distributed over 0,1^× n, it means that dH(A,x^⋆) is binomially distributed. Thus for 0≤ j ≤ n, we have P(d̃0 = j) =12^nnj.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub8",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 265,
                                    "key": "doc/body/sec7/sub8/tit",
                                    "block type": "title",
                                    "content": "Relating probabilities of (xl)l and (d̃l)l",
                                    "leftover": "Relating probabilities of (xl)l and (d̃l)l",
                                    "matches": []
                                },
                                {
                                    "leaf id": 266,
                                    "key": "doc/body/sec7/sub8/txl0",
                                    "block type": "txl",
                                    "content": "The reason for why we introduce the walk (d̃l)l is in order to bound the relevant successprobabilities of the more complicated true Sch\"oningwalk (xl)l. The lemma below considers two such inequalities, which we will use when we determine the bounds for the Groverized walk.",
                                    "leftover": "The reason for why we introduce the walk (d̃l)l is in order to bound the relevant successprobabilities of the more complicated true Sch\"oningwalk (xl)l. The lemma below considers two such inequalities, which we will use when we determine the bounds for the Groverized walk.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 267,
                                    "key": "doc/body/sec7/sub8/lemma1",
                                    "block type": "lemma",
                                    "content": "Let (xl)l∈ be the Sch\"oning process for bit strings of length n, with x^⋆ the selected satisfying assignment. Let (d̃l)l be the process as defined by () and (). Then \\begin{equation} \\begin{split} P(xm = x^{\\star})\\geq P(\\tilde{d}m = 0), \\end{split} \\end{equation} \\begin{equation} \\begin{split} & P\\big( xm = x^{\\star}|dH(x0,x^{\\star}) = j\\big)\\geq P(\\tilde{d}m = 0|\\tilde{d}0 = j), \\end{split} \\end{equation}",
                                    "leftover": "Let (xl)l∈ be the Sch\"oning process for bit strings of length n, with x^⋆ the selected satisfying assignment. Let (d̃l)l be the process as defined by () and (). Then \\begin{equation} \\begin{split} P(xm = x^{\\star})\\geq P(\\tilde{d}m = 0), \\end{split} \\end{equation} \\begin{equation} \\begin{split} & P\\big( xm = x^{\\star}|dH(x0,x^{\\star}) = j\\big)\\geq P(\\tilde{d}m = 0|\\tilde{d}0 = j), \\end{split} \\end{equation}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 268,
                                    "key": "doc/body/sec7/sub8/proof2",
                                    "block type": "proof",
                                    "content": "We begin by proving inequality (). For the sake of notational simplicity, we let ω denote the elements of the event space (where we could regard ω as (a,b) or (a,b̃)). By Lemma we know that \\begin{equation} \\begin{split} & dH\\big(xm(\\omega),x^{\\star}\\big) \\leq \\tilde{d}m(\\omega), \\end{split} \\end{equation} which implies \\begin{equation} \\begin{split} & \\tilde{d}m(\\omega) = 0\\quad \\Rightarrow \\quad dH\\big(xm(\\omega),x^{\\star}\\big) =0 \\end{split} \\end{equation} and thus \\begin{equation} \\begin{split} & {\\omega: \\tilde{d}m(\\omega) = 0} \\subset {\\omega: dH\\big(xm(\\omega),x^{\\star}\\big) = 0} = {\\omega: xm(\\omega) = x^{\\star}} \\end{split} \\end{equation} and thus \\begin{equation} \\begin{split} P(\\tilde{d}m = 0) & = P\\big({\\omega: \\tilde{d}m(\\omega) = 0}\\big) & \\leq P\\big( {\\omega: xm(\\omega) = x^{\\star}}\\big) & = P(xm = x^{\\star}), \\end{split} \\end{equation} which proves (). We next turn to the proof of () By definition of the walk (d̃l)l we have d̃0(ω) = dH(x0(ω),x^⋆), and thus \\begin{equation} {\\omega: \\tilde{d}0(\\omega) = j} = {\\omega: dH\\big(x0(\\omega),x^{\\star}\\big) = j} \\end{equation} and consequently \\begin{equation} P(\\tilde{d}0 = j) = P\\big(dH(x0,x^{\\star}) = j\\big). \\end{equation} By combining () and () we obtain \\begin{equation} {\\omega: \\tilde{d}m(\\omega) = 0}\\cap {\\omega: \\tilde{d}0(\\omega) = j} \\subset {\\omega: xm(\\omega) = x^{\\star}}\\cap{\\omega: dH\\big(x0(\\omega),x^{\\star}\\big) = j} \\end{equation} and consequently \\begin{equation} \\begin{split} P(\\tilde{d}m = 0,\\tilde{d}0 = j) = & P\\big({\\omega: \\tilde{d}m(\\omega) = 0}\\cap {\\omega: \\tilde{d}0(\\omega) = j}\\big) \\leq & P\\big( {\\omega: xm(\\omega) = x^{\\star}}\\cap{\\omega: dH\\big(x0(\\omega),x^{\\star}\\big) = j}\\big) = & P\\big( xm = x^{\\star}, dH(x0,x^{\\star}) = j\\big). \\end{split} \\end{equation} By combining this with () we can conclude that \\begin{equation} \\begin{split} P(\\tilde{d}m = 0|\\tilde{d}0 = j) \\leq & P\\big( xm = x^{\\star}|dH(x0,x^{\\star}) = j\\big), \\end{split} \\end{equation} which proves ().",
                                    "leftover": "We begin by proving inequality (). For the sake of notational simplicity, we let ω denote the elements of the event space (where we could regard ω as (a,b) or (a,b̃)). By Lemma we know that \\begin{equation} \\begin{split} & dH\\big(xm(\\omega),x^{\\star}\\big) \\leq \\tilde{d}m(\\omega), \\end{split} \\end{equation} which implies \\begin{equation} \\begin{split} & \\tilde{d}m(\\omega) = 0\\quad \\Rightarrow \\quad dH\\big(xm(\\omega),x^{\\star}\\big) =0 \\end{split} \\end{equation} and thus \\begin{equation} \\begin{split} & {\\omega: \\tilde{d}m(\\omega) = 0} \\subset {\\omega: dH\\big(xm(\\omega),x^{\\star}\\big) = 0} = {\\omega: xm(\\omega) = x^{\\star}} \\end{split} \\end{equation} and thus \\begin{equation} \\begin{split} P(\\tilde{d}m = 0) & = P\\big({\\omega: \\tilde{d}m(\\omega) = 0}\\big) & \\leq P\\big( {\\omega: xm(\\omega) = x^{\\star}}\\big) & = P(xm = x^{\\star}), \\end{split} \\end{equation} which proves (). We next turn to the proof of () By definition of the walk (d̃l)l we have d̃0(ω) = dH(x0(ω),x^⋆), and thus \\begin{equation} {\\omega: \\tilde{d}0(\\omega) = j} = {\\omega: dH\\big(x0(\\omega),x^{\\star}\\big) = j} \\end{equation} and consequently \\begin{equation} P(\\tilde{d}0 = j) = P\\big(dH(x0,x^{\\star}) = j\\big). \\end{equation} By combining () and () we obtain \\begin{equation} {\\omega: \\tilde{d}m(\\omega) = 0}\\cap {\\omega: \\tilde{d}0(\\omega) = j} \\subset {\\omega: xm(\\omega) = x^{\\star}}\\cap{\\omega: dH\\big(x0(\\omega),x^{\\star}\\big) = j} \\end{equation} and consequently \\begin{equation} \\begin{split} P(\\tilde{d}m = 0,\\tilde{d}0 = j) = & P\\big({\\omega: \\tilde{d}m(\\omega) = 0}\\cap {\\omega: \\tilde{d}0(\\omega) = j}\\big) \\leq & P\\big( {\\omega: xm(\\omega) = x^{\\star}}\\cap{\\omega: dH\\big(x0(\\omega),x^{\\star}\\big) = j}\\big) = & P\\big( xm = x^{\\star}, dH(x0,x^{\\star}) = j\\big). \\end{split} \\end{equation} By combining this with () we can conclude that \\begin{equation} \\begin{split} P(\\tilde{d}m = 0|\\tilde{d}0 = j) \\leq & P\\big( xm = x^{\\star}|dH(x0,x^{\\star}) = j\\big), \\end{split} \\end{equation} which proves ().",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub9",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 269,
                                    "key": "doc/body/sec7/sub9/tit",
                                    "block type": "title",
                                    "content": "From walks on to walks on",
                                    "leftover": "From walks on to walks on",
                                    "matches": []
                                },
                                {
                                    "leaf id": 270,
                                    "key": "doc/body/sec7/sub9/txl0",
                                    "block type": "txl",
                                    "content": "So far, we have replaced the projection of the Sch\"oningprocess (xl)l to the Hamming distance dH(xm,x^⋆) with the substitute Markovchain (d̃l)l. Similar to x^⋆ being an absorbing state of (xl), the process (d̃l)l has 0 as absorbing state. As a model of the true Sch\"oning process, this absorbing state certainly makes sense, since it corresponds to a setting where we at each step monitor whether a solution has been reached, and the process is terminated once this happens. For the sake of obtaining tractable expressions for the relevant probabilities, we here take one step further and instead consider a walk on . Analogously to how Lemma bounds the relevant probabilities of the true Sch\"oning process, with the corresponding quantities in (d̃l)l, Lemma below, bounds the relevant probabilities of (d̃l)l in terms of corresponding quantities for a Markovchain (dl)l extended to the whole of .",
                                    "leftover": "So far, we have replaced the projection of the Sch\"oningprocess (xl)l to the Hamming distance dH(xm,x^⋆) with the substitute Markovchain (d̃l)l. Similar to x^⋆ being an absorbing state of (xl), the process (d̃l)l has 0 as absorbing state. As a model of the true Sch\"oning process, this absorbing state certainly makes sense, since it corresponds to a setting where we at each step monitor whether a solution has been reached, and the process is terminated once this happens. For the sake of obtaining tractable expressions for the relevant probabilities, we here take one step further and instead consider a walk on . Analogously to how Lemma bounds the relevant probabilities of the true Sch\"oning process, with the corresponding quantities in (d̃l)l, Lemma below, bounds the relevant probabilities of (d̃l)l in terms of corresponding quantities for a Markovchain (dl)l extended to the whole of .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 271,
                                    "key": "doc/body/sec7/sub9/txl1",
                                    "block type": "txl",
                                    "content": "As a bit of a side remark, one may note that the results in () does not necessarily refer to the particular Markovchain defined by () and (), but could be any Markov chain on with fixed transition probabilities and absorbing boundary condition at 0.",
                                    "leftover": "As a bit of a side remark, one may note that the results in () does not necessarily refer to the particular Markovchain defined by () and (), but could be any Markov chain on with fixed transition probabilities and absorbing boundary condition at 0.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 272,
                                    "key": "doc/body/sec7/sub9/lemma2",
                                    "block type": "lemma",
                                    "content": "Let (d̃l)l∈ be a Markov chain on, with transition probabilities \\begin{equation} P(\\tilde{d}{l+1} = j|\\tilde{d}{l} = k) = \\delta{j,0}\\delta{k,0} + (1\\delta{k,0})\\big((1q)\\delta{j,k1} +q\\delta{j,k+1}\\big),\\quad \\forall j,k\\in\\mathbbN,\\quad \\forall l\\in\\mathbbN, \\end{equation} for some 0≤ q≤ 1. Let (dl)l∈ be a Markov chain on, with transition probabilities \\begin{equation} P(d{l+1} = j|d{l} = k) = (1q)\\delta{j,k1} + q\\delta{j,k+1},\\quad \\forall j,k\\in\\mathbbZ,\\quad \\forall. l\\in\\mathbbN. \\end{equation} Then \\begin{equation} P\\big(dm\\leq 0|d0 = j\\big) \\leq P(\\tilde{d}m = 0|\\tilde{d}0 = j),\\quad \\forall m\\in\\mathbbN,\\quad \\forall j\\in \\mathbbN. \\end{equation} Consequently, if the initial state d0 is such that \\begin{equation} P(d0 = j) = \\left{\\begin{matrix} P(\\tilde{d}0 = j), & \\quad j \\geq 0 0, & \\quad j <0 \\end{matrix}\\right. \\end{equation} then \\begin{equation} P(dm = 0) \\leq P(dm\\leq 0) \\leq P(\\tilde{d}m = 0),\\quad \\forall m\\in\\mathbbN. \\end{equation}",
                                    "leftover": "Let (d̃l)l∈ be a Markov chain on, with transition probabilities \\begin{equation} P(\\tilde{d}{l+1} = j|\\tilde{d}{l} = k) = \\delta{j,0}\\delta{k,0} + (1\\delta{k,0})\\big((1q)\\delta{j,k1} +q\\delta{j,k+1}\\big),\\quad \\forall j,k\\in\\mathbbN,\\quad \\forall l\\in\\mathbbN, \\end{equation} for some 0≤ q≤ 1. Let (dl)l∈ be a Markov chain on, with transition probabilities \\begin{equation} P(d{l+1} = j|d{l} = k) = (1q)\\delta{j,k1} + q\\delta{j,k+1},\\quad \\forall j,k\\in\\mathbbZ,\\quad \\forall. l\\in\\mathbbN. \\end{equation} Then \\begin{equation} P\\big(dm\\leq 0|d0 = j\\big) \\leq P(\\tilde{d}m = 0|\\tilde{d}0 = j),\\quad \\forall m\\in\\mathbbN,\\quad \\forall j\\in \\mathbbN. \\end{equation} Consequently, if the initial state d0 is such that \\begin{equation} P(d0 = j) = \\left{\\begin{matrix} P(\\tilde{d}0 = j), & \\quad j \\geq 0 0, & \\quad j <0 \\end{matrix}\\right. \\end{equation} then \\begin{equation} P(dm = 0) \\leq P(dm\\leq 0) \\leq P(\\tilde{d}m = 0),\\quad \\forall m\\in\\mathbbN. \\end{equation}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 273,
                                    "key": "doc/body/sec7/sub9/proof3",
                                    "block type": "proof",
                                    "content": "For notational convenience, we define \\begin{equation} \\begin{split} M{j,k} := & P(\\tilde{d}{l+1} = j|\\tilde{d}{l} = k), \\end{split} \\end{equation} and \\begin{equation} \\begin{split} \\tildeM{j,k} := & P(d{l+1} = j|d{l} = k). \\end{split} \\end{equation} By comparing with () and () one can see that \\begin{equation} \\begin{split} M{j,k} = \\tildeM{j,k},\\quad \\forall j>0,\\quad \\forall k>0. \\end{split} \\end{equation} We note that 0 is an absorbing state for (d̃l)l. Hence, \\begin{equation} \\begin{split} \\tilde{d}{s1} = 0\\quad\\Rightarrow\\quad \\tilde{d}{s} = 0, \\end{split} \\end{equation} which implies \\begin{equation} \\begin{split} \\tilde{d}s>0 \\quad \\Rightarrow\\quad \\tilde{d}{s1}>0, \\end{split} \\end{equation} which in turn implies \\begin{equation} \\begin{split} P(\\tilde{d}s= ks|\\tilde{d}{s1}=0) = 0,\\quad\\textrm{if}\\quad ks >0. \\end{split} \\end{equation} We begin by proving (). For this purpose, assume that j>0. \\begin{equation} \\begin{split} &P(\\tilde{d}l >0 |\\tilde{d}0 = j) = & \\sum{kl>0}P(\\tilde{d}l =kl |\\tilde{d}0 = j) & [\\textrm{By Markovianity}] = & \\sum{kl>0}\\sum{k{l1},\\ldots,k1} P(\\tilde{d}l = kl|\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}2 = k2|\\tilde{d}1 = k1)P(\\tilde{d}1 = k1|\\tilde{d}0 = j) = & \\sum{kl>0}\\sum{k{l1}:k{l1}>0}\\sum{k{l2},\\ldots,k1} P(\\tilde{d}l = kl |\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & + \\sum{kl>0}\\sum{k{l2},\\ldots,k1} P(\\tilde{d}l = kl|\\tilde{d}{l1} = 0)P(\\tilde{d}{l1} = 0|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & [\\textrm{Since kl> 0 it follows by () that P(d̃l = kl|d̃l1 = 0) = 0.}] = & \\sum{kl>0}\\sum{k{l1}:k{l1}>0}\\sum{k{l2},\\ldots,k1} P(\\tilde{d}l = kl |\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & [\\textrm{By iteration}] = & \\sum{kl>0}\\sum{k{l1},\\ldots,k1:k{l1} >0,\\ldots, k1 >0} P(\\tilde{d}l = kl |\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & [\\textrm{By ()}] = & \\sum{kl>0} \\sum{k{l1},\\ldots,k1:k{l1} >0,\\ldots, k1 >0} M{kl,k{l1}}\\cdots M{k1,j} & [\\textrm{Since kl > 0, kl1>0,⋯, k1>0, j>0 if follows by () that}] = & \\sum{kl>0} \\sum{k{l1},\\ldots,k1:k{l1} >0,\\ldots, k1 >0} \\tildeM{kl,k{l1}}\\cdots \\tildeM{k1,j} & [\\quad \\tildeM{kl,k{l1}}\\geq 0 \\quad] \\leq & \\sum{kl>0} \\sum{k{l1},\\ldots, k{1}}\\tildeM{kl,k{l1}}\\cdots \\tildeM{k1,j} & [\\textrm{By ()}] = & \\sum{kl>0} \\sum{k{l1},\\ldots, k{1}}P(dl = kl |d{l1} = k{l1})P(d{l1} = k{l1}|d{l2} = k{l2})\\cdots P(d1 = k1|d0 = j) & [\\textrm{By the Markovianity}] = & \\sum{kl>0}P(dl = kl|d0 =j) = & P(dl > 0|d0 =j). \\end{split} \\end{equation} Consequently \\begin{equation} \\begin{split} P(\\tilde{d}l =0 |\\tilde{d}0 = j)= &1 P(\\tilde{d}l >0 |\\tilde{d}0 = j) \\geq & 1P(dl > 0|d0 =j) = & P(dl \\leq 0|d0 =j),\\quad j>0. \\end{split} \\end{equation} In the case d̃0 = 0 we know that this is an absorbing state, and thus P(d̃l =0 |d̃0 = 0) = 1. Consequently, P(dl≤ 0|d0 = 0)≤ P(d̃l =0 |d̃0 = 0) = 1. This thus proves the inequality in (). With the initial distribution () we find \\begin{equation} \\begin{split} P(dl\\leq 0) = & \\sum{j\\in\\mathbbZ}P(dl\\leq 0|d0 = j)P(d0 = j) = & \\sum{j\\geq 0}P(dl\\leq 0|d0 = j)P(\\tilde{d}0 = j) \\leq & \\sum{j\\geq 0}P(\\tilde{d}l = 0|\\tilde{d}0 = j)P(\\tilde{d}0 = j) = & P(\\tilde{d}l = 0). \\end{split} \\end{equation}",
                                    "leftover": "For notational convenience, we define \\begin{equation} \\begin{split} M{j,k} := & P(\\tilde{d}{l+1} = j|\\tilde{d}{l} = k), \\end{split} \\end{equation} and \\begin{equation} \\begin{split} \\tildeM{j,k} := & P(d{l+1} = j|d{l} = k). \\end{split} \\end{equation} By comparing with () and () one can see that \\begin{equation} \\begin{split} M{j,k} = \\tildeM{j,k},\\quad \\forall j>0,\\quad \\forall k>0. \\end{split} \\end{equation} We note that 0 is an absorbing state for (d̃l)l. Hence, \\begin{equation} \\begin{split} \\tilde{d}{s1} = 0\\quad\\Rightarrow\\quad \\tilde{d}{s} = 0, \\end{split} \\end{equation} which implies \\begin{equation} \\begin{split} \\tilde{d}s>0 \\quad \\Rightarrow\\quad \\tilde{d}{s1}>0, \\end{split} \\end{equation} which in turn implies \\begin{equation} \\begin{split} P(\\tilde{d}s= ks|\\tilde{d}{s1}=0) = 0,\\quad\\textrm{if}\\quad ks >0. \\end{split} \\end{equation} We begin by proving (). For this purpose, assume that j>0. \\begin{equation} \\begin{split} &P(\\tilde{d}l >0 |\\tilde{d}0 = j) = & \\sum{kl>0}P(\\tilde{d}l =kl |\\tilde{d}0 = j) & [\\textrm{By Markovianity}] = & \\sum{kl>0}\\sum{k{l1},\\ldots,k1} P(\\tilde{d}l = kl|\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}2 = k2|\\tilde{d}1 = k1)P(\\tilde{d}1 = k1|\\tilde{d}0 = j) = & \\sum{kl>0}\\sum{k{l1}:k{l1}>0}\\sum{k{l2},\\ldots,k1} P(\\tilde{d}l = kl |\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & + \\sum{kl>0}\\sum{k{l2},\\ldots,k1} P(\\tilde{d}l = kl|\\tilde{d}{l1} = 0)P(\\tilde{d}{l1} = 0|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & [\\textrm{Since kl> 0 it follows by () that P(d̃l = kl|d̃l1 = 0) = 0.}] = & \\sum{kl>0}\\sum{k{l1}:k{l1}>0}\\sum{k{l2},\\ldots,k1} P(\\tilde{d}l = kl |\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & [\\textrm{By iteration}] = & \\sum{kl>0}\\sum{k{l1},\\ldots,k1:k{l1} >0,\\ldots, k1 >0} P(\\tilde{d}l = kl |\\tilde{d}{l1} = k{l1})P(\\tilde{d}{l1} = k{l1}|\\tilde{d}{l2} = k{l2})\\cdots P(\\tilde{d}1 = k1|\\tilde{d}0 = j) & [\\textrm{By ()}] = & \\sum{kl>0} \\sum{k{l1},\\ldots,k1:k{l1} >0,\\ldots, k1 >0} M{kl,k{l1}}\\cdots M{k1,j} & [\\textrm{Since kl > 0, kl1>0,⋯, k1>0, j>0 if follows by () that}] = & \\sum{kl>0} \\sum{k{l1},\\ldots,k1:k{l1} >0,\\ldots, k1 >0} \\tildeM{kl,k{l1}}\\cdots \\tildeM{k1,j} & [\\quad \\tildeM{kl,k{l1}}\\geq 0 \\quad] \\leq & \\sum{kl>0} \\sum{k{l1},\\ldots, k{1}}\\tildeM{kl,k{l1}}\\cdots \\tildeM{k1,j} & [\\textrm{By ()}] = & \\sum{kl>0} \\sum{k{l1},\\ldots, k{1}}P(dl = kl |d{l1} = k{l1})P(d{l1} = k{l1}|d{l2} = k{l2})\\cdots P(d1 = k1|d0 = j) & [\\textrm{By the Markovianity}] = & \\sum{kl>0}P(dl = kl|d0 =j) = & P(dl > 0|d0 =j). \\end{split} \\end{equation} Consequently \\begin{equation} \\begin{split} P(\\tilde{d}l =0 |\\tilde{d}0 = j)= &1 P(\\tilde{d}l >0 |\\tilde{d}0 = j) \\geq & 1P(dl > 0|d0 =j) = & P(dl \\leq 0|d0 =j),\\quad j>0. \\end{split} \\end{equation} In the case d̃0 = 0 we know that this is an absorbing state, and thus P(d̃l =0 |d̃0 = 0) = 1. Consequently, P(dl≤ 0|d0 = 0)≤ P(d̃l =0 |d̃0 = 0) = 1. This thus proves the inequality in (). With the initial distribution () we find \\begin{equation} \\begin{split} P(dl\\leq 0) = & \\sum{j\\in\\mathbbZ}P(dl\\leq 0|d0 = j)P(d0 = j) = & \\sum{j\\geq 0}P(dl\\leq 0|d0 = j)P(\\tilde{d}0 = j) \\leq & \\sum{j\\geq 0}P(\\tilde{d}l = 0|\\tilde{d}0 = j)P(\\tilde{d}0 = j) = & P(\\tilde{d}l = 0). \\end{split} \\end{equation}",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub10",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 274,
                                    "key": "doc/body/sec7/sub10/tit",
                                    "block type": "title",
                                    "content": "Bounds for Sch\"oning Walks and Groverized Walks",
                                    "leftover": "Bounds for Sch\"oning Walks and Groverized Walks",
                                    "matches": []
                                },
                                {
                                    "leaf id": 275,
                                    "key": "doc/body/sec7/sub10/txl0",
                                    "block type": "txl",
                                    "content": "Here we combine the previous observations in order to obtain the following lower bounds on the successprobability of the Sch\"oning process. We also obtain the inequalites needed for determining the desired bound on the successprobability of the the Groverized walk.",
                                    "leftover": "Here we combine the previous observations in order to obtain the following lower bounds on the successprobability of the Sch\"oning process. We also obtain the inequalites needed for determining the desired bound on the successprobability of the the Groverized walk.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 276,
                                    "key": "doc/body/sec7/sub10/proposition1",
                                    "block type": "proposition",
                                    "content": "Let (xl)l∈ be the Sch\"oning process for bit strings of length n, with x^⋆ the selected satisfying assignment. Let (d̃l)l be the process as defined by () and (). Let (dl)l be the Markov chain as defined by the transition probabilites () for q = 2/3 in Lemma, for the initial state \\begin{equation} P(d0 = j) = \\left{\\begin{matrix} P(\\tilde{d}0 = j) = P\\big(dH(x0,x^{\\star}) =j\\big) = {1}{2^n}\\binom{n}{j}, & \\quad n\\geq j \\geq 0 0, & \\quad otherwise \\end{matrix}\\right. \\end{equation} Then \\begin{equation} \\begin{split} P(xm = x^{\\star}) \\geq & P(\\tilde{d}m= 0) \\geq & P(dm\\leq 0) = & \\sum{\\substack{j,l: j+ m2l \\leq 0, 0 \\leq j\\leq n, 0\\leq l\\leq m}} {1}{2^n}\\binom{n}{j} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml} \\end{split} \\end{equation} and \\begin{equation} \\begin{split} P\\big(xm = x^{\\star}\\big|dH(x0|x^{\\star}) = j\\big) \\geq & P(\\tilde{d}m = 0|\\tilde{d}0 = j) \\geq & P(dm\\leq 0|d0 = j) = & \\sum{\\substack{l: j+ m2l \\leq 0, 0\\leq l\\leq m}} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml}. \\end{split} \\end{equation}",
                                    "leftover": "Let (xl)l∈ be the Sch\"oning process for bit strings of length n, with x^⋆ the selected satisfying assignment. Let (d̃l)l be the process as defined by () and (). Let (dl)l be the Markov chain as defined by the transition probabilites () for q = 2/3 in Lemma, for the initial state \\begin{equation} P(d0 = j) = \\left{\\begin{matrix} P(\\tilde{d}0 = j) = P\\big(dH(x0,x^{\\star}) =j\\big) = {1}{2^n}\\binom{n}{j}, & \\quad n\\geq j \\geq 0 0, & \\quad otherwise \\end{matrix}\\right. \\end{equation} Then \\begin{equation} \\begin{split} P(xm = x^{\\star}) \\geq & P(\\tilde{d}m= 0) \\geq & P(dm\\leq 0) = & \\sum{\\substack{j,l: j+ m2l \\leq 0, 0 \\leq j\\leq n, 0\\leq l\\leq m}} {1}{2^n}\\binom{n}{j} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml} \\end{split} \\end{equation} and \\begin{equation} \\begin{split} P\\big(xm = x^{\\star}\\big|dH(x0|x^{\\star}) = j\\big) \\geq & P(\\tilde{d}m = 0|\\tilde{d}0 = j) \\geq & P(dm\\leq 0|d0 = j) = & \\sum{\\substack{l: j+ m2l \\leq 0, 0\\leq l\\leq m}} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml}. \\end{split} \\end{equation}",
                                    "matches": []
                                },
                                {
                                    "leaf id": 277,
                                    "key": "doc/body/sec7/sub10/proof2",
                                    "block type": "proof",
                                    "content": "By () in Lemma yields the first inequality in (). By Proposition we know that (d̃l)l is a Markov chain with transition probabilities as in () and initial distribution (). By these observations, it follows that the second inequality in () is a direct application of () in Lemma . By Lemma, we also know that the Markov chain (dl)l defined by the transition probabilities \\begin{equation} P(d{l+1} = j|d{l} = k) = {1}{3}\\delta{j,k1} + {2}{3}\\delta{j,k+1},\\quad \\forall j,k\\in\\mathbbZ,\\quad \\forall l\\in\\mathbbN. \\end{equation} and initial distribution \\begin{equation} P(d0 = j) = \\left{\\begin{matrix} P(\\tilde{d}0 = j), & \\quad j \\geq 0 0, & \\quad j <0 \\end{matrix}\\right. \\quad= \\left{\\begin{matrix} {1}{2^n}\\binom{n}{j}, & 0\\leq j\\leq n 0, & otherwise \\end{matrix}\\right. \\end{equation} From () it follows that \\begin{equation} P(dm\\leq 0|d0 = j) = \\sum{l: j+m2l\\leq 0,\\, 0\\leq l\\leq m} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml} \\end{equation} and thus \\begin{equation} \\begin{split} P(dm\\leq 0) = & \\sumj P(dm\\leq 0|d0 = j)P(d0 = j) & [\\textrm{By ()}] = & \\sum{\\substack{j,l: j+ m2l \\leq 0, 0 \\leq j\\leq n, 0\\leq l\\leq m}} {1}{2^n}\\binom{n}{j} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml}. \\end{split} \\end{equation} Next, we turn to the inequalities in (). Inequality () in Lemma yields the first inequality in (). The second inequality in () is a direct application of () in Lemma (). By () we already know the last equality in ().",
                                    "leftover": "By () in Lemma yields the first inequality in (). By Proposition we know that (d̃l)l is a Markov chain with transition probabilities as in () and initial distribution (). By these observations, it follows that the second inequality in () is a direct application of () in Lemma . By Lemma, we also know that the Markov chain (dl)l defined by the transition probabilities \\begin{equation} P(d{l+1} = j|d{l} = k) = {1}{3}\\delta{j,k1} + {2}{3}\\delta{j,k+1},\\quad \\forall j,k\\in\\mathbbZ,\\quad \\forall l\\in\\mathbbN. \\end{equation} and initial distribution \\begin{equation} P(d0 = j) = \\left{\\begin{matrix} P(\\tilde{d}0 = j), & \\quad j \\geq 0 0, & \\quad j <0 \\end{matrix}\\right. \\quad= \\left{\\begin{matrix} {1}{2^n}\\binom{n}{j}, & 0\\leq j\\leq n 0, & otherwise \\end{matrix}\\right. \\end{equation} From () it follows that \\begin{equation} P(dm\\leq 0|d0 = j) = \\sum{l: j+m2l\\leq 0,\\, 0\\leq l\\leq m} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml} \\end{equation} and thus \\begin{equation} \\begin{split} P(dm\\leq 0) = & \\sumj P(dm\\leq 0|d0 = j)P(d0 = j) & [\\textrm{By ()}] = & \\sum{\\substack{j,l: j+ m2l \\leq 0, 0 \\leq j\\leq n, 0\\leq l\\leq m}} {1}{2^n}\\binom{n}{j} \\binom{m}{l} \\left({1}{3}\\right)^{l}\\left({2}{3}\\right)^{ml}. \\end{split} \\end{equation} Next, we turn to the inequalities in (). Inequality () in Lemma yields the first inequality in (). The second inequality in () is a direct application of () in Lemma (). By () we already know the last equality in ().",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec7/sub11",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 278,
                                    "key": "doc/body/sec7/sub11/tit",
                                    "block type": "title",
                                    "content": "Relation to the leading order analysis of the Sch\"oning and GW process",
                                    "leftover": "Relation to the leading order analysis of the Sch\"oning and GW process",
                                    "matches": []
                                },
                                {
                                    "leaf id": 279,
                                    "key": "doc/body/sec7/sub11/txl0",
                                    "block type": "txl",
                                    "content": "Here we connect to the analysis of the asymptotic scaling in the main text, by obtaining the starting points, so to speak, of the leading order analysis of the Sch\"oning process and the GW process.",
                                    "leftover": "Here we connect to the analysis of the asymptotic scaling in the main text, by obtaining the starting points, so to speak, of the leading order analysis of the Sch\"oning process and the GW process.",
                                    "matches": []
                                },
                                {
                                    "key": "doc/body/sec7/sub11/ssb1",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 280,
                                            "key": "doc/body/sec7/sub11/ssb1/tit",
                                            "block type": "title",
                                            "content": "Sch\"oning process",
                                            "leftover": "Sch\"oning process",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 281,
                                            "key": "doc/body/sec7/sub11/ssb1/txl0",
                                            "block type": "txl",
                                            "content": "For the Sch\"oning process, the average number of repetitions needed to find a solution is given by",
                                            "leftover": "For the Sch\"oning process, the average number of repetitions needed to find a solution is given by",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 282,
                                            "key": "doc/body/sec7/sub11/ssb1/equation1",
                                            "block type": "equation",
                                            "content": "NSch\"oning = 1P(xm = x^⋆).",
                                            "leftover": "NSch\"oning = 1P(xm = x^⋆).",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 283,
                                            "key": "doc/body/sec7/sub11/ssb1/equation2",
                                            "block type": "equation",
                                            "content": "P(xm = x^⋆) ≥P(dm≤0)",
                                            "leftover": "P(xm = x^⋆) ≥P(dm≤0)",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 284,
                                            "key": "doc/body/sec7/sub11/ssb1/txl3",
                                            "block type": "txl",
                                            "content": "The leadingorder analysis in the main text is based on further such inequalities, with the rationale that the 'loss' of probability weight becomes irrelevant for the rates γ = limn→∞1nlog NSch\"oning, if the inequalities are chosen to correspond to the leading order contributions. As a first step along these lines, we restrict to an event where we not only reach the desired solution, but also start the system x0 at Hamming distance dH(x0,x^⋆) = j. Trivially,",
                                            "leftover": "The leadingorder analysis in the main text is based on further such inequalities, with the rationale that the 'loss' of probability weight becomes irrelevant for the rates γ = limn→∞1nlog NSch\"oning, if the inequalities are chosen to correspond to the leading order contributions. As a first step along these lines, we restrict to an event where we not only reach the desired solution, but also start the system x0 at Hamming distance dH(x0,x^⋆) = j. Trivially,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 285,
                                            "key": "doc/body/sec7/sub11/ssb1/equation4",
                                            "block type": "equation",
                                            "content": "P(dm≤0) ≥P(dm≤0, d0 = j) = P(d0 = j)P(dm ≤0|d0 = j),",
                                            "leftover": "P(dm≤0) ≥P(dm≤0, d0 = j) = P(d0 = j)P(dm ≤0|d0 = j),",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 286,
                                            "key": "doc/body/sec7/sub11/ssb1/txl5",
                                            "block type": "txl",
                                            "content": "where can identify P(d0 = j) with P(E1) in the main text, i.e.",
                                            "leftover": "where can identify P(d0 = j) with P(E1) in the main text, i.e.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 287,
                                            "key": "doc/body/sec7/sub11/ssb1/equation6",
                                            "block type": "equation",
                                            "content": "P(d0 = j) = P(E1) = 12^nnκn, j = κn.",
                                            "leftover": "P(d0 = j) = P(E1) = 12^nnκn, j = κn.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 288,
                                            "key": "doc/body/sec7/sub11/ssb1/txl7",
                                            "block type": "txl",
                                            "content": "Next, we wish to connect the remaining factor in, i.e., P(dm≤ 0|d0 = j), to the probability P(E2), which we recall from the main text corresponds to the event E2, where precisely ν m steps decrease the Hamming distance, while precisely (1ν)m steps increase the Hamming distance. (For the walk on this extends to ν m steps in the negative direction, and (1ν)m steps in the positive direction.) We conclude that the total decrease is",
                                            "leftover": "Next, we wish to connect the remaining factor in, i.e., P(dm≤ 0|d0 = j), to the probability P(E2), which we recall from the main text corresponds to the event E2, where precisely ν m steps decrease the Hamming distance, while precisely (1ν)m steps increase the Hamming distance. (For the walk on this extends to ν m steps in the negative direction, and (1ν)m steps in the positive direction.) We conclude that the total decrease is",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 289,
                                            "key": "doc/body/sec7/sub11/ssb1/equation8",
                                            "block type": "equation",
                                            "content": "d0dm = (2ν1)m.",
                                            "leftover": "d0dm = (2ν1)m.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 290,
                                            "key": "doc/body/sec7/sub11/ssb1/txl9",
                                            "block type": "txl",
                                            "content": "Let us also recall that the combination of E1 and E2 is successful, i.e. leads to dm≤ 0, if",
                                            "leftover": "Let us also recall that the combination of E1 and E2 is successful, i.e. leads to dm≤ 0, if",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 291,
                                            "key": "doc/body/sec7/sub11/ssb1/equation10",
                                            "block type": "equation",
                                            "content": "(2ν1)m≥κn.",
                                            "leftover": "(2ν1)m≥κn.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 292,
                                            "key": "doc/body/sec7/sub11/ssb1/txl11",
                                            "block type": "txl",
                                            "content": "It is useful to note that (dl)l is not only Markovian, but also translation symmetric, which means that the change d0dm is independent of the initial state d0, i.e., the joint distribution of these factorize. (As a side remark, this independence also means that P(E1∩ E2) = P(E1)P(E2).) Hence,",
                                            "leftover": "It is useful to note that (dl)l is not only Markovian, but also translation symmetric, which means that the change d0dm is independent of the initial state d0, i.e., the joint distribution of these factorize. (As a side remark, this independence also means that P(E1∩ E2) = P(E1)P(E2).) Hence,",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 293,
                                            "key": "doc/body/sec7/sub11/ssb1/equation12",
                                            "block type": "equation",
                                            "content": "P(dm≤0|d0 = κn) = P(d0dm≥κn|d0 = κn) [Since d0dm is independent of d0] = P(d0dm≥κn).",
                                            "leftover": "P(dm≤0|d0 = κn) = P(d0dm≥κn|d0 = κn) [Since d0dm is independent of d0] = P(d0dm≥κn).",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 294,
                                            "key": "doc/body/sec7/sub11/ssb1/txl13",
                                            "block type": "txl",
                                            "content": "By comparison of with it follows that",
                                            "leftover": "By comparison of with it follows that",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 295,
                                            "key": "doc/body/sec7/sub11/ssb1/equation14",
                                            "block type": "equation",
                                            "content": "P(dm≤0|d0 = κn) = P(d0dm≥κn) ≥P(E2), if (2ν1)m≥κn.",
                                            "leftover": "P(dm≤0|d0 = κn) = P(d0dm≥κn) ≥P(E2), if (2ν1)m≥κn.",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 296,
                                            "key": "doc/body/sec7/sub11/ssb1/txl15",
                                            "block type": "txl",
                                            "content": "Alternatively, we can reach the same conclusion by comparing with to see that",
                                            "leftover": "Alternatively, we can reach the same conclusion by comparing with to see that",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 297,
                                            "key": "doc/body/sec7/sub11/ssb1/equation16",
                                            "block type": "equation",
                                            "content": "P(E2) = mνm(13)^νm(23)^(1ν)m ≤P(dm≤0|d0 = κn), if (2ν1)m≥κn",
                                            "leftover": "P(E2) = mνm(13)^νm(23)^(1ν)m ≤P(dm≤0|d0 = κn), if (2ν1)m≥κn",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 298,
                                            "key": "doc/body/sec7/sub11/ssb1/txl17",
                                            "block type": "txl",
                                            "content": "By,,, and, we can conclude that",
                                            "leftover": "By,,, and, we can conclude that",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 299,
                                            "key": "doc/body/sec7/sub11/ssb1/equation18",
                                            "block type": "equation",
                                            "content": "NSch\"oning≤1P(E1)P(E2), if (2ν1)m≥κn.",
                                            "leftover": "NSch\"oning≤1P(E1)P(E2), if (2ν1)m≥κn.",
                                            "matches": []
                                        }
                                    ]
                                },
                                {
                                    "key": "doc/body/sec7/sub11/ssb2",
                                    "block_type": "ssb",
                                    "children": [
                                        {
                                            "leaf id": 300,
                                            "key": "doc/body/sec7/sub11/ssb2/tit",
                                            "block type": "title",
                                            "content": "GW process",
                                            "leftover": "GW process",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 301,
                                            "key": "doc/body/sec7/sub11/ssb2/txl0",
                                            "block type": "txl",
                                            "content": "For the GW process, let us recall that it consists of a classical outer loop that at each round assigns a definite (classical) initial state, while the walkprocess is Groverized. We assume that the number of iterations of the Groverprocedure is tuned to the density of successful walks, for a specific initial Hamming distance j = κ n, i.e., to the successprobability P(xm = x^⋆|dH(x0|x^⋆) = κ n). In the analysis we lower bound the successprobability by assuming that process fails whenever dH(x0,x^⋆) ≠κ n (which may be pessimistic). The probability to obtain the initial state x0 with Hamming distance κ n is P(dH(x0,x^⋆) =κ n), and thus in average we need to repeat the outer loop 1/P(dH(x0,x^⋆) =κ n) times to be guaranteed to at least once reach the initial Hamming distance κ n. In the successful case, the Grover procedure requires 1/√(P(xm = x^⋆|dH(x0|x^⋆) = κ n)) iterations. Consequently, an upper bound on the total number of steps is",
                                            "leftover": "For the GW process, let us recall that it consists of a classical outer loop that at each round assigns a definite (classical) initial state, while the walkprocess is Groverized. We assume that the number of iterations of the Groverprocedure is tuned to the density of successful walks, for a specific initial Hamming distance j = κ n, i.e., to the successprobability P(xm = x^⋆|dH(x0|x^⋆) = κ n). In the analysis we lower bound the successprobability by assuming that process fails whenever dH(x0,x^⋆) ≠κ n (which may be pessimistic). The probability to obtain the initial state x0 with Hamming distance κ n is P(dH(x0,x^⋆) =κ n), and thus in average we need to repeat the outer loop 1/P(dH(x0,x^⋆) =κ n) times to be guaranteed to at least once reach the initial Hamming distance κ n. In the successful case, the Grover procedure requires 1/√(P(xm = x^⋆|dH(x0|x^⋆) = κ n)) iterations. Consequently, an upper bound on the total number of steps is",
                                            "matches": []
                                        },
                                        {
                                            "leaf id": 302,
                                            "key": "doc/body/sec7/sub11/ssb2/equation1",
                                            "block type": "equation",
                                            "content": "NGW ≤ 1P(dH(x0,x^⋆) =κn)√(P(xm = x^⋆|dH(x0|x^⋆) = κn)) [By Proposition ] ≤ 1P(d0 = κn)√(P(dm≤0|d0 = κn)) [By and ] ≤ 1P(E1)√(P(E2)), if (2ν1)m≥κn.",
                                            "leftover": "NGW ≤ 1P(dH(x0,x^⋆) =κn)√(P(xm = x^⋆|dH(x0|x^⋆) = κn)) [By Proposition ] ≤ 1P(d0 = κn)√(P(dm≤0|d0 = κn)) [By and ] ≤ 1P(E1)√(P(E2)), if (2ν1)m≥κn.",
                                            "matches": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    ]
}