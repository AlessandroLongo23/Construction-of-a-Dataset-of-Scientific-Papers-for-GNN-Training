\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{art:LeNet,art:AlexNet,art:ResNet,art:ViT}
\citation{art:Shastri,art:Lin,art:Zuo,art:Colburn,art:Li,art:Luo,art:McMahon}
\citation{art:Mangini,art:Tacchino,art:Cerezo1,art:Senokosov,art:Cerezo2}
\citation{art:Steinbrecher,art:Killoran,art:Sui,art:Stanev,art:Wood}
\citation{art:Mandel}
\citation{art:Bowie}
\newlabel{FirstPage}{{}{1}{}{section*.1}{}}
\newlabel{FirstPage@cref}{{}{[1][1][]1}}
\@writefile{toc}{\contentsline {title}{Quantum optical classifier with superexponential speedup}{1}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {abstract}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section*.3}\protected@file@percent }
\newlabel{sec:SecII}{{II}{1}{}{section*.4}{}}
\newlabel{sec:SecII@cref}{{[section][2][]II}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}METHOD}{1}{section*.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Quantum optical neuron implemented by the Hong-Ou-Mandel interferometric setup. An object is targeted by a single-photon source and classified through the rate of two-photon coincidences at the interferometer output, without reconstructing its full image. In the top branch, an additional thin lens can translate the classification problem to the Fourier domain.}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:Setup}{{1}{1}{Quantum optical neuron implemented by the Hong-Ou-Mandel interferometric setup. An object is targeted by a single-photon source and classified through the rate of two-photon coincidences at the interferometer output, without reconstructing its full image. In the top branch, an additional thin lens can translate the classification problem to the Fourier domain}{figure.1}{}}
\newlabel{fig:Setup@cref}{{[figure][1][]1}{[1][1][]1}}
\citation{art:Glorot}
\newlabel{eq:PsiO}{{1}{2}{}{equation.2.1}{}}
\newlabel{eq:PsiO@cref}{{[equation][1][]1}{[1][2][]2}}
\newlabel{eq:PsiProbe}{{2}{2}{}{equation.2.2}{}}
\newlabel{eq:PsiProbe@cref}{{[equation][2][]2}{[1][2][]2}}
\newlabel{eq:BosonicCoincidences}{{3}{2}{}{equation.2.3}{}}
\newlabel{eq:BosonicCoincidences@cref}{{[equation][3][]3}{[1][2][]2}}
\newlabel{eq:NetworkBraketPosition}{{5}{2}{}{equation.2.5}{}}
\newlabel{eq:NetworkBraketPosition@cref}{{[equation][5][]5}{[1][2][]2}}
\newlabel{eq:SigmoidFunction}{{6}{2}{}{equation.2.6}{}}
\newlabel{eq:SigmoidFunction@cref}{{[equation][6][]6}{[1][2][]2}}
\newlabel{eq:FinalOutputPosition}{{7}{2}{}{equation.2.7}{}}
\newlabel{eq:FinalOutputPosition@cref}{{[equation][7][]7}{[1][2][]2}}
\newlabel{eq:DerivativeComplete}{{8}{2}{}{equation.2.8}{}}
\newlabel{eq:DerivativeComplete@cref}{{[equation][8][]8}{[1][2][]2}}
\citation{art:Neff}
\citation{art:Zhang}
\citation{soft:TensorFlow}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Mathematical relationship between the Hong-Ou-Mandel apparatus of \cref  {fig:Setup} and the classical neuron of \cref  {eq:PerceptronAnalogy}. Each operation is identified with the corresponding component of the optical interferometer.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:Perceptron}{{2}{3}{Mathematical relationship between the Hong-Ou-Mandel apparatus of \cref {fig:Setup} and the classical neuron of \cref {eq:PerceptronAnalogy}. Each operation is identified with the corresponding component of the optical interferometer}{figure.2}{}}
\newlabel{fig:Perceptron@cref}{{[figure][2][]2}{[1][3][]3}}
\newlabel{eq:PerceptronAnalogy}{{9}{3}{}{equation.2.9}{}}
\newlabel{eq:PerceptronAnalogy@cref}{{[equation][9][]9}{[1][3][]3}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Computational and optical resources comparison between the quantum optical neuron (QON) and its classical counterparts, when reconstructing and classifying an image $x$ of $N$ pixels. Here, $\varsigma $ and $\langle x \rangle $ are the standard deviation and the average brightness of the image (which depend on the reflectivity of the object), while $\varepsilon $ is the uncertainty on the classification outcome. Our method achieves a superexponential speedup over its classical counterpart: $\mathcal  {O}(1)$ vs. $\mathcal  {O}(N)$.}}{3}{table.1}\protected@file@percent }
\newlabel{tab:ResourceCost}{{I}{3}{Computational and optical resources comparison between the quantum optical neuron (QON) and its classical counterparts, when reconstructing and classifying an image $x$ of $N$ pixels. Here, $\varsigma $ and $\langle x \rangle $ are the standard deviation and the average brightness of the image (which depend on the reflectivity of the object), while $\varepsilon $ is the uncertainty on the classification outcome. Our method achieves a superexponential speedup over its classical counterpart: $\mathcal {O}(1)$ vs. $\mathcal {O}(N)$}{table.1}{}}
\newlabel{tab:ResourceCost@cref}{{[table][1][]I}{[1][3][]3}}
\newlabel{sec:SecIII}{{III}{3}{}{section*.5}{}}
\newlabel{sec:SecIII@cref}{{[section][3][]III}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}AMPLITUDE MODULATED PROBE}{3}{section*.5}\protected@file@percent }
\newlabel{eq:LCD}{{11}{3}{}{equation.3.11}{}}
\newlabel{eq:LCD@cref}{{[equation][11][]11}{[1][3][]3}}
\newlabel{eq:LCDLayerSpatial}{{12}{3}{}{equation.3.12}{}}
\newlabel{eq:LCDLayerSpatial@cref}{{[equation][12][]12}{[1][3][]3}}
\newlabel{eq:LCDDerivativePosition}{{13}{3}{}{equation.3.13}{}}
\newlabel{eq:LCDDerivativePosition@cref}{{[equation][13][]13}{[1][3][]3}}
\citation{art:Bengio,art:Rosenblatt,art:AlexNet}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison between the quantum optical neuron (QON), a single classical neuron and a convolutional network, all trained with the same number of $\sim 1024$ parameters, optimizer and learning rates. The quantum optical neuron is modelled by an amplitude modulated probe with resolution of $32 \times 32$ pixels, both in the spatial and in the Fourier domains. The optimization is performed with learning rates $\eta _\lambda = 0.075$ and $\eta _b = 0.005$. (a) Accuracy versus the number of training epochs for the MNIST dataset. The models are trained to distinguish among images of \emph  {zeros} and \emph  {ones}, showing compatible results in terms of trainability and accuracy, whose final value is above $99\%$. The inset is a history plot of the binary cross-entropy, used as loss function in the gradient descent optimization. (b-c) Accuracy and binary cross-entropy plots versus the number of training epochs for the CIFAR-10 dataset. The models are trained to classify images of \emph  {cats} and \emph  {dogs}. Our method reaches an asymptotic accuracy above $58\%$, showing an advantage with respect to its classical counterparts.}}{4}{figure.3}\protected@file@percent }
\newlabel{fig:Training}{{3}{4}{Comparison between the quantum optical neuron (QON), a single classical neuron and a convolutional network, all trained with the same number of $\sim 1024$ parameters, optimizer and learning rates. The quantum optical neuron is modelled by an amplitude modulated probe with resolution of $32 \times 32$ pixels, both in the spatial and in the Fourier domains. The optimization is performed with learning rates $\eta _\lambda = 0.075$ and $\eta _b = 0.005$. (a) Accuracy versus the number of training epochs for the MNIST dataset. The models are trained to distinguish among images of \emph {zeros} and \emph {ones}, showing compatible results in terms of trainability and accuracy, whose final value is above $99\%$. The inset is a history plot of the binary cross-entropy, used as loss function in the gradient descent optimization. (b-c) Accuracy and binary cross-entropy plots versus the number of training epochs for the CIFAR-10 dataset. The models are trained to classify images of \emph {cats} and \emph {dogs}. Our method reaches an asymptotic accuracy above $58\%$, showing an advantage with respect to its classical counterparts}{figure.3}{}}
\newlabel{fig:Training@cref}{{[figure][3][]3}{[1][3][]4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Simulations}{4}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusions}{4}{section*.7}\protected@file@percent }
\citation{rep:QON}
\citation{art:Rezai}
\citation{book:Saleh}
\@writefile{toc}{\contentsline {section}{\numberline {}Acknowledgements}{5}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {}Data availability}{5}{section*.9}\protected@file@percent }
\@writefile{toc}{\appendix }
\newlabel{app:Imaging}{{A}{5}{}{section*.10}{}}
\newlabel{app:Imaging@cref}{{[appendix][1][2147483647]A}{[1][5][]5}}
\@writefile{toc}{\contentsline {section}{\numberline {A}SINGLE-PHOTON ENCODING}{5}{section*.10}\protected@file@percent }
\newlabel{eq:ObjectTransfer}{{A4}{5}{}{equation.A.4}{}}
\newlabel{eq:ObjectTransfer@cref}{{[equation][4][2147483647,1]A4}{[1][5][]5}}
\citation{art:Branczyk}
\newlabel{app:Coincidences}{{B}{6}{}{section*.11}{}}
\newlabel{app:Coincidences@cref}{{[appendix][2][2147483647]B}{[1][5][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {B}HONG-OU-MANDEL COINCIDENCES}{6}{section*.11}\protected@file@percent }
\newlabel{eq:PsiBipartite}{{B1}{6}{}{equation.B.1}{}}
\newlabel{eq:PsiBipartite@cref}{{[equation][1][2147483647,2]B1}{[1][5][]6}}
\newlabel{eq:PsiBipartiteOutput}{{B3}{6}{}{equation.B.3}{}}
\newlabel{eq:PsiBipartiteOutput@cref}{{[equation][3][2147483647,2]B3}{[1][6][]6}}
\newlabel{eq:CoincStep}{{B6}{6}{}{equation.B.6}{}}
\newlabel{eq:CoincStep@cref}{{[equation][6][2147483647,2]B6}{[1][6][]6}}
\citation{art:Rezai}
\newlabel{app:Training}{{C}{7}{}{section*.12}{}}
\newlabel{app:Training@cref}{{[appendix][3][2147483647]C}{[1][6][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {C}TRAINING}{7}{section*.12}\protected@file@percent }
\newlabel{eq:EntropyDerivative}{{C8}{7}{}{equation.C.8}{}}
\newlabel{eq:EntropyDerivative@cref}{{[equation][8][2147483647,3]C8}{[1][7][]7}}
\newlabel{eq:DerivativeCompleteApp}{{C10}{7}{}{equation.C.10}{}}
\newlabel{eq:DerivativeCompleteApp@cref}{{[equation][10][2147483647,3]C10}{[1][7][]7}}
\newlabel{eq:DerivativeApproximation}{{C11}{7}{}{equation.C.11}{}}
\newlabel{eq:DerivativeApproximation@cref}{{[equation][11][2147483647,3]C11}{[1][7][]7}}
\newlabel{app:Fourier}{{D}{7}{}{section*.13}{}}
\newlabel{app:Fourier@cref}{{[appendix][4][2147483647]D}{[1][7][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {D}CLASSIFICATION IN THE FOURIER DOMAIN}{7}{section*.13}\protected@file@percent }
\citation{art:Boyle}
\newlabel{eq:Lens}{{D1}{8}{}{equation.D.1}{}}
\newlabel{eq:Lens@cref}{{[equation][1][2147483647,4]D1}{[1][7][]8}}
\newlabel{eq:BosonicCoincidencesFourier}{{D2}{8}{}{equation.D.2}{}}
\newlabel{eq:BosonicCoincidencesFourier@cref}{{[equation][2][2147483647,4]D2}{[1][7][]8}}
\newlabel{eq:NetworkBraketFourierInProbe}{{D3}{8}{}{equation.D.3}{}}
\newlabel{eq:NetworkBraketFourierInProbe@cref}{{[equation][3][2147483647,4]D3}{[1][7][]8}}
\newlabel{eq:FinalOutputFourier}{{D4}{8}{}{equation.D.4}{}}
\newlabel{eq:FinalOutputFourier@cref}{{[equation][4][2147483647,4]D4}{[1][8][]8}}
\newlabel{eq:NetworkFourier}{{D5}{8}{}{equation.D.5}{}}
\newlabel{eq:NetworkFourier@cref}{{[equation][5][2147483647,4]D5}{[1][8][]8}}
\newlabel{eq:NetworkBraketFourierInImage}{{D6}{8}{}{equation.D.6}{}}
\newlabel{eq:NetworkBraketFourierInImage@cref}{{[equation][6][2147483647,4]D6}{[1][8][]8}}
\newlabel{eq:DerivativeApproximationFourier}{{D7}{8}{}{equation.D.7}{}}
\newlabel{eq:DerivativeApproximationFourier@cref}{{[equation][7][2147483647,4]D7}{[1][8][]8}}
\newlabel{eq:LCDLayerFourier}{{D8}{8}{}{equation.D.8}{}}
\newlabel{eq:LCDLayerFourier@cref}{{[equation][8][2147483647,4]D8}{[1][8][]8}}
\newlabel{eq:LCDDerivativeFourier}{{D9}{8}{}{equation.D.9}{}}
\newlabel{eq:LCDDerivativeFourier@cref}{{[equation][9][2147483647,4]D9}{[1][8][]8}}
\newlabel{app:Advantage}{{E}{8}{}{section*.14}{}}
\newlabel{app:Advantage@cref}{{[appendix][5][2147483647]E}{[1][8][]8}}
\@writefile{toc}{\contentsline {section}{\numberline {E}OPTICAL AND COMPUTATIONAL ADVANTAGE}{8}{section*.14}\protected@file@percent }
\newlabel{eq:ComputationalNeuronApp}{{E1}{8}{}{equation.E.1}{}}
\newlabel{eq:ComputationalNeuronApp@cref}{{[equation][1][2147483647,5]E1}{[1][8][]8}}
\citation{art:Kolobov,art:Fabre}
\newlabel{eq:AvgStdDev}{{E3}{9}{}{equation.E.3}{}}
\newlabel{eq:AvgStdDev@cref}{{[equation][3][2147483647,5]E3}{[1][9][]9}}
\newlabel{eq:StandardErrorClassification}{{E4}{9}{}{equation.E.4}{}}
\newlabel{eq:StandardErrorClassification@cref}{{[equation][4][2147483647,5]E4}{[1][9][]9}}
\citation{art:Santosa,art:Tikhonov}
\citation{book:Rotondi}
\bibdata{mainNotes,refs.bib}
\bibcite{art:LeNet}{{1}{1998}{{Lecun\ \emph  {et~al.}}}{{Lecun, Bottou, Bengio,\ and\ Haffner}}}
\bibcite{art:AlexNet}{{2}{2017}{{Krizhevsky\ \emph  {et~al.}}}{{Krizhevsky, Sutskever,\ and\ Hinton}}}
\bibcite{art:ResNet}{{3}{}{{He\ \emph  {et~al.}}}{{He, Zhang, Ren,\ and\ Sun}}}
\bibcite{art:ViT}{{4}{}{{Dosovitskiy\ \emph  {et~al.}}}{{Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit,\ and\ Houlsby}}}
\bibcite{art:Shastri}{{5}{2021}{{Shastri\ \emph  {et~al.}}}{{Shastri, Tait, Ferreira~de Lima, Pernice, Bhaskaran, Wright,\ and\ Prucnal}}}
\bibcite{art:Lin}{{6}{2018}{{Lin\ \emph  {et~al.}}}{{Lin, Rivenson, Yardimci, Veli, Luo, Jarrahi,\ and\ Ozcan}}}
\bibcite{art:Zuo}{{7}{2019}{{Zuo\ \emph  {et~al.}}}{{Zuo, Li, Zhao, Jiang, Chen, Chen, Jo, Liu,\ and\ Du}}}
\bibcite{art:Colburn}{{8}{2019}{{Colburn\ \emph  {et~al.}}}{{Colburn, Chu, Shilzerman,\ and\ Majumdar}}}
\bibcite{art:Li}{{9}{2021}{{Li\ \emph  {et~al.}}}{{Li, Ni, Feng, Cui, Liu, Zhang,\ and\ Huang}}}
\bibcite{art:Luo}{{10}{2022}{{Luo\ \emph  {et~al.}}}{{Luo, Zhao, Li, Çetintaş, Rivenson, Jarrahi,\ and\ Ozcan}}}
\bibcite{art:McMahon}{{11}{2023}{{McMahon}}{{}}}
\bibcite{art:Mangini}{{12}{2019}{{Benatti\ \emph  {et~al.}}}{{Benatti, Mancini,\ and\ Mangini}}}
\bibcite{art:Tacchino}{{13}{2019}{{Tacchino\ \emph  {et~al.}}}{{Tacchino, Macchiavello, Gerace,\ and\ Bajoni}}}
\bibcite{art:Cerezo1}{{14}{2021}{{Cerezo\ \emph  {et~al.}}}{{Cerezo, Arrasmith, Babbush, Benjamin, Endo, Fujii, McClean, Mitarai, Yuan, Cincio,\ and\ Coles}}}
\bibcite{art:Senokosov}{{15}{2024}{{Senokosov\ \emph  {et~al.}}}{{Senokosov, Sedykh, Sagingalieva, Kyriacou,\ and\ Melnikov}}}
\bibcite{art:Cerezo2}{{16}{2024}{{Cerezo\ \emph  {et~al.}}}{{Cerezo, Larocca, García-Martín, Diaz, Braccia, Fontana, Rudolph, Bermejo, Ijaz, Thanasilp, Anschuetz,\ and\ Holmes}}}
\@writefile{toc}{\contentsline {section}{\numberline {}References}{10}{section*.15}\protected@file@percent }
\bibcite{art:Steinbrecher}{{17}{2019}{{Steinbrecher\ \emph  {et~al.}}}{{Steinbrecher, Olson, Englund,\ and\ Carolan}}}
\bibcite{art:Killoran}{{18}{2019}{{Killoran\ \emph  {et~al.}}}{{Killoran, Bromley, Arrazola, Schuld, Quesada,\ and\ Lloyd}}}
\bibcite{art:Sui}{{19}{2020}{{Sui\ \emph  {et~al.}}}{{Sui, Wu, Liu, Chen,\ and\ Gu}}}
\bibcite{art:Stanev}{{20}{2023}{{Stanev\ \emph  {et~al.}}}{{Stanev, Spagnolo,\ and\ Sciarrino}}}
\bibcite{art:Wood}{{21}{2024}{{Wood\ \emph  {et~al.}}}{{Wood, Shrapnel,\ and\ Milburn}}}
\bibcite{art:Mandel}{{22}{1987}{{Hong\ \emph  {et~al.}}}{{Hong, Ou,\ and\ Mandel}}}
\bibcite{art:Bowie}{{23}{2023}{{Bowie\ \emph  {et~al.}}}{{Bowie, Shrapnel,\ and\ Kewming}}}
\bibcite{art:Glorot}{{24}{2010}{{Glorot\ and\ Bengio}}{{}}}
\bibcite{art:Neff}{{25}{1990}{{Neff\ \emph  {et~al.}}}{{Neff, Athale,\ and\ Lee}}}
\bibcite{art:Zhang}{{26}{2014}{{Zhang\ \emph  {et~al.}}}{{Zhang, You,\ and\ Chu}}}
\bibcite{soft:TensorFlow}{{27}{2023}{{{Tensor{F}low Developers}}}{{}}}
\bibcite{art:Bengio}{{28}{}{{Collobert\ and\ Bengio}}{{}}}
\bibcite{art:Rosenblatt}{{29}{1958}{{Rosenblatt}}{{}}}
\bibcite{rep:QON}{{30}{}{{Morgillo\ and\ Roncallo}}{{}}}
\bibcite{art:Rezai}{{31}{2022}{{Rezai\ and\ Salehi}}{{}}}
\bibcite{book:Saleh}{{32}{1991}{{Saleh\ and\ Teich}}{{}}}
\bibcite{art:Branczyk}{{33}{2017}{{Brańczyk}}{{}}}
\bibcite{art:Boyle}{{34}{1970}{{Boyle\ and\ Smith}}{{}}}
\bibcite{art:Kolobov}{{35}{1999}{{Kolobov}}{{}}}
\bibcite{art:Fabre}{{36}{2008}{{Delaubert\ \emph  {et~al.}}}{{Delaubert, Treps, Fabre, Bachor,\ and\ Réfrégier}}}
\bibcite{art:Santosa}{{37}{1986}{{Santosa\ and\ Symes}}{{}}}
\bibcite{art:Tikhonov}{{38}{1965}{{Tikhonov\ and\ Glasko}}{{}}}
\bibcite{book:Rotondi}{{39}{2022}{{Rotondi\ \emph  {et~al.}}}{{Rotondi, Pedroni,\ and\ Pievatolo}}}
\bibstyle{apsrev4-2}
\citation{REVTEX42Control}
\citation{apsrev42Control}
\newlabel{LastBibItem}{{39}{11}{}{section*.15}{}}
\newlabel{LastBibItem@cref}{{[section][4][]IV}{[1][11][]11}}
\newlabel{LastPage}{{}{11}{}{}{}}
\gdef \@abspage@last{11}
