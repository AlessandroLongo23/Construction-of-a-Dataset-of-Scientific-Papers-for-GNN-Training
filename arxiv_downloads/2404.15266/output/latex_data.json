{
    "key": "doc",
    "block_type": "document",
    "children": [
        {
            "leaf id": 0,
            "key": "doc/tit",
            "block type": "title",
            "content": "Quantum optical classifier with superexponential speedup",
            "leftover": "Quantum optical classifier with superexponential speedup",
            "matches": []
        },
        {
            "leaf id": 1,
            "key": "doc/aut0",
            "block type": "author",
            "content": "{Simone Roncallo\\,\\orcidlink{0000000335069027}} \\email[Simone Roncallo: ]{simone.roncallo01@ateneopv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Angela Rosy Morgillo\\,\\orcidlink{0009000661420692} \\email[Angela Rosy Morgillo: ]{angelarosy.morgillo01@ateneopv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Chiara Macchiavello\\,\\orcidlink{0000000229558759} \\email[Chiara Macchiavello: ]{chiara.macchiavello@unipv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Lorenzo Maccone\\,\\orcidlink{0000000267295312} \\email[Lorenzo Maccone: ]{lorenzo.maccone@unipv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Seth Lloyd\\,\\orcidlink{0000000303534529} \\email[Seth Lloyd: ]{slloyd@mit.edu} Massachusetts Institute of Technology, Cambridge, MA 02139, USA",
            "leftover": "{Simone Roncallo\\,\\orcidlink{0000000335069027}} \\email[Simone Roncallo: ]{simone.roncallo01@ateneopv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Angela Rosy Morgillo\\,\\orcidlink{0009000661420692} \\email[Angela Rosy Morgillo: ]{angelarosy.morgillo01@ateneopv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Chiara Macchiavello\\,\\orcidlink{0000000229558759} \\email[Chiara Macchiavello: ]{chiara.macchiavello@unipv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Lorenzo Maccone\\,\\orcidlink{0000000267295312} \\email[Lorenzo Maccone: ]{lorenzo.maccone@unipv.it} Dipartimento di Fisica, UniversitÃ  degli Studi di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy INFN Sezione di Pavia, Via Agostino Bassi 6, I27100, Pavia, Italy Seth Lloyd\\,\\orcidlink{0000000303534529} \\email[Seth Lloyd: ]{slloyd@mit.edu} Massachusetts Institute of Technology, Cambridge, MA 02139, USA",
            "matches": []
        },
        {
            "leaf id": 2,
            "key": "doc/abs",
            "block type": "abstract",
            "content": "We present a quantum optical pattern recognition method for binary classification tasks. Without direct image reconstruction, it classifies an object in terms of the rate of twophoton coincidences at the output of a HongOuMandel interferometer, where both the input and the classifier parameters are encoded into singlephoton states. Our method exhibits the same behaviour of a classical neuron of unit depth. Once trained, it shows a constant ğ’ª(1) complexity in the number of computational operations and photons required by a single classification. This is a superexponential advantage over a classical neuron (that is at least linear in the image resolution). We provide simulations and analytical comparisons with analogous neural network architectures.",
            "leftover": "We present a quantum optical pattern recognition method for binary classification tasks. Without direct image reconstruction, it classifies an object in terms of the rate of twophoton coincidences at the output of a HongOuMandel interferometer, where both the input and the classifier parameters are encoded into singlephoton states. Our method exhibits the same behaviour of a classical neuron of unit depth. Once trained, it shows a constant ğ’ª(1) complexity in the number of computational operations and photons required by a single classification. This is a superexponential advantage over a classical neuron (that is at least linear in the image resolution). We provide simulations and analytical comparisons with analogous neural network architectures.",
            "matches": []
        },
        {
            "key": "doc/body",
            "block_type": "body",
            "children": [
                {
                    "key": "doc/body/sec0",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 3,
                            "key": "doc/body/sec0/tit",
                            "block type": "title",
                            "content": "Introduction",
                            "leftover": "Introduction",
                            "matches": []
                        },
                        {
                            "leaf id": 4,
                            "key": "doc/body/sec0/txl0",
                            "block type": "txl",
                            "content": "Image classification has been significantly affected by the introduction of deep learning algorithms, providing several architectures that can learn and extract image features . The large number of parameters involved is motivating a consistent effort in reducing the cost of these methods, e.g. by leveraging alloptical implementations that bypass hardware usage, or quantum mechanical effects that can provide a significant speedup in these computations . Quantum optical neural networks harness the best of both worlds, i.e. deep learning capabilities from quantum optics .",
                            "leftover": "Image classification has been significantly affected by the introduction of deep learning algorithms, providing several architectures that can learn and extract image features . The large number of parameters involved is motivating a consistent effort in reducing the cost of these methods, e.g. by leveraging alloptical implementations that bypass hardware usage, or quantum mechanical effects that can provide a significant speedup in these computations . Quantum optical neural networks harness the best of both worlds, i.e. deep learning capabilities from quantum optics .",
                            "matches": []
                        },
                        {
                            "leaf id": 5,
                            "key": "doc/body/sec0/txl1",
                            "block type": "txl",
                            "content": "In this paper, we introduce a quantum optical setup to classify objects without reconstructing their images. Our approach relies on the HongOuMandel effect, for which the probability that two photons exit a beam splitter in different modes, depends on their distinguishability . In our implementation, an input object is targeted by a singlephoton source, and eventually followed by an arbitrary lens system. The singlephoton state interferes with another one, which encodes a set of trainable parameters, e.g. through a spatial light modulator. Classification occurs by measuring the rate of twophoton coincidences at the HongOuMandel output (see ). The HongOuMandel effect has been successfully applied to quantum kernel evaluation, which can compute distances between pairs of data points in the feature space. In this case, each point is sent to one branch of the interferometer, encoded in the temporal modes of a singlephoton state. In our method, the interferometer has only one independent branch, which takes the spatial modes of a singlephoton state reflected off the target object. The other branch remains fixed after training, and contains the layer of parameters. After the measurement, the response function of our apparatus mathematically resembles that of a classical neuron. For this reason, we refer to our setup as quantum optical neuron. By analytically comparing the resource cost of the classical and quantum neurons, we show that our method requires constant ğ’ª(1) computational operations and injected photons, whereas the classical methods are at least linear in the image resolution: a superexponential advantage.",
                            "leftover": "In this paper, we introduce a quantum optical setup to classify objects without reconstructing their images. Our approach relies on the HongOuMandel effect, for which the probability that two photons exit a beam splitter in different modes, depends on their distinguishability . In our implementation, an input object is targeted by a singlephoton source, and eventually followed by an arbitrary lens system. The singlephoton state interferes with another one, which encodes a set of trainable parameters, e.g. through a spatial light modulator. Classification occurs by measuring the rate of twophoton coincidences at the HongOuMandel output (see ). The HongOuMandel effect has been successfully applied to quantum kernel evaluation, which can compute distances between pairs of data points in the feature space. In this case, each point is sent to one branch of the interferometer, encoded in the temporal modes of a singlephoton state. In our method, the interferometer has only one independent branch, which takes the spatial modes of a singlephoton state reflected off the target object. The other branch remains fixed after training, and contains the layer of parameters. After the measurement, the response function of our apparatus mathematically resembles that of a classical neuron. For this reason, we refer to our setup as quantum optical neuron. By analytically comparing the resource cost of the classical and quantum neurons, we show that our method requires constant ğ’ª(1) computational operations and injected photons, whereas the classical methods are at least linear in the image resolution: a superexponential advantage.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec0/figure2",
                            "block_type": "figure",
                            "children": [
                                {
                                    "leaf id": 6,
                                    "key": "doc/body/sec0/figure2/cpt0",
                                    "block type": "cpt",
                                    "content": "Quantum optical neuron implemented by the HongOuMandel interferometric setup. An object is targeted by a singlephoton source and classified through the rate of twophoton coincidences at the interferometer output, without reconstructing its full image. In the top branch, an additional thin lens can translate the classification problem to the Fourier domain.",
                                    "leftover": "Quantum optical neuron implemented by the HongOuMandel interferometric setup. An object is targeted by a singlephoton source and classified through the rate of twophoton coincidences at the interferometer output, without reconstructing its full image. In the top branch, an additional thin lens can translate the classification problem to the Fourier domain.",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec1",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 7,
                            "key": "doc/body/sec1/tit",
                            "block type": "title",
                            "content": "METHOD",
                            "leftover": "METHOD",
                            "matches": []
                        },
                        {
                            "leaf id": 8,
                            "key": "doc/body/sec1/txl0",
                            "block type": "txl",
                            "content": "In this section, we discuss the apparatus of, without explicitly modelling the probe. Two singlephoton states are fed into the left and top branches of a 50:50 beam splitter, acting as input and processing layers, respectively. In the left branch, the singlephoton source reflects off the object, and reaches the beam splitter after a linear optical system. In the top branch, we consider a generic singlephoton state, which depends on a set of trainable real parameters. We count the twophoton coincidences at the beam splitter output. We show how to interpret the HongOuMandel response as the one produced by a singlelayer neural networklike operation on the object image.",
                            "leftover": "In this section, we discuss the apparatus of, without explicitly modelling the probe. Two singlephoton states are fed into the left and top branches of a 50:50 beam splitter, acting as input and processing layers, respectively. In the left branch, the singlephoton source reflects off the object, and reaches the beam splitter after a linear optical system. In the top branch, we consider a generic singlephoton state, which depends on a set of trainable real parameters. We count the twophoton coincidences at the beam splitter output. We show how to interpret the HongOuMandel response as the one produced by a singlelayer neural networklike operation on the object image.",
                            "matches": []
                        },
                        {
                            "leaf id": 9,
                            "key": "doc/body/sec1/txl1",
                            "block type": "txl",
                            "content": "We call input and probe modes, i.e. a and b, those fed into the left and top branches of the interferometer. In the input branch, a single photon with spectrum Ï• is generated at the longitudinal origin z=0, followed by an object with twodimensional shape ğ’ª. An imaging system with transfer function â„’d, e.g a pinhole or a linear optical apparatus, is placed after the object. Here, zo and zi are the longitudinal positions of the object and the image plane, respectively, and d = zi  zo their displacement.",
                            "leftover": "We call input and probe modes, i.e. a and b, those fed into the left and top branches of the interferometer. In the input branch, a single photon with spectrum Ï• is generated at the longitudinal origin z=0, followed by an object with twodimensional shape ğ’ª. An imaging system with transfer function â„’d, e.g a pinhole or a linear optical apparatus, is placed after the object. Here, zo and zi are the longitudinal positions of the object and the image plane, respectively, and d = zi  zo their displacement.",
                            "matches": []
                        },
                        {
                            "leaf id": 10,
                            "key": "doc/body/sec1/txl2",
                            "block type": "txl",
                            "content": "The output of the imaging optics reads (see )",
                            "leftover": "The output of the imaging optics reads (see )",
                            "matches": []
                        },
                        {
                            "leaf id": 11,
                            "key": "doc/body/sec1/equation3",
                            "block type": "equation",
                            "content": "|Î¨â„ âŸ© = âˆ«^2k â„Ì‚Ï‰(k | ğ’ª ) a^â€ gerÏ‰(k) |0âŸ©,",
                            "leftover": "|Î¨â„ âŸ© = âˆ«^2k â„Ì‚Ï‰(k | ğ’ª ) a^â€ gerÏ‰(k) |0âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 12,
                            "key": "doc/body/sec1/txl4",
                            "block type": "txl",
                            "content": "with â„Ì‚Ï‰(Â·|ğ’ª ) = [(Ï•Ì‚Ï‰â„ŒÌ‚zo)*ğ’ªÌ‚] â„’Ì‚d the total transfer function from the singlephoton source to the image plane, and a^â€ Ï‰(k) the creation operator of a photon in the input mode, acting on the vacuum state |0âŸ©. The hat operator denotes the twodimensional Fourier transform on the transverse coordinates plane, * the convolution operation, â„Œzo the transfer function from the source to the object plane, k = (kx, ky) the transverse momentum, and Ï‰ the frequency conjugated to the temporal degree of freedom of the electromagnetic potential.",
                            "leftover": "with â„Ì‚Ï‰(Â·|ğ’ª ) = [(Ï•Ì‚Ï‰â„ŒÌ‚zo)*ğ’ªÌ‚] â„’Ì‚d the total transfer function from the singlephoton source to the image plane, and a^â€ Ï‰(k) the creation operator of a photon in the input mode, acting on the vacuum state |0âŸ©. The hat operator denotes the twodimensional Fourier transform on the transverse coordinates plane, * the convolution operation, â„Œzo the transfer function from the source to the object plane, k = (kx, ky) the transverse momentum, and Ï‰ the frequency conjugated to the temporal degree of freedom of the electromagnetic potential.",
                            "matches": []
                        },
                        {
                            "leaf id": 13,
                            "key": "doc/body/sec1/txl5",
                            "block type": "txl",
                            "content": "In the probe branch, a generic quantum state is prepared, eventually followed by a linear optical system. At the beam splitter plane, the probe state reads",
                            "leftover": "In the probe branch, a generic quantum state is prepared, eventually followed by a linear optical system. At the beam splitter plane, the probe state reads",
                            "matches": []
                        },
                        {
                            "leaf id": 14,
                            "key": "doc/body/sec1/equation6",
                            "block type": "equation",
                            "content": "|Î¨ğ’° âŸ© = âˆ«^2k ğ’°Ì‚Ï‰(k|Î») bÏ‰^â€ ger(k) |0âŸ©,",
                            "leftover": "|Î¨ğ’° âŸ© = âˆ«^2k ğ’°Ì‚Ï‰(k|Î») bÏ‰^â€ ger(k) |0âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 15,
                            "key": "doc/body/sec1/txl7",
                            "block type": "txl",
                            "content": "with Î» = Î»i1 â€¦ in a collection of (trainable) parameters, ğ’° the spatial spectrum of the probe, and b^â€ Ï‰(k) the creation operator of a photon in the probe mode.",
                            "leftover": "with Î» = Î»i1 â€¦ in a collection of (trainable) parameters, ğ’° the spatial spectrum of the probe, and b^â€ Ï‰(k) the creation operator of a photon in the probe mode.",
                            "matches": []
                        },
                        {
                            "leaf id": 16,
                            "key": "doc/body/sec1/txl8",
                            "block type": "txl",
                            "content": "A photodetector is placed at the output of each branch. After feeding both states into a 50:50 beam splitter, the rate of twophoton coincidences reads",
                            "leftover": "A photodetector is placed at the output of each branch. After feeding both states into a 50:50 beam splitter, the rate of twophoton coincidences reads",
                            "matches": []
                        },
                        {
                            "leaf id": 17,
                            "key": "doc/body/sec1/align9",
                            "block type": "align",
                            "content": "p(1a âˆ©1b|Î», ğ’ª ) = {12[Î±Î»(ğ’ª )  Î»(ğ’ª ) ], with Î±Î»(ğ’ª ) = || Ï‰(Â·|ğ’ª ) ||^2 || Ï‰(Â·|Î») ||^2, Î»(ğ’ª ) = | âŸ¨Ï‰(Â·|ğ’ª ),Ï‰(Â·|Î») âŸ©|^2,",
                            "leftover": "p(1a âˆ©1b|Î», ğ’ª ) = {12[Î±Î»(ğ’ª )  Î»(ğ’ª ) ], with Î±Î»(ğ’ª ) = || Ï‰(Â·|ğ’ª ) ||^2 || Ï‰(Â·|Î») ||^2, Î»(ğ’ª ) = | âŸ¨Ï‰(Â·|ğ’ª ),Ï‰(Â·|Î») âŸ©|^2,",
                            "matches": []
                        },
                        {
                            "leaf id": 18,
                            "key": "doc/body/sec1/txl10",
                            "block type": "txl",
                            "content": "where || Â· || and âŸ¨Â·, Â·âŸ© denote the L^2norm and inner product, respectively. Here, Î±Î»(ğ’ª ) depends on the normalization of the input and probe states, which can be Î±Î» < 1 in the presence of optical losses. Whenever the two spectra are indistinguishable, i.e. when ğ’° perfectly matches â„, coincidences are not observed. On the other hand, the more distinguishable the input and the probe states are, the smaller âŸ¨â„ (Â·|ğ’ª ),ğ’° (Â·|Î») âŸ© becomes and the rate of coincidences increases. See for a derivation, and, for a similar result in the Fourier domain.",
                            "leftover": "where || Â· || and âŸ¨Â·, Â·âŸ© denote the L^2norm and inner product, respectively. Here, Î±Î»(ğ’ª ) depends on the normalization of the input and probe states, which can be Î±Î» < 1 in the presence of optical losses. Whenever the two spectra are indistinguishable, i.e. when ğ’° perfectly matches â„, coincidences are not observed. On the other hand, the more distinguishable the input and the probe states are, the smaller âŸ¨â„ (Â·|ğ’ª ),ğ’° (Â·|Î») âŸ© becomes and the rate of coincidences increases. See for a derivation, and, for a similar result in the Fourier domain.",
                            "matches": []
                        },
                        {
                            "leaf id": 19,
                            "key": "doc/body/sec1/txl11",
                            "block type": "txl",
                            "content": "At the image plane I, with transverse coordinates r = (x,y), we have",
                            "leftover": "At the image plane I, with transverse coordinates r = (x,y), we have",
                            "matches": []
                        },
                        {
                            "leaf id": 20,
                            "key": "doc/body/sec1/equation12",
                            "block type": "equation",
                            "content": "Î»(ğ’ª ) = | âˆ«I r Ï‰(r|ğ’ª )Ï‰^*(r|Î») |^2 .",
                            "leftover": "Î»(ğ’ª ) = | âˆ«I r Ï‰(r|ğ’ª )Ï‰^*(r|Î») |^2 .",
                            "matches": []
                        },
                        {
                            "leaf id": 21,
                            "key": "doc/body/sec1/txl13",
                            "block type": "txl",
                            "content": "This integral measures the pointwise overlap between the input image and the probe. We interpret it as the prediction of our classification model, where Î»âˆˆ [0,1] represents the probability that â„ belongs to the class of ğ’°. In particular, Î»â†’ 0 (Î»â†’ 1) when the class of â„ is orthogonal to (is the same of) ğ’°. In the next section, we show how to encode a generic class in ğ’°, by means of the optimization of the set of parameters Î».",
                            "leftover": "This integral measures the pointwise overlap between the input image and the probe. We interpret it as the prediction of our classification model, where Î»âˆˆ [0,1] represents the probability that â„ belongs to the class of ğ’°. In particular, Î»â†’ 0 (Î»â†’ 1) when the class of â„ is orthogonal to (is the same of) ğ’°. In the next section, we show how to encode a generic class in ğ’°, by means of the optimization of the set of parameters Î».",
                            "matches": []
                        },
                        {
                            "leaf id": 22,
                            "key": "doc/body/sec1/txl14",
                            "block type": "txl",
                            "content": "The output measurement introduces a nonlinear operation after the beam splitter, represented by the squared absolute value in the lefthand side of . We increase the predictability of our model, by enhancing this nonlinearity through the following postprocessing operations. Consider the sigmoid (logistic) function",
                            "leftover": "The output measurement introduces a nonlinear operation after the beam splitter, represented by the squared absolute value in the lefthand side of . We increase the predictability of our model, by enhancing this nonlinearity through the following postprocessing operations. Consider the sigmoid (logistic) function",
                            "matches": []
                        },
                        {
                            "leaf id": 23,
                            "key": "doc/body/sec1/equation15",
                            "block type": "equation",
                            "content": "Ïƒ(x) := {11+e^Î²x + Î³,",
                            "leftover": "Ïƒ(x) := {11+e^Î²x + Î³,",
                            "matches": []
                        },
                        {
                            "leaf id": 24,
                            "key": "doc/body/sec1/txl16",
                            "block type": "txl",
                            "content": "where Î², Î³ are hyperparameters, i.e. constants with respect to the training process. We introduce an additional trainable parameter b âˆˆâ„, called bias, which, combined with fÎ» and Ïƒ, yields",
                            "leftover": "where Î², Î³ are hyperparameters, i.e. constants with respect to the training process. We introduce an additional trainable parameter b âˆˆâ„, called bias, which, combined with fÎ» and Ïƒ, yields",
                            "matches": []
                        },
                        {
                            "leaf id": 25,
                            "key": "doc/body/sec1/equation17",
                            "block type": "equation",
                            "content": "bÎ»(ğ’ª ) = Ïƒ(Î»(ğ’ª ) + b),",
                            "leftover": "bÎ»(ğ’ª ) = Ïƒ(Î»(ğ’ª ) + b),",
                            "matches": []
                        },
                        {
                            "leaf id": 26,
                            "key": "doc/body/sec1/txl18",
                            "block type": "txl",
                            "content": "which determines the label predicted by the HongOuMandel apparatus. These modifications can improve the performance of the neuron. The sigmoid increases the nonlinearity introduced by the squared absolute value, and so the predictability of the model. In addition, the bias is introduced on heuristic motivations: it compensates the constraint given by the normalization in, while enhancing the robustness of our protocol against optical losses (which may affect the abovementioned normalizability, yielding Î±Î» < 1).",
                            "leftover": "which determines the label predicted by the HongOuMandel apparatus. These modifications can improve the performance of the neuron. The sigmoid increases the nonlinearity introduced by the squared absolute value, and so the predictability of the model. In addition, the bias is introduced on heuristic motivations: it compensates the constraint given by the normalization in, while enhancing the robustness of our protocol against optical losses (which may affect the abovementioned normalizability, yielding Î±Î» < 1).",
                            "matches": []
                        },
                        {
                            "leaf id": 27,
                            "key": "doc/body/sec1/txl19",
                            "block type": "txl",
                            "content": "We now discuss the training stage. Consider a training set, i.e. an ensemble of objects Ã˜j with target labels yj âˆˆ0,1. We separately feed each object into the input branch of the interferometer. Predicted and target classes are compared in terms of their binary crossentropy, which is used as loss function of a gradient descent optimizer. The optimizer updates Î» through the derivative of the loss function, whose only modeldependent contribution is",
                            "leftover": "We now discuss the training stage. Consider a training set, i.e. an ensemble of objects Ã˜j with target labels yj âˆˆ0,1. We separately feed each object into the input branch of the interferometer. Predicted and target classes are compared in terms of their binary crossentropy, which is used as loss function of a gradient descent optimizer. The optimizer updates Î» through the derivative of the loss function, whose only modeldependent contribution is",
                            "matches": []
                        },
                        {
                            "leaf id": 28,
                            "key": "doc/body/sec1/equation20",
                            "block type": "equation",
                            "content": "âˆ‚Î»= 2 [ âŸ¨Ï‰, Ï‰ âŸ©âŸ¨Ï‰, âˆ‚Î»Ï‰ âŸ©^* ] .",
                            "leftover": "âˆ‚Î»= 2 [ âŸ¨Ï‰, Ï‰ âŸ©âŸ¨Ï‰, âˆ‚Î»Ï‰ âŸ©^* ] .",
                            "matches": []
                        },
                        {
                            "leaf id": 29,
                            "key": "doc/body/sec1/txl21",
                            "block type": "txl",
                            "content": "Ideally, the training is complete after finding a set of parameters that minimizes the loss. Notice that our model is resilient against the issue of gradient explosion, since it depends on physical data and functions only (see for a discussion).",
                            "leftover": "Ideally, the training is complete after finding a set of parameters that minimizes the loss. Notice that our model is resilient against the issue of gradient explosion, since it depends on physical data and functions only (see for a discussion).",
                            "matches": []
                        },
                        {
                            "leaf id": 30,
                            "key": "doc/body/sec1/txl22",
                            "block type": "txl",
                            "content": "There is a formal relationship between the postprocessed output of the HongOuMandel interferometer of and that of a classical neuron. Consider fÎ»(ğ’ª ) discretized and vectorized in a mesh of N cells, either in the spatial or in the Fourier domain. Then, corresponds to the composition of a realvalued neuron, with N trainable weights, square absolute value activation function and no bias, and a second neuron, with a scalar unit weight, sigmoid activation function and a trainable bias. Namely",
                            "leftover": "There is a formal relationship between the postprocessed output of the HongOuMandel interferometer of and that of a classical neuron. Consider fÎ»(ğ’ª ) discretized and vectorized in a mesh of N cells, either in the spatial or in the Fourier domain. Then, corresponds to the composition of a realvalued neuron, with N trainable weights, square absolute value activation function and no bias, and a second neuron, with a scalar unit weight, sigmoid activation function and a trainable bias. Namely",
                            "matches": []
                        },
                        {
                            "leaf id": 31,
                            "key": "doc/body/sec1/equation23",
                            "block type": "equation",
                            "content": "Gbw(x) = Ïƒ(|w Â·x|^2 + b ),",
                            "leftover": "Gbw(x) = Ïƒ(|w Â·x|^2 + b ),",
                            "matches": []
                        },
                        {
                            "leaf id": 32,
                            "key": "doc/body/sec1/txl24",
                            "block type": "txl",
                            "content": "where x âˆˆâ„‚^N is the input, while w âˆˆâ„‚^N and b âˆˆâ„ are the weights and bias, respectively. We can formally identify Gbw(x) with FbÎ»(ğ’ª ) under the substitution",
                            "leftover": "where x âˆˆâ„‚^N is the input, while w âˆˆâ„‚^N and b âˆˆâ„ are the weights and bias, respectively. We can formally identify Gbw(x) with FbÎ»(ğ’ª ) under the substitution",
                            "matches": []
                        },
                        {
                            "leaf id": 33,
                            "key": "doc/body/sec1/equation25",
                            "block type": "equation",
                            "content": "( x, w ) ( Ï‰(r|ğ’ª ), Ï‰(r|Î») ),",
                            "leftover": "( x, w ) ( Ï‰(r|ğ’ª ), Ï‰(r|Î») ),",
                            "matches": []
                        },
                        {
                            "leaf id": 34,
                            "key": "doc/body/sec1/txl26",
                            "block type": "txl",
                            "content": "where is the discretization and vectorization to â„‚^N. This analogy is represented in .",
                            "leftover": "where is the discretization and vectorization to â„‚^N. This analogy is represented in .",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec1/figure27",
                            "block_type": "figure",
                            "children": [
                                {
                                    "leaf id": 35,
                                    "key": "doc/body/sec1/figure27/cpt0",
                                    "block type": "cpt",
                                    "content": "Mathematical relationship between the HongOuMandel apparatus of and the classical neuron of . Each operation is identified with the corresponding component of the optical interferometer.",
                                    "leftover": "Mathematical relationship between the HongOuMandel apparatus of and the classical neuron of . Each operation is identified with the corresponding component of the optical interferometer.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "leaf id": 36,
                            "key": "doc/body/sec1/txl28",
                            "block type": "txl",
                            "content": "A classical neuron requires at least N photons and N computational operations to classify an image composed of N pixels. Our setup bypasses both costs, by leveraging two essential features. On the one hand, it is completely optical, avoiding the computational need of processing the image. On the other hand, it classifies patterns through the HongOuMandel effect, reducing the photon cost of imaging. In both ways, it provides a superexponential speedup, from ğ’ª(N) to ğ’ª(1). Photon losses due to absorption introduce a constant overhead in both the classical and quantum strategies, which depends on the total reflectivity of the object. We summarize this discussion in . See for a detailed derivation.",
                            "leftover": "A classical neuron requires at least N photons and N computational operations to classify an image composed of N pixels. Our setup bypasses both costs, by leveraging two essential features. On the one hand, it is completely optical, avoiding the computational need of processing the image. On the other hand, it classifies patterns through the HongOuMandel effect, reducing the photon cost of imaging. In both ways, it provides a superexponential speedup, from ğ’ª(N) to ğ’ª(1). Photon losses due to absorption introduce a constant overhead in both the classical and quantum strategies, which depends on the total reflectivity of the object. We summarize this discussion in . See for a detailed derivation.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec1/table29",
                            "block_type": "table",
                            "children": [
                                {
                                    "leaf id": 37,
                                    "key": "doc/body/sec1/table29/tabular0",
                                    "block type": "tabular",
                                    "content": "{|c|c|c|c|} \\cline{34} \\multicolumn{1}c{} & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}QON & Classical \\multicolumn{2}{|c|}{\\parbox{3cm}{ \\ [0.5pt] Computational (# of operations) [3pt]}} & ğ’ª(1) & N \\multirow{2}{*}{\\parbox{2.25cm}{ Optical (# of photons)}} & Imaging & None & Î˜(Ï‚^2âŸ¨ x âŸ© N) \\cline{24} & Classification & ğ’ª(Îµ^2) & Î©(Îµ^2âŸ¨ x âŸ© N)",
                                    "leftover": "{|c|c|c|c|} \\cline{34} \\multicolumn{1}c{} & \\multicolumn{1}{c|}{} & \\multicolumn{1}{c|}QON & Classical \\multicolumn{2}{|c|}{\\parbox{3cm}{ \\ [0.5pt] Computational (# of operations) [3pt]}} & ğ’ª(1) & N \\multirow{2}{*}{\\parbox{2.25cm}{ Optical (# of photons)}} & Imaging & None & Î˜(Ï‚^2âŸ¨ x âŸ© N) \\cline{24} & Classification & ğ’ª(Îµ^2) & Î©(Îµ^2âŸ¨ x âŸ© N)",
                                    "matches": []
                                },
                                {
                                    "leaf id": 38,
                                    "key": "doc/body/sec1/table29/cpt1",
                                    "block type": "cpt",
                                    "content": "Computational and optical resources comparison between the quantum optical neuron (QON) and its classical counterparts, when reconstructing and classifying an image x of N pixels. Here, Ï‚ and âŸ¨ x âŸ© are the standard deviation and the average brightness of the image (which depend on the reflectivity of the object), while Îµ is the uncertainty on the classification outcome. Our method achieves a superexponential speedup over its classical counterpart: ğ’ª(1) vs. ğ’ª(N).",
                                    "leftover": "Computational and optical resources comparison between the quantum optical neuron (QON) and its classical counterparts, when reconstructing and classifying an image x of N pixels. Here, Ï‚ and âŸ¨ x âŸ© are the standard deviation and the average brightness of the image (which depend on the reflectivity of the object), while Îµ is the uncertainty on the classification outcome. Our method achieves a superexponential speedup over its classical counterpart: ğ’ª(1) vs. ğ’ª(N).",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec2",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 39,
                            "key": "doc/body/sec2/tit",
                            "block type": "title",
                            "content": "AMPLITUDE MODULATED PROBE",
                            "leftover": "AMPLITUDE MODULATED PROBE",
                            "matches": []
                        },
                        {
                            "leaf id": 40,
                            "key": "doc/body/sec2/txl0",
                            "block type": "txl",
                            "content": "We specialize our discussion by replacing the generic probe state ğ’° with a toy model of an amplitude spatial light modulator (SLM), placed in the top branch of the HongOuMandel interferometer, e.g. a liquid crystal (LC) grid with negligible losses . Different approaches can be investigated, such as phaseonly SLM, which may exhibit superior resiliency against losses.",
                            "leftover": "We specialize our discussion by replacing the generic probe state ğ’° with a toy model of an amplitude spatial light modulator (SLM), placed in the top branch of the HongOuMandel interferometer, e.g. a liquid crystal (LC) grid with negligible losses . Different approaches can be investigated, such as phaseonly SLM, which may exhibit superior resiliency against losses.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec2/figure*1",
                            "block_type": "figure*",
                            "children": [
                                {
                                    "leaf id": 41,
                                    "key": "doc/body/sec2/figure*1/cpt0",
                                    "block type": "cpt",
                                    "content": "Comparison between the quantum optical neuron (QON), a single classical neuron and a convolutional network, all trained with the same number of âˆ¼ 1024 parameters, optimizer and learning rates. The quantum optical neuron is modelled by an amplitude modulated probe with resolution of 32 Ã— 32 pixels, both in the spatial and in the Fourier domains. The optimization is performed with learning rates Î·Î» = 0.075 and Î·b = 0.005. (a) Accuracy versus the number of training epochs for the MNIST dataset. The models are trained to distinguish among images of zeros and ones, showing compatible results in terms of trainability and accuracy, whose final value is above 99. The inset is a history plot of the binary crossentropy, used as loss function in the gradient descent optimization. (bc) Accuracy and binary crossentropy plots versus the number of training epochs for the CIFAR10 dataset. The models are trained to classify images of cats and dogs. Our method reaches an asymptotic accuracy above 58, showing an advantage with respect to its classical counterparts.",
                                    "leftover": "Comparison between the quantum optical neuron (QON), a single classical neuron and a convolutional network, all trained with the same number of âˆ¼ 1024 parameters, optimizer and learning rates. The quantum optical neuron is modelled by an amplitude modulated probe with resolution of 32 Ã— 32 pixels, both in the spatial and in the Fourier domains. The optimization is performed with learning rates Î·Î» = 0.075 and Î·b = 0.005. (a) Accuracy versus the number of training epochs for the MNIST dataset. The models are trained to distinguish among images of zeros and ones, showing compatible results in terms of trainability and accuracy, whose final value is above 99. The inset is a history plot of the binary crossentropy, used as loss function in the gradient descent optimization. (bc) Accuracy and binary crossentropy plots versus the number of training epochs for the CIFAR10 dataset. The models are trained to classify images of cats and dogs. Our method reaches an asymptotic accuracy above 58, showing an advantage with respect to its classical counterparts.",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "leaf id": 42,
                            "key": "doc/body/sec2/txl2",
                            "block type": "txl",
                            "content": "Consider a pattern on a greyscale LC grid with N real amplitudes Î»Î¼Î½. Each pixel, labelled by (Î¼,Î½), is represented by an L Ã— L square with center rÎ¼Î½ = (Î¼ + 1/2, Î½ + 1/2)L. Upon an overall parameterindependent normalization, the probe can be approximated as a combination of tophat functions",
                            "leftover": "Consider a pattern on a greyscale LC grid with N real amplitudes Î»Î¼Î½. Each pixel, labelled by (Î¼,Î½), is represented by an L Ã— L square with center rÎ¼Î½ = (Î¼ + 1/2, Î½ + 1/2)L. Upon an overall parameterindependent normalization, the probe can be approximated as a combination of tophat functions",
                            "matches": []
                        },
                        {
                            "leaf id": 43,
                            "key": "doc/body/sec2/equation3",
                            "block type": "equation",
                            "content": "Ï‰(r|Î») = âˆ‘Î¼,Î½ u(rrÎ¼Î½){Î»Î¼Î½||Î»||,",
                            "leftover": "Ï‰(r|Î») = âˆ‘Î¼,Î½ u(rrÎ¼Î½){Î»Î¼Î½||Î»||,",
                            "matches": []
                        },
                        {
                            "leaf id": 44,
                            "key": "doc/body/sec2/txl4",
                            "block type": "txl",
                            "content": "where ||Î»||^2 = âˆ‘Î¼,Î½Î»Î¼Î½^2 and u(r) := Î¸(r + L/2)Î¸(r  L/2), with Î¸ the twodimensional Heaviside step function. Under this choice, simplifies to",
                            "leftover": "where ||Î»||^2 = âˆ‘Î¼,Î½Î»Î¼Î½^2 and u(r) := Î¸(r + L/2)Î¸(r  L/2), with Î¸ the twodimensional Heaviside step function. Under this choice, simplifies to",
                            "matches": []
                        },
                        {
                            "leaf id": 45,
                            "key": "doc/body/sec2/equation5",
                            "block type": "equation",
                            "content": "Î»(ğ’ª ) = | âˆ‘Î¼,Î½ (u â‹†Ï‰)(rÎ¼Î½) {Î»Î¼Î½||Î»|| |^2,",
                            "leftover": "Î»(ğ’ª ) = | âˆ‘Î¼,Î½ (u â‹†Ï‰)(rÎ¼Î½) {Î»Î¼Î½||Î»|| |^2,",
                            "matches": []
                        },
                        {
                            "leaf id": 46,
                            "key": "doc/body/sec2/txl6",
                            "block type": "txl",
                            "content": "where â‹† is the crosscorrelation operation. We introduce a bias and a sigmoid activation function, so that the postprocessed output reads bÎ»(ğ’ª ) = Ïƒ(Î»(ğ’ª ) + b). Assuming that â„ is real, simplifies to",
                            "leftover": "where â‹† is the crosscorrelation operation. We introduce a bias and a sigmoid activation function, so that the postprocessed output reads bÎ»(ğ’ª ) = Ïƒ(Î»(ğ’ª ) + b). Assuming that â„ is real, simplifies to",
                            "matches": []
                        },
                        {
                            "leaf id": 47,
                            "key": "doc/body/sec2/equation7",
                            "block type": "equation",
                            "content": "âˆ‚Î¼Î½ â‰ƒ2 {âˆš(f)||Î»||[(u â‹†Ï‰)(rÎ¼Î½)  âˆš(f) {Î»Î¼Î½||Î»|| ],",
                            "leftover": "âˆ‚Î¼Î½ â‰ƒ2 {âˆš(f)||Î»||[(u â‹†Ï‰)(rÎ¼Î½)  âˆš(f) {Î»Î¼Î½||Î»|| ],",
                            "matches": []
                        },
                        {
                            "leaf id": 48,
                            "key": "doc/body/sec2/txl8",
                            "block type": "txl",
                            "content": "with âˆ‚Î¼Î½ := âˆ‚ f / âˆ‚Î»Î¼Î½. This expression can be evaluated in an alloptical way, by taking the amplitude measurement of â„ directly in the left branch of the interferometer, before the beam splitter. This operation can be done offline, and once per training object. In the next section, we present a simulation of these results, for different choices of the dataset.",
                            "leftover": "with âˆ‚Î¼Î½ := âˆ‚ f / âˆ‚Î»Î¼Î½. This expression can be evaluated in an alloptical way, by taking the amplitude measurement of â„ directly in the left branch of the interferometer, before the beam splitter. This operation can be done offline, and once per training object. In the next section, we present a simulation of these results, for different choices of the dataset.",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec2/sub9",
                            "block_type": "sub",
                            "children": [
                                {
                                    "leaf id": 49,
                                    "key": "doc/body/sec2/sub9/tit",
                                    "block type": "title",
                                    "content": "Simulations",
                                    "leftover": "Simulations",
                                    "matches": []
                                },
                                {
                                    "leaf id": 50,
                                    "key": "doc/body/sec2/sub9/txl0",
                                    "block type": "txl",
                                    "content": "We present a simulation of the model introduced above, comparing its performance against those of classical neural networkbased techniques, for different datasets. All the simulations are run in Python and TensorFlow, and summarized in .",
                                    "leftover": "We present a simulation of the model introduced above, comparing its performance against those of classical neural networkbased techniques, for different datasets. All the simulations are run in Python and TensorFlow, and summarized in .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 51,
                                    "key": "doc/body/sec2/sub9/txl1",
                                    "block type": "txl",
                                    "content": "We tested our model using two widely recognized datasets: the MNIST, which contains 28 Ã— 28 images of handwritten digits from 0 to 9, and the CIFAR10, comprised of 32 Ã— 32 color images, distributed across 10 different classes. We guaranteed a fair comparison by increasing the MNIST resolution to 32 Ã— 32 pixels (separately padding each image of the dataset), while converting the CIFAR10 to greyscale. We represent each element of the dataset as (xj, yj), where yj âˆˆ0, 1 is the true class label, and xj is the input vector, obtained by discretizing and vectorizing either the amplitudes â„ or their Fourier spectrum â„Ì‚, thus bypassing the simulation of the imaging optics. We adopt the binary crossentropy as loss function, combined with the standard (nonstochastic) gradient descent optimizer. We use the accuracy, i.e. the proportion of correct predictions over the total ones, as figure of merit of our results.",
                                    "leftover": "We tested our model using two widely recognized datasets: the MNIST, which contains 28 Ã— 28 images of handwritten digits from 0 to 9, and the CIFAR10, comprised of 32 Ã— 32 color images, distributed across 10 different classes. We guaranteed a fair comparison by increasing the MNIST resolution to 32 Ã— 32 pixels (separately padding each image of the dataset), while converting the CIFAR10 to greyscale. We represent each element of the dataset as (xj, yj), where yj âˆˆ0, 1 is the true class label, and xj is the input vector, obtained by discretizing and vectorizing either the amplitudes â„ or their Fourier spectrum â„Ì‚, thus bypassing the simulation of the imaging optics. We adopt the binary crossentropy as loss function, combined with the standard (nonstochastic) gradient descent optimizer. We use the accuracy, i.e. the proportion of correct predictions over the total ones, as figure of merit of our results.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 52,
                                    "key": "doc/body/sec2/sub9/txl2",
                                    "block type": "txl",
                                    "content": "Our model demonstrates significative performances in both datasets (see ). In the MNIST, it achieves accuracy rates exceeding 99, when discerning between zeros and ones. In the CIFAR10, it reaches accuracy above 58, when distinguishing between cats and dogs. This difference reflects the complexity of the two classification tasks.",
                                    "leftover": "Our model demonstrates significative performances in both datasets (see ). In the MNIST, it achieves accuracy rates exceeding 99, when discerning between zeros and ones. In the CIFAR10, it reaches accuracy above 58, when distinguishing between cats and dogs. This difference reflects the complexity of the two classification tasks.",
                                    "matches": []
                                },
                                {
                                    "leaf id": 53,
                                    "key": "doc/body/sec2/sub9/txl3",
                                    "block type": "txl",
                                    "content": "We compared our model against conventional neural network designs with a similar number of parameters. Specifically, we considered a single neuron and a convolutional neural network, commonly employed in pattern recognition tasks . Adopting the TensorFlow notation, the convolutional structure is: Conv2D (10, 3 Ã— 3) â†’ Conv2D (4, 2 Ã— 2) â†’ MaxPooling2D (2 Ã— 2). Roughly, all the architectures have âˆ¼ 10^3 trainable parameters. All the models equally perform in the MNIST dataset, both in terms of trainability and final accuracy. When applied to the CIFAR10 dataset, our classifier outperforms the conventional ones, showing superior efficiency under a stronglyconstrained parameters count. All the findings emphasize the competitive accuracy of our method, and also its comparative advantage in pattern recognition tasks with a limited number of parameters.",
                                    "leftover": "We compared our model against conventional neural network designs with a similar number of parameters. Specifically, we considered a single neuron and a convolutional neural network, commonly employed in pattern recognition tasks . Adopting the TensorFlow notation, the convolutional structure is: Conv2D (10, 3 Ã— 3) â†’ Conv2D (4, 2 Ã— 2) â†’ MaxPooling2D (2 Ã— 2). Roughly, all the architectures have âˆ¼ 10^3 trainable parameters. All the models equally perform in the MNIST dataset, both in terms of trainability and final accuracy. When applied to the CIFAR10 dataset, our classifier outperforms the conventional ones, showing superior efficiency under a stronglyconstrained parameters count. All the findings emphasize the competitive accuracy of our method, and also its comparative advantage in pattern recognition tasks with a limited number of parameters.",
                                    "matches": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "key": "doc/body/sec3",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 54,
                            "key": "doc/body/sec3/tit",
                            "block type": "title",
                            "content": "Conclusions",
                            "leftover": "Conclusions",
                            "matches": []
                        },
                        {
                            "leaf id": 55,
                            "key": "doc/body/sec3/txl0",
                            "block type": "txl",
                            "content": "In summary, we introduced an interferometric setup of a quantum optical classifier, with the HongOuMandel effect as cornerstone of our classification method. We demonstrated the mathematical relation between our model and a classical neuron, constrained to unit depth, showing their similarity in terms of structure and response function. Our design is completely optical and singlephoton based: it provides a superexponential speedup with respect to its classical counterpart, in terms of number of photons and computational resources. After modelling the classifier in terms of a spatial light modulator, we numerically compared our performances against those of standard neural network architectures, showing compatible to superior capabilities in terms of accuracy and training convergence, under the same number of parameters and depending on the pattern complexity.",
                            "leftover": "In summary, we introduced an interferometric setup of a quantum optical classifier, with the HongOuMandel effect as cornerstone of our classification method. We demonstrated the mathematical relation between our model and a classical neuron, constrained to unit depth, showing their similarity in terms of structure and response function. Our design is completely optical and singlephoton based: it provides a superexponential speedup with respect to its classical counterpart, in terms of number of photons and computational resources. After modelling the classifier in terms of a spatial light modulator, we numerically compared our performances against those of standard neural network architectures, showing compatible to superior capabilities in terms of accuracy and training convergence, under the same number of parameters and depending on the pattern complexity.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec4",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 56,
                            "key": "doc/body/sec4/tit",
                            "block type": "title",
                            "content": "Acknowledgements",
                            "leftover": "Acknowledgements",
                            "matches": []
                        },
                        {
                            "leaf id": 57,
                            "key": "doc/body/sec4/txl0",
                            "block type": "txl",
                            "content": "S.R. acknowledges support from the PRIN MUR Project 2022SW3RPY. A.R.M. acknowledges support from the PNRR MUR Project PE0000023NQSTI. C.M. acknowledges support from the National Research Centre for HPC, Big Data and Quantum Computing, PNRR MUR Project CN0000013ICSC. L.M. acknowledges support from the PRIN MUR Project 2022RATBS4 and from the U.S. Department of Energy, Office of Science, National Quantum Information Science Research Centers, Superconducting Quantum Materials and Systems Center (SQMS) under Contract No. DEAC0207CH11359. S.L. acknowledges support from ARO, DOE, and DARPA.",
                            "leftover": "S.R. acknowledges support from the PRIN MUR Project 2022SW3RPY. A.R.M. acknowledges support from the PNRR MUR Project PE0000023NQSTI. C.M. acknowledges support from the National Research Centre for HPC, Big Data and Quantum Computing, PNRR MUR Project CN0000013ICSC. L.M. acknowledges support from the PRIN MUR Project 2022RATBS4 and from the U.S. Department of Energy, Office of Science, National Quantum Information Science Research Centers, Superconducting Quantum Materials and Systems Center (SQMS) under Contract No. DEAC0207CH11359. S.L. acknowledges support from ARO, DOE, and DARPA.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec5",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 58,
                            "key": "doc/body/sec5/tit",
                            "block type": "title",
                            "content": "Data availability",
                            "leftover": "Data availability",
                            "matches": []
                        },
                        {
                            "leaf id": 59,
                            "key": "doc/body/sec5/txl0",
                            "block type": "txl",
                            "content": "The underlying code that generated the data for this study is openly available in GitHub .",
                            "leftover": "The underlying code that generated the data for this study is openly available in GitHub .",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec6",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 60,
                            "key": "doc/body/sec6/tit",
                            "block type": "title",
                            "content": "SINGLEPHOTON ENCODING",
                            "leftover": "SINGLEPHOTON ENCODING",
                            "matches": []
                        },
                        {
                            "leaf id": 61,
                            "key": "doc/body/sec6/txl0",
                            "block type": "txl",
                            "content": "In this section, we consider the singlephoton state obtained at the output of the left branch of the HongOuMandel apparatus, providing a detailed discussion of . We adopt units in which c = 1.",
                            "leftover": "In this section, we consider the singlephoton state obtained at the output of the left branch of the HongOuMandel apparatus, providing a detailed discussion of . We adopt units in which c = 1.",
                            "matches": []
                        },
                        {
                            "leaf id": 62,
                            "key": "doc/body/sec6/txl1",
                            "block type": "txl",
                            "content": "Consider a generic singlephoton state, generated by a monochromatic source with longitudinal position z",
                            "leftover": "Consider a generic singlephoton state, generated by a monochromatic source with longitudinal position z",
                            "matches": []
                        },
                        {
                            "leaf id": 63,
                            "key": "doc/body/sec6/equation2",
                            "block type": "equation",
                            "content": "|Î¨âŸ© = âˆ«^3k Î¦Ì‚(k) a^â€ ger(k)|0âŸ©,",
                            "leftover": "|Î¨âŸ© = âˆ«^3k Î¦Ì‚(k) a^â€ ger(k)|0âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 64,
                            "key": "doc/body/sec6/txl3",
                            "block type": "txl",
                            "content": "with momentum spectrum Î¦ and k = (kx,ky,kz). We neglect the polarization of the photon and consider the singlefrequencymode assumption, i.e. we assume that the wavefront propagates along definitesign zdirections only. Then, k = (kx,ky) represents the only independent degrees of freedom of the singlephoton state, which reads",
                            "leftover": "with momentum spectrum Î¦ and k = (kx,ky,kz). We neglect the polarization of the photon and consider the singlefrequencymode assumption, i.e. we assume that the wavefront propagates along definitesign zdirections only. Then, k = (kx,ky) represents the only independent degrees of freedom of the singlephoton state, which reads",
                            "matches": []
                        },
                        {
                            "leaf id": 65,
                            "key": "doc/body/sec6/align4",
                            "block type": "align",
                            "content": "|Î¨âŸ© = âˆ«^2k Ï•Ì‚Ï‰(k) a^â€ gerÏ‰(k)|0âŸ©, = âˆ«S ^2r Ï•Ï‰(r) aÏ‰^â€ ger(r)|0âŸ©,",
                            "leftover": "|Î¨âŸ© = âˆ«^2k Ï•Ì‚Ï‰(k) a^â€ gerÏ‰(k)|0âŸ©, = âˆ«S ^2r Ï•Ï‰(r) aÏ‰^â€ ger(r)|0âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 66,
                            "key": "doc/body/sec6/txl5",
                            "block type": "txl",
                            "content": "where Ï•Ì‚Ï‰(k) = Î¦Ì‚(kx,ky,âˆš(Ï‰^2kx^2ky^2)) and r = (rx,ry) labels the transverse coordinates on the source plane S.",
                            "leftover": "where Ï•Ì‚Ï‰(k) = Î¦Ì‚(kx,ky,âˆš(Ï‰^2kx^2ky^2)) and r = (rx,ry) labels the transverse coordinates on the source plane S.",
                            "matches": []
                        },
                        {
                            "leaf id": 67,
                            "key": "doc/body/sec6/txl6",
                            "block type": "txl",
                            "content": "For simplicity, we assume that the source is placed at the longitudinal origin z = 0. Consider an object with two dimensional shape ğ’ª, placed at longitudinal position zo. After freespace propagation occurs, the singlephoton spectrum undergoes spatial amplitude modulation, that is Î¨ğ’ª(r) = ğ’ª (r) Î¨(r)â†’, with Î¨(r)â†’ the spatial input wavefront on the object plane O. Namely",
                            "leftover": "For simplicity, we assume that the source is placed at the longitudinal origin z = 0. Consider an object with two dimensional shape ğ’ª, placed at longitudinal position zo. After freespace propagation occurs, the singlephoton spectrum undergoes spatial amplitude modulation, that is Î¨ğ’ª(r) = ğ’ª (r) Î¨(r)â†’, with Î¨(r)â†’ the spatial input wavefront on the object plane O. Namely",
                            "matches": []
                        },
                        {
                            "leaf id": 68,
                            "key": "doc/body/sec6/equation7",
                            "block type": "equation",
                            "content": "|Î¨ğ’ª âŸ© = âˆ«O ^2r [Ï•Ï‰*â„Œzo](r)ğ’ª (r) a^â€ gerÏ‰(r)|0âŸ©,",
                            "leftover": "|Î¨ğ’ª âŸ© = âˆ«O ^2r [Ï•Ï‰*â„Œzo](r)ğ’ª (r) a^â€ gerÏ‰(r)|0âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 69,
                            "key": "doc/body/sec6/txl8",
                            "block type": "txl",
                            "content": "where â„Œzo denotes the freespace transfer function between the S and O planes. Using twice the convolution theorem, it follows that",
                            "leftover": "where â„Œzo denotes the freespace transfer function between the S and O planes. Using twice the convolution theorem, it follows that",
                            "matches": []
                        },
                        {
                            "leaf id": 70,
                            "key": "doc/body/sec6/equation9",
                            "block type": "equation",
                            "content": "|Î¨ğ’ª âŸ© = âˆ«^2k [(Ï•Ì‚Ï‰â„Œzo)*ğ’ªÌ‚](k) a^â€ gerÏ‰(k) |0âŸ© .",
                            "leftover": "|Î¨ğ’ª âŸ© = âˆ«^2k [(Ï•Ì‚Ï‰â„Œzo)*ğ’ªÌ‚](k) a^â€ gerÏ‰(k) |0âŸ© .",
                            "matches": []
                        },
                        {
                            "leaf id": 71,
                            "key": "doc/body/sec6/txl10",
                            "block type": "txl",
                            "content": "Consider a linear optical system with transfer function â„’, with image plane at longitudinal position zi. By applying again the convolution theorem to Ï‰(Â·|ğ’ª ) = ((Ï•Ï‰*â„Œzo) Ã˜)*â„’zo  z, we obtain",
                            "leftover": "Consider a linear optical system with transfer function â„’, with image plane at longitudinal position zi. By applying again the convolution theorem to Ï‰(Â·|ğ’ª ) = ((Ï•Ï‰*â„Œzo) Ã˜)*â„’zo  z, we obtain",
                            "matches": []
                        },
                        {
                            "leaf id": 72,
                            "key": "doc/body/sec6/equation11",
                            "block type": "equation",
                            "content": "|Î¨â„ âŸ© = âˆ«^2k â„Ì‚Ï‰(k | ğ’ª ) a^â€ gerÏ‰(k) |0âŸ©,",
                            "leftover": "|Î¨â„ âŸ© = âˆ«^2k â„Ì‚Ï‰(k | ğ’ª ) a^â€ gerÏ‰(k) |0âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 73,
                            "key": "doc/body/sec6/txl12",
                            "block type": "txl",
                            "content": "with â„Ì‚Ï‰(k|ğ’ª ) = [(Ï•Ì‚Ï‰â„Œzo)*ğ’ªÌ‚] â„’Ì‚d. Notice that Ï‰(r|ğ’ª ) describes the image formed on a screen placed at distance d from the object.",
                            "leftover": "with â„Ì‚Ï‰(k|ğ’ª ) = [(Ï•Ì‚Ï‰â„Œzo)*ğ’ªÌ‚] â„’Ì‚d. Notice that Ï‰(r|ğ’ª ) describes the image formed on a screen placed at distance d from the object.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec7",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 74,
                            "key": "doc/body/sec7/tit",
                            "block type": "title",
                            "content": "HONGOUMANDEL COINCIDENCES",
                            "leftover": "HONGOUMANDEL COINCIDENCES",
                            "matches": []
                        },
                        {
                            "leaf id": 75,
                            "key": "doc/body/sec7/txl0",
                            "block type": "txl",
                            "content": "In this section, we compute the rate of coincidences at the output of the HongOuMandel interferometer of, with left and top branch states given by, respectively. We write the inputprobe bipartite state as",
                            "leftover": "In this section, we compute the rate of coincidences at the output of the HongOuMandel interferometer of, with left and top branch states given by, respectively. We write the inputprobe bipartite state as",
                            "matches": []
                        },
                        {
                            "leaf id": 76,
                            "key": "doc/body/sec7/equation1",
                            "block type": "equation",
                            "content": "|Î¨â„ âŸ© âŠ—|Î¨ğ’° âŸ© = âˆ«^2k1 ^2k2 Î¨Ì‚(k1,k2) a^â€ ger(k1) b^â€ ger(k2) |0âŸ©,",
                            "leftover": "|Î¨â„ âŸ© âŠ—|Î¨ğ’° âŸ© = âˆ«^2k1 ^2k2 Î¨Ì‚(k1,k2) a^â€ ger(k1) b^â€ ger(k2) |0âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 77,
                            "key": "doc/body/sec7/txl2",
                            "block type": "txl",
                            "content": "with Î¨Ì‚(k1,k2) = â„Ì‚(k1 | ğ’ª ) ğ’°Ì‚(k2|Î»), where we dropped the Ï‰ subscript for simplicity. The 50:50 beam splitter acts as the unitary operation",
                            "leftover": "with Î¨Ì‚(k1,k2) = â„Ì‚(k1 | ğ’ª ) ğ’°Ì‚(k2|Î»), where we dropped the Ï‰ subscript for simplicity. The 50:50 beam splitter acts as the unitary operation",
                            "matches": []
                        },
                        {
                            "leaf id": 78,
                            "key": "doc/body/sec7/equation3",
                            "block type": "equation",
                            "content": "a^â€ ger â†’{1âˆš(2)( a^â€ ger + b^â€ ger ) b^â€ ger â†’{1âˆš(2)( a^â€ ger  b^â€ ger ),",
                            "leftover": "a^â€ ger â†’{1âˆš(2)( a^â€ ger + b^â€ ger ) b^â€ ger â†’{1âˆš(2)( a^â€ ger  b^â€ ger ),",
                            "matches": []
                        },
                        {
                            "leaf id": 79,
                            "key": "doc/body/sec7/txl4",
                            "block type": "txl",
                            "content": "yielding",
                            "leftover": "yielding",
                            "matches": []
                        },
                        {
                            "leaf id": 80,
                            "key": "doc/body/sec7/equation5",
                            "block type": "equation",
                            "content": "|Î¨â„ âŸ© âŠ—|Î¨ğ’° âŸ© â†’|Î¦âŸ© = {12 âˆ«^2k1 ^2k2 Î¨Ì‚(k1,k2) [ a^â€ ger(k1) + b^â€ ger(k1) ][ a^â€ ger(k2)  b^â€ ger(k2) ] |0âŸ© .",
                            "leftover": "|Î¨â„ âŸ© âŠ—|Î¨ğ’° âŸ© â†’|Î¦âŸ© = {12 âˆ«^2k1 ^2k2 Î¨Ì‚(k1,k2) [ a^â€ ger(k1) + b^â€ ger(k1) ][ a^â€ ger(k2)  b^â€ ger(k2) ] |0âŸ© .",
                            "matches": []
                        },
                        {
                            "leaf id": 81,
                            "key": "doc/body/sec7/txl6",
                            "block type": "txl",
                            "content": "Detection of mode m âˆˆa,b is described by the projector Î m = âˆ«^2k m^â€ (k)|0âŸ©âŸ¨0|m(k). The rate of coincidences, i.e. the probability that one and only one photon is detected in each mode, reads",
                            "leftover": "Detection of mode m âˆˆa,b is described by the projector Î m = âˆ«^2k m^â€ (k)|0âŸ©âŸ¨0|m(k). The rate of coincidences, i.e. the probability that one and only one photon is detected in each mode, reads",
                            "matches": []
                        },
                        {
                            "leaf id": 82,
                            "key": "doc/body/sec7/gather7",
                            "block type": "gather",
                            "content": "p(1a âˆ©1b) = [|Î¦âŸ©âŸ¨Î¦|Î a âŠ—Î b], with Î a âŠ—Î b = âˆ«^2k3 ^2k4 a^â€ ger(k3) b^â€ ger(k4) |0âŸ©âŸ¨0| a(k3) b(k4) .",
                            "leftover": "p(1a âˆ©1b) = [|Î¦âŸ©âŸ¨Î¦|Î a âŠ—Î b], with Î a âŠ—Î b = âˆ«^2k3 ^2k4 a^â€ ger(k3) b^â€ ger(k4) |0âŸ©âŸ¨0| a(k3) b(k4) .",
                            "matches": []
                        },
                        {
                            "leaf id": 83,
                            "key": "doc/body/sec7/txl8",
                            "block type": "txl",
                            "content": "By substitution of, we get",
                            "leftover": "By substitution of, we get",
                            "matches": []
                        },
                        {
                            "leaf id": 84,
                            "key": "doc/body/sec7/equation9",
                            "block type": "equation",
                            "content": "p(1a âˆ©1b) = {14âˆ«âˆi=1^6 ^2ki Î¨Ì‚(k1,k2) Î¨Ì‚^*(k5,k6) W1(k1,k2,k3,k4)W2(k3,k4,k5,k6),",
                            "leftover": "p(1a âˆ©1b) = {14âˆ«âˆi=1^6 ^2ki Î¨Ì‚(k1,k2) Î¨Ì‚^*(k5,k6) W1(k1,k2,k3,k4)W2(k3,k4,k5,k6),",
                            "matches": []
                        },
                        {
                            "leaf id": 85,
                            "key": "doc/body/sec7/txl10",
                            "block type": "txl",
                            "content": "where",
                            "leftover": "where",
                            "matches": []
                        },
                        {
                            "leaf id": 86,
                            "key": "doc/body/sec7/gather11",
                            "block type": "gather",
                            "content": "W1(k1,k2,k3,k4) = âŸ¨0| a(k3) b(k4)[a^â€ ger(k1)a^â€ ger(k2)  a^â€ ger(k1)b^â€ ger(k2) + b^â€ ger(k1)a^â€ ger(k2)  b^â€ ger(k1)b^â€ ger(k2) ] |0âŸ© = Î´(k2  k3)Î´(k1  k4)  Î´(k1  k3)Î´(k2  k4), W2(k3,k4,k5,k6) = âŸ¨0| [a(k6)a(k5)  b(k6)a(k5) + a(k6)b(k5)  b(k6)b(k5) ] a^â€ ger(k3) b^â€ ger(k4) |0âŸ© = Î´(k3  k6)Î´(k4  k5)  Î´(k3  k5)Î´(k4  k6) .",
                            "leftover": "W1(k1,k2,k3,k4) = âŸ¨0| a(k3) b(k4)[a^â€ ger(k1)a^â€ ger(k2)  a^â€ ger(k1)b^â€ ger(k2) + b^â€ ger(k1)a^â€ ger(k2)  b^â€ ger(k1)b^â€ ger(k2) ] |0âŸ© = Î´(k2  k3)Î´(k1  k4)  Î´(k1  k3)Î´(k2  k4), W2(k3,k4,k5,k6) = âŸ¨0| [a(k6)a(k5)  b(k6)a(k5) + a(k6)b(k5)  b(k6)b(k5) ] a^â€ ger(k3) b^â€ ger(k4) |0âŸ© = Î´(k3  k6)Î´(k4  k5)  Î´(k3  k5)Î´(k4  k6) .",
                            "matches": []
                        },
                        {
                            "leaf id": 87,
                            "key": "doc/body/sec7/txl12",
                            "block type": "txl",
                            "content": "By integrating out the Dirac deltas in, we obtain",
                            "leftover": "By integrating out the Dirac deltas in, we obtain",
                            "matches": []
                        },
                        {
                            "leaf id": 88,
                            "key": "doc/body/sec7/equation13",
                            "block type": "equation",
                            "content": "p(1a âˆ©1b) = {12âˆ«^2k1 ^2k2 ^2k5 ^2k6 Î¨Ì‚(k1,k2) Î¨Ì‚^*(k5,k6) [Î´(k1  k5)Î´(k2k6)  Î´(k1  k6)Î´(k2  k5) ] .",
                            "leftover": "p(1a âˆ©1b) = {12âˆ«^2k1 ^2k2 ^2k5 ^2k6 Î¨Ì‚(k1,k2) Î¨Ì‚^*(k5,k6) [Î´(k1  k5)Î´(k2k6)  Î´(k1  k6)Î´(k2  k5) ] .",
                            "matches": []
                        },
                        {
                            "leaf id": 89,
                            "key": "doc/body/sec7/txl14",
                            "block type": "txl",
                            "content": "Finally, the rate of coincidences reads",
                            "leftover": "Finally, the rate of coincidences reads",
                            "matches": []
                        },
                        {
                            "leaf id": 90,
                            "key": "doc/body/sec7/equation15",
                            "block type": "equation",
                            "content": "p(1a âˆ©1b|Î», ğ’ª ) = {12 âˆ«^2k1 |â„Ì‚(k1 | ğ’ª )|^2 âˆ«^2k2 |ğ’°Ì‚(k2|Î»)|^2  {12 | âˆ«^2k â„Ì‚(k | ğ’ª ) ğ’°Ì‚^*(k|Î») |^2 .",
                            "leftover": "p(1a âˆ©1b|Î», ğ’ª ) = {12 âˆ«^2k1 |â„Ì‚(k1 | ğ’ª )|^2 âˆ«^2k2 |ğ’°Ì‚(k2|Î»)|^2  {12 | âˆ«^2k â„Ì‚(k | ğ’ª ) ğ’°Ì‚^*(k|Î») |^2 .",
                            "matches": []
                        },
                        {
                            "leaf id": 91,
                            "key": "doc/body/sec7/txl16",
                            "block type": "txl",
                            "content": "More compactly,",
                            "leftover": "More compactly,",
                            "matches": []
                        },
                        {
                            "leaf id": 92,
                            "key": "doc/body/sec7/equation17",
                            "block type": "equation",
                            "content": "p(1a âˆ©1b|Î», ğ’ª ) = {12[|| Ï‰(Â·|ğ’ª ) ||^2 || Ï‰(Â·|Î») ||^2  | âŸ¨Ï‰(Â·|ğ’ª ),Ï‰(Â·|Î») âŸ©|^2 ],",
                            "leftover": "p(1a âˆ©1b|Î», ğ’ª ) = {12[|| Ï‰(Â·|ğ’ª ) ||^2 || Ï‰(Â·|Î») ||^2  | âŸ¨Ï‰(Â·|ğ’ª ),Ï‰(Â·|Î») âŸ©|^2 ],",
                            "matches": []
                        },
                        {
                            "leaf id": 93,
                            "key": "doc/body/sec7/txl18",
                            "block type": "txl",
                            "content": "with || Â· || and âŸ¨Â·, Â·âŸ© denoting the L^2norm and inner product, which is precisely the results of .",
                            "leftover": "with || Â· || and âŸ¨Â·, Â·âŸ© denoting the L^2norm and inner product, which is precisely the results of .",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec8",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 94,
                            "key": "doc/body/sec8/tit",
                            "block type": "title",
                            "content": "TRAINING",
                            "leftover": "TRAINING",
                            "matches": []
                        },
                        {
                            "leaf id": 95,
                            "key": "doc/body/sec8/txl0",
                            "block type": "txl",
                            "content": "In this section, we discuss how to train the HongOuMandel interferometer as a binary classifier. We separately feed each element of the training set (an ensemble of objects with known labels) into the input branch of, comparing the predicted classes with the target ones. We optimize the probe parameters Î» by means of the gradient descent algorithm, and using the binary crossentropy as loss function.",
                            "leftover": "In this section, we discuss how to train the HongOuMandel interferometer as a binary classifier. We separately feed each element of the training set (an ensemble of objects with known labels) into the input branch of, comparing the predicted classes with the target ones. We optimize the probe parameters Î» by means of the gradient descent algorithm, and using the binary crossentropy as loss function.",
                            "matches": []
                        },
                        {
                            "leaf id": 96,
                            "key": "doc/body/sec8/txl1",
                            "block type": "txl",
                            "content": "Consider a training set made of M objects Ã˜j, each associated to a binary target label yj âˆˆ0,1, with 0 â‰¤ j â‰¤ M  1. We denote f ^(j)Î» = Î»(Ã˜j) our model prediction. After feeding Ã˜j into the input branch of the interferometer",
                            "leftover": "Consider a training set made of M objects Ã˜j, each associated to a binary target label yj âˆˆ0,1, with 0 â‰¤ j â‰¤ M  1. We denote f ^(j)Î» = Î»(Ã˜j) our model prediction. After feeding Ã˜j into the input branch of the interferometer",
                            "matches": []
                        },
                        {
                            "leaf id": 97,
                            "key": "doc/body/sec8/gather2",
                            "block type": "gather",
                            "content": "f ^(j)Î»= C  2p(1a âˆ©1b|Î», Ã˜j), bÎ»^(j) = Ïƒ(f ^(j)Î»+ b),",
                            "leftover": "f ^(j)Î»= C  2p(1a âˆ©1b|Î», Ã˜j), bÎ»^(j) = Ïƒ(f ^(j)Î»+ b),",
                            "matches": []
                        },
                        {
                            "leaf id": 98,
                            "key": "doc/body/sec8/txl3",
                            "block type": "txl",
                            "content": "where p âˆˆ [0, 1/2]. For simplicity, we assumed that the losses are independent on both the input and the probe, that is C := Î±Î»(Ã˜j) âˆ€Î», j.",
                            "leftover": "where p âˆˆ [0, 1/2]. For simplicity, we assumed that the losses are independent on both the input and the probe, that is C := Î±Î»(Ã˜j) âˆ€Î», j.",
                            "matches": []
                        },
                        {
                            "leaf id": 99,
                            "key": "doc/body/sec8/txl4",
                            "block type": "txl",
                            "content": "Given a sample object, the binary crossentropy between the target label and the predicted one reads",
                            "leftover": "Given a sample object, the binary crossentropy between the target label and the predicted one reads",
                            "matches": []
                        },
                        {
                            "leaf id": 100,
                            "key": "doc/body/sec8/equation5",
                            "block type": "equation",
                            "content": "H(yj,bÎ»^(j)) =  yjlog(bÎ»^(j))  (1yj)log(1bÎ»^(j)) .",
                            "leftover": "H(yj,bÎ»^(j)) =  yjlog(bÎ»^(j))  (1yj)log(1bÎ»^(j)) .",
                            "matches": []
                        },
                        {
                            "leaf id": 101,
                            "key": "doc/body/sec8/txl6",
                            "block type": "txl",
                            "content": "We optimize the probe parameters by means of the gradient descent algorithm, where the binary crossentropy, averaged on the training set, is used as loss function. Namely",
                            "leftover": "We optimize the probe parameters by means of the gradient descent algorithm, where the binary crossentropy, averaged on the training set, is used as loss function. Namely",
                            "matches": []
                        },
                        {
                            "leaf id": 102,
                            "key": "doc/body/sec8/gather7",
                            "block type": "gather",
                            "content": "Î»â†’Î» {Î·Î»M âˆ‘j=0^M1 âˆ‚Î»H(yj,F ^(j)bÎ»), b â†’b  {Î·bM âˆ‘j=0^M1 âˆ‚b H(yj,F ^(j)bÎ»),",
                            "leftover": "Î»â†’Î» {Î·Î»M âˆ‘j=0^M1 âˆ‚Î»H(yj,F ^(j)bÎ»), b â†’b  {Î·bM âˆ‘j=0^M1 âˆ‚b H(yj,F ^(j)bÎ»),",
                            "matches": []
                        },
                        {
                            "leaf id": 103,
                            "key": "doc/body/sec8/txl8",
                            "block type": "txl",
                            "content": "with Î·Î», Î·b the learning rates of the probe and bias parameters, respectively. The derivatives with respect to the parameters and the bias yield",
                            "leftover": "with Î·Î», Î·b the learning rates of the probe and bias parameters, respectively. The derivatives with respect to the parameters and the bias yield",
                            "matches": []
                        },
                        {
                            "leaf id": 104,
                            "key": "doc/body/sec8/gather9",
                            "block type": "gather",
                            "content": "âˆ‚Î»H = (âˆ‚F H )(âˆ‚Î¾ Ïƒ) âˆ‚Î», âˆ‚b H = (âˆ‚F H )âˆ‚Î¾ Ïƒ,",
                            "leftover": "âˆ‚Î»H = (âˆ‚F H )(âˆ‚Î¾ Ïƒ) âˆ‚Î», âˆ‚b H = (âˆ‚F H )âˆ‚Î¾ Ïƒ,",
                            "matches": []
                        },
                        {
                            "leaf id": 105,
                            "key": "doc/body/sec8/txl10",
                            "block type": "txl",
                            "content": "with Î¾bÎ» = Î» + b. Then,",
                            "leftover": "with Î¾bÎ» = Î» + b. Then,",
                            "matches": []
                        },
                        {
                            "leaf id": 106,
                            "key": "doc/body/sec8/gather11",
                            "block type": "gather",
                            "content": "âˆ‚F H = {F yF (1F ), âˆ‚Î¾Ïƒ= Î²(1  F ),",
                            "leftover": "âˆ‚F H = {F yF (1F ), âˆ‚Î¾Ïƒ= Î²(1  F ),",
                            "matches": []
                        },
                        {
                            "leaf id": 107,
                            "key": "doc/body/sec8/txl12",
                            "block type": "txl",
                            "content": "with Î² the hyperparameter of . For any complex function of real variable h: â„â†’â„‚, it follows that âˆ‚Î»|h(Î»)| = [h(Î»)(âˆ‚Î» h(Î»))^*]/|h(Î»)|. Hence,",
                            "leftover": "with Î² the hyperparameter of . For any complex function of real variable h: â„â†’â„‚, it follows that âˆ‚Î»|h(Î»)| = [h(Î»)(âˆ‚Î» h(Î»))^*]/|h(Î»)|. Hence,",
                            "matches": []
                        },
                        {
                            "leaf id": 108,
                            "key": "doc/body/sec8/equation13",
                            "block type": "equation",
                            "content": "âˆ‚Î»= 2 [ âŸ¨Ï‰, Ï‰ âŸ©âŸ¨Ï‰, âˆ‚Î»Ï‰ âŸ©^* ] .",
                            "leftover": "âˆ‚Î»= 2 [ âŸ¨Ï‰, Ï‰ âŸ©âŸ¨Ï‰, âˆ‚Î»Ï‰ âŸ©^* ] .",
                            "matches": []
                        },
                        {
                            "leaf id": 109,
                            "key": "doc/body/sec8/txl14",
                            "block type": "txl",
                            "content": "Neglecting the phase of âŸ¨â„, âŸ©,",
                            "leftover": "Neglecting the phase of âŸ¨â„, âŸ©,",
                            "matches": []
                        },
                        {
                            "leaf id": 110,
                            "key": "doc/body/sec8/equation15",
                            "block type": "equation",
                            "content": "âˆ‚Î»â‰ƒ2 âˆš(f) [ âŸ¨Ï‰, âˆ‚Î»Ï‰ âŸ©] .",
                            "leftover": "âˆ‚Î»â‰ƒ2 âˆš(f) [ âŸ¨Ï‰, âˆ‚Î»Ï‰ âŸ©] .",
                            "matches": []
                        },
                        {
                            "leaf id": 111,
                            "key": "doc/body/sec8/txl16",
                            "block type": "txl",
                            "content": "This assumption, which we verified in our simulations under a selfconsistency test, simplifies the computation of the first factor of, which is directly determined at the output of the HongOuMandel interferometer.",
                            "leftover": "This assumption, which we verified in our simulations under a selfconsistency test, simplifies the computation of the first factor of, which is directly determined at the output of the HongOuMandel interferometer.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec9",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 112,
                            "key": "doc/body/sec9/tit",
                            "block type": "title",
                            "content": "CLASSIFICATION IN THE FOURIER DOMAIN",
                            "leftover": "CLASSIFICATION IN THE FOURIER DOMAIN",
                            "matches": []
                        },
                        {
                            "leaf id": 113,
                            "key": "doc/body/sec9/txl0",
                            "block type": "txl",
                            "content": "In this section, we discuss the effect of adding a single lens in the probe branch of the HongOuMandel interferometer, as shown in . We summarize the main calculations, which closely follow that of .",
                            "leftover": "In this section, we discuss the effect of adding a single lens in the probe branch of the HongOuMandel interferometer, as shown in . We summarize the main calculations, which closely follow that of .",
                            "matches": []
                        },
                        {
                            "leaf id": 114,
                            "key": "doc/body/sec9/txl1",
                            "block type": "txl",
                            "content": "A thin lens is placed at one focal length â„“ from both the probe image plane and the beam splitter. In the nearfield limit, the lens performs a Fourier transform of the probe state, yielding |Î¨ğ’°âŸ©â†’|Î¨ğ’° 'âŸ©, where",
                            "leftover": "A thin lens is placed at one focal length â„“ from both the probe image plane and the beam splitter. In the nearfield limit, the lens performs a Fourier transform of the probe state, yielding |Î¨ğ’°âŸ©â†’|Î¨ğ’° 'âŸ©, where",
                            "matches": []
                        },
                        {
                            "leaf id": 115,
                            "key": "doc/body/sec9/equation2",
                            "block type": "equation",
                            "content": "ğ’° 'Ï‰(r|Î») = i {Ï‰â„“ e^2i Ï‰f ğ’°Ì‚Ï‰({Ï‰â„“r|Î») .",
                            "leftover": "ğ’° 'Ï‰(r|Î») = i {Ï‰â„“ e^2i Ï‰f ğ’°Ì‚Ï‰({Ï‰â„“r|Î») .",
                            "matches": []
                        },
                        {
                            "leaf id": 116,
                            "key": "doc/body/sec9/txl3",
                            "block type": "txl",
                            "content": "After the beam splitter, the rate of coincidences is",
                            "leftover": "After the beam splitter, the rate of coincidences is",
                            "matches": []
                        },
                        {
                            "leaf id": 117,
                            "key": "doc/body/sec9/gather4",
                            "block type": "gather",
                            "content": "p(1a âˆ©1b|Î», ğ’ª ) = {12[Î±Ï‰(ğ’ª )  f Î»(ğ’ª ) ], f Î»(ğ’ª ) = | âŸ¨Ï‰(Â·|ğ’ª ),ğ’°Ì‚Ï‰(Â·|Î») âŸ©|^2,",
                            "leftover": "p(1a âˆ©1b|Î», ğ’ª ) = {12[Î±Ï‰(ğ’ª )  f Î»(ğ’ª ) ], f Î»(ğ’ª ) = | âŸ¨Ï‰(Â·|ğ’ª ),ğ’°Ì‚Ï‰(Â·|Î») âŸ©|^2,",
                            "matches": []
                        },
                        {
                            "leaf id": 118,
                            "key": "doc/body/sec9/txl5",
                            "block type": "txl",
                            "content": "yielding",
                            "leftover": "yielding",
                            "matches": []
                        },
                        {
                            "leaf id": 119,
                            "key": "doc/body/sec9/gather6",
                            "block type": "gather",
                            "content": "F bÎ»(ğ’ª ) = Ïƒ(f Î»(ğ’ª ) + b), f Î»(ğ’ª ) = | âˆ«I r r' Ï‰(r|ğ’ª )Ï‰^*(r'|Î»)e^i rÂ·r' |^2,",
                            "leftover": "F bÎ»(ğ’ª ) = Ïƒ(f Î»(ğ’ª ) + b), f Î»(ğ’ª ) = | âˆ«I r r' Ï‰(r|ğ’ª )Ï‰^*(r'|Î»)e^i rÂ·r' |^2,",
                            "matches": []
                        },
                        {
                            "leaf id": 120,
                            "key": "doc/body/sec9/txl7",
                            "block type": "txl",
                            "content": "with Ïƒ and b the sigmoid activation function and bias, already introduced in . In contrast to, f Î»(ğ’ª ) is not a pointwise evaluation: it combines the image spatial modes with the momentum spectrum of the probe state. Using the duality of the Fourier transform, it follows that",
                            "leftover": "with Ïƒ and b the sigmoid activation function and bias, already introduced in . In contrast to, f Î»(ğ’ª ) is not a pointwise evaluation: it combines the image spatial modes with the momentum spectrum of the probe state. Using the duality of the Fourier transform, it follows that",
                            "matches": []
                        },
                        {
                            "leaf id": 121,
                            "key": "doc/body/sec9/equation8",
                            "block type": "equation",
                            "content": "f Î»(ğ’ª ) = | âŸ¨â„Ì‚Ï‰(Â·|ğ’ª ),Ï‰(Â·|Î») âŸ©|^2,",
                            "leftover": "f Î»(ğ’ª ) = | âŸ¨â„Ì‚Ï‰(Â·|ğ’ª ),Ï‰(Â·|Î») âŸ©|^2,",
                            "matches": []
                        },
                        {
                            "leaf id": 122,
                            "key": "doc/body/sec9/txl9",
                            "block type": "txl",
                            "content": "which corresponds to the output of the same scheme of, but with the thin lens placed in the left branch, before the beam splitter. Equivalently, this takes the Fourier transform of the image, instead of that of the probe. In the next section, we leverage this symmetry to simplify both the training process and the numerical simulations.",
                            "leftover": "which corresponds to the output of the same scheme of, but with the thin lens placed in the left branch, before the beam splitter. Equivalently, this takes the Fourier transform of the image, instead of that of the probe. In the next section, we leverage this symmetry to simplify both the training process and the numerical simulations.",
                            "matches": []
                        },
                        {
                            "leaf id": 123,
                            "key": "doc/body/sec9/txl10",
                            "block type": "txl",
                            "content": "The training of the model follows the same procedure of . By placing the lens on the top branch of the interferometer, while using the duality of the Fourier transform, we get",
                            "leftover": "The training of the model follows the same procedure of . By placing the lens on the top branch of the interferometer, while using the duality of the Fourier transform, we get",
                            "matches": []
                        },
                        {
                            "leaf id": 124,
                            "key": "doc/body/sec9/equation11",
                            "block type": "equation",
                            "content": "âˆ‚Î»f â‰ƒ2 âˆš(f ) [ âŸ¨â„Ì‚Ï‰, âˆ‚Î»Ï‰ âŸ©] .",
                            "leftover": "âˆ‚Î»f â‰ƒ2 âˆš(f ) [ âŸ¨â„Ì‚Ï‰, âˆ‚Î»Ï‰ âŸ©] .",
                            "matches": []
                        },
                        {
                            "leaf id": 125,
                            "key": "doc/body/sec9/txl12",
                            "block type": "txl",
                            "content": "Under the same conditions of, the last two equations become",
                            "leftover": "Under the same conditions of, the last two equations become",
                            "matches": []
                        },
                        {
                            "leaf id": 126,
                            "key": "doc/body/sec9/gather13",
                            "block type": "gather",
                            "content": "f Î»(ğ’ª ) = | âˆ‘Î¼,Î½ (u â‹†â„Ì‚^*Ï‰)(rÎ¼Î½) {Î»Î¼Î½||Î»|| |^2, âˆ‚Î¼Î½ f â‰ƒ2 {âˆš(f )||Î»||[ (u â‹†â„Ì‚^*Ï‰)(rÎ¼Î½)  âˆš(f ) {Î»Î¼Î½||Î»|| ],",
                            "leftover": "f Î»(ğ’ª ) = | âˆ‘Î¼,Î½ (u â‹†â„Ì‚^*Ï‰)(rÎ¼Î½) {Î»Î¼Î½||Î»|| |^2, âˆ‚Î¼Î½ f â‰ƒ2 {âˆš(f )||Î»||[ (u â‹†â„Ì‚^*Ï‰)(rÎ¼Î½)  âˆš(f ) {Î»Î¼Î½||Î»|| ],",
                            "matches": []
                        },
                        {
                            "leaf id": 127,
                            "key": "doc/body/sec9/txl14",
                            "block type": "txl",
                            "content": "where in the last step we neglected the phase of âŸ¨â„Ì‚,âŸ©. Similarly to, can be evaluated in an alloptical way through the characterization of the real part of â„Ì‚, namely, by performing an amplitude and phase measurement at the output of a thin lens, placed in the left branch, before the beam splitter. In, we compare the predictability of the neuron in the spatial and Fourier domains.",
                            "leftover": "where in the last step we neglected the phase of âŸ¨â„Ì‚,âŸ©. Similarly to, can be evaluated in an alloptical way through the characterization of the real part of â„Ì‚, namely, by performing an amplitude and phase measurement at the output of a thin lens, placed in the left branch, before the beam splitter. In, we compare the predictability of the neuron in the spatial and Fourier domains.",
                            "matches": []
                        }
                    ]
                },
                {
                    "key": "doc/body/sec10",
                    "block_type": "sec",
                    "children": [
                        {
                            "leaf id": 128,
                            "key": "doc/body/sec10/tit",
                            "block type": "title",
                            "content": "OPTICAL AND COMPUTATIONAL ADVANTAGE",
                            "leftover": "OPTICAL AND COMPUTATIONAL ADVANTAGE",
                            "matches": []
                        },
                        {
                            "leaf id": 129,
                            "key": "doc/body/sec10/txl0",
                            "block type": "txl",
                            "content": "In this section, we discuss the optical and computational advantage as the number of photons and operations required by a single image classification. Assuming that all the parameters have been previously trained with optimal accuracy, we show that our protocol requires a constant number of resources, i.e. ğ’ª(1) complexity, independently of the input image resolution: it provides a superexponential speedup over its classical counterpart.",
                            "leftover": "In this section, we discuss the optical and computational advantage as the number of photons and operations required by a single image classification. Assuming that all the parameters have been previously trained with optimal accuracy, we show that our protocol requires a constant number of resources, i.e. ğ’ª(1) complexity, independently of the input image resolution: it provides a superexponential speedup over its classical counterpart.",
                            "matches": []
                        },
                        {
                            "leaf id": 130,
                            "key": "doc/body/sec10/txl1",
                            "block type": "txl",
                            "content": "We first discuss the computational advantage when substituting a classical neuron with a quantum optical one. From now on, we denote Î©, Î˜ and ğ’ª, respectively the lower, tight and upper bounds on the number of resources needed by a certain (optical or computational) operation. Consider a digital image x of N pixels, fed into a neuron",
                            "leftover": "We first discuss the computational advantage when substituting a classical neuron with a quantum optical one. From now on, we denote Î©, Î˜ and ğ’ª, respectively the lower, tight and upper bounds on the number of resources needed by a certain (optical or computational) operation. Consider a digital image x of N pixels, fed into a neuron",
                            "matches": []
                        },
                        {
                            "leaf id": 131,
                            "key": "doc/body/sec10/equation2",
                            "block type": "equation",
                            "content": "Gbw(x) = Ïƒ(wÂ·x + b),",
                            "leftover": "Gbw(x) = Ïƒ(wÂ·x + b),",
                            "matches": []
                        },
                        {
                            "leaf id": 132,
                            "key": "doc/body/sec10/txl3",
                            "block type": "txl",
                            "content": "where x, w âˆˆâ„^N, b âˆˆâ„ and Ïƒ is the sigmoid activation of, with hyperparameters Î² = 1 and Î³ = 0. costs N operations to compute w Â· x. The HongOuMandel interferometer performs the same operation in an alloptical way, leaving the computational cost of the activation function and bias only, which is ğ’ª(1).",
                            "leftover": "where x, w âˆˆâ„^N, b âˆˆâ„ and Ïƒ is the sigmoid activation of, with hyperparameters Î² = 1 and Î³ = 0. costs N operations to compute w Â· x. The HongOuMandel interferometer performs the same operation in an alloptical way, leaving the computational cost of the activation function and bias only, which is ğ’ª(1).",
                            "matches": []
                        },
                        {
                            "leaf id": 133,
                            "key": "doc/body/sec10/txl4",
                            "block type": "txl",
                            "content": "We now discuss the optical advantage when using coincidences to classify singlephoton states instead of a classical neuron on fully reconstructed images. After targeting an object with light, a digital image x is an ensemble of grey levels obtained by counting the number of photons collected by different pixels on a sensor grid, e.g. a chargecoupled device . Let np be the average number of photons in the input state, and Î¼i the average number of photons collected by the ith pixel of the grid, with i âˆˆ0,â€¦,N. Assuming perfect quantum efficiency and sufficiently low exposure times to neglect the saturation of the sensor, the grey values at each pixel read",
                            "leftover": "We now discuss the optical advantage when using coincidences to classify singlephoton states instead of a classical neuron on fully reconstructed images. After targeting an object with light, a digital image x is an ensemble of grey levels obtained by counting the number of photons collected by different pixels on a sensor grid, e.g. a chargecoupled device . Let np be the average number of photons in the input state, and Î¼i the average number of photons collected by the ith pixel of the grid, with i âˆˆ0,â€¦,N. Assuming perfect quantum efficiency and sufficiently low exposure times to neglect the saturation of the sensor, the grey values at each pixel read",
                            "matches": []
                        },
                        {
                            "leaf id": 134,
                            "key": "doc/body/sec10/equation5",
                            "block type": "equation",
                            "content": "xi = {Î¼iLÎ¼w,",
                            "leftover": "xi = {Î¼iLÎ¼w,",
                            "matches": []
                        },
                        {
                            "leaf id": 135,
                            "key": "doc/body/sec10/txl6",
                            "block type": "txl",
                            "content": "with L the number of grey levels, i.e. the depth of the image, and Î¼w = maxiÎ¼i the maximum number of photons collected in a single pixel. Indeed, xi âˆˆ0, 1, â€¦, L1 with 0 and L labelling the black and white colors, respectively. Each pixel has variance Ï‚i^2 = Î”Î¼i^2 L^2/Î¼w^2, with Î”Î¼i^2 the variance on the number of collected photons. For coherent light, the photodetection process undergoes the standard quantum limit (SQL), with Poissonian fluctuations that satisfy Î”Î¼i^2 â‰ƒÎ¼i. The average uncertainty reads",
                            "leftover": "with L the number of grey levels, i.e. the depth of the image, and Î¼w = maxiÎ¼i the maximum number of photons collected in a single pixel. Indeed, xi âˆˆ0, 1, â€¦, L1 with 0 and L labelling the black and white colors, respectively. Each pixel has variance Ï‚i^2 = Î”Î¼i^2 L^2/Î¼w^2, with Î”Î¼i^2 the variance on the number of collected photons. For coherent light, the photodetection process undergoes the standard quantum limit (SQL), with Poissonian fluctuations that satisfy Î”Î¼i^2 â‰ƒÎ¼i. The average uncertainty reads",
                            "matches": []
                        },
                        {
                            "leaf id": 136,
                            "key": "doc/body/sec10/equation7",
                            "block type": "equation",
                            "content": "Ï‚^2 := {1Nâˆ‘i=0^N Ï‚i^2 SQLâ‰ƒ âŸ¨x âŸ©^2 N np^1,",
                            "leftover": "Ï‚^2 := {1Nâˆ‘i=0^N Ï‚i^2 SQLâ‰ƒ âŸ¨x âŸ©^2 N np^1,",
                            "matches": []
                        },
                        {
                            "leaf id": 137,
                            "key": "doc/body/sec10/txl8",
                            "block type": "txl",
                            "content": "with âŸ¨ x âŸ© = N^1âˆ‘i xi âˆˆ [0,L] the average brightness of the image, which we assume to be independent of its resolution. Hence, the number of photons np required by a full image reconstruction with average variance Ï‚^2 is Î˜(Ï‚^2âŸ¨ x âŸ© N). This is the cost of image reconstruction only. We now take into account the information propagation through the neuron of .",
                            "leftover": "with âŸ¨ x âŸ© = N^1âˆ‘i xi âˆˆ [0,L] the average brightness of the image, which we assume to be independent of its resolution. Hence, the number of photons np required by a full image reconstruction with average variance Ï‚^2 is Î˜(Ï‚^2âŸ¨ x âŸ© N). This is the cost of image reconstruction only. We now take into account the information propagation through the neuron of .",
                            "matches": []
                        },
                        {
                            "key": "doc/body/sec10/proposition9",
                            "block_type": "proposition",
                            "children": [
                                {
                                    "leaf id": 138,
                                    "key": "doc/body/sec10/proposition9/txl0",
                                    "block type": "txl",
                                    "content": "Consider a neuron with sigmoid activation function. Suppose that there exists a sequence of parameters (wN, bN) âˆˆâ„^N+1N â‰« 1 that optimally solve the Npixel image classification task, with bN and the â„“^1norm ||wN||1 asymptotically bounded for N â†’âˆ. Then, the number of photons np required to classify an image x with uncertainty Îµ, is Î©(Îµ^2âŸ¨ x âŸ© N).",
                                    "leftover": "Consider a neuron with sigmoid activation function. Suppose that there exists a sequence of parameters (wN, bN) âˆˆâ„^N+1N â‰« 1 that optimally solve the Npixel image classification task, with bN and the â„“^1norm ||wN||1 asymptotically bounded for N â†’âˆ. Then, the number of photons np required to classify an image x with uncertainty Îµ, is Î©(Îµ^2âŸ¨ x âŸ© N).",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "key": "doc/body/sec10/proof10",
                            "block_type": "proof",
                            "children": [
                                {
                                    "leaf id": 139,
                                    "key": "doc/body/sec10/proof10/txl0",
                                    "block type": "txl",
                                    "content": "Consider the output of the neuron Gbw(x) = Ïƒ(wNÂ· x + bN), and its derivative âˆ‚ G(x) = Gbw(x)(1Gbw(x)). By neglecting the spatial neighbourhood correlations, which may introduce at most a constant overhead in our estimation, we propagate the uncertainty of x as",
                                    "leftover": "Consider the output of the neuron Gbw(x) = Ïƒ(wNÂ· x + bN), and its derivative âˆ‚ G(x) = Gbw(x)(1Gbw(x)). By neglecting the spatial neighbourhood correlations, which may introduce at most a constant overhead in our estimation, we propagate the uncertainty of x as",
                                    "matches": []
                                },
                                {
                                    "leaf id": 140,
                                    "key": "doc/body/sec10/proof10/equation1",
                                    "block type": "equation",
                                    "content": "Îµ^2 = âŸ¨x âŸ©(âˆ‚G)^2(x) âˆ‘i=0^N1(wN)i^2 xi NÃ±^1p,",
                                    "leftover": "Îµ^2 = âŸ¨x âŸ©(âˆ‚G)^2(x) âˆ‘i=0^N1(wN)i^2 xi NÃ±^1p,",
                                    "matches": []
                                },
                                {
                                    "leaf id": 141,
                                    "key": "doc/body/sec10/proof10/txl2",
                                    "block type": "txl",
                                    "content": "where Ã±p = nr np, with nr is the number of independent image acquisition and classification. Since black pixels do not contribute to this summation, we get",
                                    "leftover": "where Ã±p = nr np, with nr is the number of independent image acquisition and classification. Since black pixels do not contribute to this summation, we get",
                                    "matches": []
                                },
                                {
                                    "leaf id": 142,
                                    "key": "doc/body/sec10/proof10/equation3",
                                    "block type": "equation",
                                    "content": "âˆ‘i=0^N1(wN)i^2 xi â‰¥âˆ‘iâˆ‰â„¬(wN)i^2 = ||wN||^2  âˆ‘iâˆˆâ„¬(wN)i^2,",
                                    "leftover": "âˆ‘i=0^N1(wN)i^2 xi â‰¥âˆ‘iâˆ‰â„¬(wN)i^2 = ||wN||^2  âˆ‘iâˆˆâ„¬(wN)i^2,",
                                    "matches": []
                                },
                                {
                                    "leaf id": 143,
                                    "key": "doc/body/sec10/proof10/txl4",
                                    "block type": "txl",
                                    "content": "with â„¬ = iâˆˆâ„• | xi = 0 for 0 â‰¤ i â‰¤ N  1 the set of black pixels labels. However, ||wN||^2 â‰«âˆ‘iâˆˆâ„¬(wN)i^2. Otherwise, ||wN||^2 â‰ƒâˆ‘iâˆˆâ„¬(wN)i^2 would imply either that the image is mostly black, independently of its resolution, or that (wN)i â‰ƒ 0 for all nonblack pixels, which are both conditions that prevent the learnability of the neuron. By substitution into we get",
                                    "leftover": "with â„¬ = iâˆˆâ„• | xi = 0 for 0 â‰¤ i â‰¤ N  1 the set of black pixels labels. However, ||wN||^2 â‰«âˆ‘iâˆˆâ„¬(wN)i^2. Otherwise, ||wN||^2 â‰ƒâˆ‘iâˆˆâ„¬(wN)i^2 would imply either that the image is mostly black, independently of its resolution, or that (wN)i â‰ƒ 0 for all nonblack pixels, which are both conditions that prevent the learnability of the neuron. By substitution into we get",
                                    "matches": []
                                },
                                {
                                    "leaf id": 144,
                                    "key": "doc/body/sec10/proof10/equation5",
                                    "block type": "equation",
                                    "content": "Ã±p â‰¥Îµ^2 âŸ¨x âŸ©(âˆ‚G)^2(x) ||wN||^2 N .",
                                    "leftover": "Ã±p â‰¥Îµ^2 âŸ¨x âŸ©(âˆ‚G)^2(x) ||wN||^2 N .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 145,
                                    "key": "doc/body/sec10/proof10/txl6",
                                    "block type": "txl",
                                    "content": "Since wN is a sequence of nontrivial solutions of the classification problem, the â„“^2norm ||wN||^2 cannot go to zero for N â†’âˆ. Finally, we show that (âˆ‚ G(x))^2 does not converge to 0 for N â†’âˆ. Consider",
                                    "leftover": "Since wN is a sequence of nontrivial solutions of the classification problem, the â„“^2norm ||wN||^2 cannot go to zero for N â†’âˆ. Finally, we show that (âˆ‚ G(x))^2 does not converge to 0 for N â†’âˆ. Consider",
                                    "matches": []
                                },
                                {
                                    "leaf id": 146,
                                    "key": "doc/body/sec10/proof10/equation7",
                                    "block type": "equation",
                                    "content": "(âˆ‚G)^2(x) = {e^2(wNÂ·x + bN)[1+e^(wNÂ·x + bN)]^4 .",
                                    "leftover": "(âˆ‚G)^2(x) = {e^2(wNÂ·x + bN)[1+e^(wNÂ·x + bN)]^4 .",
                                    "matches": []
                                },
                                {
                                    "leaf id": 147,
                                    "key": "doc/body/sec10/proof10/txl8",
                                    "block type": "txl",
                                    "content": "If bN is asymptotically limited, (âˆ‚ G)^2 converges to zero if and only if wNÂ· x â†’Â±âˆ. By splitting this scalar product into positive and negative contributions wNÂ· x = âˆ‘(wN)i > 0(wN)i xi  âˆ‘(wN)i < 0|(wN)i| xi, it follows that",
                                    "leftover": "If bN is asymptotically limited, (âˆ‚ G)^2 converges to zero if and only if wNÂ· x â†’Â±âˆ. By splitting this scalar product into positive and negative contributions wNÂ· x = âˆ‘(wN)i > 0(wN)i xi  âˆ‘(wN)i < 0|(wN)i| xi, it follows that",
                                    "matches": []
                                },
                                {
                                    "leaf id": 148,
                                    "key": "doc/body/sec10/proof10/align9",
                                    "block type": "align",
                                    "content": "wNÂ·x â‰¤âˆ‘(wN)i > 0(wN)i xi â‰¤L||wN||1, wNÂ·x â‰¥ âˆ‘(wN)i < 0|(wN)i| xi â‰¥ L||wN||1,",
                                    "leftover": "wNÂ·x â‰¤âˆ‘(wN)i > 0(wN)i xi â‰¤L||wN||1, wNÂ·x â‰¥ âˆ‘(wN)i < 0|(wN)i| xi â‰¥ L||wN||1,",
                                    "matches": []
                                },
                                {
                                    "leaf id": 149,
                                    "key": "doc/body/sec10/proof10/txl10",
                                    "block type": "txl",
                                    "content": "namely that |wNÂ· x| â‰¤ L ||wN||1. Since the â„“^1norm is limited, (âˆ‚ G)^2 admits strictly positive lower bound for N â†’âˆ. Finally, this imply that Ã±p = Î©(Îµ^2âŸ¨ x âŸ© N).",
                                    "leftover": "namely that |wNÂ· x| â‰¤ L ||wN||1. Since the â„“^1norm is limited, (âˆ‚ G)^2 admits strictly positive lower bound for N â†’âˆ. Finally, this imply that Ã±p = Î©(Îµ^2âŸ¨ x âŸ© N).",
                                    "matches": []
                                }
                            ]
                        },
                        {
                            "leaf id": 150,
                            "key": "doc/body/sec10/txl11",
                            "block type": "txl",
                            "content": "In the previous discussion, two conditions lead to the above lower bound. On the one hand, that ||wN||^2 â†›0 for N â†’âˆ, which is essential to guarantee that the neuron is trainable at any resolution. On the other hand, that ||wN||1 is bounded for N â†’âˆ, which is compatible with LASSO and Tikhonov's regularization techniques .",
                            "leftover": "In the previous discussion, two conditions lead to the above lower bound. On the one hand, that ||wN||^2 â†›0 for N â†’âˆ, which is essential to guarantee that the neuron is trainable at any resolution. On the other hand, that ||wN||1 is bounded for N â†’âˆ, which is compatible with LASSO and Tikhonov's regularization techniques .",
                            "matches": []
                        },
                        {
                            "leaf id": 151,
                            "key": "doc/body/sec10/txl12",
                            "block type": "txl",
                            "content": "We show that our protocol exponentially reduces this cost, requiring only the estimation of the rate of coincidences of the HongOuMandel interferometer of . Let Ã±p = 2np be the number input photons, and pÌƒâˆˆ [0,1/2] the empirical rate of coincidences. Under the normal approximation, with the 95 confidence level, the estimation uncertainty reads",
                            "leftover": "We show that our protocol exponentially reduces this cost, requiring only the estimation of the rate of coincidences of the HongOuMandel interferometer of . Let Ã±p = 2np be the number input photons, and pÌƒâˆˆ [0,1/2] the empirical rate of coincidences. Under the normal approximation, with the 95 confidence level, the estimation uncertainty reads",
                            "matches": []
                        },
                        {
                            "leaf id": 152,
                            "key": "doc/body/sec10/equation13",
                            "block type": "equation",
                            "content": "Îµ= 2 âˆš({pÌƒ(1pÌƒ))Ã±p .",
                            "leftover": "Îµ= 2 âˆš({pÌƒ(1pÌƒ))Ã±p .",
                            "matches": []
                        },
                        {
                            "leaf id": 153,
                            "key": "doc/body/sec10/txl14",
                            "block type": "txl",
                            "content": "Since 4 pÌƒ(1pÌƒ) â‰¤ 1, the total number of photons is ğ’ª (Îµ^2), which is constant with respect to the resolution of the image.",
                            "leftover": "Since 4 pÌƒ(1pÌƒ) â‰¤ 1, the total number of photons is ğ’ª (Îµ^2), which is constant with respect to the resolution of the image.",
                            "matches": []
                        },
                        {
                            "leaf id": 154,
                            "key": "doc/body/sec10/txl15",
                            "block type": "txl",
                            "content": "In conclusion, the quantum optical neuron provides a superexponential advantage over its classical counterpart, both in the number of operations and photons saved to classify a single image. We summarize these results in . \\bibliography{refs.bib}",
                            "leftover": "In conclusion, the quantum optical neuron provides a superexponential advantage over its classical counterpart, both in the number of operations and photons saved to classify a single image. We summarize these results in . \\bibliography{refs.bib}",
                            "matches": []
                        }
                    ]
                }
            ]
        },
        {
            "leaf id": 155,
            "key": "doc/bib0",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Lecun}, \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Bottou}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Bengio},\\ and\\ \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Haffner},\\ }\\bibfield title {\\bibinfo title {Gradientbased learning applied to document recognition},\\ }\\bibfield journal {\\bibinfo journal {Proc. IEEE}\\ }\\textbf {\\bibinfo volume {86}},\\ \\bibinfo pages {2278} (\\bibinfo year {1998})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Lecun}, \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Bottou}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Bengio},\\ and\\ \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Haffner},\\ }\\bibfield title {\\bibinfo title {Gradientbased learning applied to document recognition},\\ }\\bibfield journal {\\bibinfo journal {Proc. IEEE}\\ }\\textbf {\\bibinfo volume {86}},\\ \\bibinfo pages {2278} (\\bibinfo year {1998})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 156,
            "key": "doc/bib1",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Krizhevsky}, \\bibinfo author {\\bibfnamefont {I.}~\\bibnamefont Sutskever},\\ and\\ \\bibinfo author {\\bibfnamefont {G.~E.}\\ \\bibnamefont Hinton},\\ }\\bibfield title {\\bibinfo title {ImageNet classification with deep convolutional neural networks},\\ }\\bibfield journal {\\bibinfo journal {Commun. ACM}\\ }\\textbf {\\bibinfo volume {60}},\\ \\bibinfo pages {84â€“90} (\\bibinfo year {2017})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Krizhevsky}, \\bibinfo author {\\bibfnamefont {I.}~\\bibnamefont Sutskever},\\ and\\ \\bibinfo author {\\bibfnamefont {G.~E.}\\ \\bibnamefont Hinton},\\ }\\bibfield title {\\bibinfo title {ImageNet classification with deep convolutional neural networks},\\ }\\bibfield journal {\\bibinfo journal {Commun. ACM}\\ }\\textbf {\\bibinfo volume {60}},\\ \\bibinfo pages {84â€“90} (\\bibinfo year {2017})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 157,
            "key": "doc/bib2",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont He}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Zhang}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Ren},\\ and\\ \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Sun},\\ }\\bibfield title {\\bibinfo title {Deep residual learning for image recognition},\\ }in\\ \\emph {\\bibinfo booktitle {IEEE Conference on Computer Vision and Pattern Recognition}},\\ \\bibinfo {series and number} {CVPR '16},\\ p.\\ \\bibinfo pages {770}\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont He}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Zhang}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Ren},\\ and\\ \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Sun},\\ }\\bibfield title {\\bibinfo title {Deep residual learning for image recognition},\\ }in\\ \\emph {\\bibinfo booktitle {IEEE Conference on Computer Vision and Pattern Recognition}},\\ \\bibinfo {series and number} {CVPR '16},\\ p.\\ \\bibinfo pages {770}\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 158,
            "key": "doc/bib3",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Dosovitskiy}, \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Beyer}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Kolesnikov}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Weissenborn}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Zhai}, \\bibinfo author {\\bibfnamefont {T.}~\\bibnamefont Unterthiner}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Dehghani}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Minderer}, \\bibinfo author {\\bibfnamefont {G.}~\\bibnamefont Heigold}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Gelly}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Uszkoreit},\\ and\\ \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Houlsby},\\ }\\bibfield title {\\bibinfo title {An image is worth 16x16 words: Transformers for image recognition at scale},\\ }in\\ \\emph {\\bibinfo booktitle {International Conference on Learning Representations}},\\ \\bibinfo {series and number} {ICLR '21},\\ \\Eprint {https://arxiv.org/abs/2010.11929} {arXiv:2010.11929 [cs.CV]} \\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Dosovitskiy}, \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Beyer}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Kolesnikov}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Weissenborn}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Zhai}, \\bibinfo author {\\bibfnamefont {T.}~\\bibnamefont Unterthiner}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Dehghani}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Minderer}, \\bibinfo author {\\bibfnamefont {G.}~\\bibnamefont Heigold}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Gelly}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Uszkoreit},\\ and\\ \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Houlsby},\\ }\\bibfield title {\\bibinfo title {An image is worth 16x16 words: Transformers for image recognition at scale},\\ }in\\ \\emph {\\bibinfo booktitle {International Conference on Learning Representations}},\\ \\bibinfo {series and number} {ICLR '21},\\ \\Eprint {https://arxiv.org/abs/2010.11929} {arXiv:2010.11929 [cs.CV]} \\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 159,
            "key": "doc/bib4",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {B.~J.}\\ \\bibnamefont Shastri}, \\bibinfo author {\\bibfnamefont {A.~N.}\\ \\bibnamefont Tait}, \\bibinfo author {\\bibfnamefont {T.}~\\bibnamefont {Ferreira~de Lima}}, \\bibinfo author {\\bibfnamefont {W.~H.~P.}\\ \\bibnamefont Pernice}, \\bibinfo author {\\bibfnamefont {H.}~\\bibnamefont Bhaskaran}, \\bibinfo author {\\bibfnamefont {C.~D.}\\ \\bibnamefont Wright},\\ and\\ \\bibinfo author {\\bibfnamefont {P.~R.}\\ \\bibnamefont Prucnal},\\ }\\bibfield title {\\bibinfo title {Photonics for artificial intelligence and neuromorphic computing},\\ }\\bibfield journal {\\bibinfo journal {Nat. Photon.}\\ }\\textbf {\\bibinfo volume {15}},\\ \\bibinfo pages {102â€“114} (\\bibinfo year {2021})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {B.~J.}\\ \\bibnamefont Shastri}, \\bibinfo author {\\bibfnamefont {A.~N.}\\ \\bibnamefont Tait}, \\bibinfo author {\\bibfnamefont {T.}~\\bibnamefont {Ferreira~de Lima}}, \\bibinfo author {\\bibfnamefont {W.~H.~P.}\\ \\bibnamefont Pernice}, \\bibinfo author {\\bibfnamefont {H.}~\\bibnamefont Bhaskaran}, \\bibinfo author {\\bibfnamefont {C.~D.}\\ \\bibnamefont Wright},\\ and\\ \\bibinfo author {\\bibfnamefont {P.~R.}\\ \\bibnamefont Prucnal},\\ }\\bibfield title {\\bibinfo title {Photonics for artificial intelligence and neuromorphic computing},\\ }\\bibfield journal {\\bibinfo journal {Nat. Photon.}\\ }\\textbf {\\bibinfo volume {15}},\\ \\bibinfo pages {102â€“114} (\\bibinfo year {2021})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 160,
            "key": "doc/bib5",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Lin}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Rivenson}, \\bibinfo author {\\bibfnamefont {N.~T.}\\ \\bibnamefont Yardimci}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Veli}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Luo}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Jarrahi},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Ozcan},\\ }\\bibfield title {\\bibinfo title {Alloptical machine learning using diftive deep neural networks},\\ }\\bibfield journal {\\bibinfo journal Science\\ }\\textbf {\\bibinfo volume {361}},\\ \\bibinfo pages {1004â€“1008} (\\bibinfo year {2018})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Lin}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Rivenson}, \\bibinfo author {\\bibfnamefont {N.~T.}\\ \\bibnamefont Yardimci}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Veli}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Luo}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Jarrahi},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Ozcan},\\ }\\bibfield title {\\bibinfo title {Alloptical machine learning using diftive deep neural networks},\\ }\\bibfield journal {\\bibinfo journal Science\\ }\\textbf {\\bibinfo volume {361}},\\ \\bibinfo pages {1004â€“1008} (\\bibinfo year {2018})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 161,
            "key": "doc/bib6",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Zuo}, \\bibinfo author {\\bibfnamefont {B.}~\\bibnamefont Li}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Zhao}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Jiang}, \\bibinfo author {\\bibfnamefont {Y.C.}\\ \\bibnamefont Chen}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Chen}, \\bibinfo author {\\bibfnamefont {G.B.}\\ \\bibnamefont Jo}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Liu},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Du},\\ }\\bibfield title {\\bibinfo title {Alloptical neural network with nonlinear activation functions},\\ }\\bibfield journal {\\bibinfo journal Optica\\ }\\textbf {\\bibinfo volume {6}},\\ \\bibinfo pages {1132} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Zuo}, \\bibinfo author {\\bibfnamefont {B.}~\\bibnamefont Li}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Zhao}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Jiang}, \\bibinfo author {\\bibfnamefont {Y.C.}\\ \\bibnamefont Chen}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Chen}, \\bibinfo author {\\bibfnamefont {G.B.}\\ \\bibnamefont Jo}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Liu},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Du},\\ }\\bibfield title {\\bibinfo title {Alloptical neural network with nonlinear activation functions},\\ }\\bibfield journal {\\bibinfo journal Optica\\ }\\textbf {\\bibinfo volume {6}},\\ \\bibinfo pages {1132} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 162,
            "key": "doc/bib7",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Colburn}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Chu}, \\bibinfo author {\\bibfnamefont {E.}~\\bibnamefont Shilzerman},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Majumdar},\\ }\\bibfield title {\\bibinfo title {Optical frontend for a convolutional neural network},\\ }\\bibfield journal {\\bibinfo journal {Appl. Opt.}\\ }\\textbf {\\bibinfo volume {58}},\\ \\bibinfo pages {3179} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Colburn}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Chu}, \\bibinfo author {\\bibfnamefont {E.}~\\bibnamefont Shilzerman},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Majumdar},\\ }\\bibfield title {\\bibinfo title {Optical frontend for a convolutional neural network},\\ }\\bibfield journal {\\bibinfo journal {Appl. Opt.}\\ }\\textbf {\\bibinfo volume {58}},\\ \\bibinfo pages {3179} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 163,
            "key": "doc/bib8",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Li}, \\bibinfo author {\\bibfnamefont {B.}~\\bibnamefont Ni}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Feng}, \\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont Cui}, \\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Liu}, \\bibinfo author {\\bibfnamefont {W.}~\\bibnamefont Zhang},\\ and\\ \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Huang},\\ }\\bibfield title {\\bibinfo title {Alloptical image identification with programmable matrix transformation},\\ }\\bibfield journal {\\bibinfo journal {Opt. Express}\\ }\\textbf {\\bibinfo volume {29}},\\ \\bibinfo pages {26474} (\\bibinfo year {2021})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Li}, \\bibinfo author {\\bibfnamefont {B.}~\\bibnamefont Ni}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Feng}, \\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont Cui}, \\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Liu}, \\bibinfo author {\\bibfnamefont {W.}~\\bibnamefont Zhang},\\ and\\ \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Huang},\\ }\\bibfield title {\\bibinfo title {Alloptical image identification with programmable matrix transformation},\\ }\\bibfield journal {\\bibinfo journal {Opt. Express}\\ }\\textbf {\\bibinfo volume {29}},\\ \\bibinfo pages {26474} (\\bibinfo year {2021})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 164,
            "key": "doc/bib9",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Luo}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Zhao}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Li}, \\bibinfo author {\\bibfnamefont {E.}~\\bibnamefont {Ã‡etintaÅŸ}}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Rivenson}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Jarrahi},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Ozcan},\\ }\\bibfield title {\\bibinfo title {Computational imaging without a computer: seeing through random diffusers at the speed of light},\\ }\\bibfield journal {\\bibinfo journal eLight\\ }\\textbf {\\bibinfo volume {2}},\\ \\bibinfo pages {4} (\\bibinfo year {2022})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Luo}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Zhao}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Li}, \\bibinfo author {\\bibfnamefont {E.}~\\bibnamefont {Ã‡etintaÅŸ}}, \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Rivenson}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Jarrahi},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Ozcan},\\ }\\bibfield title {\\bibinfo title {Computational imaging without a computer: seeing through random diffusers at the speed of light},\\ }\\bibfield journal {\\bibinfo journal eLight\\ }\\textbf {\\bibinfo volume {2}},\\ \\bibinfo pages {4} (\\bibinfo year {2022})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 165,
            "key": "doc/bib10",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {P.~L.}\\ \\bibnamefont McMahon},\\ }\\bibfield title {\\bibinfo title {The physics of optical computing},\\ }\\bibfield journal {\\bibinfo journal {Nat. Rev. Phys.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {717â€“734} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {P.~L.}\\ \\bibnamefont McMahon},\\ }\\bibfield title {\\bibinfo title {The physics of optical computing},\\ }\\bibfield journal {\\bibinfo journal {Nat. Rev. Phys.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {717â€“734} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 166,
            "key": "doc/bib11",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Benatti}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Mancini},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Mangini},\\ }\\bibfield title {\\bibinfo title {Continuous variable quantum perceptron},\\ }\\bibfield journal {\\bibinfo journal {Int. J. Quantum Inf.}\\ }\\textbf {\\bibinfo volume {17}},\\ \\bibinfo pages {1941009} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Benatti}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Mancini},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Mangini},\\ }\\bibfield title {\\bibinfo title {Continuous variable quantum perceptron},\\ }\\bibfield journal {\\bibinfo journal {Int. J. Quantum Inf.}\\ }\\textbf {\\bibinfo volume {17}},\\ \\bibinfo pages {1941009} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 167,
            "key": "doc/bib12",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Tacchino}, \\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Macchiavello}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Gerace},\\ and\\ \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Bajoni},\\ }\\bibfield title {\\bibinfo title {An artificial neuron implemented on an actual quantum processor},\\ }\\bibfield journal {\\bibinfo journal {Npj Quantum Inf.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {26} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Tacchino}, \\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Macchiavello}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Gerace},\\ and\\ \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Bajoni},\\ }\\bibfield title {\\bibinfo title {An artificial neuron implemented on an actual quantum processor},\\ }\\bibfield journal {\\bibinfo journal {Npj Quantum Inf.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {26} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 168,
            "key": "doc/bib13",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Cerezo}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Arrasmith}, \\bibinfo author {\\bibfnamefont {R.}~\\bibnamefont Babbush}, \\bibinfo author {\\bibfnamefont {S.~C.}\\ \\bibnamefont Benjamin}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Endo}, \\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont Fujii}, \\bibinfo author {\\bibfnamefont {J.~R.}\\ \\bibnamefont McClean}, \\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont Mitarai}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Yuan}, \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Cincio},\\ and\\ \\bibinfo author {\\bibfnamefont {P.~J.}\\ \\bibnamefont Coles},\\ }\\bibfield title {\\bibinfo title {Variational quantum algorithms},\\ }\\bibfield journal {\\bibinfo journal {Nat. Rev. Phys.}\\ }\\textbf {\\bibinfo volume {3}},\\ \\bibinfo pages {625â€“644} (\\bibinfo year {2021})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Cerezo}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Arrasmith}, \\bibinfo author {\\bibfnamefont {R.}~\\bibnamefont Babbush}, \\bibinfo author {\\bibfnamefont {S.~C.}\\ \\bibnamefont Benjamin}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Endo}, \\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont Fujii}, \\bibinfo author {\\bibfnamefont {J.~R.}\\ \\bibnamefont McClean}, \\bibinfo author {\\bibfnamefont {K.}~\\bibnamefont Mitarai}, \\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Yuan}, \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Cincio},\\ and\\ \\bibinfo author {\\bibfnamefont {P.~J.}\\ \\bibnamefont Coles},\\ }\\bibfield title {\\bibinfo title {Variational quantum algorithms},\\ }\\bibfield journal {\\bibinfo journal {Nat. Rev. Phys.}\\ }\\textbf {\\bibinfo volume {3}},\\ \\bibinfo pages {625â€“644} (\\bibinfo year {2021})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 169,
            "key": "doc/bib14",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Senokosov}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Sedykh}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Sagingalieva}, \\bibinfo author {\\bibfnamefont {B.}~\\bibnamefont Kyriacou},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Melnikov},\\ }\\bibfield title {\\bibinfo title {Quantum machine learning for image classification},\\ }\\bibfield journal {\\bibinfo journal {Mach. Learn.: Sci. Technol.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {015040} (\\bibinfo year {2024})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Senokosov}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Sedykh}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Sagingalieva}, \\bibinfo author {\\bibfnamefont {B.}~\\bibnamefont Kyriacou},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Melnikov},\\ }\\bibfield title {\\bibinfo title {Quantum machine learning for image classification},\\ }\\bibfield journal {\\bibinfo journal {Mach. Learn.: Sci. Technol.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {015040} (\\bibinfo year {2024})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 170,
            "key": "doc/bib15",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Cerezo}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Larocca}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont {GarcÃ­aMartÃ­n}}, \\bibinfo author {\\bibfnamefont {N.~L.}\\ \\bibnamefont Diaz}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Braccia}, \\bibinfo author {\\bibfnamefont {E.}~\\bibnamefont Fontana}, \\bibinfo author {\\bibfnamefont {M.~S.}\\ \\bibnamefont Rudolph}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Bermejo}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Ijaz}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Thanasilp}, \\bibinfo author {\\bibfnamefont {E.~R.}\\ \\bibnamefont Anschuetz},\\ and\\ \\bibinfo author {\\bibfnamefont {Z.}~\\bibnamefont Holmes},\\ }\\bibinfo title {Does provable absence of barren plateaus imply classical simulability? Or, why we need to rethink variational quantum computing} (\\bibinfo year {2024}),\\ \\Eprint {https://arxiv.org/abs/2312.09121} {arXiv:2312.09121 [quantph]} \\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Cerezo}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Larocca}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont {GarcÃ­aMartÃ­n}}, \\bibinfo author {\\bibfnamefont {N.~L.}\\ \\bibnamefont Diaz}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Braccia}, \\bibinfo author {\\bibfnamefont {E.}~\\bibnamefont Fontana}, \\bibinfo author {\\bibfnamefont {M.~S.}\\ \\bibnamefont Rudolph}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Bermejo}, \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Ijaz}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Thanasilp}, \\bibinfo author {\\bibfnamefont {E.~R.}\\ \\bibnamefont Anschuetz},\\ and\\ \\bibinfo author {\\bibfnamefont {Z.}~\\bibnamefont Holmes},\\ }\\bibinfo title {Does provable absence of barren plateaus imply classical simulability? Or, why we need to rethink variational quantum computing} (\\bibinfo year {2024}),\\ \\Eprint {https://arxiv.org/abs/2312.09121} {arXiv:2312.09121 [quantph]} \\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 171,
            "key": "doc/bib16",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {G.~R.}\\ \\bibnamefont Steinbrecher}, \\bibinfo author {\\bibfnamefont {J.~P.}\\ \\bibnamefont Olson}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Englund},\\ and\\ \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Carolan},\\ }\\bibfield title {\\bibinfo title {Quantum optical neural networks},\\ }\\bibfield journal {\\bibinfo journal {Npj Quantum Inf.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {60} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {G.~R.}\\ \\bibnamefont Steinbrecher}, \\bibinfo author {\\bibfnamefont {J.~P.}\\ \\bibnamefont Olson}, \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Englund},\\ and\\ \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Carolan},\\ }\\bibfield title {\\bibinfo title {Quantum optical neural networks},\\ }\\bibfield journal {\\bibinfo journal {Npj Quantum Inf.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {60} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 172,
            "key": "doc/bib17",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Killoran}, \\bibinfo author {\\bibfnamefont {T.~R.}\\ \\bibnamefont Bromley}, \\bibinfo author {\\bibfnamefont {J.~M.}\\ \\bibnamefont Arrazola}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Schuld}, \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Quesada},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Lloyd},\\ }\\bibfield title {\\bibinfo title {Continuousvariable quantum neural networks},\\ }\\bibfield journal {\\bibinfo journal {Phys. Rev. Res.}\\ }\\textbf {\\bibinfo volume {1}},\\ \\bibinfo pages {033063} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Killoran}, \\bibinfo author {\\bibfnamefont {T.~R.}\\ \\bibnamefont Bromley}, \\bibinfo author {\\bibfnamefont {J.~M.}\\ \\bibnamefont Arrazola}, \\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Schuld}, \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Quesada},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Lloyd},\\ }\\bibfield title {\\bibinfo title {Continuousvariable quantum neural networks},\\ }\\bibfield journal {\\bibinfo journal {Phys. Rev. Res.}\\ }\\textbf {\\bibinfo volume {1}},\\ \\bibinfo pages {033063} (\\bibinfo year {2019})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 173,
            "key": "doc/bib18",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Sui}, \\bibinfo author {\\bibfnamefont {Q.}~\\bibnamefont Wu}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Liu}, \\bibinfo author {\\bibfnamefont {Q.}~\\bibnamefont Chen},\\ and\\ \\bibinfo author {\\bibfnamefont {G.}~\\bibnamefont Gu},\\ }\\bibfield title {\\bibinfo title {A review of optical neural networks},\\ }\\bibfield journal {\\bibinfo journal {IEEE Access}\\ }\\textbf {\\bibinfo volume {8}},\\ \\bibinfo pages {70773} (\\bibinfo year {2020})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Sui}, \\bibinfo author {\\bibfnamefont {Q.}~\\bibnamefont Wu}, \\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Liu}, \\bibinfo author {\\bibfnamefont {Q.}~\\bibnamefont Chen},\\ and\\ \\bibinfo author {\\bibfnamefont {G.}~\\bibnamefont Gu},\\ }\\bibfield title {\\bibinfo title {A review of optical neural networks},\\ }\\bibfield journal {\\bibinfo journal {IEEE Access}\\ }\\textbf {\\bibinfo volume {8}},\\ \\bibinfo pages {70773} (\\bibinfo year {2020})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 174,
            "key": "doc/bib19",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Stanev}, \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Spagnolo},\\ and\\ \\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Sciarrino},\\ }\\bibfield title {\\bibinfo title {Deterministic optimal quantum cloning via a quantumoptical neural network},\\ }\\bibfield journal {\\bibinfo journal {Phys. Rev. Res.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {013139} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Stanev}, \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Spagnolo},\\ and\\ \\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Sciarrino},\\ }\\bibfield title {\\bibinfo title {Deterministic optimal quantum cloning via a quantumoptical neural network},\\ }\\bibfield journal {\\bibinfo journal {Phys. Rev. Res.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {013139} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 175,
            "key": "doc/bib20",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Wood}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Shrapnel},\\ and\\ \\bibinfo author {\\bibfnamefont {G.~J.}\\ \\bibnamefont Milburn},\\ }\\bibinfo title {A Kerr kernel quantum learning machine} (\\bibinfo year {2024}),\\ \\Eprint {https://arxiv.org/abs/2404.01787} {arXiv:2404.01787 [quantph]} \\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Wood}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Shrapnel},\\ and\\ \\bibinfo author {\\bibfnamefont {G.~J.}\\ \\bibnamefont Milburn},\\ }\\bibinfo title {A Kerr kernel quantum learning machine} (\\bibinfo year {2024}),\\ \\Eprint {https://arxiv.org/abs/2404.01787} {arXiv:2404.01787 [quantph]} \\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 176,
            "key": "doc/bib21",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {C.~K.}\\ \\bibnamefont Hong}, \\bibinfo author {\\bibfnamefont {Z.~Y.}\\ \\bibnamefont Ou},\\ and\\ \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Mandel},\\ }\\bibfield title {\\bibinfo title {Measurement of subpicosecond time intervals between two photons by interference},\\ }\\bibfield journal {\\bibinfo journal {Phys. Rev. Lett.}\\ }\\textbf {\\bibinfo volume {59}},\\ \\bibinfo pages {2044} (\\bibinfo year {1987})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {C.~K.}\\ \\bibnamefont Hong}, \\bibinfo author {\\bibfnamefont {Z.~Y.}\\ \\bibnamefont Ou},\\ and\\ \\bibinfo author {\\bibfnamefont {L.}~\\bibnamefont Mandel},\\ }\\bibfield title {\\bibinfo title {Measurement of subpicosecond time intervals between two photons by interference},\\ }\\bibfield journal {\\bibinfo journal {Phys. Rev. Lett.}\\ }\\textbf {\\bibinfo volume {59}},\\ \\bibinfo pages {2044} (\\bibinfo year {1987})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 177,
            "key": "doc/bib22",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Bowie}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Shrapnel},\\ and\\ \\bibinfo author {\\bibfnamefont {M.~J.}\\ \\bibnamefont Kewming},\\ }\\bibfield title {\\bibinfo title {Quantum kernel evaluation via Hongâ€“Ouâ€“Mandel interference},\\ }\\bibfield journal {\\bibinfo journal {Quantum Sci. Technol.}\\ }\\textbf {\\bibinfo volume {9}},\\ \\bibinfo pages {015001} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Bowie}, \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Shrapnel},\\ and\\ \\bibinfo author {\\bibfnamefont {M.~J.}\\ \\bibnamefont Kewming},\\ }\\bibfield title {\\bibinfo title {Quantum kernel evaluation via Hongâ€“Ouâ€“Mandel interference},\\ }\\bibfield journal {\\bibinfo journal {Quantum Sci. Technol.}\\ }\\textbf {\\bibinfo volume {9}},\\ \\bibinfo pages {015001} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 178,
            "key": "doc/bib23",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Glorot}\\ and\\ \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Bengio},\\ }\\bibfield title {\\bibinfo title {Understanding the difficulty of training deep feedforward neural networks},\\ }in\\ \\emph {\\bibinfo booktitle {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics}},\\ \\bibinfo series PMLR, Vol.~\\bibinfo volume {9}\\ (\\bibinfo year {2010})\\ pp.\\ \\bibinfo pages {249256}\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {X.}~\\bibnamefont Glorot}\\ and\\ \\bibinfo author {\\bibfnamefont {Y.}~\\bibnamefont Bengio},\\ }\\bibfield title {\\bibinfo title {Understanding the difficulty of training deep feedforward neural networks},\\ }in\\ \\emph {\\bibinfo booktitle {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics}},\\ \\bibinfo series PMLR, Vol.~\\bibinfo volume {9}\\ (\\bibinfo year {2010})\\ pp.\\ \\bibinfo pages {249256}\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 179,
            "key": "doc/bib24",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Neff}, \\bibinfo author {\\bibfnamefont {R.}~\\bibnamefont Athale},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Lee},\\ }\\bibfield title {\\bibinfo title {Twodimensional spatial light modulators: a tutorial},\\ }\\bibfield journal {\\bibinfo journal {Proc. IEEE}\\ }\\textbf {\\bibinfo volume {78}},\\ \\bibinfo pages {826} (\\bibinfo year {1990})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {J.}~\\bibnamefont Neff}, \\bibinfo author {\\bibfnamefont {R.}~\\bibnamefont Athale},\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Lee},\\ }\\bibfield title {\\bibinfo title {Twodimensional spatial light modulators: a tutorial},\\ }\\bibfield journal {\\bibinfo journal {Proc. IEEE}\\ }\\textbf {\\bibinfo volume {78}},\\ \\bibinfo pages {826} (\\bibinfo year {1990})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 180,
            "key": "doc/bib25",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Z.}~\\bibnamefont Zhang}, \\bibinfo author {\\bibfnamefont {Z.}~\\bibnamefont You},\\ and\\ \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Chu},\\ }\\bibfield title {\\bibinfo title {Fundamentals of phaseonly liquid crystal on silicon (LCOS) devices},\\ }\\bibfield journal {\\bibinfo journal {Light Sci. Appl.}\\ }\\textbf {\\bibinfo volume {3}},\\ \\bibinfo pages {e213} (\\bibinfo year {2014})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {Z.}~\\bibnamefont Zhang}, \\bibinfo author {\\bibfnamefont {Z.}~\\bibnamefont You},\\ and\\ \\bibinfo author {\\bibfnamefont {D.}~\\bibnamefont Chu},\\ }\\bibfield title {\\bibinfo title {Fundamentals of phaseonly liquid crystal on silicon (LCOS) devices},\\ }\\bibfield journal {\\bibinfo journal {Light Sci. Appl.}\\ }\\textbf {\\bibinfo volume {3}},\\ \\bibinfo pages {e213} (\\bibinfo year {2014})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 181,
            "key": "doc/bib26",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibnamefont {{TensorFlow Developers}}},\\ }\\bibinfo title {TensorFlow} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibnamefont {{TensorFlow Developers}}},\\ }\\bibinfo title {TensorFlow} (\\bibinfo year {2023})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 182,
            "key": "doc/bib27",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {R.}~\\bibnamefont Collobert}\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Bengio},\\ }\\bibfield title {\\bibinfo title {Links between perceptrons, MLPs and SVMs},\\ }in\\ \\emph {\\bibinfo booktitle {Proceedings of the TwentyFirst International Conference on Machine Learning}},\\ \\bibinfo {series and number} {ICML '04},\\ p.~\\bibinfo pages {23}\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {R.}~\\bibnamefont Collobert}\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Bengio},\\ }\\bibfield title {\\bibinfo title {Links between perceptrons, MLPs and SVMs},\\ }in\\ \\emph {\\bibinfo booktitle {Proceedings of the TwentyFirst International Conference on Machine Learning}},\\ \\bibinfo {series and number} {ICML '04},\\ p.~\\bibinfo pages {23}\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 183,
            "key": "doc/bib28",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Rosenblatt},\\ }\\bibfield title {\\bibinfo title {The perceptron: A probabilistic model for information storage and organization in the brain},\\ }\\bibfield journal {\\bibinfo journal {Psychol. Rev.}\\ }\\textbf {\\bibinfo volume {65}},\\ \\bibinfo pages {386} (\\bibinfo year {1958})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Rosenblatt},\\ }\\bibfield title {\\bibinfo title {The perceptron: A probabilistic model for information storage and organization in the brain},\\ }\\bibfield journal {\\bibinfo journal {Psychol. Rev.}\\ }\\textbf {\\bibinfo volume {65}},\\ \\bibinfo pages {386} (\\bibinfo year {1958})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 184,
            "key": "doc/bib29",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.~R.}\\ \\bibnamefont Morgillo}\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Roncallo},\\ }\\bibinfo note {https://github.com/simoneroncallo/quantumopticalneuron}\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.~R.}\\ \\bibnamefont Morgillo}\\ and\\ \\bibinfo author {\\bibfnamefont {S.}~\\bibnamefont Roncallo},\\ }\\bibinfo note {https://github.com/simoneroncallo/quantumopticalneuron}\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 185,
            "key": "doc/bib30",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Rezai}\\ and\\ \\bibinfo author {\\bibfnamefont {J.~A.}\\ \\bibnamefont Salehi},\\ }\\bibfield title {\\bibinfo title {Fundamentals of quantum Fourier optics},\\ }\\bibfield journal {\\bibinfo journal {IEEE Trans. Quantum Eng.}\\ }\\textbf {\\bibinfo volume {4}},\\ \\bibinfo pages {1} (\\bibinfo year {2022})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.}~\\bibnamefont Rezai}\\ and\\ \\bibinfo author {\\bibfnamefont {J.~A.}\\ \\bibnamefont Salehi},\\ }\\bibfield title {\\bibinfo title {Fundamentals of quantum Fourier optics},\\ }\\bibfield journal {\\bibinfo journal {IEEE Trans. Quantum Eng.}\\ }\\textbf {\\bibinfo volume {4}},\\ \\bibinfo pages {1} (\\bibinfo year {2022})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 186,
            "key": "doc/bib31",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {B.~E.~A.}\\ \\bibnamefont Saleh}\\ and\\ \\bibinfo author {\\bibfnamefont {M.~C.}\\ \\bibnamefont Teich},\\ }\\emph {\\bibinfo title {Fundamentals of Photonics}}\\ (\\bibinfo publisher Wiley,\\ \\bibinfo year {1991})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {B.~E.~A.}\\ \\bibnamefont Saleh}\\ and\\ \\bibinfo author {\\bibfnamefont {M.~C.}\\ \\bibnamefont Teich},\\ }\\emph {\\bibinfo title {Fundamentals of Photonics}}\\ (\\bibinfo publisher Wiley,\\ \\bibinfo year {1991})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 187,
            "key": "doc/bib32",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.~M.}\\ \\bibnamefont {BraÅ„czyk}},\\ }\\bibinfo title {HongOuMandel interference} (\\bibinfo year {2017}),\\ \\Eprint {https://arxiv.org/abs/1711.00080} {arXiv:1711.00080 [quantph]} \\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.~M.}\\ \\bibnamefont {BraÅ„czyk}},\\ }\\bibinfo title {HongOuMandel interference} (\\bibinfo year {2017}),\\ \\Eprint {https://arxiv.org/abs/1711.00080} {arXiv:1711.00080 [quantph]} \\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 188,
            "key": "doc/bib33",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {W.~S.}\\ \\bibnamefont Boyle}\\ and\\ \\bibinfo author {\\bibfnamefont {G.~E.}\\ \\bibnamefont Smith},\\ }\\bibfield title {\\bibinfo title {Charge coupled semiconductor devices},\\ }\\bibfield journal {\\bibinfo journal {Bell Syst. Tech. J.}\\ }\\textbf {\\bibinfo volume {49}},\\ \\bibinfo pages {587} (\\bibinfo year {1970})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {W.~S.}\\ \\bibnamefont Boyle}\\ and\\ \\bibinfo author {\\bibfnamefont {G.~E.}\\ \\bibnamefont Smith},\\ }\\bibfield title {\\bibinfo title {Charge coupled semiconductor devices},\\ }\\bibfield journal {\\bibinfo journal {Bell Syst. Tech. J.}\\ }\\textbf {\\bibinfo volume {49}},\\ \\bibinfo pages {587} (\\bibinfo year {1970})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 189,
            "key": "doc/bib34",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.~I.}\\ \\bibnamefont Kolobov},\\ }\\bibfield title {\\bibinfo title {The spatial behavior of nonclassical light},\\ }\\bibfield journal {\\bibinfo journal {Rev. Mod. Phys.}\\ }\\textbf {\\bibinfo volume {71}},\\ \\bibinfo pages {1539} (\\bibinfo year {1999})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {M.~I.}\\ \\bibnamefont Kolobov},\\ }\\bibfield title {\\bibinfo title {The spatial behavior of nonclassical light},\\ }\\bibfield journal {\\bibinfo journal {Rev. Mod. Phys.}\\ }\\textbf {\\bibinfo volume {71}},\\ \\bibinfo pages {1539} (\\bibinfo year {1999})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 190,
            "key": "doc/bib35",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {V.}~\\bibnamefont Delaubert}, \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Treps}, \\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Fabre}, \\bibinfo author {\\bibfnamefont {H.~A.}\\ \\bibnamefont Bachor},\\ and\\ \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont {RÃ©frÃ©gier}},\\ }\\bibfield title {\\bibinfo title {Quantum limits in image processing},\\ }\\bibfield journal {\\bibinfo journal EPL\\ }\\textbf {\\bibinfo volume {81}},\\ \\bibinfo pages {44001} (\\bibinfo year {2008})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {V.}~\\bibnamefont Delaubert}, \\bibinfo author {\\bibfnamefont {N.}~\\bibnamefont Treps}, \\bibinfo author {\\bibfnamefont {C.}~\\bibnamefont Fabre}, \\bibinfo author {\\bibfnamefont {H.~A.}\\ \\bibnamefont Bachor},\\ and\\ \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont {RÃ©frÃ©gier}},\\ }\\bibfield title {\\bibinfo title {Quantum limits in image processing},\\ }\\bibfield journal {\\bibinfo journal EPL\\ }\\textbf {\\bibinfo volume {81}},\\ \\bibinfo pages {44001} (\\bibinfo year {2008})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 191,
            "key": "doc/bib36",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Santosa}\\ and\\ \\bibinfo author {\\bibfnamefont {W.~W.}\\ \\bibnamefont Symes},\\ }\\bibfield title {\\bibinfo title {Linear inversion of bandlimited reflection seismograms},\\ }\\bibfield journal {\\bibinfo journal {SIAM J. Sci. Stat. Comput.}\\ }\\textbf {\\bibinfo volume {7}},\\ \\bibinfo pages {1307â€“1330} (\\bibinfo year {1986})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {F.}~\\bibnamefont Santosa}\\ and\\ \\bibinfo author {\\bibfnamefont {W.~W.}\\ \\bibnamefont Symes},\\ }\\bibfield title {\\bibinfo title {Linear inversion of bandlimited reflection seismograms},\\ }\\bibfield journal {\\bibinfo journal {SIAM J. Sci. Stat. Comput.}\\ }\\textbf {\\bibinfo volume {7}},\\ \\bibinfo pages {1307â€“1330} (\\bibinfo year {1986})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 192,
            "key": "doc/bib37",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Tikhonov}\\ and\\ \\bibinfo author {\\bibfnamefont {V.}~\\bibnamefont Glasko},\\ }\\bibfield title {\\bibinfo title {Use of the regularization method in nonlinear problems},\\ }\\bibfield journal {\\bibinfo journal {USSR Comput. Math. Math. Phys.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {93} (\\bibinfo year {1965})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Tikhonov}\\ and\\ \\bibinfo author {\\bibfnamefont {V.}~\\bibnamefont Glasko},\\ }\\bibfield title {\\bibinfo title {Use of the regularization method in nonlinear problems},\\ }\\bibfield journal {\\bibinfo journal {USSR Comput. Math. Math. Phys.}\\ }\\textbf {\\bibinfo volume {5}},\\ \\bibinfo pages {93} (\\bibinfo year {1965})\\BibitemShut NoStop%",
            "matches": []
        },
        {
            "leaf id": 193,
            "key": "doc/bib38",
            "block type": "bibliography",
            "content": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Rotondi}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Pedroni},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Pievatolo},\\ }\\emph {\\bibinfo title {Probability, Statistics and Simulation: With Application Programs Written in R}}\\ (\\bibinfo publisher Springer,\\ \\bibinfo year {2022})\\BibitemShut NoStop%",
            "leftover": "% \\BibitemOpen \\bibfield author {\\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Rotondi}, \\bibinfo author {\\bibfnamefont {P.}~\\bibnamefont Pedroni},\\ and\\ \\bibinfo author {\\bibfnamefont {A.}~\\bibnamefont Pievatolo},\\ }\\emph {\\bibinfo title {Probability, Statistics and Simulation: With Application Programs Written in R}}\\ (\\bibinfo publisher Springer,\\ \\bibinfo year {2022})\\BibitemShut NoStop%",
            "matches": []
        }
    ]
}